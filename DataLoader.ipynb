{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a338313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne, mne_bids, HelperFunctions\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from mne_bids import (BIDSPath, read_raw_bids)\n",
    "from autoreject import AutoReject\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    # data\n",
    "    \"data_path\": \"F:/Masterthesis/Data/\",\n",
    "    \"task\": \"N170\",\n",
    "    \"preprocessing\": \"light\",\n",
    "    \"n_subjects\": 40,\n",
    "    \"reject_incorrect_responses\": True,\n",
    "    \"input_window_samples\": 256,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ed1d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw(parameters, subject_id):\n",
    "    \"\"\"\n",
    "    Loads a single subject from the ERP Core data, applies filtering and ICA, and returns a mne.Raw object.\n",
    "    \"\"\"\n",
    "    with HelperFunctions.suppress_stdout():\n",
    "        bids_root = parameters[\"data_path\"]+\"/\"+parameters[\"task\"]\n",
    "        bids_path = BIDSPath(subject=subject_id, task=parameters[\"task\"],\n",
    "                             session=parameters[\"task\"], datatype='eeg', \n",
    "                             suffix='eeg', root=bids_root)\n",
    "        raw = read_raw_bids(bids_path)\n",
    "        raw.load_data()\n",
    "        HelperFunctions.read_annotations_core(bids_path,raw)\n",
    "        raw.set_channel_types({'HEOG_left': 'eog', 'HEOG_right': 'eog', 'VEOG_lower': 'eog'})\n",
    "        raw.set_montage('standard_1020',match_case=False)\n",
    "        if parameters[\"preprocessing\"] == \"medium\":\n",
    "            raw.filter(0.5,40)\n",
    "        if parameters[\"preprocessing\"] == \"heavy\":\n",
    "            raw.filter(0.5,40)\n",
    "            ica, badComps = HelperFunctions.load_precomputed_ica(bids_root, subject_id,parameters[\"task\"])\n",
    "            HelperFunctions.add_ica_info(raw,ica)\n",
    "            ica.apply(raw)\n",
    "        raw = raw.resample(128)\n",
    "    return raw\n",
    "\n",
    "def epoch_raw(parameters, raw):\n",
    "    \"\"\"\n",
    "    Takes a mne.Raw object, loads the correct events, and returns a mne.Epoch object.\n",
    "    \"\"\"\n",
    "    with HelperFunctions.suppress_stdout():\n",
    "        # get correct tmin, tmax, and event mapping per task\n",
    "        custom_mapping, tmin, tmax = get_task_specifics(parameters)\n",
    "        \n",
    "        # shift annotations by lcd monitor delay\n",
    "        if parameters[\"task\"] != \"MNE\":\n",
    "            raw.annotations.onset = raw.annotations.onset+.026\n",
    "        \n",
    "        # load events\n",
    "        (events_from_annot, event_dict) = mne.events_from_annotations(raw, event_id=custom_mapping)\n",
    "        \n",
    "        if parameters[\"reject_incorrect_responses\"] == True and parameters[\"task\"] in [\"N170\", \"N400\", \"N2pc\", \"P3\"]:\n",
    "        # only include events where response is in time and correct\n",
    "            events_0, lag_0 = mne.event.define_target_events(events_from_annot, 0, 201, raw.info['sfreq'], 0, 0.8, 0, 999)\n",
    "            events_1, lag_1 = mne.event.define_target_events(events_from_annot, 1, 201, raw.info['sfreq'], 0, 0.8, 1, 999)\n",
    "            events_from_annot = np.concatenate((events_0, events_1), axis=0)\n",
    "            # sort event array by timepoints to get rid of warning\n",
    "            events_from_annot = events_from_annot[events_from_annot[:, 0].argsort()]\n",
    "            # drop responses\n",
    "            event_dict.pop('response:201')\n",
    "            event_dict.pop('response:202')           \n",
    "\n",
    "        # epoch with no constant detrend to remove dc offset\n",
    "        epoch = mne.Epochs(raw, events_from_annot, event_dict,\n",
    "                           tmin=tmin,tmax=tmax, preload=True,\n",
    "                           reject_by_annotation=True, baseline=None, \n",
    "                           picks=range(0,30), detrend=0)\n",
    "        \n",
    "        # apply autoreject for heavy preprocessing to remove artefacts\n",
    "        if parameters[\"preprocessing\"] == \"heavy\":\n",
    "            ar = AutoReject()\n",
    "            epoch = ar.fit_transform(epoch) \n",
    "    return epoch\n",
    "\n",
    "def get_task_specifics(parameters):\n",
    "    \"\"\"\n",
    "    Returns mapping, tmin, tmax, specific to the task.\n",
    "    \"\"\"\n",
    "    tmin = -0.199\n",
    "    tmax = 0.80\n",
    "    if parameters[\"task\"] == \"N170\":\n",
    "        # Cars: 0, Faces: 1\n",
    "        custom_mapping = dict((\"stimulus:\"+str(i), 1) for i in range(0,41))\n",
    "        custom_mapping.update(dict((\"stimulus:\"+str(i), 0) for i in range(41,81)))\n",
    "    elif parameters[\"task\"] == \"N400\":\n",
    "        # unrelated word: 0, Related word: 1\n",
    "        custom_mapping = {'stimulus:221': 0, 'stimulus:222': 0, \n",
    "                          'stimulus:211': 1, 'stimulus:212': 1} \n",
    "    elif parameters[\"task\"] == \"P3\":\n",
    "        # target=stimulus (rare): 0, target!=stimulus (frequent): 1\n",
    "        custom_mapping = {'stimulus:11': 0, 'stimulus:12': 1, 'stimulus:13': 1, 'stimulus:14': 1, 'stimulus:15': 1, \n",
    "                          'stimulus:21': 1, 'stimulus:22': 0, 'stimulus:23': 1, 'stimulus:24': 1, 'stimulus:25': 1,\n",
    "                          'stimulus:31': 1, 'stimulus:32': 1, 'stimulus:33': 0, 'stimulus:34': 1, 'stimulus:35': 1,\n",
    "                          'stimulus:41': 1, 'stimulus:42': 1, 'stimulus:43': 1, 'stimulus:44': 0, 'stimulus:45': 1,\n",
    "                          'stimulus:51': 1, 'stimulus:52': 1, 'stimulus:53': 1, 'stimulus:54': 1, 'stimulus:55': 0}\n",
    "    # add button responses to tasks that have them\n",
    "    if parameters[\"reject_incorrect_responses\"] == True and parameters[\"task\"] in [\"N170\", \"N400\", \"N2pc\", \"P3\"]:\n",
    "            custom_mapping.update({'response:201': 201, 'response:202': 202})\n",
    "    return custom_mapping, tmin, tmax\n",
    "\n",
    "def create_df(parameters):\n",
    "    df_list = []\n",
    "    for i in range(parameters[\"n_subjects\"]):\n",
    "        subjectID = f\"{i+1:03d}\"\n",
    "        raw = load_raw(parameters, subjectID)\n",
    "        epoch = epoch_raw(parameters, raw)\n",
    "        df = epoch.to_data_frame()\n",
    "        df[\"subjectID\"] = i\n",
    "        df_list.append(df)\n",
    "    df = pd.concat(df_list, axis=0)\n",
    "    \n",
    "    # change condition naming to binary labels\n",
    "    custom_mapping = get_task_specifics(parameters)[0]\n",
    "    for condition in custom_mapping:\n",
    "        df[\"condition\"] = df[\"condition\"].replace(condition,custom_mapping[condition])\n",
    "    \n",
    "    # reshape data\n",
    "    data = df.iloc[:,3:33]\n",
    "    data = data.to_numpy().reshape(int(data.shape[0]/parameters[\"input_window_samples\"]), parameters[\"input_window_samples\"], -1)\n",
    "    data = np.transpose(data,axes=[0,2,1])\n",
    "    # create labels\n",
    "    df = df[[\"epoch\",\"condition\",\"subjectID\"]].drop_duplicates()\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    df[\"data\"]=pd.Series(list(data))\n",
    "    df = df.drop(columns=[\"index\"])\n",
    "    return df\n",
    "\n",
    "def load_df(parameters):\n",
    "    df = pd.read_pickle(parameters[\"data_path\"]+\"/Dataframes/\"+parameters[\"task\"]+\"_ds_\"+parameters[\"preprocessing\"]+\".pkl\")\n",
    "    return df\n",
    "\n",
    "def create_data_labels(df, list_of_subjects=None):\n",
    "    \"\"\"\n",
    "    Takes dataframe and returns numpy versions of the data and labels. \n",
    "    \"\"\"\n",
    "    # get data from dataframe and reshape back\n",
    "    if list_of_subjects != None:\n",
    "        df = df[df[\"subjectID\"].isin(list_of_subjects)]\n",
    "    data = np.dstack(df[\"data\"].to_numpy())\n",
    "    data = np.moveaxis(data, -1, 0)\n",
    "    # get labels from dataframe\n",
    "    labels = df[\"condition\"].to_numpy()\n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e96154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-001_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-001_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-001\\**\\sub-001_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-001_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    }
   ],
   "source": [
    "raw = load_raw(parameters, \"001\")\n",
    "e = epoch_raw(parameters,raw)\n",
    "df = e.to_data_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c95280dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>condition</th>\n",
       "      <th>epoch</th>\n",
       "      <th>FP1</th>\n",
       "      <th>F3</th>\n",
       "      <th>F7</th>\n",
       "      <th>FC3</th>\n",
       "      <th>C3</th>\n",
       "      <th>C5</th>\n",
       "      <th>P3</th>\n",
       "      <th>...</th>\n",
       "      <th>FCz</th>\n",
       "      <th>Cz</th>\n",
       "      <th>C4</th>\n",
       "      <th>C6</th>\n",
       "      <th>P4</th>\n",
       "      <th>P8</th>\n",
       "      <th>P10</th>\n",
       "      <th>PO8</th>\n",
       "      <th>PO4</th>\n",
       "      <th>O2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-195</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>45.596199</td>\n",
       "      <td>47.292836</td>\n",
       "      <td>46.466654</td>\n",
       "      <td>41.128503</td>\n",
       "      <td>31.878718</td>\n",
       "      <td>25.379012</td>\n",
       "      <td>10.135864</td>\n",
       "      <td>...</td>\n",
       "      <td>37.192617</td>\n",
       "      <td>28.406003</td>\n",
       "      <td>24.983277</td>\n",
       "      <td>43.754374</td>\n",
       "      <td>9.741328</td>\n",
       "      <td>31.474213</td>\n",
       "      <td>42.337803</td>\n",
       "      <td>20.595739</td>\n",
       "      <td>5.454449</td>\n",
       "      <td>8.279213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-188</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>24.404889</td>\n",
       "      <td>28.461491</td>\n",
       "      <td>23.985574</td>\n",
       "      <td>25.265925</td>\n",
       "      <td>21.625795</td>\n",
       "      <td>13.511440</td>\n",
       "      <td>3.931843</td>\n",
       "      <td>...</td>\n",
       "      <td>23.355127</td>\n",
       "      <td>20.536652</td>\n",
       "      <td>22.640195</td>\n",
       "      <td>13.827365</td>\n",
       "      <td>9.125549</td>\n",
       "      <td>4.375870</td>\n",
       "      <td>14.574665</td>\n",
       "      <td>-5.512242</td>\n",
       "      <td>-1.311431</td>\n",
       "      <td>-6.946693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-180</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>2.668258</td>\n",
       "      <td>6.948098</td>\n",
       "      <td>6.277180</td>\n",
       "      <td>6.864293</td>\n",
       "      <td>7.035689</td>\n",
       "      <td>-1.989608</td>\n",
       "      <td>-1.028976</td>\n",
       "      <td>...</td>\n",
       "      <td>4.150612</td>\n",
       "      <td>5.194571</td>\n",
       "      <td>3.556398</td>\n",
       "      <td>13.325658</td>\n",
       "      <td>-8.219313</td>\n",
       "      <td>-18.021922</td>\n",
       "      <td>-6.412509</td>\n",
       "      <td>-30.261847</td>\n",
       "      <td>-15.051173</td>\n",
       "      <td>-17.214696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-172</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>-16.992458</td>\n",
       "      <td>-10.886024</td>\n",
       "      <td>-12.660524</td>\n",
       "      <td>-8.406941</td>\n",
       "      <td>-2.385155</td>\n",
       "      <td>-11.059883</td>\n",
       "      <td>-4.802285</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.417976</td>\n",
       "      <td>-6.557006</td>\n",
       "      <td>-11.523773</td>\n",
       "      <td>-9.745009</td>\n",
       "      <td>-17.446089</td>\n",
       "      <td>-34.803403</td>\n",
       "      <td>-21.841026</td>\n",
       "      <td>-44.401731</td>\n",
       "      <td>-27.124281</td>\n",
       "      <td>-30.413412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-164</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>-14.193366</td>\n",
       "      <td>-8.145872</td>\n",
       "      <td>-9.260839</td>\n",
       "      <td>-5.862750</td>\n",
       "      <td>-3.247439</td>\n",
       "      <td>-12.290643</td>\n",
       "      <td>-3.299425</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.584371</td>\n",
       "      <td>-7.975423</td>\n",
       "      <td>-10.767908</td>\n",
       "      <td>-4.907827</td>\n",
       "      <td>-9.590886</td>\n",
       "      <td>-27.136627</td>\n",
       "      <td>-16.254731</td>\n",
       "      <td>-28.376640</td>\n",
       "      <td>-14.134598</td>\n",
       "      <td>-15.679527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>766</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>8.635242</td>\n",
       "      <td>1.808964</td>\n",
       "      <td>13.996889</td>\n",
       "      <td>4.836501</td>\n",
       "      <td>2.124371</td>\n",
       "      <td>10.119360</td>\n",
       "      <td>6.139558</td>\n",
       "      <td>...</td>\n",
       "      <td>1.540429</td>\n",
       "      <td>0.460351</td>\n",
       "      <td>0.664874</td>\n",
       "      <td>0.746436</td>\n",
       "      <td>1.445564</td>\n",
       "      <td>2.187732</td>\n",
       "      <td>1.504510</td>\n",
       "      <td>-2.792277</td>\n",
       "      <td>-2.240896</td>\n",
       "      <td>-0.407900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>773</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>11.412126</td>\n",
       "      <td>2.824708</td>\n",
       "      <td>8.947058</td>\n",
       "      <td>3.818979</td>\n",
       "      <td>2.764923</td>\n",
       "      <td>10.180047</td>\n",
       "      <td>7.664329</td>\n",
       "      <td>...</td>\n",
       "      <td>2.512359</td>\n",
       "      <td>1.077859</td>\n",
       "      <td>-0.966865</td>\n",
       "      <td>-1.201587</td>\n",
       "      <td>1.387821</td>\n",
       "      <td>7.544793</td>\n",
       "      <td>7.358878</td>\n",
       "      <td>1.448891</td>\n",
       "      <td>-2.550330</td>\n",
       "      <td>0.591870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>781</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>22.382695</td>\n",
       "      <td>13.978760</td>\n",
       "      <td>22.814464</td>\n",
       "      <td>12.340680</td>\n",
       "      <td>7.434694</td>\n",
       "      <td>15.197139</td>\n",
       "      <td>7.333579</td>\n",
       "      <td>...</td>\n",
       "      <td>10.708669</td>\n",
       "      <td>7.163315</td>\n",
       "      <td>11.690747</td>\n",
       "      <td>21.156703</td>\n",
       "      <td>6.265479</td>\n",
       "      <td>15.546739</td>\n",
       "      <td>15.902253</td>\n",
       "      <td>5.051569</td>\n",
       "      <td>-0.814472</td>\n",
       "      <td>-0.218900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>789</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>20.038114</td>\n",
       "      <td>9.931568</td>\n",
       "      <td>16.959954</td>\n",
       "      <td>10.259957</td>\n",
       "      <td>6.698042</td>\n",
       "      <td>10.914976</td>\n",
       "      <td>6.760029</td>\n",
       "      <td>...</td>\n",
       "      <td>12.730795</td>\n",
       "      <td>12.037104</td>\n",
       "      <td>17.876320</td>\n",
       "      <td>20.325921</td>\n",
       "      <td>13.153664</td>\n",
       "      <td>25.667889</td>\n",
       "      <td>22.132428</td>\n",
       "      <td>16.895305</td>\n",
       "      <td>6.850399</td>\n",
       "      <td>9.174860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>797</td>\n",
       "      <td>stimulus:80</td>\n",
       "      <td>0</td>\n",
       "      <td>10.886701</td>\n",
       "      <td>-0.504542</td>\n",
       "      <td>10.276249</td>\n",
       "      <td>1.509538</td>\n",
       "      <td>-0.228959</td>\n",
       "      <td>8.525554</td>\n",
       "      <td>1.675647</td>\n",
       "      <td>...</td>\n",
       "      <td>5.868591</td>\n",
       "      <td>5.541304</td>\n",
       "      <td>13.059069</td>\n",
       "      <td>10.617658</td>\n",
       "      <td>15.036787</td>\n",
       "      <td>24.021727</td>\n",
       "      <td>18.858303</td>\n",
       "      <td>19.629436</td>\n",
       "      <td>13.081990</td>\n",
       "      <td>12.764845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     time    condition  epoch        FP1         F3         F7        FC3  \\\n",
       "0    -195  stimulus:80      0  45.596199  47.292836  46.466654  41.128503   \n",
       "1    -188  stimulus:80      0  24.404889  28.461491  23.985574  25.265925   \n",
       "2    -180  stimulus:80      0   2.668258   6.948098   6.277180   6.864293   \n",
       "3    -172  stimulus:80      0 -16.992458 -10.886024 -12.660524  -8.406941   \n",
       "4    -164  stimulus:80      0 -14.193366  -8.145872  -9.260839  -5.862750   \n",
       "..    ...          ...    ...        ...        ...        ...        ...   \n",
       "123   766  stimulus:80      0   8.635242   1.808964  13.996889   4.836501   \n",
       "124   773  stimulus:80      0  11.412126   2.824708   8.947058   3.818979   \n",
       "125   781  stimulus:80      0  22.382695  13.978760  22.814464  12.340680   \n",
       "126   789  stimulus:80      0  20.038114   9.931568  16.959954  10.259957   \n",
       "127   797  stimulus:80      0  10.886701  -0.504542  10.276249   1.509538   \n",
       "\n",
       "            C3         C5         P3  ...        FCz         Cz         C4  \\\n",
       "0    31.878718  25.379012  10.135864  ...  37.192617  28.406003  24.983277   \n",
       "1    21.625795  13.511440   3.931843  ...  23.355127  20.536652  22.640195   \n",
       "2     7.035689  -1.989608  -1.028976  ...   4.150612   5.194571   3.556398   \n",
       "3    -2.385155 -11.059883  -4.802285  ... -11.417976  -6.557006 -11.523773   \n",
       "4    -3.247439 -12.290643  -3.299425  ... -11.584371  -7.975423 -10.767908   \n",
       "..         ...        ...        ...  ...        ...        ...        ...   \n",
       "123   2.124371  10.119360   6.139558  ...   1.540429   0.460351   0.664874   \n",
       "124   2.764923  10.180047   7.664329  ...   2.512359   1.077859  -0.966865   \n",
       "125   7.434694  15.197139   7.333579  ...  10.708669   7.163315  11.690747   \n",
       "126   6.698042  10.914976   6.760029  ...  12.730795  12.037104  17.876320   \n",
       "127  -0.228959   8.525554   1.675647  ...   5.868591   5.541304  13.059069   \n",
       "\n",
       "            C6         P4         P8        P10        PO8        PO4  \\\n",
       "0    43.754374   9.741328  31.474213  42.337803  20.595739   5.454449   \n",
       "1    13.827365   9.125549   4.375870  14.574665  -5.512242  -1.311431   \n",
       "2    13.325658  -8.219313 -18.021922  -6.412509 -30.261847 -15.051173   \n",
       "3    -9.745009 -17.446089 -34.803403 -21.841026 -44.401731 -27.124281   \n",
       "4    -4.907827  -9.590886 -27.136627 -16.254731 -28.376640 -14.134598   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "123   0.746436   1.445564   2.187732   1.504510  -2.792277  -2.240896   \n",
       "124  -1.201587   1.387821   7.544793   7.358878   1.448891  -2.550330   \n",
       "125  21.156703   6.265479  15.546739  15.902253   5.051569  -0.814472   \n",
       "126  20.325921  13.153664  25.667889  22.132428  16.895305   6.850399   \n",
       "127  10.617658  15.036787  24.021727  18.858303  19.629436  13.081990   \n",
       "\n",
       "            O2  \n",
       "0     8.279213  \n",
       "1    -6.946693  \n",
       "2   -17.214696  \n",
       "3   -30.413412  \n",
       "4   -15.679527  \n",
       "..         ...  \n",
       "123  -0.407900  \n",
       "124   0.591870  \n",
       "125  -0.218900  \n",
       "126   9.174860  \n",
       "127  12.764845  \n",
       "\n",
       "[128 rows x 33 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"epoch\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecd5a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_df(parameters)\n",
    "data, labels = create_data_labels(df, [0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b3f7fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-001_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-001_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-001\\**\\sub-001_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-001_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-002_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-002_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-002_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-002\\\\ses-N170\\\\eeg\\\\sub-002_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-002\\\\ses-N170\\\\eeg\\\\sub-002_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-002\\**\\sub-002_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-002_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-003_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-003_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-003_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-003\\\\ses-N170\\\\eeg\\\\sub-003_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-003\\\\ses-N170\\\\eeg\\\\sub-003_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-003\\**\\sub-003_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-003_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-004_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-004_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-004_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-004\\\\ses-N170\\\\eeg\\\\sub-004_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-004\\\\ses-N170\\\\eeg\\\\sub-004_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-004\\**\\sub-004_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-004_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-005_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-005_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-005_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-005\\\\ses-N170\\\\eeg\\\\sub-005_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-005\\\\ses-N170\\\\eeg\\\\sub-005_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-005\\**\\sub-005_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-005_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-006_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-006_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-006_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-006\\\\ses-N170\\\\eeg\\\\sub-006_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-006\\\\ses-N170\\\\eeg\\\\sub-006_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-006\\**\\sub-006_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-006_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-007_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-007_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-007_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-007\\\\ses-N170\\\\eeg\\\\sub-007_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-007\\\\ses-N170\\\\eeg\\\\sub-007_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-007\\**\\sub-007_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-007_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-008_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-008_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-008_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-008\\\\ses-N170\\\\eeg\\\\sub-008_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-008\\\\ses-N170\\\\eeg\\\\sub-008_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-008\\**\\sub-008_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-008_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-009_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-009_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-009_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-009\\\\ses-N170\\\\eeg\\\\sub-009_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-009\\\\ses-N170\\\\eeg\\\\sub-009_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-009\\**\\sub-009_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-009_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-010_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-010_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-010_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-010\\\\ses-N170\\\\eeg\\\\sub-010_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-010\\\\ses-N170\\\\eeg\\\\sub-010_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-010\\**\\sub-010_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-010_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-011_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-011_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-011_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-011\\\\ses-N170\\\\eeg\\\\sub-011_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-011\\\\ses-N170\\\\eeg\\\\sub-011_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-011\\**\\sub-011_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-011_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-012_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-012_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-012_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-012\\\\ses-N170\\\\eeg\\\\sub-012_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-012\\\\ses-N170\\\\eeg\\\\sub-012_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-012\\**\\sub-012_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-012_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-013_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-013_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-013_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-013\\\\ses-N170\\\\eeg\\\\sub-013_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-013\\\\ses-N170\\\\eeg\\\\sub-013_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-013\\**\\sub-013_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-013_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-014_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-014_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-014_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-014\\\\ses-N170\\\\eeg\\\\sub-014_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-014\\\\ses-N170\\\\eeg\\\\sub-014_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-014\\**\\sub-014_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-014_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-015_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-015_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-015_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-015\\\\ses-N170\\\\eeg\\\\sub-015_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-015\\\\ses-N170\\\\eeg\\\\sub-015_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-015\\**\\sub-015_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-015_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-016_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-016_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-016_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-016\\\\ses-N170\\\\eeg\\\\sub-016_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-016\\\\ses-N170\\\\eeg\\\\sub-016_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-016\\**\\sub-016_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-016_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-017_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-017_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-017_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-017\\\\ses-N170\\\\eeg\\\\sub-017_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-017\\\\ses-N170\\\\eeg\\\\sub-017_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-017\\**\\sub-017_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-017_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-018_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-018_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-018_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-018\\\\ses-N170\\\\eeg\\\\sub-018_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-018\\\\ses-N170\\\\eeg\\\\sub-018_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-018\\**\\sub-018_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-018_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-019_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-019_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-019_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-019\\\\ses-N170\\\\eeg\\\\sub-019_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-019\\\\ses-N170\\\\eeg\\\\sub-019_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-019\\**\\sub-019_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-019_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-020_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-020_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-020_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-020\\\\ses-N170\\\\eeg\\\\sub-020_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-020\\\\ses-N170\\\\eeg\\\\sub-020_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-020\\**\\sub-020_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-020_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-021_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-021_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-021_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-021\\\\ses-N170\\\\eeg\\\\sub-021_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-021\\\\ses-N170\\\\eeg\\\\sub-021_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-021\\**\\sub-021_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-021_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-022_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-022_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-022_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-022\\\\ses-N170\\\\eeg\\\\sub-022_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-022\\\\ses-N170\\\\eeg\\\\sub-022_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-022\\**\\sub-022_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-022_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-023_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-023_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-023_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-023\\\\ses-N170\\\\eeg\\\\sub-023_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-023\\\\ses-N170\\\\eeg\\\\sub-023_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-023\\**\\sub-023_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-023_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-024_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-024_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-024_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-024\\\\ses-N170\\\\eeg\\\\sub-024_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-024\\\\ses-N170\\\\eeg\\\\sub-024_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-024\\**\\sub-024_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-024_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-025_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-025_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-025_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-025\\\\ses-N170\\\\eeg\\\\sub-025_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-025\\\\ses-N170\\\\eeg\\\\sub-025_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-025\\**\\sub-025_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-025_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-026_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-026_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-026_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-026\\\\ses-N170\\\\eeg\\\\sub-026_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-026\\\\ses-N170\\\\eeg\\\\sub-026_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-026\\**\\sub-026_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-026_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-027_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-027_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-027_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-027\\\\ses-N170\\\\eeg\\\\sub-027_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-027\\\\ses-N170\\\\eeg\\\\sub-027_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-027\\**\\sub-027_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-027_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-028_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-028_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-028_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-028\\\\ses-N170\\\\eeg\\\\sub-028_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-028\\\\ses-N170\\\\eeg\\\\sub-028_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-028\\**\\sub-028_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-028_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-029_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-029_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-029_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-029\\\\ses-N170\\\\eeg\\\\sub-029_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-029\\\\ses-N170\\\\eeg\\\\sub-029_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-029\\**\\sub-029_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-029_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-030_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-030_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-030_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-030\\\\ses-N170\\\\eeg\\\\sub-030_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-030\\\\ses-N170\\\\eeg\\\\sub-030_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-030\\**\\sub-030_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-030_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-031_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-031_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-031_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-031\\\\ses-N170\\\\eeg\\\\sub-031_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-031\\\\ses-N170\\\\eeg\\\\sub-031_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-031\\**\\sub-031_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-031_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-032_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-032_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-032_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-032\\\\ses-N170\\\\eeg\\\\sub-032_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-032\\\\ses-N170\\\\eeg\\\\sub-032_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-032\\**\\sub-032_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-032_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-033_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-033_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-033_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-033\\\\ses-N170\\\\eeg\\\\sub-033_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-033\\\\ses-N170\\\\eeg\\\\sub-033_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-033\\**\\sub-033_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-033_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-034_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-034_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-034_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-034\\\\ses-N170\\\\eeg\\\\sub-034_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-034\\\\ses-N170\\\\eeg\\\\sub-034_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-034\\**\\sub-034_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-034_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-035_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-035_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-035_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-035\\\\ses-N170\\\\eeg\\\\sub-035_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-035\\\\ses-N170\\\\eeg\\\\sub-035_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-035\\**\\sub-035_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-035_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-036_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-036_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-036_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-036\\\\ses-N170\\\\eeg\\\\sub-036_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-036\\\\ses-N170\\\\eeg\\\\sub-036_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-036\\**\\sub-036_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-036_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-037_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-037_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-037_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-037\\\\ses-N170\\\\eeg\\\\sub-037_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-037\\\\ses-N170\\\\eeg\\\\sub-037_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-037\\**\\sub-037_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-037_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-038_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-038_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-038_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-038\\\\ses-N170\\\\eeg\\\\sub-038_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-038\\\\ses-N170\\\\eeg\\\\sub-038_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-038\\**\\sub-038_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-038_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-039_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-039_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-039_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-039\\\\ses-N170\\\\eeg\\\\sub-039_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-039\\\\ses-N170\\\\eeg\\\\sub-039_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-039\\**\\sub-039_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-039_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-040_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-040_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-040_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-040\\\\ses-N170\\\\eeg\\\\sub-040_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-040\\\\ses-N170\\\\eeg\\\\sub-040_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-040\\**\\sub-040_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-040_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-001_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-001_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-001\\**\\sub-001_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-001_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-002_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-002_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-002_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-002\\\\ses-N170\\\\eeg\\\\sub-002_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-002\\\\ses-N170\\\\eeg\\\\sub-002_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-002\\**\\sub-002_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-002_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-003_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-003_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-003_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-003\\\\ses-N170\\\\eeg\\\\sub-003_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-003\\\\ses-N170\\\\eeg\\\\sub-003_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-003\\**\\sub-003_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-003_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-004_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-004_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-004_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-004\\\\ses-N170\\\\eeg\\\\sub-004_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-004\\\\ses-N170\\\\eeg\\\\sub-004_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-004\\**\\sub-004_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-004_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-005_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-005_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-005_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-005\\\\ses-N170\\\\eeg\\\\sub-005_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-005\\\\ses-N170\\\\eeg\\\\sub-005_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-005\\**\\sub-005_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-005_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-006_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-006_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-006_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-006\\\\ses-N170\\\\eeg\\\\sub-006_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-006\\\\ses-N170\\\\eeg\\\\sub-006_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-006\\**\\sub-006_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-006_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-007_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-007_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-007_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-007\\\\ses-N170\\\\eeg\\\\sub-007_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-007\\\\ses-N170\\\\eeg\\\\sub-007_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-007\\**\\sub-007_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-007_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-008_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-008_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-008_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-008\\\\ses-N170\\\\eeg\\\\sub-008_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-008\\\\ses-N170\\\\eeg\\\\sub-008_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-008\\**\\sub-008_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-008_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-009_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-009_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-009_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-009\\\\ses-N170\\\\eeg\\\\sub-009_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-009\\\\ses-N170\\\\eeg\\\\sub-009_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-009\\**\\sub-009_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-009_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-010_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-010_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-010_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-010\\\\ses-N170\\\\eeg\\\\sub-010_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-010\\\\ses-N170\\\\eeg\\\\sub-010_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-010\\**\\sub-010_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-010_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-011_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-011_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-011_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-011\\\\ses-N170\\\\eeg\\\\sub-011_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-011\\\\ses-N170\\\\eeg\\\\sub-011_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-011\\**\\sub-011_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-011_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-012_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-012_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-012_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-012\\\\ses-N170\\\\eeg\\\\sub-012_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-012\\\\ses-N170\\\\eeg\\\\sub-012_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-012\\**\\sub-012_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-012_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-013_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-013_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-013_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-013\\\\ses-N170\\\\eeg\\\\sub-013_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-013\\\\ses-N170\\\\eeg\\\\sub-013_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-013\\**\\sub-013_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-013_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-014_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-014_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-014_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-014\\\\ses-N170\\\\eeg\\\\sub-014_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-014\\\\ses-N170\\\\eeg\\\\sub-014_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-014\\**\\sub-014_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-014_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-015_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-015_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-015_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-015\\\\ses-N170\\\\eeg\\\\sub-015_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-015\\\\ses-N170\\\\eeg\\\\sub-015_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-015\\**\\sub-015_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-015_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-016_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-016_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-016_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-016\\\\ses-N170\\\\eeg\\\\sub-016_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-016\\\\ses-N170\\\\eeg\\\\sub-016_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-016\\**\\sub-016_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-016_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-017_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-017_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-017_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-017\\\\ses-N170\\\\eeg\\\\sub-017_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-017\\\\ses-N170\\\\eeg\\\\sub-017_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-017\\**\\sub-017_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-017_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-018_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-018_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-018_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-018\\\\ses-N170\\\\eeg\\\\sub-018_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-018\\\\ses-N170\\\\eeg\\\\sub-018_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-018\\**\\sub-018_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-018_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-019_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-019_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-019_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-019\\\\ses-N170\\\\eeg\\\\sub-019_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-019\\\\ses-N170\\\\eeg\\\\sub-019_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-019\\**\\sub-019_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-019_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-020_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-020_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-020_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-020\\\\ses-N170\\\\eeg\\\\sub-020_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-020\\\\ses-N170\\\\eeg\\\\sub-020_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-020\\**\\sub-020_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-020_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-021_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-021_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-021_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-021\\\\ses-N170\\\\eeg\\\\sub-021_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-021\\\\ses-N170\\\\eeg\\\\sub-021_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-021\\**\\sub-021_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-021_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-022_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-022_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-022_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-022\\\\ses-N170\\\\eeg\\\\sub-022_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-022\\\\ses-N170\\\\eeg\\\\sub-022_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-022\\**\\sub-022_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-022_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-023_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-023_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-023_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-023\\\\ses-N170\\\\eeg\\\\sub-023_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-023\\\\ses-N170\\\\eeg\\\\sub-023_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-023\\**\\sub-023_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-023_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-024_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-024_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-024_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-024\\\\ses-N170\\\\eeg\\\\sub-024_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-024\\\\ses-N170\\\\eeg\\\\sub-024_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-024\\**\\sub-024_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-024_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-025_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-025_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-025_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-025\\\\ses-N170\\\\eeg\\\\sub-025_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-025\\\\ses-N170\\\\eeg\\\\sub-025_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-025\\**\\sub-025_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-025_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-026_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-026_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-026_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-026\\\\ses-N170\\\\eeg\\\\sub-026_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-026\\\\ses-N170\\\\eeg\\\\sub-026_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-026\\**\\sub-026_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-026_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-027_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-027_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-027_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-027\\\\ses-N170\\\\eeg\\\\sub-027_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-027\\\\ses-N170\\\\eeg\\\\sub-027_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-027\\**\\sub-027_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-027_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-028_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-028_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-028_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-028\\\\ses-N170\\\\eeg\\\\sub-028_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-028\\\\ses-N170\\\\eeg\\\\sub-028_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-028\\**\\sub-028_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-028_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-029_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-029_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-029_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-029\\\\ses-N170\\\\eeg\\\\sub-029_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-029\\\\ses-N170\\\\eeg\\\\sub-029_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-029\\**\\sub-029_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-029_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-030_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-030_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-030_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-030\\\\ses-N170\\\\eeg\\\\sub-030_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-030\\\\ses-N170\\\\eeg\\\\sub-030_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-030\\**\\sub-030_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-030_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-031_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-031_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-031_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-031\\\\ses-N170\\\\eeg\\\\sub-031_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-031\\\\ses-N170\\\\eeg\\\\sub-031_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-031\\**\\sub-031_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-031_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-032_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-032_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-032_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-032\\\\ses-N170\\\\eeg\\\\sub-032_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-032\\\\ses-N170\\\\eeg\\\\sub-032_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-032\\**\\sub-032_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-032_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-033_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-033_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-033_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-033\\\\ses-N170\\\\eeg\\\\sub-033_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-033\\\\ses-N170\\\\eeg\\\\sub-033_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-033\\**\\sub-033_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-033_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-034_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-034_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-034_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-034\\\\ses-N170\\\\eeg\\\\sub-034_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-034\\\\ses-N170\\\\eeg\\\\sub-034_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-034\\**\\sub-034_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-034_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-035_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-035_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-035_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-035\\\\ses-N170\\\\eeg\\\\sub-035_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-035\\\\ses-N170\\\\eeg\\\\sub-035_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-035\\**\\sub-035_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-035_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-036_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-036_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-036_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-036\\\\ses-N170\\\\eeg\\\\sub-036_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-036\\\\ses-N170\\\\eeg\\\\sub-036_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-036\\**\\sub-036_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-036_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-037_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-037_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-037_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-037\\\\ses-N170\\\\eeg\\\\sub-037_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-037\\\\ses-N170\\\\eeg\\\\sub-037_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-037\\**\\sub-037_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-037_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-038_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-038_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-038_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-038\\\\ses-N170\\\\eeg\\\\sub-038_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-038\\\\ses-N170\\\\eeg\\\\sub-038_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-038\\**\\sub-038_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-038_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-039_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-039_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-039_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-039\\\\ses-N170\\\\eeg\\\\sub-039_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-039\\\\ses-N170\\\\eeg\\\\sub-039_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-039\\**\\sub-039_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-039_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-040_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-040_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-040_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-040\\\\ses-N170\\\\eeg\\\\sub-040_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-040\\\\ses-N170\\\\eeg\\\\sub-040_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-040\\**\\sub-040_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-040_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-001_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-001_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-001\\**\\sub-001_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-001_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 184.50it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:09<00:00,  3.10it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 113/113 [00:00<00:00, 674.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▍                                                   | 19/113 [00:00<00:00, 188.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|████████████████████▊                                         | 38/113 [00:00<00:00, 185.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████▎                              | 57/113 [00:00<00:00, 181.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  67%|█████████████████████████████████████████▋                    | 76/113 [00:00<00:00, 175.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|███████████████████████████████████████████████████▌          | 94/113 [00:00<00:00, 174.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 113/113 [00:00<00:00, 177.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 22.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 22.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 22.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.17s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|██████████▉                                                   | 20/113 [00:00<00:00, 189.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▍                                        | 39/113 [00:00<00:00, 183.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▊                              | 58/113 [00:00<00:00, 186.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|██████████████████████████████████████████▏                   | 77/113 [00:00<00:00, 180.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 113/113 [00:00<00:00, 179.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 25.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 25.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 25.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.12s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▍                                                   | 19/113 [00:00<00:00, 183.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|████████████████████▊                                         | 38/113 [00:00<00:00, 166.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▏                               | 55/113 [00:00<00:00, 148.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|██████████████████████████████████████▉                       | 71/113 [00:00<00:00, 135.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  75%|██████████████████████████████████████████████▋               | 85/113 [00:00<00:00, 136.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 113/113 [00:00<00:00, 146.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 204.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.03s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/113 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|██████████▉                                                   | 20/113 [00:00<00:00, 191.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▉                                        | 40/113 [00:00<00:00, 191.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  53%|████████████████████████████████▉                             | 60/113 [00:00<00:00, 191.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▉                  | 80/113 [00:00<00:00, 182.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 113/113 [00:00<00:00, 181.72it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-002_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-002_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-002_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-002\\\\ses-N170\\\\eeg\\\\sub-002_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-002\\\\ses-N170\\\\eeg\\\\sub-002_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-002\\**\\sub-002_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-002_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 154.80it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.61it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/158 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▋                                   | 68/158 [00:00<00:00, 675.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 158/158 [00:00<00:00, 643.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/158 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|███████                                                       | 18/158 [00:00<00:00, 170.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▏                                               | 36/158 [00:00<00:00, 173.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|█████████████████████▏                                        | 54/158 [00:00<00:00, 168.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▊                                  | 71/158 [00:00<00:00, 166.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 89/158 [00:00<00:00, 167.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▎                   | 107/158 [00:00<00:00, 168.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████▎            | 125/158 [00:00<00:00, 170.73it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 158/158 [00:00<00:00, 171.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 16.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.62s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/158 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|███████                                                       | 18/158 [00:00<00:00, 173.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▏                                               | 36/158 [00:00<00:00, 170.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|█████████████████████▏                                        | 54/158 [00:00<00:00, 171.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 72/158 [00:00<00:00, 172.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▎                          | 90/158 [00:00<00:00, 171.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▋                   | 108/158 [00:00<00:00, 170.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▋            | 126/158 [00:00<00:00, 173.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 158/158 [00:00<00:00, 173.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:03<00:01,  1.56s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/158 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|███████                                                       | 18/158 [00:00<00:00, 176.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▏                                               | 36/158 [00:00<00:00, 177.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|█████████████████████▏                                        | 54/158 [00:00<00:00, 177.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 72/158 [00:00<00:00, 176.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▎                          | 90/158 [00:00<00:00, 176.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▋                   | 108/158 [00:00<00:00, 174.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|█████████████████████████████████████████████████            | 127/158 [00:00<00:00, 179.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 158/158 [00:00<00:00, 177.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 164.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.37s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/158 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|███████                                                       | 18/158 [00:00<00:00, 176.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▏                                               | 36/158 [00:00<00:00, 177.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|█████████████████████▏                                        | 54/158 [00:00<00:00, 175.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 72/158 [00:00<00:00, 173.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▎                          | 90/158 [00:00<00:00, 174.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▋                   | 108/158 [00:00<00:00, 173.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  81%|█████████████████████████████████████████████████▍           | 128/158 [00:00<00:00, 178.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 158/158 [00:00<00:00, 176.94it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-003_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-003_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-003_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-003\\\\ses-N170\\\\eeg\\\\sub-003_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-003\\\\ses-N170\\\\eeg\\\\sub-003_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-003\\**\\sub-003_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-003_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 162.79it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/153 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▏                                  | 67/153 [00:00<00:00, 665.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 153/153 [00:00<00:00, 650.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/153 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▌                                                 | 31/153 [00:00<00:00, 301.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  41%|█████████████████████████                                     | 62/153 [00:00<00:00, 298.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▎                        | 92/153 [00:00<00:00, 267.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▊             | 120/153 [00:00<00:00, 267.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 153/153 [00:00<00:00, 258.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 16.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 16.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.26s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/153 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▌                                                 | 31/153 [00:00<00:00, 307.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  41%|█████████████████████████                                     | 62/153 [00:00<00:00, 304.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▋                        | 93/153 [00:00<00:00, 271.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████▏            | 121/153 [00:00<00:00, 272.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 153/153 [00:00<00:00, 263.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.20s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/153 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▌                                                 | 31/153 [00:00<00:00, 304.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  41%|█████████████████████████                                     | 62/153 [00:00<00:00, 301.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▋                        | 93/153 [00:00<00:00, 272.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████▏            | 121/153 [00:00<00:00, 272.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 153/153 [00:00<00:00, 263.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 163.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.02s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/153 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▌                                                 | 31/153 [00:00<00:00, 306.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  41%|█████████████████████████                                     | 62/153 [00:00<00:00, 303.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▋                        | 93/153 [00:00<00:00, 272.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▋            | 122/153 [00:00<00:00, 273.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 153/153 [00:00<00:00, 263.37it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-004_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-004_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-004_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-004\\\\ses-N170\\\\eeg\\\\sub-004_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-004\\\\ses-N170\\\\eeg\\\\sub-004_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-004\\**\\sub-004_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-004_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 159.52it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.85it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 68/149 [00:00<00:00, 671.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 666.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▉                                                    | 24/149 [00:00<00:00, 235.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 48/149 [00:00<00:00, 221.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▎                            | 80/149 [00:00<00:00, 260.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▊                 | 107/149 [00:00<00:00, 255.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 257.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.19s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▉                                                    | 24/149 [00:00<00:00, 233.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 48/149 [00:00<00:00, 225.53it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  54%|█████████████████████████████████▎                            | 80/149 [00:00<00:00, 264.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▊                 | 107/149 [00:00<00:00, 252.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 256.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.15s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▉                                                    | 24/149 [00:00<00:00, 235.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 48/149 [00:00<00:00, 224.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▎                            | 80/149 [00:00<00:00, 262.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▊                 | 107/149 [00:00<00:00, 254.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 260.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 171.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▉                                                    | 24/149 [00:00<00:00, 232.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 48/149 [00:00<00:00, 220.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▎                            | 80/149 [00:00<00:00, 263.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▊                 | 107/149 [00:00<00:00, 256.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 258.92it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-005_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-005_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-005_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-005\\\\ses-N170\\\\eeg\\\\sub-005_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-005\\\\ses-N170\\\\eeg\\\\sub-005_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-005\\**\\sub-005_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-005_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 159.98it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.55it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  40%|█████████████████████████                                     | 63/156 [00:00<00:00, 622.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 612.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▎                                                   | 26/156 [00:00<00:00, 255.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  33%|████████████████████▋                                         | 52/156 [00:00<00:00, 220.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████                               | 78/156 [00:00<00:00, 232.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  67%|████████████████████████████████████████▋                    | 104/156 [00:00<00:00, 239.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▍          | 129/156 [00:00<00:00, 235.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 227.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 15.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 14.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 14.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 14.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.45s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████▎                                                     | 21/156 [00:00<00:00, 206.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  27%|████████████████▋                                             | 42/156 [00:00<00:00, 201.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 66/156 [00:00<00:00, 217.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  58%|████████████████████████████████████▏                         | 91/156 [00:00<00:00, 229.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  74%|████████████████████████████████████████████▉                | 115/156 [00:00<00:00, 230.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 215.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.37s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▋                                                   | 27/156 [00:00<00:00, 255.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|█████████████████████                                         | 53/156 [00:00<00:00, 227.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▍                              | 79/156 [00:00<00:00, 240.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  67%|████████████████████████████████████████▋                    | 104/156 [00:00<00:00, 243.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▍          | 129/156 [00:00<00:00, 234.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 227.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.17s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▋                                                   | 27/156 [00:00<00:00, 262.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▍                                        | 54/156 [00:00<00:00, 234.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  53%|████████████████████████████████▌                             | 82/156 [00:00<00:00, 253.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▏                  | 108/156 [00:00<00:00, 252.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 233.51it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-006_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-006_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-006_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-006\\\\ses-N170\\\\eeg\\\\sub-006_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-006\\\\ses-N170\\\\eeg\\\\sub-006_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-006\\**\\sub-006_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-006_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 161.70it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.60it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/127 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 661.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/127 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▊                                                    | 20/127 [00:00<00:00, 198.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|████████████████████▉                                         | 43/127 [00:00<00:00, 213.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▋                              | 65/127 [00:00<00:00, 202.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▍                   | 87/127 [00:00<00:00, 205.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 206.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 20.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 20.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.18s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/127 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▊                                                    | 20/127 [00:00<00:00, 192.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▍                                        | 44/127 [00:00<00:00, 213.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  52%|████████████████████████████████▏                             | 66/127 [00:00<00:00, 198.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▉                   | 88/127 [00:00<00:00, 203.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 205.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 22.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 22.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 22.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.14s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/127 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▊                                                    | 20/127 [00:00<00:00, 189.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  33%|████████████████████▌                                         | 42/127 [00:00<00:00, 206.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|██████████████████████████████▊                               | 63/127 [00:00<00:00, 194.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▌                     | 83/127 [00:00<00:00, 194.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  81%|█████████████████████████████████████████████████▍           | 103/127 [00:00<00:00, 194.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 201.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 201.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/127 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▊                                                    | 20/127 [00:00<00:00, 190.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|████████████████████▉                                         | 43/127 [00:00<00:00, 207.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████▏                              | 64/127 [00:00<00:00, 199.29it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  67%|█████████████████████████████████████████▍                    | 85/127 [00:00<00:00, 202.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 127/127 [00:00<00:00, 204.40it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-007_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-007_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-007_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-007\\\\ses-N170\\\\eeg\\\\sub-007_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-007\\\\ses-N170\\\\eeg\\\\sub-007_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-007\\**\\sub-007_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-007_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 160.78it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.59it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████                                   | 68/156 [00:00<00:00, 668.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 635.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▉                                                    | 25/156 [00:00<00:00, 245.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▊                                          | 50/156 [00:00<00:00, 238.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|█████████████████████████████▍                                | 74/156 [00:00<00:00, 216.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▏                       | 96/156 [00:00<00:00, 210.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▋             | 122/156 [00:00<00:00, 225.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 217.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 16.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.38s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▉                                                    | 25/156 [00:00<00:00, 243.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▊                                          | 50/156 [00:00<00:00, 243.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▊                                | 75/156 [00:00<00:00, 222.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|██████████████████████████████████████▉                       | 98/156 [00:00<00:00, 216.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▉            | 125/156 [00:00<00:00, 233.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 223.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.32s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  15%|█████████▌                                                    | 24/156 [00:00<00:00, 235.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  31%|███████████████████                                           | 48/156 [00:00<00:00, 233.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▌                                 | 72/156 [00:00<00:00, 213.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▎                        | 94/156 [00:00<00:00, 211.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  74%|█████████████████████████████████████████████▎               | 116/156 [00:00<00:00, 213.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 212.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 172.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.15s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▉                                                    | 25/156 [00:00<00:00, 236.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  31%|███████████████████▍                                          | 49/156 [00:00<00:00, 237.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|█████████████████████████████                                 | 73/156 [00:00<00:00, 218.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▏                       | 96/156 [00:00<00:00, 210.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▋             | 122/156 [00:00<00:00, 226.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 218.67it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-008_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-008_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-008_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-008\\\\ses-N170\\\\eeg\\\\sub-008_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-008\\\\ses-N170\\\\eeg\\\\sub-008_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-008\\**\\sub-008_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-008_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 156.69it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.50it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▋                                 | 68/147 [00:00<00:00, 668.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 638.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 17/147 [00:00<00:00, 165.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▎                                               | 34/147 [00:00<00:00, 165.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▌                                        | 51/147 [00:00<00:00, 163.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▋                                 | 68/147 [00:00<00:00, 161.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  58%|███████████████████████████████████▊                          | 85/147 [00:00<00:00, 162.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▎                  | 102/147 [00:00<00:00, 161.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  81%|█████████████████████████████████████████████████▍           | 119/147 [00:00<00:00, 162.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 162.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.56s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▌                                                      | 18/147 [00:00<00:00, 171.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▌                                              | 37/147 [00:00<00:00, 176.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|███████████████████████▏                                      | 55/147 [00:00<00:00, 171.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|██████████████████████████████▊                               | 73/147 [00:00<00:00, 172.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▍                       | 91/147 [00:00<00:00, 172.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  74%|█████████████████████████████████████████████▏               | 109/147 [00:00<00:00, 172.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▋        | 127/147 [00:00<00:00, 173.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 171.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.48s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▌                                                      | 18/147 [00:00<00:00, 173.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████▏                                              | 36/147 [00:00<00:00, 176.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▊                                       | 54/147 [00:00<00:00, 174.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▎                               | 72/147 [00:00<00:00, 173.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▉                        | 90/147 [00:00<00:00, 172.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|████████████████████████████████████████████▊                | 108/147 [00:00<00:00, 171.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 126/147 [00:00<00:00, 171.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 171.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 175.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.30s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 17/147 [00:00<00:00, 168.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▊                                               | 35/147 [00:00<00:00, 169.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▉                                        | 52/147 [00:00<00:00, 165.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|█████████████████████████████                                 | 69/147 [00:00<00:00, 163.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▎                         | 86/147 [00:00<00:00, 163.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|██████████████████████████████████████████▋                  | 103/147 [00:00<00:00, 163.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|█████████████████████████████████████████████████▊           | 120/147 [00:00<00:00, 162.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 163.77it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-009_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-009_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-009_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-009\\\\ses-N170\\\\eeg\\\\sub-009_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-009\\\\ses-N170\\\\eeg\\\\sub-009_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-009\\**\\sub-009_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-009_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 152.69it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.63it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/155 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▍                                   | 66/155 [00:00<00:00, 658.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 155/155 [00:00<00:00, 653.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/155 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|██████▊                                                       | 17/155 [00:00<00:00, 166.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▍                                               | 36/155 [00:00<00:00, 177.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▌                                        | 54/155 [00:00<00:00, 176.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▌                                | 74/155 [00:00<00:00, 185.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▏                        | 93/155 [00:00<00:00, 179.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▋                 | 111/155 [00:00<00:00, 175.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▊          | 129/155 [00:00<00:00, 174.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 155/155 [00:00<00:00, 178.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.53s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/155 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▌                                                      | 19/155 [00:00<00:00, 182.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▏                                              | 38/155 [00:00<00:00, 184.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▊                                       | 57/155 [00:00<00:00, 179.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████▏                              | 78/155 [00:00<00:00, 188.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|██████████████████████████████████████▊                       | 97/155 [00:00<00:00, 182.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  75%|█████████████████████████████████████████████▋               | 116/155 [00:00<00:00, 179.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▋        | 134/155 [00:00<00:00, 176.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 155/155 [00:00<00:00, 180.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.47s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/155 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 18/155 [00:00<00:00, 178.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▍                                               | 36/155 [00:00<00:00, 177.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▌                                        | 54/155 [00:00<00:00, 174.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|██████████████████████████████                                | 75/155 [00:00<00:00, 184.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▌                        | 94/155 [00:00<00:00, 178.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████                 | 112/155 [00:00<00:00, 176.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████▏         | 130/155 [00:00<00:00, 174.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 155/155 [00:00<00:00, 177.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 167.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.30s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/155 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 18/155 [00:00<00:00, 176.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▍                                               | 36/155 [00:00<00:00, 176.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▌                                        | 54/155 [00:00<00:00, 173.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▌                                | 74/155 [00:00<00:00, 182.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▏                        | 93/155 [00:00<00:00, 177.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▋                 | 111/155 [00:00<00:00, 176.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▊          | 129/155 [00:00<00:00, 173.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 155/155 [00:00<00:00, 177.36it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-010_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-010_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-010_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-010\\\\ses-N170\\\\eeg\\\\sub-010_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-010\\\\ses-N170\\\\eeg\\\\sub-010_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-010\\**\\sub-010_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-010_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 162.60it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.85it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/134 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 134/134 [00:00<00:00, 657.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/134 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  21%|████████████▉                                                 | 28/134 [00:00<00:00, 264.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  41%|█████████████████████████▍                                    | 55/134 [00:00<00:00, 228.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████▊                      | 86/134 [00:00<00:00, 257.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 134/134 [00:00<00:00, 252.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.11s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/134 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▍                                                 | 27/134 [00:00<00:00, 265.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  40%|████████████████████████▉                                     | 54/134 [00:00<00:00, 221.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████▊                      | 86/134 [00:00<00:00, 254.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 134/134 [00:00<00:00, 250.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 20.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.07s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/134 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▍                                                 | 27/134 [00:00<00:00, 265.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  40%|████████████████████████▉                                     | 54/134 [00:00<00:00, 226.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████▊                      | 86/134 [00:00<00:00, 257.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 134/134 [00:00<00:00, 255.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 189.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.09it/s]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/134 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▍                                                 | 27/134 [00:00<00:00, 269.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  40%|████████████████████████▉                                     | 54/134 [00:00<00:00, 231.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|███████████████████████████████████████▎                      | 85/134 [00:00<00:00, 263.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 134/134 [00:00<00:00, 258.44it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-011_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-011_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-011_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-011\\\\ses-N170\\\\eeg\\\\sub-011_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-011\\\\ses-N170\\\\eeg\\\\sub-011_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-011\\**\\sub-011_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-011_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 157.51it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.60it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▊                                  | 66/147 [00:00<00:00, 658.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 623.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 17/147 [00:00<00:00, 167.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▊                                               | 35/147 [00:00<00:00, 169.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▊                                       | 54/147 [00:00<00:00, 174.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▎                               | 72/147 [00:00<00:00, 172.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|██████████████████████████████████████▊                       | 92/147 [00:00<00:00, 178.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  75%|█████████████████████████████████████████████▋               | 110/147 [00:00<00:00, 175.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  87%|█████████████████████████████████████████████████████        | 128/147 [00:00<00:00, 171.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 172.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 16.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.53s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 17/147 [00:00<00:00, 165.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▊                                               | 35/147 [00:00<00:00, 168.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▊                                       | 54/147 [00:00<00:00, 175.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▎                               | 72/147 [00:00<00:00, 174.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▉                        | 90/147 [00:00<00:00, 175.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|████████████████████████████████████████████▊                | 108/147 [00:00<00:00, 172.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 126/147 [00:00<00:00, 168.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 170.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.47s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▌                                                      | 18/147 [00:00<00:00, 171.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████▏                                              | 36/147 [00:00<00:00, 172.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|███████████████████████▏                                      | 55/147 [00:00<00:00, 178.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|██████████████████████████████▊                               | 73/147 [00:00<00:00, 177.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|██████████████████████████████████████▊                       | 92/147 [00:00<00:00, 180.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  76%|██████████████████████████████████████████████               | 111/147 [00:00<00:00, 177.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  88%|█████████████████████████████████████████████████████▌       | 129/147 [00:00<00:00, 172.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 171.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.29s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 17/147 [00:00<00:00, 168.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▊                                               | 35/147 [00:00<00:00, 170.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▊                                       | 54/147 [00:00<00:00, 178.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▎                               | 72/147 [00:00<00:00, 178.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▍                       | 91/147 [00:00<00:00, 178.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  74%|█████████████████████████████████████████████▏               | 109/147 [00:00<00:00, 175.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▋        | 127/147 [00:00<00:00, 173.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 173.86it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-012_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-012_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-012_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-012\\\\ses-N170\\\\eeg\\\\sub-012_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-012\\\\ses-N170\\\\eeg\\\\sub-012_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-012\\**\\sub-012_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-012_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 156.27it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/144 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▉                                  | 65/144 [00:00<00:00, 638.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 609.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/144 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▎                                                      | 17/144 [00:00<00:00, 165.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▋                                               | 34/144 [00:00<00:00, 154.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▉                                        | 51/144 [00:00<00:00, 158.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|█████████████████████████████▎                                | 68/144 [00:00<00:00, 161.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▌                         | 85/144 [00:00<00:00, 162.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▏                 | 102/144 [00:00<00:00, 163.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▍          | 119/144 [00:00<00:00, 164.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 163.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.54s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/144 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▎                                                      | 17/144 [00:00<00:00, 167.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▋                                               | 34/144 [00:00<00:00, 166.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▉                                        | 51/144 [00:00<00:00, 165.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|█████████████████████████████▎                                | 68/144 [00:00<00:00, 165.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▌                         | 85/144 [00:00<00:00, 164.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▏                 | 102/144 [00:00<00:00, 163.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▍          | 119/144 [00:00<00:00, 164.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 164.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.48s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/144 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▎                                                      | 17/144 [00:00<00:00, 163.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▋                                               | 34/144 [00:00<00:00, 164.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▉                                        | 51/144 [00:00<00:00, 162.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|█████████████████████████████▎                                | 68/144 [00:00<00:00, 163.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▌                         | 85/144 [00:00<00:00, 163.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▏                 | 102/144 [00:00<00:00, 155.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▍          | 119/144 [00:00<00:00, 159.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 161.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 175.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.31s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/144 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▎                                                      | 17/144 [00:00<00:00, 166.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▋                                               | 34/144 [00:00<00:00, 167.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▉                                        | 51/144 [00:00<00:00, 167.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|█████████████████████████████▎                                | 68/144 [00:00<00:00, 166.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▌                         | 85/144 [00:00<00:00, 165.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▋                 | 103/144 [00:00<00:00, 167.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████▎         | 121/144 [00:00<00:00, 168.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 144/144 [00:00<00:00, 167.24it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-013_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-013_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-013_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-013\\\\ses-N170\\\\eeg\\\\sub-013_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-013\\\\ses-N170\\\\eeg\\\\sub-013_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-013\\**\\sub-013_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-013_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 153.94it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.69it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▉                                  | 67/149 [00:00<00:00, 665.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 641.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|███████                                                       | 17/149 [00:00<00:00, 165.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▌                                               | 35/149 [00:00<00:00, 170.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████                                        | 53/149 [00:00<00:00, 170.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▉                                | 72/149 [00:00<00:00, 176.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▍                        | 90/149 [00:00<00:00, 176.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████▏                | 108/149 [00:00<00:00, 176.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  85%|███████████████████████████████████████████████████▌         | 126/149 [00:00<00:00, 175.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 173.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.51s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|███████                                                       | 17/149 [00:00<00:00, 165.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▌                                               | 35/149 [00:00<00:00, 172.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████                                        | 53/149 [00:00<00:00, 173.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▉                                | 72/149 [00:00<00:00, 178.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▍                        | 90/149 [00:00<00:00, 175.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████▏                | 108/149 [00:00<00:00, 175.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  85%|███████████████████████████████████████████████████▌         | 126/149 [00:00<00:00, 174.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 172.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.46s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|███████                                                       | 17/149 [00:00<00:00, 162.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▌                                               | 35/149 [00:00<00:00, 169.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████                                        | 53/149 [00:00<00:00, 172.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▉                                | 72/149 [00:00<00:00, 176.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▍                        | 90/149 [00:00<00:00, 176.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████▏                | 108/149 [00:00<00:00, 174.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  85%|███████████████████████████████████████████████████▌         | 126/149 [00:00<00:00, 164.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 165.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 172.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.30s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/149 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|███████                                                       | 17/149 [00:00<00:00, 159.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▌                                               | 35/149 [00:00<00:00, 167.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████                                        | 53/149 [00:00<00:00, 171.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▉                                | 72/149 [00:00<00:00, 174.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▍                        | 90/149 [00:00<00:00, 174.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████▏                | 108/149 [00:00<00:00, 173.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  85%|███████████████████████████████████████████████████▌         | 126/149 [00:00<00:00, 174.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 149/149 [00:00<00:00, 170.90it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-014_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-014_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-014_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-014\\\\ses-N170\\\\eeg\\\\sub-014_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-014\\\\ses-N170\\\\eeg\\\\sub-014_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-014\\**\\sub-014_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-014_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 155.03it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:12<00:00,  2.49it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▍                                   | 67/157 [00:00<00:00, 658.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 647.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|██████▋                                                       | 17/157 [00:00<00:00, 163.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  22%|█████████████▍                                                | 34/157 [00:00<00:00, 166.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  33%|████████████████████▌                                         | 52/157 [00:00<00:00, 168.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▏                                  | 69/157 [00:00<00:00, 166.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▌                          | 90/157 [00:00<00:00, 181.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▎                  | 109/157 [00:00<00:00, 174.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  81%|█████████████████████████████████████████████████▎           | 127/157 [00:00<00:00, 172.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 176.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 16.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 16.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.58s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|██████▋                                                       | 17/157 [00:00<00:00, 163.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  22%|█████████████▊                                                | 35/157 [00:00<00:00, 169.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|████████████████████▉                                         | 53/157 [00:00<00:00, 171.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|████████████████████████████                                  | 71/157 [00:00<00:00, 170.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▎                         | 92/157 [00:00<00:00, 181.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▏                 | 111/157 [00:00<00:00, 176.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|██████████████████████████████████████████████████           | 129/157 [00:00<00:00, 175.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 178.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:03<00:01,  1.52s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|██████▋                                                       | 17/157 [00:00<00:00, 167.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  22%|█████████████▊                                                | 35/157 [00:00<00:00, 172.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|████████████████████▉                                         | 53/157 [00:00<00:00, 173.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|████████████████████████████                                  | 71/157 [00:00<00:00, 172.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  58%|███████████████████████████████████▉                          | 91/157 [00:00<00:00, 181.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|██████████████████████████████████████████▋                  | 110/157 [00:00<00:00, 174.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|█████████████████████████████████████████████████▋           | 128/157 [00:00<00:00, 173.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 174.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 161.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.34s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  11%|██████▋                                                       | 17/157 [00:00<00:00, 166.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  22%|█████████████▊                                                | 35/157 [00:00<00:00, 170.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|████████████████████▉                                         | 53/157 [00:00<00:00, 172.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|████████████████████████████                                  | 71/157 [00:00<00:00, 171.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  58%|███████████████████████████████████▉                          | 91/157 [00:00<00:00, 180.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|██████████████████████████████████████████▋                  | 110/157 [00:00<00:00, 174.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|█████████████████████████████████████████████████▋           | 128/157 [00:00<00:00, 174.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 177.55it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-015_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-015_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-015_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-015\\\\ses-N170\\\\eeg\\\\sub-015_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-015\\\\ses-N170\\\\eeg\\\\sub-015_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-015\\**\\sub-015_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-015_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 157.47it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/145 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▋                                 | 67/145 [00:00<00:00, 658.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 145/145 [00:00<00:00, 632.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/145 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▎                                                   | 24/145 [00:00<00:00, 232.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  33%|████████████████████▌                                         | 48/145 [00:00<00:00, 226.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|██████████████████████████████▊                               | 72/145 [00:00<00:00, 230.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  66%|█████████████████████████████████████████                     | 96/145 [00:00<00:00, 226.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|██████████████████████████████████████████████████           | 119/145 [00:00<00:00, 219.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 145/145 [00:00<00:00, 221.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.28s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/145 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▎                                                   | 24/145 [00:00<00:00, 231.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  33%|████████████████████▌                                         | 48/145 [00:00<00:00, 226.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████▏                              | 73/145 [00:00<00:00, 234.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  67%|█████████████████████████████████████████▍                    | 97/145 [00:00<00:00, 229.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▍          | 120/145 [00:00<00:00, 224.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 145/145 [00:00<00:00, 224.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.23s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/145 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▊                                                    | 23/145 [00:00<00:00, 227.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▋                                          | 46/145 [00:00<00:00, 220.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▎                               | 71/145 [00:00<00:00, 229.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▏                     | 94/145 [00:00<00:00, 224.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  81%|█████████████████████████████████████████████████▏           | 117/145 [00:00<00:00, 218.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 145/145 [00:00<00:00, 220.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 178.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.07s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/145 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▎                                                   | 24/145 [00:00<00:00, 229.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|████████████████████                                          | 47/145 [00:00<00:00, 226.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▎                               | 71/145 [00:00<00:00, 226.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▏                     | 94/145 [00:00<00:00, 221.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  81%|█████████████████████████████████████████████████▏           | 117/145 [00:00<00:00, 215.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 145/145 [00:00<00:00, 217.90it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-016_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-016_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-016_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-016\\\\ses-N170\\\\eeg\\\\sub-016_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-016\\\\ses-N170\\\\eeg\\\\sub-016_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-016\\**\\sub-016_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-016_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 169.92it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:08<00:00,  3.47it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                         | 0/79 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|███████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 638.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                         | 0/79 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  30%|███████████████████▏                                           | 24/79 [00:00<00:00, 238.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|██████████████████████████████████████▎                        | 48/79 [00:00<00:00, 209.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|███████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 205.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 29.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 28.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 28.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:00<00:01,  1.29it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                         | 0/79 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  30%|███████████████████▏                                           | 24/79 [00:00<00:00, 238.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|██████████████████████████████████████▎                        | 48/79 [00:00<00:00, 205.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|███████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 200.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 31.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 31.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:01<00:00,  1.32it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                         | 0/79 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  30%|███████████████████▏                                           | 24/79 [00:00<00:00, 238.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|██████████████████████████████████████▎                        | 48/79 [00:00<00:00, 207.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|███████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 200.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 263.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.53it/s]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                         | 0/79 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  30%|███████████████████▏                                           | 24/79 [00:00<00:00, 233.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|██████████████████████████████████████▎                        | 48/79 [00:00<00:00, 207.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|███████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 202.59it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-017_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-017_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-017_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-017\\\\ses-N170\\\\eeg\\\\sub-017_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-017\\\\ses-N170\\\\eeg\\\\sub-017_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-017\\**\\sub-017_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-017_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 154.30it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:12<00:00,  2.48it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████                                    | 66/157 [00:00<00:00, 648.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 632.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|███████▉                                                      | 20/157 [00:00<00:00, 194.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▊                                              | 40/157 [00:00<00:00, 180.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▎                                      | 59/157 [00:00<00:00, 178.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|██████████████████████████████▊                               | 78/157 [00:00<00:00, 179.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▉                        | 96/157 [00:00<00:00, 177.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|████████████████████████████████████████████▎                | 114/157 [00:00<00:00, 172.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████▎         | 132/157 [00:00<00:00, 171.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 174.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 16.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 16.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.58s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████▎                                                     | 21/157 [00:00<00:00, 204.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  27%|████████████████▌                                             | 42/157 [00:00<00:00, 189.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████▍                                     | 62/157 [00:00<00:00, 187.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  52%|███████████████████████████████▉                              | 81/157 [00:00<00:00, 183.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|██████████████████████████████████████▊                      | 100/157 [00:00<00:00, 180.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  76%|██████████████████████████████████████████████▏              | 119/157 [00:00<00:00, 175.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  87%|█████████████████████████████████████████████████████▏       | 137/157 [00:00<00:00, 174.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 179.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:03<00:01,  1.52s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████▎                                                     | 21/157 [00:00<00:00, 202.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  27%|████████████████▌                                             | 42/157 [00:00<00:00, 183.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████                                      | 61/157 [00:00<00:00, 179.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▌                              | 80/157 [00:00<00:00, 181.05it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  63%|███████████████████████████████████████                       | 99/157 [00:00<00:00, 177.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  75%|█████████████████████████████████████████████▍               | 117/157 [00:00<00:00, 174.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▍        | 135/157 [00:00<00:00, 174.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 177.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 159.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.34s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|███████▉                                                      | 20/157 [00:00<00:00, 196.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▊                                              | 40/157 [00:00<00:00, 180.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▎                                      | 59/157 [00:00<00:00, 177.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▍                               | 77/157 [00:00<00:00, 177.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▌                        | 95/157 [00:00<00:00, 177.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▉                 | 113/157 [00:00<00:00, 172.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▉          | 131/157 [00:00<00:00, 171.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 174.14it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-018_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-018_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-018_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-018\\\\ses-N170\\\\eeg\\\\sub-018_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-018\\\\ses-N170\\\\eeg\\\\sub-018_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-018\\**\\sub-018_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-018_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 160.51it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.75it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|█████████████████████████████▍                                | 66/139 [00:00<00:00, 655.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 648.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████                                                      | 18/139 [00:00<00:00, 176.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████                                              | 36/139 [00:00<00:00, 169.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▋                                      | 53/139 [00:00<00:00, 168.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████▏                              | 70/139 [00:00<00:00, 162.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|██████████████████████████████████████▊                       | 87/139 [00:00<00:00, 163.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  75%|█████████████████████████████████████████████▋               | 104/139 [00:00<00:00, 165.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  87%|█████████████████████████████████████████████████████        | 121/139 [00:00<00:00, 162.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 163.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.50s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████                                                      | 18/139 [00:00<00:00, 171.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████                                              | 36/139 [00:00<00:00, 165.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████                                      | 54/139 [00:00<00:00, 167.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▋                              | 71/139 [00:00<00:00, 163.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|███████████████████████████████████████▎                      | 88/139 [00:00<00:00, 162.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  76%|██████████████████████████████████████████████               | 105/139 [00:00<00:00, 164.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  88%|█████████████████████████████████████████████████████▌       | 122/139 [00:00<00:00, 160.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 162.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 20.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 20.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.44s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████                                                      | 18/139 [00:00<00:00, 171.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████                                              | 36/139 [00:00<00:00, 165.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████                                      | 54/139 [00:00<00:00, 169.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▋                              | 71/139 [00:00<00:00, 165.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|███████████████████████████████████████▎                      | 88/139 [00:00<00:00, 166.38it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  76%|██████████████████████████████████████████████               | 105/139 [00:00<00:00, 167.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  88%|█████████████████████████████████████████████████████▌       | 122/139 [00:00<00:00, 162.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 164.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 180.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.27s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████                                                      | 18/139 [00:00<00:00, 176.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████                                              | 36/139 [00:00<00:00, 168.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████                                      | 54/139 [00:00<00:00, 169.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▋                              | 71/139 [00:00<00:00, 164.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████▋                      | 89/139 [00:00<00:00, 166.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  76%|██████████████████████████████████████████████▌              | 106/139 [00:00<00:00, 167.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 165.51it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-019_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-019_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-019_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-019\\\\ses-N170\\\\eeg\\\\sub-019_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-019\\\\ses-N170\\\\eeg\\\\sub-019_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-019\\**\\sub-019_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-019_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 153.05it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:12<00:00,  2.47it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████                                    | 66/157 [00:00<00:00, 655.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 650.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|███████▉                                                      | 20/157 [00:00<00:00, 190.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████▏                                             | 41/157 [00:00<00:00, 198.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████▍                                     | 62/157 [00:00<00:00, 201.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  55%|█████████████████████████████████▉                            | 86/157 [00:00<00:00, 211.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▎                  | 109/157 [00:00<00:00, 217.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▉          | 131/157 [00:00<00:00, 210.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 204.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 16.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 16.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.45s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████▎                                                     | 21/157 [00:00<00:00, 198.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████▏                                             | 41/157 [00:00<00:00, 198.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████▍                                     | 62/157 [00:00<00:00, 198.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▌                            | 85/157 [00:00<00:00, 208.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▌                   | 107/157 [00:00<00:00, 209.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|█████████████████████████████████████████████████▋           | 128/157 [00:00<00:00, 200.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 198.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.41s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████▎                                                     | 21/157 [00:00<00:00, 198.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████▏                                             | 41/157 [00:00<00:00, 198.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████▍                                     | 62/157 [00:00<00:00, 203.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▌                            | 85/157 [00:00<00:00, 212.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▌                   | 107/157 [00:00<00:00, 212.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|██████████████████████████████████████████████████           | 129/157 [00:00<00:00, 207.15it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 202.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 161.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.23s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|███████▉                                                      | 20/157 [00:00<00:00, 199.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████▏                                             | 41/157 [00:00<00:00, 200.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████▍                                     | 62/157 [00:00<00:00, 201.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  55%|█████████████████████████████████▉                            | 86/157 [00:00<00:00, 211.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▎                  | 109/157 [00:00<00:00, 214.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▉          | 131/157 [00:00<00:00, 209.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 204.05it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-020_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-020_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-020_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-020\\\\ses-N170\\\\eeg\\\\sub-020_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-020\\\\ses-N170\\\\eeg\\\\sub-020_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-020\\**\\sub-020_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-020_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 157.86it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.61it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 67/147 [00:00<00:00, 658.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 635.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▌                                                   | 25/147 [00:00<00:00, 245.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|█████████████████████                                         | 50/147 [00:00<00:00, 193.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|██████████████████████████████▊                               | 73/147 [00:00<00:00, 207.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████                      | 95/147 [00:00<00:00, 205.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████▏            | 116/147 [00:00<00:00, 203.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 199.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.38s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|██████████▉                                                   | 26/147 [00:00<00:00, 245.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▌                                        | 51/147 [00:00<00:00, 194.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████▏                              | 74/147 [00:00<00:00, 207.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▍                     | 96/147 [00:00<00:00, 204.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▉            | 118/147 [00:00<00:00, 206.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 202.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.33s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|██████████▉                                                   | 26/147 [00:00<00:00, 250.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▉                                        | 52/147 [00:00<00:00, 192.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▋                              | 75/147 [00:00<00:00, 202.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▍                     | 96/147 [00:00<00:00, 204.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▌            | 117/147 [00:00<00:00, 203.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 200.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.16s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|██████████▉                                                   | 26/147 [00:00<00:00, 249.07it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  35%|█████████████████████▌                                        | 51/147 [00:00<00:00, 194.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████▏                              | 74/147 [00:00<00:00, 205.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▍                     | 96/147 [00:00<00:00, 204.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▌            | 117/147 [00:00<00:00, 205.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 201.45it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-021_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-021_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-021_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-021\\\\ses-N170\\\\eeg\\\\sub-021_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-021\\\\ses-N170\\\\eeg\\\\sub-021_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-021\\**\\sub-021_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-021_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 152.28it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.70it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▍                                  | 68/154 [00:00<00:00, 675.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 655.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▋                                                      | 19/154 [00:00<00:00, 180.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▎                                              | 38/154 [00:00<00:00, 175.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▌                                       | 56/154 [00:00<00:00, 175.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▊                                | 74/154 [00:00<00:00, 176.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████                         | 92/154 [00:00<00:00, 177.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▉                 | 111/154 [00:00<00:00, 177.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████          | 129/154 [00:00<00:00, 177.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 175.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.53s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▋                                                      | 19/154 [00:00<00:00, 183.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▎                                              | 38/154 [00:00<00:00, 179.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▌                                       | 56/154 [00:00<00:00, 175.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▊                                | 74/154 [00:00<00:00, 174.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████▍                        | 93/154 [00:00<00:00, 176.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▉                 | 111/154 [00:00<00:00, 176.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████          | 129/154 [00:00<00:00, 176.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 174.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:03<00:01,  1.50s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 18/154 [00:00<00:00, 153.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  22%|█████████████▋                                                | 34/154 [00:00<00:00, 147.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  33%|████████████████████▌                                         | 51/154 [00:00<00:00, 156.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|██████████████████████████▉                                   | 67/154 [00:00<00:00, 154.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  55%|██████████████████████████████████▏                           | 85/154 [00:00<00:00, 160.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  66%|████████████████████████████████████████▍                    | 102/154 [00:00<00:00, 156.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▌             | 120/154 [00:00<00:00, 163.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  89%|██████████████████████████████████████████████████████▎      | 137/154 [00:00<00:00, 141.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:01<00:00, 148.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 164.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.37s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  12%|███████▏                                                      | 18/154 [00:00<00:00, 179.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▍                                               | 36/154 [00:00<00:00, 175.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▋                                        | 54/154 [00:00<00:00, 173.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|████████████████████████████▉                                 | 72/154 [00:00<00:00, 175.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  58%|████████████████████████████████████▏                         | 90/154 [00:00<00:00, 176.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|██████████████████████████████████████████▊                  | 108/154 [00:00<00:00, 176.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|█████████████████████████████████████████████████▉           | 126/154 [00:00<00:00, 174.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 173.08it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-022_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-022_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-022_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-022\\\\ses-N170\\\\eeg\\\\sub-022_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-022\\\\ses-N170\\\\eeg\\\\sub-022_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-022\\**\\sub-022_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-022_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 155.86it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.50it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 62/147 [00:00<00:00, 615.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 614.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▋                                                    | 23/147 [00:00<00:00, 220.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  31%|███████████████████▍                                          | 46/147 [00:00<00:00, 208.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 67/147 [00:00<00:00, 194.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▋                         | 87/147 [00:00<00:00, 182.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▉                 | 106/147 [00:00<00:00, 181.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 126/147 [00:00<00:00, 185.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 188.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.44s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▋                                                    | 23/147 [00:00<00:00, 223.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  31%|███████████████████▍                                          | 46/147 [00:00<00:00, 210.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▋                                 | 68/147 [00:00<00:00, 194.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████                         | 88/147 [00:00<00:00, 187.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|████████████████████████████████████████████▍                | 107/147 [00:00<00:00, 185.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▋        | 127/147 [00:00<00:00, 188.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 192.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.38s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▋                                                    | 23/147 [00:00<00:00, 217.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  31%|██████████████████▉                                           | 45/147 [00:00<00:00, 209.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▊                                  | 66/147 [00:00<00:00, 196.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▎                         | 86/147 [00:00<00:00, 186.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▌                 | 105/147 [00:00<00:00, 185.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 126/147 [00:00<00:00, 190.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 189.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 172.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.21s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▋                                                    | 23/147 [00:00<00:00, 225.45it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  31%|███████████████████▍                                          | 46/147 [00:00<00:00, 210.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▋                                 | 68/147 [00:00<00:00, 195.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  60%|█████████████████████████████████████                         | 88/147 [00:00<00:00, 187.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|████████████████████████████████████████████▍                | 107/147 [00:00<00:00, 185.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▋        | 127/147 [00:00<00:00, 189.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 191.85it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-023_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-023_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-023_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-023\\\\ses-N170\\\\eeg\\\\sub-023_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-023\\\\ses-N170\\\\eeg\\\\sub-023_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-023\\**\\sub-023_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-023_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 153.47it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.68it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▊                                 | 65/140 [00:00<00:00, 638.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 632.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  15%|█████████▎                                                    | 21/140 [00:00<00:00, 198.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|██████████████████▏                                           | 41/140 [00:00<00:00, 181.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▌                                   | 60/140 [00:00<00:00, 180.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 79/140 [00:00<00:00, 181.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|███████████████████████████████████████████▍                  | 98/140 [00:00<00:00, 184.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|██████████████████████████████████████████████████▉          | 117/140 [00:00<00:00, 183.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 180.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.41s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  15%|█████████▎                                                    | 21/140 [00:00<00:00, 206.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  30%|██████████████████▌                                           | 42/140 [00:00<00:00, 189.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▍                                  | 62/140 [00:00<00:00, 185.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▎                         | 82/140 [00:00<00:00, 188.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████                 | 101/140 [00:00<00:00, 185.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 120/140 [00:00<00:00, 186.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 183.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 20.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 20.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.35s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  15%|█████████▎                                                    | 21/140 [00:00<00:00, 200.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  30%|██████████████████▌                                           | 42/140 [00:00<00:00, 187.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████                                   | 61/140 [00:00<00:00, 183.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▍                          | 80/140 [00:00<00:00, 183.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▌                 | 100/140 [00:00<00:00, 185.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 120/140 [00:00<00:00, 189.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 183.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 175.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.18s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  15%|█████████▎                                                    | 21/140 [00:00<00:00, 198.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|██████████████████▏                                           | 41/140 [00:00<00:00, 181.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▌                                   | 60/140 [00:00<00:00, 179.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 79/140 [00:00<00:00, 180.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▊                  | 99/140 [00:00<00:00, 183.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  85%|███████████████████████████████████████████████████▊         | 119/140 [00:00<00:00, 185.37it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 179.97it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-024_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-024_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-024_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-024\\\\ses-N170\\\\eeg\\\\sub-024_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-024\\\\ses-N170\\\\eeg\\\\sub-024_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-024\\**\\sub-024_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-024_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 154.65it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.58it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▊                                  | 66/147 [00:00<00:00, 655.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 624.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▍                                                     | 20/147 [00:00<00:00, 189.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▎                                            | 41/147 [00:00<00:00, 199.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 67/147 [00:00<00:00, 222.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▍                       | 91/147 [00:00<00:00, 224.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▎             | 114/147 [00:00<00:00, 224.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 210.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.34s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▍                                                     | 20/147 [00:00<00:00, 194.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▎                                            | 41/147 [00:00<00:00, 200.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 67/147 [00:00<00:00, 224.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▍                       | 91/147 [00:00<00:00, 225.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▎             | 114/147 [00:00<00:00, 226.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 212.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.29s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▍                                                     | 20/147 [00:00<00:00, 194.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▎                                            | 41/147 [00:00<00:00, 199.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 67/147 [00:00<00:00, 221.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▍                       | 91/147 [00:00<00:00, 223.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▎             | 114/147 [00:00<00:00, 225.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 206.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 172.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.12s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▍                                                     | 20/147 [00:00<00:00, 192.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▎                                            | 41/147 [00:00<00:00, 200.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▎                                 | 67/147 [00:00<00:00, 224.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▍                       | 91/147 [00:00<00:00, 225.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▋             | 115/147 [00:00<00:00, 225.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 211.39it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-025_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-025_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-025_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-025\\\\ses-N170\\\\eeg\\\\sub-025_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-025\\\\ses-N170\\\\eeg\\\\sub-025_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-025\\**\\sub-025_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-025_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 156.67it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.57it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▌                                   | 63/147 [00:00<00:00, 625.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 594.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▍                                                     | 20/147 [00:00<00:00, 196.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  27%|████████████████▊                                             | 40/147 [00:00<00:00, 180.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  40%|████████████████████████▉                                     | 59/147 [00:00<00:00, 182.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▋                            | 80/147 [00:00<00:00, 190.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▍                   | 100/147 [00:00<00:00, 190.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|█████████████████████████████████████████████████▊           | 120/147 [00:00<00:00, 191.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 190.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.43s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 21/147 [00:00<00:00, 204.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▋                                            | 42/147 [00:00<00:00, 186.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  41%|█████████████████████████▋                                    | 61/147 [00:00<00:00, 184.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▌                           | 82/147 [00:00<00:00, 193.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▎                  | 102/147 [00:00<00:00, 193.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████▍         | 124/147 [00:00<00:00, 201.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 190.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.39s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 21/147 [00:00<00:00, 208.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▋                                            | 42/147 [00:00<00:00, 190.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 62/147 [00:00<00:00, 192.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▍                          | 84/147 [00:00<00:00, 197.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▌                 | 105/147 [00:00<00:00, 198.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 195.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.21s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/147 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 21/147 [00:00<00:00, 200.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▋                                            | 42/147 [00:00<00:00, 186.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  41%|█████████████████████████▋                                    | 61/147 [00:00<00:00, 186.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▌                           | 82/147 [00:00<00:00, 194.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▎                  | 102/147 [00:00<00:00, 195.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  85%|███████████████████████████████████████████████████▊         | 125/147 [00:00<00:00, 205.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 147/147 [00:00<00:00, 194.99it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-026_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-026_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-026_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-026\\\\ses-N170\\\\eeg\\\\sub-026_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-026\\\\ses-N170\\\\eeg\\\\sub-026_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-026\\**\\sub-026_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-026_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 152.69it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:12<00:00,  2.49it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▍                                  | 69/156 [00:00<00:00, 685.00it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 625.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▉                                                  | 30/156 [00:00<00:00, 283.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▍                                      | 59/156 [00:00<00:00, 220.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  53%|████████████████████████████████▌                             | 82/156 [00:00<00:00, 208.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  67%|████████████████████████████████████████▋                    | 104/156 [00:00<00:00, 192.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████▍            | 124/156 [00:00<00:00, 189.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 203.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 16.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 16.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.45s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▌                                                  | 29/156 [00:00<00:00, 282.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|███████████████████████                                       | 58/156 [00:00<00:00, 219.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  52%|████████████████████████████████▏                             | 81/156 [00:00<00:00, 196.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|███████████████████████████████████████▉                     | 102/156 [00:00<00:00, 186.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▎             | 121/156 [00:00<00:00, 185.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 197.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.41s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▌                                                  | 29/156 [00:00<00:00, 279.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▋                                       | 57/156 [00:00<00:00, 209.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▍                              | 79/156 [00:00<00:00, 195.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████                      | 100/156 [00:00<00:00, 185.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  76%|██████████████████████████████████████████████▌              | 119/156 [00:00<00:00, 158.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  87%|█████████████████████████████████████████████████████▏       | 136/156 [00:00<00:00, 160.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 175.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 141.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.27s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/156 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▌                                                  | 29/156 [00:00<00:00, 278.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▋                                       | 57/156 [00:00<00:00, 203.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▍                              | 79/156 [00:00<00:00, 185.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  63%|███████████████████████████████████████▎                      | 99/156 [00:00<00:00, 178.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  76%|██████████████████████████████████████████████▏              | 118/156 [00:00<00:00, 178.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 156/156 [00:00<00:00, 191.79it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-027_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-027_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-027_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-027\\\\ses-N170\\\\eeg\\\\sub-027_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-027\\\\ses-N170\\\\eeg\\\\sub-027_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-027\\**\\sub-027_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-027_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 159.94it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.78it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/135 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|██████████████████████████████▊                               | 67/135 [00:00<00:00, 661.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 652.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/135 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████▏                                              | 33/135 [00:00<00:00, 312.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▊                                | 65/135 [00:00<00:00, 260.34it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  68%|██████████████████████████████████████████▎                   | 92/135 [00:00<00:00, 254.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 242.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.15s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/135 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████▏                                              | 33/135 [00:00<00:00, 318.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▊                                | 65/135 [00:00<00:00, 265.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|██████████████████████████████████████████▋                   | 93/135 [00:00<00:00, 257.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 243.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  50%|██████████████████████████████████████▌                                      | 5/10 [00:00<00:00, 20.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.10s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/135 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████▏                                              | 33/135 [00:00<00:00, 312.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▊                                | 65/135 [00:00<00:00, 248.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  67%|█████████████████████████████████████████▊                    | 91/135 [00:00<00:00, 242.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 237.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 185.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.05it/s]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/135 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████▏                                              | 33/135 [00:00<00:00, 315.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▊                                | 65/135 [00:00<00:00, 260.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|██████████████████████████████████████████▎                   | 92/135 [00:00<00:00, 257.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 135/135 [00:00<00:00, 240.48it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-028_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-028_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-028_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-028\\\\ses-N170\\\\eeg\\\\sub-028_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-028\\\\ses-N170\\\\eeg\\\\sub-028_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-028\\**\\sub-028_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-028_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 160.00it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.74it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/143 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▎                                  | 63/143 [00:00<00:00, 619.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 143/143 [00:00<00:00, 615.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/143 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|███████████▎                                                  | 26/143 [00:00<00:00, 255.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▌                                       | 52/143 [00:00<00:00, 198.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  52%|████████████████████████████████                              | 74/143 [00:00<00:00, 203.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  67%|█████████████████████████████████████████▌                    | 96/143 [00:00<00:00, 206.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 143/143 [00:00<00:00, 223.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.27s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/143 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|███████████▎                                                  | 26/143 [00:00<00:00, 250.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▌                                       | 52/143 [00:00<00:00, 196.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  52%|████████████████████████████████                              | 74/143 [00:00<00:00, 202.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  67%|█████████████████████████████████████████▌                    | 96/143 [00:00<00:00, 208.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 143/143 [00:00<00:00, 223.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 20.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.24s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/143 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  16%|█████████▉                                                    | 23/143 [00:00<00:00, 227.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 46/143 [00:00<00:00, 186.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▌                                 | 66/143 [00:00<00:00, 162.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████▍                      | 91/143 [00:00<00:00, 190.36it/s]\u001b[A\u001b[AC:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\mne\\bem.py:991: RuntimeWarning: Mean of empty slice.\n",
      "  radius_init = radii.mean()\n",
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\numpy\\core\\_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n",
      "\n",
      "\n",
      "Repairing epochs:  78%|███████████████████████████████████████████████▎             | 111/143 [00:00<00:00, 191.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 143/143 [00:00<00:00, 204.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.09s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/143 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▊                                                   | 25/143 [00:00<00:00, 245.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▋                                        | 50/143 [00:00<00:00, 189.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▎                               | 70/143 [00:00<00:00, 187.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▎                     | 93/143 [00:00<00:00, 200.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▋            | 114/143 [00:00<00:00, 195.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 143/143 [00:00<00:00, 205.42it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-029_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-029_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-029_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-029\\\\ses-N170\\\\eeg\\\\sub-029_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-029\\\\ses-N170\\\\eeg\\\\sub-029_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-029\\**\\sub-029_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-029_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 160.58it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.76it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  47%|████████████████████████████▉                                 | 65/139 [00:00<00:00, 645.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 619.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▍                                                     | 19/139 [00:00<00:00, 183.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  27%|████████████████▉                                             | 38/139 [00:00<00:00, 183.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▎                                   | 59/139 [00:00<00:00, 190.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▏                          | 79/139 [00:00<00:00, 186.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▋                  | 98/139 [00:00<00:00, 182.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████▎         | 117/139 [00:00<00:00, 176.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 179.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.41s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▉                                                     | 20/139 [00:00<00:00, 190.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▊                                            | 40/139 [00:00<00:00, 188.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▎                                   | 59/139 [00:00<00:00, 181.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▊                           | 78/139 [00:00<00:00, 181.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|███████████████████████████████████████████▎                  | 97/139 [00:00<00:00, 181.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▉          | 116/139 [00:00<00:00, 177.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 180.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 20.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 20.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.36s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▉                                                     | 20/139 [00:00<00:00, 189.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▍                                            | 39/139 [00:00<00:00, 187.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▎                                   | 59/139 [00:00<00:00, 192.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▏                          | 79/139 [00:00<00:00, 187.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▋                  | 98/139 [00:00<00:00, 185.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████▎         | 117/139 [00:00<00:00, 177.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 181.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 172.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.19s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/139 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▉                                                     | 20/139 [00:00<00:00, 188.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▊                                            | 40/139 [00:00<00:00, 189.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▏                                  | 61/139 [00:00<00:00, 193.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  58%|████████████████████████████████████▏                         | 81/139 [00:00<00:00, 191.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|████████████████████████████████████████████▎                | 101/139 [00:00<00:00, 182.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▋        | 120/139 [00:00<00:00, 177.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 139/139 [00:00<00:00, 183.05it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-030_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-030_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-030_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-030\\\\ses-N170\\\\eeg\\\\sub-030_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-030\\\\ses-N170\\\\eeg\\\\sub-030_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-030\\**\\sub-030_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-030_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 156.29it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.63it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|████████████████████████████                                  | 67/148 [00:00<00:00, 665.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 645.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|███████████████▉                                              | 38/148 [00:00<00:00, 377.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▊                              | 76/148 [00:00<00:00, 305.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|████████████████████████████████████████████▌                | 108/148 [00:00<00:00, 261.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 256.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.20s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████                                               | 36/148 [00:00<00:00, 357.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▏                               | 72/148 [00:00<00:00, 307.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|██████████████████████████████████████████▊                  | 104/148 [00:00<00:00, 272.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 256.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.16s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████                                               | 36/148 [00:00<00:00, 352.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▏                               | 72/148 [00:00<00:00, 289.97it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  69%|██████████████████████████████████████████                   | 102/148 [00:00<00:00, 262.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 244.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.00s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▌                                              | 37/148 [00:00<00:00, 367.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████                               | 74/148 [00:00<00:00, 306.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▋                 | 106/148 [00:00<00:00, 264.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 256.49it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-031_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-031_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-031_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-031\\\\ses-N170\\\\eeg\\\\sub-031_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-031\\\\ses-N170\\\\eeg\\\\sub-031_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-031\\**\\sub-031_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-031_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 156.67it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.74it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▋                                  | 66/148 [00:00<00:00, 648.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 618.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|███████▉                                                      | 19/148 [00:00<00:00, 183.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|███████████████▉                                              | 38/148 [00:00<00:00, 175.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|███████████████████████▉                                      | 57/148 [00:00<00:00, 178.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▊                              | 76/148 [00:00<00:00, 178.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████▍                      | 94/148 [00:00<00:00, 178.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  76%|██████████████████████████████████████████████▏              | 112/148 [00:00<00:00, 172.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  88%|█████████████████████████████████████████████████████▌       | 130/148 [00:00<00:00, 168.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 171.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:03,  1.53s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|███████▉                                                      | 19/148 [00:00<00:00, 184.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|███████████████▉                                              | 38/148 [00:00<00:00, 178.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|███████████████████████▉                                      | 57/148 [00:00<00:00, 182.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▊                              | 76/148 [00:00<00:00, 181.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████▊                      | 95/148 [00:00<00:00, 180.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  77%|██████████████████████████████████████████████▉              | 114/148 [00:00<00:00, 176.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 175.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.47s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|███████▉                                                      | 19/148 [00:00<00:00, 186.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|███████████████▉                                              | 38/148 [00:00<00:00, 179.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▍                                      | 56/148 [00:00<00:00, 169.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▍                              | 75/148 [00:00<00:00, 173.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  64%|███████████████████████████████████████▍                      | 94/148 [00:00<00:00, 176.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  76%|██████████████████████████████████████████████▏              | 112/148 [00:00<00:00, 171.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  88%|█████████████████████████████████████████████████████▌       | 130/148 [00:00<00:00, 169.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 170.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 170.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.30s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▌                                                      | 18/148 [00:00<00:00, 178.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|███████████████                                               | 36/148 [00:00<00:00, 175.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▌                                       | 54/148 [00:00<00:00, 174.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▏                               | 72/148 [00:00<00:00, 176.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▌                       | 92/148 [00:00<00:00, 181.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  75%|█████████████████████████████████████████████▊               | 111/148 [00:00<00:00, 175.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  87%|█████████████████████████████████████████████████████▏       | 129/148 [00:00<00:00, 169.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 171.93it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-032_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-032_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-032_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-032\\\\ses-N170\\\\eeg\\\\sub-032_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-032\\\\ses-N170\\\\eeg\\\\sub-032_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-032\\**\\sub-032_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-032_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 155.86it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.65it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 65/154 [00:00<00:00, 645.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 632.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 18/154 [00:00<00:00, 171.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▍                                               | 36/154 [00:00<00:00, 175.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▏                                       | 55/154 [00:00<00:00, 180.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▏                               | 75/154 [00:00<00:00, 184.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▊                        | 94/154 [00:00<00:00, 180.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  74%|█████████████████████████████████████████████▏               | 114/154 [00:00<00:00, 185.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 188.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 16.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 16.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.48s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 18/154 [00:00<00:00, 171.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▍                                               | 36/154 [00:00<00:00, 174.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▏                                       | 55/154 [00:00<00:00, 179.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▏                               | 75/154 [00:00<00:00, 185.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▊                        | 94/154 [00:00<00:00, 184.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  74%|█████████████████████████████████████████████▏               | 114/154 [00:00<00:00, 188.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 189.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.43s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 18/154 [00:00<00:00, 175.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  23%|██████████████▍                                               | 36/154 [00:00<00:00, 177.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▏                                       | 55/154 [00:00<00:00, 180.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▏                               | 75/154 [00:00<00:00, 185.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  61%|█████████████████████████████████████▊                        | 94/154 [00:00<00:00, 182.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  74%|█████████████████████████████████████████████▏               | 114/154 [00:00<00:00, 187.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 188.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 164.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.25s/it]\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:   0%|                                                                        | 0/154 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▏                                                      | 18/154 [00:00<00:00, 173.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  24%|██████████████▉                                               | 37/154 [00:00<00:00, 178.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  36%|██████████████████████▌                                       | 56/154 [00:00<00:00, 181.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▌                               | 76/154 [00:00<00:00, 186.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  62%|██████████████████████████████████████▏                       | 95/154 [00:00<00:00, 186.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  75%|█████████████████████████████████████████████▌               | 115/154 [00:00<00:00, 189.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 154/154 [00:00<00:00, 189.84it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-033_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-033_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-033_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-033\\\\ses-N170\\\\eeg\\\\sub-033_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-033\\\\ses-N170\\\\eeg\\\\sub-033_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-033\\**\\sub-033_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-033_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 155.03it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:12<00:00,  2.50it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▍                                   | 67/157 [00:00<00:00, 665.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 639.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▏                                                 | 31/157 [00:00<00:00, 298.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████                                      | 61/157 [00:00<00:00, 225.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▌                            | 85/157 [00:00<00:00, 216.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|█████████████████████████████████████████▉                   | 108/157 [00:00<00:00, 206.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|██████████████████████████████████████████████████           | 129/157 [00:00<00:00, 197.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 202.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 16.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 16.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 16.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 16.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.45s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  20%|████████████▏                                                 | 31/157 [00:00<00:00, 295.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████                                      | 61/157 [00:00<00:00, 225.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▌                            | 85/157 [00:00<00:00, 219.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  69%|█████████████████████████████████████████▉                   | 108/157 [00:00<00:00, 210.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▌          | 130/157 [00:00<00:00, 202.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 205.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.41s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▊                                                  | 30/157 [00:00<00:00, 291.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▋                                      | 60/157 [00:00<00:00, 226.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▏                            | 84/157 [00:00<00:00, 211.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▏                   | 106/157 [00:00<00:00, 194.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▉            | 126/157 [00:00<00:00, 192.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 196.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 161.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.23s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/157 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▊                                                  | 30/157 [00:00<00:00, 294.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▋                                      | 60/157 [00:00<00:00, 220.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▏                            | 84/157 [00:00<00:00, 210.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▏                   | 106/157 [00:00<00:00, 198.47it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  81%|█████████████████████████████████████████████████▎           | 127/157 [00:00<00:00, 193.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 157/157 [00:00<00:00, 194.58it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-034_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-034_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-034_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-034\\\\ses-N170\\\\eeg\\\\sub-034_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-034\\\\ses-N170\\\\eeg\\\\sub-034_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-034\\**\\sub-034_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-034_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 156.33it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.55it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▍                                 | 67/146 [00:00<00:00, 658.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 651.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▋                                                      | 18/146 [00:00<00:00, 175.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▋                                              | 37/146 [00:00<00:00, 183.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████▏                                     | 57/146 [00:00<00:00, 190.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  53%|████████████████████████████████▋                             | 77/146 [00:00<00:00, 182.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  66%|█████████████████████████████████████████▏                    | 97/146 [00:00<00:00, 187.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  80%|████████████████████████████████████████████████▉            | 117/146 [00:00<00:00, 190.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 190.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.39s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▋                                                      | 18/146 [00:00<00:00, 173.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████▏                                             | 38/146 [00:00<00:00, 185.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  40%|████████████████████████▋                                     | 58/146 [00:00<00:00, 189.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  53%|████████████████████████████████▋                             | 77/146 [00:00<00:00, 181.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  66%|█████████████████████████████████████████▏                    | 97/146 [00:00<00:00, 186.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████▍            | 116/146 [00:00<00:00, 185.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 189.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 20.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.35s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▋                                                      | 18/146 [00:00<00:00, 175.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  25%|███████████████▎                                              | 36/146 [00:00<00:00, 177.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  39%|████████████████████████▏                                     | 57/146 [00:00<00:00, 188.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  52%|████████████████████████████████▎                             | 76/146 [00:00<00:00, 180.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  66%|████████████████████████████████████████▊                     | 96/146 [00:00<00:00, 185.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████             | 115/146 [00:00<00:00, 184.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 187.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 175.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.19s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  12%|███████▋                                                      | 18/146 [00:00<00:00, 171.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  26%|████████████████▏                                             | 38/146 [00:00<00:00, 183.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  40%|████████████████████████▋                                     | 58/146 [00:00<00:00, 187.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  53%|████████████████████████████████▋                             | 77/146 [00:00<00:00, 180.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  66%|█████████████████████████████████████████▏                    | 97/146 [00:00<00:00, 185.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████▍            | 116/146 [00:00<00:00, 186.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 188.98it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-035_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-035_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-035_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-035\\\\ses-N170\\\\eeg\\\\sub-035_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-035\\\\ses-N170\\\\eeg\\\\sub-035_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-035\\**\\sub-035_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-035_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 162.59it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.70it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/122 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 647.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/122 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▋                                                     | 17/122 [00:00<00:00, 162.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▊                                            | 35/122 [00:00<00:00, 171.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▉                                   | 53/122 [00:00<00:00, 170.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  58%|████████████████████████████████████                          | 71/122 [00:00<00:00, 168.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████▋                 | 88/122 [00:00<00:00, 166.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▌        | 105/122 [00:00<00:00, 165.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 166.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 21.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 21.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 21.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.29s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/122 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▋                                                     | 17/122 [00:00<00:00, 167.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  30%|██████████████████▎                                           | 36/122 [00:00<00:00, 174.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▍                                  | 54/122 [00:00<00:00, 172.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▌                         | 72/122 [00:00<00:00, 169.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|█████████████████████████████████████████████▏                | 89/122 [00:00<00:00, 167.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 168.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 23.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 23.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 23.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.25s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/122 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▋                                                     | 17/122 [00:00<00:00, 164.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▊                                            | 35/122 [00:00<00:00, 170.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▉                                   | 53/122 [00:00<00:00, 169.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▌                          | 70/122 [00:00<00:00, 168.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|████████████████████████████████████████████▏                 | 87/122 [00:00<00:00, 167.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▌        | 105/122 [00:00<00:00, 168.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 168.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 200.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.10s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/122 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▋                                                     | 17/122 [00:00<00:00, 167.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▊                                            | 35/122 [00:00<00:00, 173.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▉                                   | 53/122 [00:00<00:00, 172.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  58%|████████████████████████████████████                          | 71/122 [00:00<00:00, 169.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████▋                 | 88/122 [00:00<00:00, 167.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 122/122 [00:00<00:00, 169.36it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-036_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-036_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-036_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-036\\\\ses-N170\\\\eeg\\\\sub-036_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-036\\\\ses-N170\\\\eeg\\\\sub-036_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-036\\**\\sub-036_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-036_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 155.05it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.53it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/152 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  44%|███████████████████████████▎                                  | 67/152 [00:00<00:00, 665.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 152/152 [00:00<00:00, 637.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/152 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▉                                                     | 22/152 [00:00<00:00, 210.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 49/152 [00:00<00:00, 240.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████                               | 76/152 [00:00<00:00, 248.67it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:  66%|████████████████████████████████████████▌                    | 101/152 [00:00<00:00, 243.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▌          | 126/152 [00:00<00:00, 214.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 152/152 [00:00<00:00, 222.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.32s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/152 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▉                                                     | 22/152 [00:00<00:00, 212.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 49/152 [00:00<00:00, 237.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  49%|██████████████████████████████▌                               | 75/152 [00:00<00:00, 246.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  66%|████████████████████████████████████████▏                    | 100/152 [00:00<00:00, 244.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|██████████████████████████████████████████████████▏          | 125/152 [00:00<00:00, 214.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 152/152 [00:00<00:00, 221.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.27s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/152 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▉                                                     | 22/152 [00:00<00:00, 212.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 49/152 [00:00<00:00, 237.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  48%|█████████████████████████████▊                                | 73/152 [00:00<00:00, 233.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▍                     | 99/152 [00:00<00:00, 242.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  82%|█████████████████████████████████████████████████▊           | 124/152 [00:00<00:00, 213.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 152/152 [00:00<00:00, 218.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 167.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.11s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/152 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▉                                                     | 22/152 [00:00<00:00, 210.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  32%|███████████████████▉                                          | 49/152 [00:00<00:00, 238.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████                               | 76/152 [00:00<00:00, 247.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  66%|████████████████████████████████████████▌                    | 101/152 [00:00<00:00, 240.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▌          | 126/152 [00:00<00:00, 213.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 152/152 [00:00<00:00, 221.23it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-037_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-037_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-037_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-037\\\\ses-N170\\\\eeg\\\\sub-037_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-037\\\\ses-N170\\\\eeg\\\\sub-037_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-037\\**\\sub-037_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-037_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 155.09it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.56it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|████████████████████████████                                  | 66/146 [00:00<00:00, 655.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 631.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▉                                                  | 28/146 [00:00<00:00, 271.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▊                                      | 56/146 [00:00<00:00, 244.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  55%|██████████████████████████████████▍                           | 81/146 [00:00<00:00, 236.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▊                 | 105/146 [00:00<00:00, 237.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 240.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.22s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▉                                                  | 28/146 [00:00<00:00, 267.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▎                                      | 55/146 [00:00<00:00, 245.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  55%|█████████████████████████████████▉                            | 80/146 [00:00<00:00, 242.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▊                 | 105/146 [00:00<00:00, 238.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 241.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.18s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|███████████▍                                                  | 27/146 [00:00<00:00, 268.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▉                                       | 54/146 [00:00<00:00, 242.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▌                            | 79/146 [00:00<00:00, 241.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▍                 | 104/146 [00:00<00:00, 235.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 239.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 172.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.02s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/146 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  19%|███████████▉                                                  | 28/146 [00:00<00:00, 272.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  38%|███████████████████████▊                                      | 56/146 [00:00<00:00, 245.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  55%|██████████████████████████████████▍                           | 81/146 [00:00<00:00, 238.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▊                 | 105/146 [00:00<00:00, 238.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 146/146 [00:00<00:00, 240.61it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-038_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-038_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-038_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-038\\\\ses-N170\\\\eeg\\\\sub-038_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-038\\\\ses-N170\\\\eeg\\\\sub-038_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-038\\**\\sub-038_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-038_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 157.49it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.68it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|████████████████████████████                                  | 67/148 [00:00<00:00, 665.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 650.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 21/148 [00:00<00:00, 206.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▌                                            | 42/148 [00:00<00:00, 200.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▍                                   | 63/148 [00:00<00:00, 198.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▏                          | 84/148 [00:00<00:00, 203.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████                 | 107/148 [00:00<00:00, 209.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 202.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 17.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 17.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 17.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 17.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 17.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.36s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 21/148 [00:00<00:00, 200.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▌                                            | 42/148 [00:00<00:00, 199.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  43%|██████████████████████████▍                                   | 63/148 [00:00<00:00, 199.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▏                          | 84/148 [00:00<00:00, 201.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████                 | 107/148 [00:00<00:00, 208.15it/s]\u001b[A\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 201.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 19.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 19.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 19.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 19.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 19.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.32s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 21/148 [00:00<00:00, 202.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▌                                            | 42/148 [00:00<00:00, 196.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|█████████████████████████▉                                    | 62/148 [00:00<00:00, 197.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  57%|███████████████████████████████████▏                          | 84/148 [00:00<00:00, 201.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|███████████████████████████████████████████▋                 | 106/148 [00:00<00:00, 207.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 127/148 [00:00<00:00, 199.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 199.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 169.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.16s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/148 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 21/148 [00:00<00:00, 199.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▏                                            | 41/148 [00:00<00:00, 198.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  41%|█████████████████████████▌                                    | 61/148 [00:00<00:00, 197.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  55%|██████████████████████████████████▎                           | 82/148 [00:00<00:00, 201.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▎                 | 105/148 [00:00<00:00, 208.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  85%|███████████████████████████████████████████████████▉         | 126/148 [00:00<00:00, 199.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 148/148 [00:00<00:00, 200.32it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-039_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-039_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-039_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-039\\\\ses-N170\\\\eeg\\\\sub-039_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-039\\\\ses-N170\\\\eeg\\\\sub-039_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-039\\**\\sub-039_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-039_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 158.60it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:10<00:00,  2.74it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▉                                  | 63/140 [00:00<00:00, 625.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 613.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 20/140 [00:00<00:00, 193.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▋                                            | 40/140 [00:00<00:00, 183.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 59/140 [00:00<00:00, 180.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▌                           | 78/140 [00:00<00:00, 182.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|███████████████████████████████████████████▍                  | 98/140 [00:00<00:00, 186.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|██████████████████████████████████████████████████▉          | 117/140 [00:00<00:00, 182.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 182.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.39s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 20/140 [00:00<00:00, 190.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▋                                            | 40/140 [00:00<00:00, 185.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 59/140 [00:00<00:00, 183.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 79/140 [00:00<00:00, 187.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▌                 | 100/140 [00:00<00:00, 190.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 120/140 [00:00<00:00, 186.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 187.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 20.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 20.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.34s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 20/140 [00:00<00:00, 195.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▋                                            | 40/140 [00:00<00:00, 182.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 59/140 [00:00<00:00, 182.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 79/140 [00:00<00:00, 185.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▊                  | 99/140 [00:00<00:00, 187.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████▍         | 118/140 [00:00<00:00, 184.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 181.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 175.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.18s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/140 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▊                                                     | 20/140 [00:00<00:00, 192.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  29%|█████████████████▋                                            | 40/140 [00:00<00:00, 186.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 59/140 [00:00<00:00, 184.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 79/140 [00:00<00:00, 187.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  71%|███████████████████████████████████████████▌                 | 100/140 [00:00<00:00, 191.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▎        | 120/140 [00:00<00:00, 189.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 140/140 [00:00<00:00, 187.78it/s]\u001b[A\u001b[A\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Data file name in EEG.data (sub-040_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-040_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Expected to find a single channels file associated with sub-040_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-040\\\\ses-N170\\\\eeg\\\\sub-040_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-040\\\\ses-N170\\\\eeg\\\\sub-040_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-040\\**\\sub-040_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-32-ed1cd67b1fc2>:10: RuntimeWarning: Participants file not found for sub-040_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "Creating augmented epochs: 100%|██████████████████████████████████████████████████████| 30/30 [00:00<00:00, 157.69it/s]\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:11<00:00,  2.58it/s]\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/142 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  46%|████████████████████████████▍                                 | 65/142 [00:00<00:00, 648.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 636.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/142 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  14%|████████▋                                                     | 20/142 [00:00<00:00, 188.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  30%|██████████████████▊                                           | 43/142 [00:00<00:00, 206.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  45%|███████████████████████████▉                                  | 64/142 [00:00<00:00, 191.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  59%|████████████████████████████████████▋                         | 84/142 [00:00<00:00, 189.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  73%|████████████████████████████████████████████▏                | 103/142 [00:00<00:00, 188.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  86%|████████████████████████████████████████████████████▍        | 122/142 [00:00<00:00, 186.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 188.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:00, 18.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 18.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 18.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:00<00:00, 18.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 18.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:01<00:02,  1.39s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/142 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████▎                                                     | 19/142 [00:00<00:00, 186.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▍                                            | 40/142 [00:00<00:00, 199.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 60/142 [00:00<00:00, 197.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 80/142 [00:00<00:00, 190.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|██████████████████████████████████████████▉                  | 100/142 [00:00<00:00, 188.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████          | 119/142 [00:00<00:00, 188.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 188.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:00, 20.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:00<00:00, 20.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 20.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:02<00:01,  1.34s/it]\u001b[A\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repairing epochs:   0%|                                                                        | 0/142 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████▎                                                     | 19/142 [00:00<00:00, 188.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▍                                            | 40/142 [00:00<00:00, 196.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 60/142 [00:00<00:00, 192.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 80/142 [00:00<00:00, 188.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|██████████████████████████████████████████▉                  | 100/142 [00:00<00:00, 189.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  84%|███████████████████████████████████████████████████          | 119/142 [00:00<00:00, 188.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 189.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold: 100%|███████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 180.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:03<00:00,  1.17s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/142 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  13%|████████▎                                                     | 19/142 [00:00<00:00, 186.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  28%|█████████████████▍                                            | 40/142 [00:00<00:00, 199.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  42%|██████████████████████████▏                                   | 60/142 [00:00<00:00, 193.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  56%|██████████████████████████████████▉                           | 80/142 [00:00<00:00, 189.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|███████████████████████████████████████████▏                  | 99/142 [00:00<00:00, 188.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|██████████████████████████████████████████████████▋          | 118/142 [00:00<00:00, 188.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 142/142 [00:00<00:00, 188.33it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 19787520 into shape (2576,256,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-61074727e8f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpreprocessing\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"light\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"medium\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"heavy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"preprocessing\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"data_path\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/Dataframes/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"task\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_ds128_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"preprocessing\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-ed1cd67b1fc2>\u001b[0m in \u001b[0;36mcreate_df\u001b[1;34m(parameters)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;31m# reshape data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_window_samples\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"input_window_samples\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;31m# create labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 19787520 into shape (2576,256,newaxis)"
     ]
    }
   ],
   "source": [
    "# TODO: put this in a function\n",
    "for task in [\"N170\", \"N400\", \"P3\"]:\n",
    "    parameters[\"task\"] = task\n",
    "    for preprocessing in [\"light\", \"medium\", \"heavy\"]:\n",
    "        parameters[\"preprocessing\"] = preprocessing\n",
    "        df = create_df(parameters)\n",
    "        df.to_pickle(parameters[\"data_path\"]+\"/Dataframes/\"+parameters[\"task\"]+\"_ds128_\"+parameters[\"preprocessing\"]+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2b667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b01238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78255d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bed6dcc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 1 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6965\u001b[0m                     \u001b[32m0.6979\u001b[0m        \u001b[35m0.6798\u001b[0m            \u001b[31m0.6716\u001b[0m                     \u001b[94m0.6730\u001b[0m        \u001b[36m0.6513\u001b[0m  0.0010  6.0309\n",
      "      2            \u001b[36m0.7140\u001b[0m                     \u001b[32m0.7151\u001b[0m        \u001b[35m0.5948\u001b[0m            \u001b[31m0.7131\u001b[0m                     \u001b[94m0.7142\u001b[0m        \u001b[36m0.6165\u001b[0m  0.0010  5.4694\n",
      "      3            \u001b[36m0.7406\u001b[0m                     \u001b[32m0.7411\u001b[0m        \u001b[35m0.5650\u001b[0m            \u001b[31m0.7174\u001b[0m                     \u001b[94m0.7179\u001b[0m        \u001b[36m0.5766\u001b[0m  0.0010  5.5192\n",
      "      4            \u001b[36m0.7538\u001b[0m                     \u001b[32m0.7540\u001b[0m        \u001b[35m0.5442\u001b[0m            \u001b[31m0.7347\u001b[0m                     \u001b[94m0.7350\u001b[0m        \u001b[36m0.5573\u001b[0m  0.0010  5.5202\n",
      "      5            0.7523                     0.7533        \u001b[35m0.5357\u001b[0m            \u001b[31m0.7424\u001b[0m                     \u001b[94m0.7435\u001b[0m        \u001b[36m0.5440\u001b[0m  0.0010  5.6788\n",
      "      6            \u001b[36m0.7717\u001b[0m                     \u001b[32m0.7715\u001b[0m        \u001b[35m0.5162\u001b[0m            \u001b[31m0.7606\u001b[0m                     \u001b[94m0.7603\u001b[0m        \u001b[36m0.5212\u001b[0m  0.0009  5.5741\n",
      "      7            \u001b[36m0.7741\u001b[0m                     \u001b[32m0.7742\u001b[0m        \u001b[35m0.5119\u001b[0m            0.7563                     0.7563        \u001b[36m0.5148\u001b[0m  0.0009  5.6250\n",
      "      8            \u001b[36m0.7832\u001b[0m                     \u001b[32m0.7833\u001b[0m        \u001b[35m0.5014\u001b[0m            0.7563                     0.7565        0.5224  0.0009  5.5153\n",
      "      9            \u001b[36m0.7843\u001b[0m                     \u001b[32m0.7839\u001b[0m        \u001b[35m0.4933\u001b[0m            0.7563                     0.7560        \u001b[36m0.5142\u001b[0m  0.0009  5.5202\n",
      "     10            \u001b[36m0.7923\u001b[0m                     \u001b[32m0.7923\u001b[0m        0.4960            0.7528                     0.7529        \u001b[36m0.5109\u001b[0m  0.0008  5.5342\n",
      "     11            \u001b[36m0.7944\u001b[0m                     \u001b[32m0.7946\u001b[0m        \u001b[35m0.4874\u001b[0m            \u001b[31m0.7632\u001b[0m                     \u001b[94m0.7634\u001b[0m        \u001b[36m0.5102\u001b[0m  0.0008  5.5362\n",
      "     12            \u001b[36m0.7955\u001b[0m                     \u001b[32m0.7954\u001b[0m        \u001b[35m0.4802\u001b[0m            \u001b[31m0.7710\u001b[0m                     \u001b[94m0.7710\u001b[0m        \u001b[36m0.5016\u001b[0m  0.0008  5.6120\n",
      "     13            \u001b[36m0.8018\u001b[0m                     \u001b[32m0.8019\u001b[0m        \u001b[35m0.4775\u001b[0m            \u001b[31m0.7736\u001b[0m                     \u001b[94m0.7736\u001b[0m        \u001b[36m0.4996\u001b[0m  0.0007  5.5043\n",
      "     14            \u001b[36m0.8039\u001b[0m                     \u001b[32m0.8042\u001b[0m        0.4780            0.7675                     0.7678        0.5043  0.0007  5.5043\n",
      "     15            \u001b[36m0.8063\u001b[0m                     \u001b[32m0.8060\u001b[0m        \u001b[35m0.4710\u001b[0m            0.7675                     0.7672        0.5026  0.0006  5.5083\n",
      "     16            \u001b[36m0.8076\u001b[0m                     \u001b[32m0.8077\u001b[0m        \u001b[35m0.4619\u001b[0m            0.7736                     \u001b[94m0.7737\u001b[0m        0.5085  0.0006  5.5033\n",
      "     17            0.8026                     0.8026        \u001b[35m0.4560\u001b[0m            0.7718                     0.7717        \u001b[36m0.4927\u001b[0m  0.0005  5.5202\n",
      "     18            0.8074                     0.8072        0.4648            0.7666                     0.7666        0.5017  0.0005  5.5063\n",
      "     19            \u001b[36m0.8113\u001b[0m                     \u001b[32m0.8112\u001b[0m        \u001b[35m0.4508\u001b[0m            \u001b[31m0.7796\u001b[0m                     \u001b[94m0.7795\u001b[0m        0.4984  0.0005  5.5292\n",
      "     20            0.8061                     0.8059        \u001b[35m0.4500\u001b[0m            0.7684                     0.7681        0.4994  0.0004  5.5093\n",
      "     21            0.8076                     0.8076        0.4527            0.7779                     0.7780        \u001b[36m0.4892\u001b[0m  0.0004  5.5372\n",
      "     22            \u001b[36m0.8124\u001b[0m                     \u001b[32m0.8125\u001b[0m        \u001b[35m0.4495\u001b[0m            0.7753                     0.7754        0.4985  0.0003  5.5093\n",
      "     23            0.8100                     0.8099        0.4533            0.7796                     0.7795        0.4929  0.0003  5.5182\n",
      "     24            \u001b[36m0.8126\u001b[0m                     0.8125        \u001b[35m0.4455\u001b[0m            0.7736                     0.7735        0.4935  0.0002  5.5232\n",
      "     25            \u001b[36m0.8141\u001b[0m                     \u001b[32m0.8140\u001b[0m        \u001b[35m0.4333\u001b[0m            0.7796                     0.7795        0.4941  0.0002  5.5053\n",
      "     26            0.8130                     0.8131        0.4360            0.7718                     0.7720        0.4961  0.0002  5.5133\n",
      "     27            0.8139                     0.8138        0.4442            0.7753                     0.7752        0.4960  0.0001  5.4973\n",
      "     28            0.8132                     0.8132        0.4470            0.7770                     0.7771        0.4960  0.0001  5.5182\n",
      "     29            \u001b[36m0.8150\u001b[0m                     \u001b[32m0.8150\u001b[0m        0.4378            0.7787                     0.7787        0.4940  0.0001  5.5282\n",
      "     30            \u001b[36m0.8158\u001b[0m                     \u001b[32m0.8158\u001b[0m        0.4339            \u001b[31m0.7805\u001b[0m                     \u001b[94m0.7804\u001b[0m        0.4941  0.0001  5.5631\n",
      "     31            0.8158                     \u001b[32m0.8158\u001b[0m        \u001b[35m0.4289\u001b[0m            0.7787                     0.7788        0.4944  0.0000  5.5551\n",
      "     32            \u001b[36m0.8160\u001b[0m                     \u001b[32m0.8161\u001b[0m        0.4313            0.7787                     0.7788        0.4944  0.0000  5.6020\n",
      "     33            0.8154                     0.8154        0.4367            0.7787                     0.7788        0.4943  0.0000  5.6489\n",
      "     34            0.8152                     0.8152        0.4348            0.7787                     0.7788        0.4942  0.0000  5.5761\n",
      "     35            0.8154                     0.8154        0.4362            0.7805                     \u001b[94m0.7805\u001b[0m        0.4943  0.0000  5.5541\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7036\u001b[0m                     \u001b[32m0.7049\u001b[0m        \u001b[35m0.6785\u001b[0m            \u001b[31m0.6828\u001b[0m                     \u001b[94m0.6843\u001b[0m        \u001b[36m0.6469\u001b[0m  0.0010  5.5382\n",
      "      2            \u001b[36m0.7294\u001b[0m                     \u001b[32m0.7302\u001b[0m        \u001b[35m0.5883\u001b[0m            \u001b[31m0.7053\u001b[0m                     \u001b[94m0.7063\u001b[0m        \u001b[36m0.6090\u001b[0m  0.0010  5.5053\n",
      "      3            \u001b[36m0.7445\u001b[0m                     \u001b[32m0.7451\u001b[0m        \u001b[35m0.5677\u001b[0m            \u001b[31m0.7347\u001b[0m                     \u001b[94m0.7354\u001b[0m        \u001b[36m0.5692\u001b[0m  0.0010  5.5202\n",
      "      4            \u001b[36m0.7542\u001b[0m                     \u001b[32m0.7545\u001b[0m        \u001b[35m0.5525\u001b[0m            0.7312                     0.7316        \u001b[36m0.5437\u001b[0m  0.0010  5.5182\n",
      "      5            \u001b[36m0.7616\u001b[0m                     \u001b[32m0.7616\u001b[0m        \u001b[35m0.5333\u001b[0m            0.7303                     0.7304        \u001b[36m0.5221\u001b[0m  0.0010  5.5412\n",
      "      6            \u001b[36m0.7700\u001b[0m                     \u001b[32m0.7699\u001b[0m        \u001b[35m0.5204\u001b[0m            \u001b[31m0.7563\u001b[0m                     \u001b[94m0.7563\u001b[0m        \u001b[36m0.5079\u001b[0m  0.0009  5.5282\n",
      "      7            \u001b[36m0.7750\u001b[0m                     \u001b[32m0.7751\u001b[0m        \u001b[35m0.5088\u001b[0m            0.7519                     0.7522        \u001b[36m0.5004\u001b[0m  0.0009  5.5512\n",
      "      8            \u001b[36m0.7791\u001b[0m                     \u001b[32m0.7789\u001b[0m        \u001b[35m0.5004\u001b[0m            0.7511                     0.7511        0.5010  0.0009  5.5432\n",
      "      9            \u001b[36m0.7892\u001b[0m                     \u001b[32m0.7891\u001b[0m        \u001b[35m0.4942\u001b[0m            0.7545                     0.7545        \u001b[36m0.4856\u001b[0m  0.0009  5.5711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10            \u001b[36m0.7899\u001b[0m                     \u001b[32m0.7896\u001b[0m        \u001b[35m0.4880\u001b[0m            \u001b[31m0.7597\u001b[0m                     \u001b[94m0.7597\u001b[0m        0.4921  0.0008  5.5901\n",
      "     11            \u001b[36m0.7953\u001b[0m                     \u001b[32m0.7950\u001b[0m        0.4898            \u001b[31m0.7623\u001b[0m                     \u001b[94m0.7621\u001b[0m        0.4856  0.0008  5.6260\n",
      "     12            0.7951                     0.7950        \u001b[35m0.4801\u001b[0m            0.7623                     \u001b[94m0.7622\u001b[0m        \u001b[36m0.4808\u001b[0m  0.0008  5.6289\n",
      "     13            \u001b[36m0.8057\u001b[0m                     \u001b[32m0.8056\u001b[0m        \u001b[35m0.4797\u001b[0m            \u001b[31m0.7649\u001b[0m                     \u001b[94m0.7648\u001b[0m        \u001b[36m0.4789\u001b[0m  0.0007  5.6449\n",
      "     14            0.8037                     0.8034        \u001b[35m0.4708\u001b[0m            \u001b[31m0.7710\u001b[0m                     \u001b[94m0.7706\u001b[0m        \u001b[36m0.4758\u001b[0m  0.0007  5.6459\n",
      "     15            \u001b[36m0.8063\u001b[0m                     \u001b[32m0.8066\u001b[0m        \u001b[35m0.4646\u001b[0m            \u001b[31m0.7744\u001b[0m                     \u001b[94m0.7750\u001b[0m        0.4784  0.0006  5.6130\n",
      "     16            \u001b[36m0.8070\u001b[0m                     \u001b[32m0.8070\u001b[0m        0.4677            \u001b[31m0.7796\u001b[0m                     \u001b[94m0.7796\u001b[0m        0.4787  0.0006  5.4893\n",
      "     17            0.8026                     0.8022        \u001b[35m0.4640\u001b[0m            0.7623                     0.7619        0.4783  0.0005  5.4953\n",
      "     18            \u001b[36m0.8126\u001b[0m                     \u001b[32m0.8123\u001b[0m        \u001b[35m0.4602\u001b[0m            0.7744                     0.7742        \u001b[36m0.4751\u001b[0m  0.0005  5.5033\n",
      "     19            0.8106                     0.8108        \u001b[35m0.4587\u001b[0m            0.7692                     0.7695        0.4751  0.0005  5.4963\n",
      "     20            \u001b[36m0.8182\u001b[0m                     \u001b[32m0.8182\u001b[0m        \u001b[35m0.4528\u001b[0m            0.7753                     0.7753        \u001b[36m0.4719\u001b[0m  0.0004  5.4903\n",
      "     21            0.8169                     0.8169        \u001b[35m0.4430\u001b[0m            0.7761                     0.7762        \u001b[36m0.4703\u001b[0m  0.0004  5.4943\n",
      "     22            \u001b[36m0.8195\u001b[0m                     \u001b[32m0.8195\u001b[0m        0.4478            0.7796                     \u001b[94m0.7797\u001b[0m        0.4709  0.0003  5.5053\n",
      "     23            \u001b[36m0.8204\u001b[0m                     \u001b[32m0.8205\u001b[0m        0.4533            0.7727                     0.7728        0.4717  0.0003  5.5063\n",
      "     24            0.8199                     0.8198        0.4480            0.7727                     0.7725        0.4715  0.0002  5.5043\n",
      "     25            0.8165                     0.8167        \u001b[35m0.4384\u001b[0m            0.7744                     0.7747        \u001b[36m0.4689\u001b[0m  0.0002  5.5013\n",
      "     26            0.8199                     0.8201        0.4404            0.7779                     0.7780        \u001b[36m0.4674\u001b[0m  0.0002  5.4963\n",
      "     27            0.8199                     0.8200        0.4466            0.7753                     0.7753        0.4687  0.0001  5.4943\n",
      "     28            \u001b[36m0.8217\u001b[0m                     \u001b[32m0.8217\u001b[0m        \u001b[35m0.4363\u001b[0m            0.7718                     0.7718        0.4681  0.0001  5.4923\n",
      "     29            0.8212                     0.8212        0.4383            0.7753                     0.7752        0.4680  0.0001  5.5003\n",
      "     30            0.8214                     0.8214        0.4382            0.7761                     0.7761        0.4678  0.0001  5.5003\n",
      "     31            0.8206                     0.8206        0.4365            0.7753                     0.7753        0.4686  0.0000  5.4973\n",
      "     32            0.8210                     0.8211        0.4385            0.7736                     0.7736        0.4685  0.0000  5.4953\n",
      "     33            0.8214                     0.8215        0.4391            0.7744                     0.7745        0.4685  0.0000  5.4963\n",
      "     34            \u001b[36m0.8221\u001b[0m                     \u001b[32m0.8222\u001b[0m        0.4412            0.7761                     0.7762        0.4686  0.0000  5.4993\n",
      "     35            0.8214                     0.8215        \u001b[35m0.4346\u001b[0m            0.7736                     0.7736        0.4684  0.0000  5.4973\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6924\u001b[0m                     \u001b[32m0.6933\u001b[0m        \u001b[35m0.6877\u001b[0m            \u001b[31m0.7035\u001b[0m                     \u001b[94m0.7044\u001b[0m        \u001b[36m0.6538\u001b[0m  0.0010  5.6309\n",
      "      2            \u001b[36m0.7220\u001b[0m                     \u001b[32m0.7225\u001b[0m        \u001b[35m0.6024\u001b[0m            \u001b[31m0.7329\u001b[0m                     \u001b[94m0.7335\u001b[0m        \u001b[36m0.6170\u001b[0m  0.0010  5.5392\n",
      "      3            \u001b[36m0.7404\u001b[0m                     \u001b[32m0.7402\u001b[0m        \u001b[35m0.5713\u001b[0m            \u001b[31m0.7338\u001b[0m                     \u001b[94m0.7336\u001b[0m        \u001b[36m0.5842\u001b[0m  0.0010  5.5182\n",
      "      4            \u001b[36m0.7449\u001b[0m                     \u001b[32m0.7444\u001b[0m        \u001b[35m0.5481\u001b[0m            0.7312                     0.7307        \u001b[36m0.5505\u001b[0m  0.0010  5.5063\n",
      "      5            \u001b[36m0.7631\u001b[0m                     \u001b[32m0.7630\u001b[0m        \u001b[35m0.5307\u001b[0m            \u001b[31m0.7347\u001b[0m                     \u001b[94m0.7346\u001b[0m        \u001b[36m0.5503\u001b[0m  0.0010  5.5063\n",
      "      6            \u001b[36m0.7657\u001b[0m                     \u001b[32m0.7659\u001b[0m        \u001b[35m0.5180\u001b[0m            \u001b[31m0.7468\u001b[0m                     \u001b[94m0.7470\u001b[0m        \u001b[36m0.5396\u001b[0m  0.0009  5.5013\n",
      "      7            \u001b[36m0.7786\u001b[0m                     \u001b[32m0.7787\u001b[0m        \u001b[35m0.5059\u001b[0m            0.7407                     0.7406        0.5448  0.0009  5.5023\n",
      "      8            \u001b[36m0.7845\u001b[0m                     \u001b[32m0.7843\u001b[0m        \u001b[35m0.4984\u001b[0m            0.7373                     0.7370        \u001b[36m0.5296\u001b[0m  0.0009  5.4983\n",
      "      9            \u001b[36m0.7853\u001b[0m                     \u001b[32m0.7857\u001b[0m        \u001b[35m0.4923\u001b[0m            \u001b[31m0.7537\u001b[0m                     \u001b[94m0.7540\u001b[0m        0.5337  0.0009  5.5013\n",
      "     10            \u001b[36m0.7949\u001b[0m                     \u001b[32m0.7950\u001b[0m        \u001b[35m0.4808\u001b[0m            \u001b[31m0.7571\u001b[0m                     \u001b[94m0.7572\u001b[0m        \u001b[36m0.5176\u001b[0m  0.0008  5.5023\n",
      "     11            \u001b[36m0.7955\u001b[0m                     0.7950        0.4829            0.7485                     0.7480        0.5218  0.0008  5.5043\n",
      "     12            \u001b[36m0.7959\u001b[0m                     \u001b[32m0.7953\u001b[0m        \u001b[35m0.4760\u001b[0m            0.7381                     0.7375        0.5251  0.0008  5.5041\n",
      "     13            \u001b[36m0.8011\u001b[0m                     \u001b[32m0.8015\u001b[0m        \u001b[35m0.4706\u001b[0m            \u001b[31m0.7580\u001b[0m                     \u001b[94m0.7585\u001b[0m        \u001b[36m0.5118\u001b[0m  0.0007  5.5003\n",
      "     14            \u001b[36m0.8046\u001b[0m                     \u001b[32m0.8047\u001b[0m        0.4715            0.7554                     0.7555        \u001b[36m0.5070\u001b[0m  0.0007  5.5053\n",
      "     15            0.8035                     0.8033        \u001b[35m0.4623\u001b[0m            0.7494                     0.7492        0.5071  0.0006  5.5013\n",
      "     16            \u001b[36m0.8089\u001b[0m                     \u001b[32m0.8087\u001b[0m        \u001b[35m0.4572\u001b[0m            \u001b[31m0.7597\u001b[0m                     \u001b[94m0.7597\u001b[0m        0.5077  0.0006  5.5013\n",
      "     17            \u001b[36m0.8091\u001b[0m                     \u001b[32m0.8094\u001b[0m        \u001b[35m0.4511\u001b[0m            \u001b[31m0.7649\u001b[0m                     \u001b[94m0.7653\u001b[0m        \u001b[36m0.5053\u001b[0m  0.0005  5.4963\n",
      "     18            0.8085                     0.8085        \u001b[35m0.4494\u001b[0m            \u001b[31m0.7744\u001b[0m                     \u001b[94m0.7745\u001b[0m        \u001b[36m0.5043\u001b[0m  0.0005  5.4953\n",
      "     19            \u001b[36m0.8128\u001b[0m                     \u001b[32m0.8127\u001b[0m        0.4495            0.7606                     0.7605        \u001b[36m0.5009\u001b[0m  0.0005  5.5023\n",
      "     20            0.8119                     0.8116        0.4500            0.7692                     0.7690        0.5070  0.0004  5.5252\n",
      "     21            \u001b[36m0.8171\u001b[0m                     \u001b[32m0.8170\u001b[0m        \u001b[35m0.4446\u001b[0m            0.7658                     0.7658        \u001b[36m0.4973\u001b[0m  0.0004  5.4963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22            \u001b[36m0.8208\u001b[0m                     \u001b[32m0.8206\u001b[0m        \u001b[35m0.4357\u001b[0m            0.7658                     0.7657        0.5023  0.0003  5.4983\n",
      "     23            \u001b[36m0.8214\u001b[0m                     \u001b[32m0.8213\u001b[0m        0.4413            0.7649                     0.7649        \u001b[36m0.4967\u001b[0m  0.0003  5.5003\n",
      "     24            0.8188                     0.8186        0.4381            0.7692                     0.7691        0.4995  0.0002  5.4973\n",
      "     25            0.8208                     0.8206        0.4405            0.7675                     0.7674        0.5035  0.0002  5.4973\n",
      "     26            \u001b[36m0.8221\u001b[0m                     \u001b[32m0.8221\u001b[0m        0.4366            0.7666                     0.7668        0.4982  0.0002  5.4993\n",
      "     27            0.8206                     0.8202        \u001b[35m0.4268\u001b[0m            0.7684                     0.7682        0.5019  0.0001  5.4993\n",
      "     28            0.8212                     0.8211        0.4375            \u001b[31m0.7753\u001b[0m                     \u001b[94m0.7753\u001b[0m        0.4988  0.0001  5.4983\n",
      "     29            0.8219                     0.8217        0.4346            0.7684                     0.7683        0.4969  0.0001  5.5033\n",
      "     30            0.8191                     0.8189        0.4316            0.7701                     0.7701        \u001b[36m0.4963\u001b[0m  0.0001  5.5023\n",
      "     31            0.8212                     0.8211        0.4329            0.7692                     0.7693        0.4972  0.0000  5.5003\n",
      "     32            0.8217                     0.8215        0.4296            0.7718                     0.7719        0.4965  0.0000  5.5003\n",
      "     33            0.8206                     0.8204        0.4289            0.7710                     0.7709        0.4964  0.0000  5.5013\n",
      "     34            0.8221                     0.8219        0.4323            0.7710                     0.7709        0.4964  0.0000  5.5003\n",
      "     35            0.8219                     0.8217        0.4315            0.7710                     0.7709        0.4964  0.0000  5.5053\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6896\u001b[0m                     \u001b[32m0.6915\u001b[0m        \u001b[35m0.6839\u001b[0m            \u001b[31m0.6880\u001b[0m                     \u001b[94m0.6901\u001b[0m        \u001b[36m0.6521\u001b[0m  0.0010  5.4713\n",
      "      2            \u001b[36m0.7287\u001b[0m                     \u001b[32m0.7298\u001b[0m        \u001b[35m0.5953\u001b[0m            \u001b[31m0.7122\u001b[0m                     \u001b[94m0.7135\u001b[0m        \u001b[36m0.6162\u001b[0m  0.0010  5.4933\n",
      "      3            \u001b[36m0.7369\u001b[0m                     \u001b[32m0.7373\u001b[0m        \u001b[35m0.5623\u001b[0m            \u001b[31m0.7243\u001b[0m                     \u001b[94m0.7248\u001b[0m        \u001b[36m0.5790\u001b[0m  0.0010  5.4634\n",
      "      4            \u001b[36m0.7527\u001b[0m                     \u001b[32m0.7531\u001b[0m        \u001b[35m0.5435\u001b[0m            \u001b[31m0.7312\u001b[0m                     \u001b[94m0.7317\u001b[0m        \u001b[36m0.5546\u001b[0m  0.0010  5.4614\n",
      "      5            \u001b[36m0.7633\u001b[0m                     \u001b[32m0.7635\u001b[0m        \u001b[35m0.5264\u001b[0m            0.7269                     0.7272        \u001b[36m0.5434\u001b[0m  0.0010  5.4644\n",
      "      6            \u001b[36m0.7663\u001b[0m                     \u001b[32m0.7658\u001b[0m        \u001b[35m0.5143\u001b[0m            \u001b[31m0.7355\u001b[0m                     \u001b[94m0.7352\u001b[0m        \u001b[36m0.5415\u001b[0m  0.0009  5.4614\n",
      "      7            \u001b[36m0.7737\u001b[0m                     \u001b[32m0.7739\u001b[0m        \u001b[35m0.4999\u001b[0m            \u001b[31m0.7433\u001b[0m                     \u001b[94m0.7438\u001b[0m        \u001b[36m0.5298\u001b[0m  0.0009  5.4613\n",
      "      8            \u001b[36m0.7797\u001b[0m                     \u001b[32m0.7806\u001b[0m        \u001b[35m0.4984\u001b[0m            0.7433                     \u001b[94m0.7442\u001b[0m        0.5457  0.0009  5.4624\n",
      "      9            \u001b[36m0.7910\u001b[0m                     \u001b[32m0.7913\u001b[0m        \u001b[35m0.4908\u001b[0m            \u001b[31m0.7537\u001b[0m                     \u001b[94m0.7541\u001b[0m        0.5301  0.0009  5.4654\n",
      "     10            \u001b[36m0.7981\u001b[0m                     \u001b[32m0.7979\u001b[0m        \u001b[35m0.4812\u001b[0m            0.7528                     0.7527        \u001b[36m0.5276\u001b[0m  0.0008  5.4624\n",
      "     11            \u001b[36m0.7994\u001b[0m                     \u001b[32m0.7992\u001b[0m        \u001b[35m0.4779\u001b[0m            \u001b[31m0.7589\u001b[0m                     \u001b[94m0.7587\u001b[0m        \u001b[36m0.5212\u001b[0m  0.0008  5.4803\n",
      "     12            0.7985                     0.7981        \u001b[35m0.4718\u001b[0m            0.7528                     0.7523        \u001b[36m0.5173\u001b[0m  0.0008  5.4594\n",
      "     13            \u001b[36m0.8057\u001b[0m                     \u001b[32m0.8057\u001b[0m        \u001b[35m0.4694\u001b[0m            0.7511                     0.7513        \u001b[36m0.5119\u001b[0m  0.0007  5.4644\n",
      "     14            \u001b[36m0.8098\u001b[0m                     \u001b[32m0.8103\u001b[0m        \u001b[35m0.4587\u001b[0m            0.7580                     \u001b[94m0.7587\u001b[0m        \u001b[36m0.5082\u001b[0m  0.0007  5.4614\n",
      "     15            \u001b[36m0.8132\u001b[0m                     \u001b[32m0.8132\u001b[0m        0.4593            \u001b[31m0.7666\u001b[0m                     \u001b[94m0.7666\u001b[0m        \u001b[36m0.4974\u001b[0m  0.0006  5.4644\n",
      "     16            \u001b[36m0.8173\u001b[0m                     \u001b[32m0.8174\u001b[0m        \u001b[35m0.4487\u001b[0m            0.7597                     0.7598        \u001b[36m0.4955\u001b[0m  0.0006  5.4624\n",
      "     17            \u001b[36m0.8186\u001b[0m                     \u001b[32m0.8190\u001b[0m        \u001b[35m0.4485\u001b[0m            0.7615                     0.7620        0.5004  0.0005  5.4634\n",
      "     18            \u001b[36m0.8219\u001b[0m                     \u001b[32m0.8217\u001b[0m        \u001b[35m0.4425\u001b[0m            \u001b[31m0.7692\u001b[0m                     \u001b[94m0.7691\u001b[0m        0.4962  0.0005  5.4624\n",
      "     19            0.8210                     0.8207        \u001b[35m0.4379\u001b[0m            \u001b[31m0.7718\u001b[0m                     \u001b[94m0.7716\u001b[0m        \u001b[36m0.4952\u001b[0m  0.0005  5.4885\n",
      "     20            \u001b[36m0.8284\u001b[0m                     \u001b[32m0.8283\u001b[0m        0.4393            0.7692                     0.7693        \u001b[36m0.4932\u001b[0m  0.0004  5.4584\n",
      "     21            \u001b[36m0.8294\u001b[0m                     \u001b[32m0.8294\u001b[0m        \u001b[35m0.4346\u001b[0m            \u001b[31m0.7787\u001b[0m                     \u001b[94m0.7788\u001b[0m        0.4949  0.0004  5.4624\n",
      "     22            0.8279                     0.8281        \u001b[35m0.4297\u001b[0m            0.7718                     0.7722        \u001b[36m0.4912\u001b[0m  0.0003  5.4604\n",
      "     23            0.8294                     \u001b[32m0.8295\u001b[0m        0.4375            0.7727                     0.7729        0.4920  0.0003  5.4634\n",
      "     24            0.8260                     0.8257        \u001b[35m0.4285\u001b[0m            0.7770                     0.7768        0.4947  0.0002  5.4664\n",
      "     25            0.8249                     0.8246        \u001b[35m0.4270\u001b[0m            0.7770                     0.7767        0.4919  0.0002  5.4734\n",
      "     26            \u001b[36m0.8312\u001b[0m                     \u001b[32m0.8311\u001b[0m        0.4328            \u001b[31m0.7831\u001b[0m                     \u001b[94m0.7831\u001b[0m        \u001b[36m0.4870\u001b[0m  0.0002  5.4604\n",
      "     27            0.8307                     0.8306        \u001b[35m0.4220\u001b[0m            0.7761                     0.7761        0.4898  0.0001  5.4604\n",
      "     28            0.8310                     0.8308        \u001b[35m0.4220\u001b[0m            0.7779                     0.7777        0.4900  0.0001  5.4614\n",
      "     29            \u001b[36m0.8325\u001b[0m                     \u001b[32m0.8324\u001b[0m        0.4220            0.7779                     0.7779        0.4879  0.0001  5.4654\n",
      "     30            0.8325                     0.8324        \u001b[35m0.4162\u001b[0m            0.7787                     0.7787        0.4888  0.0001  5.4624\n",
      "     31            0.8323                     0.8322        0.4211            0.7796                     0.7796        0.4891  0.0000  5.4644\n",
      "     32            \u001b[36m0.8327\u001b[0m                     \u001b[32m0.8327\u001b[0m        0.4245            0.7779                     0.7779        0.4886  0.0000  5.4614\n",
      "     33            \u001b[36m0.8335\u001b[0m                     \u001b[32m0.8335\u001b[0m        \u001b[35m0.4126\u001b[0m            0.7770                     0.7771        0.4884  0.0000  5.4614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34            0.8333                     0.8333        0.4243            0.7787                     0.7787        0.4885  0.0000  5.4584\n",
      "     35            0.8335                     0.8335        0.4174            0.7787                     0.7787        0.4885  0.0000  5.4624\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7043\u001b[0m                     \u001b[32m0.7055\u001b[0m        \u001b[35m0.6737\u001b[0m            \u001b[31m0.6733\u001b[0m                     \u001b[94m0.6747\u001b[0m        \u001b[36m0.6452\u001b[0m  0.0010  5.4813\n",
      "      2            \u001b[36m0.7255\u001b[0m                     \u001b[32m0.7257\u001b[0m        \u001b[35m0.5961\u001b[0m            \u001b[31m0.7156\u001b[0m                     \u001b[94m0.7162\u001b[0m        \u001b[36m0.6063\u001b[0m  0.0010  5.4574\n",
      "      3            \u001b[36m0.7428\u001b[0m                     \u001b[32m0.7429\u001b[0m        \u001b[35m0.5694\u001b[0m            \u001b[31m0.7286\u001b[0m                     \u001b[94m0.7291\u001b[0m        \u001b[36m0.5722\u001b[0m  0.0010  5.4574\n",
      "      4            \u001b[36m0.7579\u001b[0m                     \u001b[32m0.7585\u001b[0m        \u001b[35m0.5457\u001b[0m            0.7269                     0.7278        \u001b[36m0.5448\u001b[0m  0.0010  5.4564\n",
      "      5            \u001b[36m0.7592\u001b[0m                     \u001b[32m0.7594\u001b[0m        \u001b[35m0.5372\u001b[0m            \u001b[31m0.7450\u001b[0m                     \u001b[94m0.7455\u001b[0m        \u001b[36m0.5285\u001b[0m  0.0010  5.4564\n",
      "      6            \u001b[36m0.7652\u001b[0m                     \u001b[32m0.7647\u001b[0m        \u001b[35m0.5206\u001b[0m            0.7450                     0.7449        \u001b[36m0.5131\u001b[0m  0.0009  5.4624\n",
      "      7            \u001b[36m0.7683\u001b[0m                     \u001b[32m0.7681\u001b[0m        \u001b[35m0.5074\u001b[0m            0.7442                     0.7444        0.5309  0.0009  5.4554\n",
      "      8            \u001b[36m0.7862\u001b[0m                     \u001b[32m0.7860\u001b[0m        0.5104            \u001b[31m0.7666\u001b[0m                     \u001b[94m0.7667\u001b[0m        \u001b[36m0.5032\u001b[0m  0.0009  5.4594\n",
      "      9            \u001b[36m0.7929\u001b[0m                     \u001b[32m0.7927\u001b[0m        \u001b[35m0.4893\u001b[0m            0.7589                     0.7589        \u001b[36m0.5012\u001b[0m  0.0009  5.4534\n",
      "     10            0.7836                     0.7826        \u001b[35m0.4819\u001b[0m            0.7450                     0.7441        0.5084  0.0008  5.4524\n",
      "     11            \u001b[36m0.8074\u001b[0m                     \u001b[32m0.8073\u001b[0m        \u001b[35m0.4809\u001b[0m            \u001b[31m0.7736\u001b[0m                     \u001b[94m0.7737\u001b[0m        \u001b[36m0.4846\u001b[0m  0.0008  5.4604\n",
      "     12            0.8035                     0.8029        \u001b[35m0.4664\u001b[0m            0.7666                     0.7662        0.4864  0.0008  5.4594\n",
      "     13            0.8052                     0.8050        \u001b[35m0.4622\u001b[0m            \u001b[31m0.7787\u001b[0m                     \u001b[94m0.7787\u001b[0m        \u001b[36m0.4819\u001b[0m  0.0007  5.4544\n",
      "     14            \u001b[36m0.8104\u001b[0m                     \u001b[32m0.8102\u001b[0m        0.4645            0.7753                     0.7753        \u001b[36m0.4815\u001b[0m  0.0007  5.4594\n",
      "     15            0.8098                     0.8099        \u001b[35m0.4541\u001b[0m            \u001b[31m0.7805\u001b[0m                     \u001b[94m0.7808\u001b[0m        \u001b[36m0.4807\u001b[0m  0.0006  5.4574\n",
      "     16            \u001b[36m0.8121\u001b[0m                     \u001b[32m0.8122\u001b[0m        0.4568            0.7761                     0.7765        \u001b[36m0.4782\u001b[0m  0.0006  5.4574\n",
      "     17            \u001b[36m0.8184\u001b[0m                     \u001b[32m0.8182\u001b[0m        \u001b[35m0.4502\u001b[0m            0.7779                     0.7780        0.4833  0.0005  5.4544\n",
      "     18            0.8180                     \u001b[32m0.8184\u001b[0m        \u001b[35m0.4495\u001b[0m            0.7744                     0.7751        0.4821  0.0005  5.4843\n",
      "     19            0.8178                     0.8179        \u001b[35m0.4450\u001b[0m            \u001b[31m0.7831\u001b[0m                     \u001b[94m0.7834\u001b[0m        \u001b[36m0.4767\u001b[0m  0.0005  5.4534\n",
      "     20            \u001b[36m0.8258\u001b[0m                     \u001b[32m0.8255\u001b[0m        \u001b[35m0.4409\u001b[0m            0.7753                     0.7752        0.4791  0.0004  5.4554\n",
      "     21            0.8234                     0.8231        \u001b[35m0.4386\u001b[0m            0.7753                     0.7753        0.4845  0.0004  5.4624\n",
      "     22            0.8247                     0.8245        \u001b[35m0.4361\u001b[0m            0.7779                     0.7778        \u001b[36m0.4765\u001b[0m  0.0003  5.4594\n",
      "     23            \u001b[36m0.8286\u001b[0m                     \u001b[32m0.8284\u001b[0m        0.4373            0.7805                     0.7805        \u001b[36m0.4748\u001b[0m  0.0003  5.4554\n",
      "     24            0.8230                     0.8230        \u001b[35m0.4233\u001b[0m            0.7787                     0.7791        \u001b[36m0.4740\u001b[0m  0.0002  5.4594\n",
      "     25            0.8277                     0.8275        0.4280            0.7813                     0.7814        0.4751  0.0002  5.4554\n",
      "     26            0.8286                     0.8284        0.4283            0.7787                     0.7788        0.4741  0.0002  5.4544\n",
      "     27            \u001b[36m0.8288\u001b[0m                     \u001b[32m0.8288\u001b[0m        0.4270            0.7787                     0.7790        \u001b[36m0.4724\u001b[0m  0.0001  5.4584\n",
      "     28            \u001b[36m0.8292\u001b[0m                     \u001b[32m0.8291\u001b[0m        0.4269            0.7831                     0.7832        0.4727  0.0001  5.4564\n",
      "     29            \u001b[36m0.8305\u001b[0m                     \u001b[32m0.8304\u001b[0m        0.4295            \u001b[31m0.7857\u001b[0m                     \u001b[94m0.7859\u001b[0m        \u001b[36m0.4719\u001b[0m  0.0001  5.4544\n",
      "     30            0.8294                     0.8294        0.4241            0.7857                     \u001b[94m0.7859\u001b[0m        0.4724  0.0001  5.4594\n",
      "     31            0.8294                     0.8293        0.4267            0.7822                     0.7823        0.4724  0.0000  5.4594\n",
      "     32            0.8279                     0.8278        \u001b[35m0.4194\u001b[0m            0.7831                     0.7833        0.4728  0.0000  5.4544\n",
      "     33            0.8281                     0.8280        0.4217            0.7831                     0.7833        0.4728  0.0000  5.4624\n",
      "     34            0.8284                     0.8283        0.4263            0.7839                     0.7841        0.4727  0.0000  5.4574\n",
      "     35            0.8290                     0.8289        0.4256            0.7857                     0.7859        0.4728  0.0000  5.4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6872\u001b[0m                     \u001b[32m0.6998\u001b[0m        \u001b[35m0.6732\u001b[0m            \u001b[31m0.6889\u001b[0m                     \u001b[94m0.7061\u001b[0m        \u001b[36m0.6295\u001b[0m  0.0010  3.3381\n",
      "      2            \u001b[36m0.7147\u001b[0m                     \u001b[32m0.7261\u001b[0m        \u001b[35m0.5927\u001b[0m            \u001b[31m0.7120\u001b[0m                     \u001b[94m0.7292\u001b[0m        \u001b[36m0.6203\u001b[0m  0.0010  3.2732\n",
      "      3            0.6959                     0.7153        \u001b[35m0.5571\u001b[0m            0.6889                     0.7127        \u001b[36m0.6167\u001b[0m  0.0010  3.2842\n",
      "      4            \u001b[36m0.7321\u001b[0m                     \u001b[32m0.7421\u001b[0m        \u001b[35m0.5338\u001b[0m            \u001b[31m0.7221\u001b[0m                     \u001b[94m0.7360\u001b[0m        \u001b[36m0.5654\u001b[0m  0.0010  3.2723\n",
      "      5            0.7230                     0.7380        \u001b[35m0.5300\u001b[0m            0.7106                     0.7297        0.5680  0.0010  3.2683\n",
      "      6            0.7281                     \u001b[32m0.7440\u001b[0m        \u001b[35m0.5167\u001b[0m            0.7077                     0.7280        0.5699  0.0009  3.2713\n",
      "      7            \u001b[36m0.7567\u001b[0m                     \u001b[32m0.7631\u001b[0m        \u001b[35m0.5134\u001b[0m            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7395\u001b[0m        \u001b[36m0.5433\u001b[0m  0.0009  3.2742\n",
      "      8            \u001b[36m0.7683\u001b[0m                     \u001b[32m0.7711\u001b[0m        \u001b[35m0.4975\u001b[0m            \u001b[31m0.7410\u001b[0m                     \u001b[94m0.7504\u001b[0m        \u001b[36m0.5232\u001b[0m  0.0009  3.2742\n",
      "      9            \u001b[36m0.7744\u001b[0m                     \u001b[32m0.7779\u001b[0m        0.4987            0.7337                     0.7420        \u001b[36m0.5184\u001b[0m  0.0009  3.2732\n",
      "     10            \u001b[36m0.7788\u001b[0m                     \u001b[32m0.7841\u001b[0m        \u001b[35m0.4923\u001b[0m            0.7279                     0.7374        0.5231  0.0008  3.2723\n",
      "     11            \u001b[36m0.7824\u001b[0m                     0.7831        \u001b[35m0.4861\u001b[0m            0.7337                     0.7393        \u001b[36m0.5178\u001b[0m  0.0008  3.2732\n",
      "     12            \u001b[36m0.7875\u001b[0m                     \u001b[32m0.7864\u001b[0m        \u001b[35m0.4725\u001b[0m            \u001b[31m0.7453\u001b[0m                     0.7501        \u001b[36m0.5106\u001b[0m  0.0008  3.2693\n",
      "     13            \u001b[36m0.7896\u001b[0m                     \u001b[32m0.7899\u001b[0m        0.4770            \u001b[31m0.7540\u001b[0m                     \u001b[94m0.7589\u001b[0m        0.5144  0.0007  3.2713\n",
      "     14            \u001b[36m0.7958\u001b[0m                     \u001b[32m0.7957\u001b[0m        \u001b[35m0.4619\u001b[0m            0.7424                     0.7463        0.5138  0.0007  3.2752\n",
      "     15            \u001b[36m0.8045\u001b[0m                     \u001b[32m0.8033\u001b[0m        0.4687            0.7381                     0.7414        0.5168  0.0006  3.2732\n",
      "     16            0.7965                     0.8018        \u001b[35m0.4561\u001b[0m            0.7381                     0.7489        0.5120  0.0006  3.2703\n",
      "     17            0.8005                     0.8026        \u001b[35m0.4503\u001b[0m            0.7381                     0.7435        0.5145  0.0005  3.2762\n",
      "     18            \u001b[36m0.8052\u001b[0m                     \u001b[32m0.8056\u001b[0m        0.4547            0.7352                     0.7394        0.5139  0.0005  3.2713\n",
      "     19            0.8045                     0.8051        \u001b[35m0.4439\u001b[0m            0.7438                     0.7482        0.5123  0.0005  3.2732\n",
      "     20            \u001b[36m0.8143\u001b[0m                     \u001b[32m0.8143\u001b[0m        0.4481            0.7395                     0.7424        0.5136  0.0004  3.2703\n",
      "     21            0.8074                     0.8068        0.4536            0.7438                     0.7470        0.5160  0.0004  3.2723\n",
      "     22            0.8128                     \u001b[32m0.8144\u001b[0m        0.4450            0.7438                     0.7485        0.5153  0.0003  3.2703\n",
      "     23            0.8114                     \u001b[32m0.8168\u001b[0m        \u001b[35m0.4406\u001b[0m            0.7410                     0.7501        0.5236  0.0003  3.2683\n",
      "     24            0.8077                     0.8145        0.4410            0.7366                     0.7476        0.5290  0.0002  3.2742\n",
      "     25            0.8121                     0.8161        \u001b[35m0.4284\u001b[0m            0.7323                     0.7392        0.5220  0.0002  3.2723\n",
      "     26            \u001b[36m0.8168\u001b[0m                     \u001b[32m0.8198\u001b[0m        0.4331            0.7424                     0.7478        0.5161  0.0002  3.2713\n",
      "     27            0.8164                     0.8181        0.4363            0.7424                     0.7460        0.5157  0.0001  3.2752\n",
      "     28            \u001b[36m0.8179\u001b[0m                     0.8197        0.4336            0.7395                     0.7433        0.5162  0.0001  3.2832\n",
      "     29            0.8168                     0.8192        0.4314            0.7366                     0.7416        0.5186  0.0001  3.2742\n",
      "     30            0.8172                     0.8197        \u001b[35m0.4261\u001b[0m            0.7366                     0.7419        0.5193  0.0001  3.2762\n",
      "     31            0.8164                     0.8188        \u001b[35m0.4228\u001b[0m            0.7381                     0.7429        0.5188  0.0000  3.2732\n",
      "     32            \u001b[36m0.8182\u001b[0m                     \u001b[32m0.8209\u001b[0m        0.4266            0.7424                     0.7481        0.5195  0.0000  3.2683\n",
      "     33            \u001b[36m0.8186\u001b[0m                     \u001b[32m0.8214\u001b[0m        0.4267            0.7410                     0.7471        0.5196  0.0000  3.2703\n",
      "     34            \u001b[36m0.8193\u001b[0m                     \u001b[32m0.8222\u001b[0m        0.4300            0.7410                     0.7471        0.5197  0.0000  3.2683\n",
      "     35            0.8193                     \u001b[32m0.8225\u001b[0m        0.4320            0.7424                     0.7490        0.5202  0.0000  3.2713\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6825\u001b[0m                     \u001b[32m0.6995\u001b[0m        \u001b[35m0.6628\u001b[0m            \u001b[31m0.6802\u001b[0m                     \u001b[94m0.6958\u001b[0m        \u001b[36m0.6386\u001b[0m  0.0010  3.2623\n",
      "      2            \u001b[36m0.7169\u001b[0m                     \u001b[32m0.7279\u001b[0m        \u001b[35m0.5800\u001b[0m            \u001b[31m0.7048\u001b[0m                     \u001b[94m0.7158\u001b[0m        \u001b[36m0.6188\u001b[0m  0.0010  3.2613\n",
      "      3            \u001b[36m0.7256\u001b[0m                     \u001b[32m0.7370\u001b[0m        \u001b[35m0.5482\u001b[0m            \u001b[31m0.7178\u001b[0m                     \u001b[94m0.7288\u001b[0m        \u001b[36m0.5880\u001b[0m  0.0010  3.2643\n",
      "      4            \u001b[36m0.7404\u001b[0m                     \u001b[32m0.7481\u001b[0m        \u001b[35m0.5421\u001b[0m            \u001b[31m0.7221\u001b[0m                     \u001b[94m0.7294\u001b[0m        \u001b[36m0.5699\u001b[0m  0.0010  4.3324\n",
      "      5            0.7288                     0.7443        \u001b[35m0.5260\u001b[0m            0.6990                     0.7129        0.5759  0.0010  3.3052\n",
      "      6            \u001b[36m0.7498\u001b[0m                     \u001b[32m0.7611\u001b[0m        \u001b[35m0.5080\u001b[0m            0.7077                     0.7184        \u001b[36m0.5516\u001b[0m  0.0009  3.2793\n",
      "      7            \u001b[36m0.7632\u001b[0m                     \u001b[32m0.7703\u001b[0m        \u001b[35m0.4970\u001b[0m            0.7033                     0.7096        \u001b[36m0.5370\u001b[0m  0.0009  3.2473\n",
      "      8            \u001b[36m0.7657\u001b[0m                     0.7688        0.5030            0.7192                     0.7208        \u001b[36m0.5316\u001b[0m  0.0009  3.2513\n",
      "      9            \u001b[36m0.7770\u001b[0m                     \u001b[32m0.7793\u001b[0m        0.5016            0.7207                     0.7221        0.5326  0.0009  3.2503\n",
      "     10            0.7697                     0.7789        0.4998            0.7091                     0.7182        0.5372  0.0008  3.2513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            \u001b[36m0.7810\u001b[0m                     \u001b[32m0.7861\u001b[0m        \u001b[35m0.4874\u001b[0m            0.7164                     0.7202        \u001b[36m0.5239\u001b[0m  0.0008  3.2503\n",
      "     12            0.7773                     0.7820        \u001b[35m0.4779\u001b[0m            0.7120                     0.7148        0.5305  0.0008  3.2493\n",
      "     13            \u001b[36m0.7944\u001b[0m                     \u001b[32m0.7944\u001b[0m        \u001b[35m0.4643\u001b[0m            \u001b[31m0.7337\u001b[0m                     \u001b[94m0.7306\u001b[0m        0.5249  0.0007  3.2483\n",
      "     14            0.7864                     0.7897        0.4672            0.7120                     0.7130        0.5276  0.0007  3.2533\n",
      "     15            0.7882                     0.7913        0.4671            0.7265                     0.7276        \u001b[36m0.5224\u001b[0m  0.0006  3.2493\n",
      "     16            \u001b[36m0.7972\u001b[0m                     \u001b[32m0.8011\u001b[0m        0.4656            0.7294                     \u001b[94m0.7324\u001b[0m        0.5233  0.0006  3.2563\n",
      "     17            0.7972                     0.8005        \u001b[35m0.4582\u001b[0m            0.7236                     0.7253        \u001b[36m0.5213\u001b[0m  0.0005  3.2553\n",
      "     18            \u001b[36m0.8045\u001b[0m                     \u001b[32m0.8077\u001b[0m        \u001b[35m0.4520\u001b[0m            0.7308                     0.7322        0.5253  0.0005  3.2513\n",
      "     19            \u001b[36m0.8052\u001b[0m                     0.8064        \u001b[35m0.4517\u001b[0m            0.7265                     0.7261        0.5235  0.0005  3.2513\n",
      "     20            0.8038                     \u001b[32m0.8083\u001b[0m        \u001b[35m0.4501\u001b[0m            0.7279                     0.7310        0.5235  0.0004  3.2513\n",
      "     21            \u001b[36m0.8077\u001b[0m                     \u001b[32m0.8122\u001b[0m        \u001b[35m0.4486\u001b[0m            0.7149                     0.7180        0.5228  0.0004  3.2473\n",
      "     22            0.8070                     0.8108        \u001b[35m0.4475\u001b[0m            0.7265                     0.7294        \u001b[36m0.5175\u001b[0m  0.0003  3.2483\n",
      "     23            0.8045                     0.8111        0.4530            0.7265                     \u001b[94m0.7324\u001b[0m        0.5217  0.0003  3.2503\n",
      "     24            0.8049                     0.8098        \u001b[35m0.4377\u001b[0m            0.7279                     0.7310        0.5213  0.0002  3.2483\n",
      "     25            0.8005                     0.8080        0.4480            0.7192                     0.7253        0.5236  0.0002  3.2553\n",
      "     26            \u001b[36m0.8099\u001b[0m                     \u001b[32m0.8144\u001b[0m        0.4417            0.7236                     0.7262        0.5197  0.0002  3.2533\n",
      "     27            \u001b[36m0.8164\u001b[0m                     \u001b[32m0.8191\u001b[0m        \u001b[35m0.4323\u001b[0m            0.7279                     0.7295        0.5195  0.0001  3.2503\n",
      "     28            0.8125                     0.8161        0.4371            0.7323                     \u001b[94m0.7341\u001b[0m        0.5194  0.0001  3.2503\n",
      "     29            0.8132                     0.8175        0.4430            0.7308                     0.7331        0.5209  0.0001  3.2493\n",
      "     30            0.8114                     0.8149        \u001b[35m0.4304\u001b[0m            0.7308                     0.7328        0.5207  0.0001  3.2503\n",
      "     31            0.8132                     0.8171        0.4369            0.7323                     0.7341        0.5212  0.0000  3.2493\n",
      "     32            0.8139                     0.8183        0.4351            0.7294                     0.7314        0.5210  0.0000  3.2513\n",
      "     33            0.8128                     0.8173        \u001b[35m0.4269\u001b[0m            0.7308                     0.7328        0.5208  0.0000  3.2543\n",
      "     34            0.8121                     0.8166        0.4384            0.7265                     0.7288        0.5209  0.0000  3.2533\n",
      "     35            0.8128                     0.8173        0.4329            0.7308                     0.7331        0.5209  0.0000  3.2473\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6948\u001b[0m                     \u001b[32m0.7047\u001b[0m        \u001b[35m0.6645\u001b[0m            \u001b[31m0.7106\u001b[0m                     \u001b[94m0.7180\u001b[0m        \u001b[36m0.6281\u001b[0m  0.0010  3.2503\n",
      "      2            \u001b[36m0.7104\u001b[0m                     \u001b[32m0.7249\u001b[0m        \u001b[35m0.5839\u001b[0m            \u001b[31m0.7192\u001b[0m                     \u001b[94m0.7328\u001b[0m        \u001b[36m0.6205\u001b[0m  0.0010  3.2483\n",
      "      3            \u001b[36m0.7263\u001b[0m                     \u001b[32m0.7385\u001b[0m        \u001b[35m0.5574\u001b[0m            \u001b[31m0.7323\u001b[0m                     \u001b[94m0.7446\u001b[0m        \u001b[36m0.5984\u001b[0m  0.0010  3.2493\n",
      "      4            \u001b[36m0.7335\u001b[0m                     \u001b[32m0.7451\u001b[0m        \u001b[35m0.5435\u001b[0m            \u001b[31m0.7366\u001b[0m                     \u001b[94m0.7482\u001b[0m        \u001b[36m0.5741\u001b[0m  0.0010  3.2503\n",
      "      5            \u001b[36m0.7415\u001b[0m                     \u001b[32m0.7538\u001b[0m        \u001b[35m0.5389\u001b[0m            0.7236                     0.7373        \u001b[36m0.5632\u001b[0m  0.0010  3.2513\n",
      "      6            \u001b[36m0.7491\u001b[0m                     0.7516        \u001b[35m0.5224\u001b[0m            \u001b[31m0.7381\u001b[0m                     0.7408        \u001b[36m0.5365\u001b[0m  0.0009  3.2513\n",
      "      7            \u001b[36m0.7600\u001b[0m                     \u001b[32m0.7671\u001b[0m        \u001b[35m0.5114\u001b[0m            \u001b[31m0.7482\u001b[0m                     \u001b[94m0.7542\u001b[0m        \u001b[36m0.5269\u001b[0m  0.0009  3.2503\n",
      "      8            \u001b[36m0.7672\u001b[0m                     \u001b[32m0.7708\u001b[0m        \u001b[35m0.5007\u001b[0m            \u001b[31m0.7612\u001b[0m                     \u001b[94m0.7639\u001b[0m        \u001b[36m0.5195\u001b[0m  0.0009  3.2503\n",
      "      9            \u001b[36m0.7744\u001b[0m                     \u001b[32m0.7774\u001b[0m        0.5101            \u001b[31m0.7641\u001b[0m                     \u001b[94m0.7675\u001b[0m        \u001b[36m0.5169\u001b[0m  0.0009  3.2563\n",
      "     10            0.7686                     0.7750        \u001b[35m0.4953\u001b[0m            0.7612                     \u001b[94m0.7678\u001b[0m        \u001b[36m0.5091\u001b[0m  0.0008  3.2493\n",
      "     11            \u001b[36m0.7755\u001b[0m                     \u001b[32m0.7797\u001b[0m        \u001b[35m0.4926\u001b[0m            0.7554                     0.7602        \u001b[36m0.5076\u001b[0m  0.0008  3.2533\n",
      "     12            \u001b[36m0.7791\u001b[0m                     \u001b[32m0.7846\u001b[0m        \u001b[35m0.4764\u001b[0m            0.7496                     0.7549        \u001b[36m0.5070\u001b[0m  0.0008  3.2493\n",
      "     13            \u001b[36m0.7846\u001b[0m                     0.7842        \u001b[35m0.4763\u001b[0m            0.7569                     0.7561        0.5094  0.0007  3.2533\n",
      "     14            \u001b[36m0.7886\u001b[0m                     \u001b[32m0.7860\u001b[0m        0.4803            0.7612                     0.7597        0.5173  0.0007  3.2503\n",
      "     15            \u001b[36m0.7889\u001b[0m                     \u001b[32m0.7884\u001b[0m        \u001b[35m0.4695\u001b[0m            0.7540                     0.7541        0.5136  0.0006  3.2553\n",
      "     16            \u001b[36m0.7994\u001b[0m                     \u001b[32m0.7975\u001b[0m        \u001b[35m0.4639\u001b[0m            0.7583                     0.7571        \u001b[36m0.5069\u001b[0m  0.0006  3.2513\n",
      "     17            \u001b[36m0.8016\u001b[0m                     \u001b[32m0.8014\u001b[0m        \u001b[35m0.4548\u001b[0m            0.7554                     0.7548        0.5106  0.0005  3.2493\n",
      "     18            \u001b[36m0.8070\u001b[0m                     \u001b[32m0.8090\u001b[0m        0.4599            0.7583                     0.7604        \u001b[36m0.5033\u001b[0m  0.0005  3.2563\n",
      "     19            0.8038                     0.8048        \u001b[35m0.4474\u001b[0m            0.7569                     0.7588        0.5076  0.0005  3.2503\n",
      "     20            \u001b[36m0.8121\u001b[0m                     \u001b[32m0.8137\u001b[0m        0.4613            0.7641                     0.7657        \u001b[36m0.4982\u001b[0m  0.0004  3.2513\n",
      "     21            0.8085                     0.8115        0.4551            0.7612                     0.7642        0.5068  0.0004  3.2523\n",
      "     22            0.8088                     \u001b[32m0.8145\u001b[0m        \u001b[35m0.4406\u001b[0m            0.7627                     0.7667        0.5029  0.0003  3.2503\n",
      "     23            0.8077                     0.8082        0.4483            0.7598                     0.7611        0.5061  0.0003  3.2513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24            0.8121                     0.8131        \u001b[35m0.4395\u001b[0m            \u001b[31m0.7670\u001b[0m                     \u001b[94m0.7686\u001b[0m        0.4993  0.0002  3.2503\n",
      "     25            \u001b[36m0.8157\u001b[0m                     \u001b[32m0.8165\u001b[0m        \u001b[35m0.4369\u001b[0m            0.7670                     0.7674        0.5040  0.0002  3.2553\n",
      "     26            0.8139                     0.8151        0.4405            0.7656                     0.7667        0.5048  0.0002  3.2563\n",
      "     27            \u001b[36m0.8164\u001b[0m                     \u001b[32m0.8167\u001b[0m        0.4373            0.7641                     0.7650        0.5050  0.0001  3.2483\n",
      "     28            0.8157                     \u001b[32m0.8181\u001b[0m        \u001b[35m0.4332\u001b[0m            0.7641                     0.7663        0.5029  0.0001  3.2473\n",
      "     29            0.8154                     0.8177        0.4335            0.7641                     0.7660        0.5047  0.0001  3.2493\n",
      "     30            \u001b[36m0.8172\u001b[0m                     \u001b[32m0.8196\u001b[0m        0.4336            0.7627                     0.7649        0.5048  0.0001  3.2523\n",
      "     31            0.8150                     0.8178        0.4413            0.7656                     0.7679        0.5045  0.0000  3.2503\n",
      "     32            0.8135                     0.8170        0.4373            0.7627                     0.7658        0.5046  0.0000  3.2553\n",
      "     33            0.8121                     0.8154        \u001b[35m0.4238\u001b[0m            0.7598                     0.7626        0.5046  0.0000  3.2543\n",
      "     34            0.8132                     0.8162        0.4341            0.7627                     0.7652        0.5046  0.0000  3.2483\n",
      "     35            0.8135                     0.8165        0.4311            0.7641                     0.7669        0.5046  0.0000  3.2513\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7028\u001b[0m                     \u001b[32m0.7154\u001b[0m        \u001b[35m0.6798\u001b[0m            \u001b[31m0.6802\u001b[0m                     \u001b[94m0.6922\u001b[0m        \u001b[36m0.6393\u001b[0m  0.0010  3.2523\n",
      "      2            \u001b[36m0.7158\u001b[0m                     \u001b[32m0.7305\u001b[0m        \u001b[35m0.5819\u001b[0m            \u001b[31m0.7004\u001b[0m                     \u001b[94m0.7169\u001b[0m        \u001b[36m0.6236\u001b[0m  0.0010  3.2563\n",
      "      3            \u001b[36m0.7335\u001b[0m                     \u001b[32m0.7442\u001b[0m        \u001b[35m0.5555\u001b[0m            \u001b[31m0.7019\u001b[0m                     0.7122        \u001b[36m0.5966\u001b[0m  0.0010  3.2523\n",
      "      4            \u001b[36m0.7444\u001b[0m                     \u001b[32m0.7512\u001b[0m        \u001b[35m0.5277\u001b[0m            \u001b[31m0.7106\u001b[0m                     0.7159        \u001b[36m0.5671\u001b[0m  0.0010  3.2543\n",
      "      5            \u001b[36m0.7571\u001b[0m                     \u001b[32m0.7637\u001b[0m        0.5370            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7355\u001b[0m        \u001b[36m0.5563\u001b[0m  0.0010  3.2543\n",
      "      6            0.7571                     \u001b[32m0.7651\u001b[0m        \u001b[35m0.5138\u001b[0m            0.7164                     0.7250        \u001b[36m0.5498\u001b[0m  0.0009  3.2553\n",
      "      7            \u001b[36m0.7621\u001b[0m                     0.7640        \u001b[35m0.5078\u001b[0m            \u001b[31m0.7352\u001b[0m                     \u001b[94m0.7373\u001b[0m        \u001b[36m0.5301\u001b[0m  0.0009  3.2523\n",
      "      8            \u001b[36m0.7694\u001b[0m                     \u001b[32m0.7769\u001b[0m        \u001b[35m0.5003\u001b[0m            0.7352                     \u001b[94m0.7430\u001b[0m        0.5367  0.0009  3.2523\n",
      "      9            \u001b[36m0.7719\u001b[0m                     \u001b[32m0.7783\u001b[0m        \u001b[35m0.4964\u001b[0m            0.7192                     0.7253        0.5360  0.0009  3.2533\n",
      "     10            0.7683                     0.7769        \u001b[35m0.4852\u001b[0m            0.7236                     0.7331        \u001b[36m0.5297\u001b[0m  0.0008  3.2533\n",
      "     11            \u001b[36m0.7791\u001b[0m                     \u001b[32m0.7828\u001b[0m        \u001b[35m0.4840\u001b[0m            0.7337                     0.7354        \u001b[36m0.5251\u001b[0m  0.0008  3.2573\n",
      "     12            \u001b[36m0.7853\u001b[0m                     \u001b[32m0.7882\u001b[0m        0.4840            0.7352                     0.7364        0.5315  0.0008  3.2533\n",
      "     13            \u001b[36m0.7860\u001b[0m                     \u001b[32m0.7917\u001b[0m        \u001b[35m0.4636\u001b[0m            \u001b[31m0.7424\u001b[0m                     \u001b[94m0.7463\u001b[0m        0.5260  0.0007  3.2543\n",
      "     14            \u001b[36m0.7962\u001b[0m                     \u001b[32m0.7976\u001b[0m        0.4691            0.7410                     0.7398        0.5323  0.0007  3.2553\n",
      "     15            0.7849                     0.7919        \u001b[35m0.4616\u001b[0m            0.7395                     0.7454        0.5253  0.0006  3.2553\n",
      "     16            0.7871                     0.7953        \u001b[35m0.4563\u001b[0m            0.7279                     0.7355        0.5315  0.0006  3.2513\n",
      "     17            0.7795                     0.7913        \u001b[35m0.4506\u001b[0m            0.7221                     0.7324        0.5398  0.0005  3.2553\n",
      "     18            \u001b[36m0.7991\u001b[0m                     \u001b[32m0.7978\u001b[0m        \u001b[35m0.4467\u001b[0m            \u001b[31m0.7438\u001b[0m                     0.7407        0.5324  0.0005  3.2533\n",
      "     19            \u001b[36m0.8041\u001b[0m                     \u001b[32m0.8078\u001b[0m        0.4534            \u001b[31m0.7496\u001b[0m                     \u001b[94m0.7504\u001b[0m        0.5280  0.0005  3.2563\n",
      "     20            0.7958                     0.8013        0.4527            0.7438                     0.7473        0.5281  0.0004  3.2593\n",
      "     21            0.8001                     0.8057        \u001b[35m0.4419\u001b[0m            0.7410                     0.7441        \u001b[36m0.5198\u001b[0m  0.0004  3.2603\n",
      "     22            \u001b[36m0.8103\u001b[0m                     \u001b[32m0.8119\u001b[0m        0.4421            \u001b[31m0.7511\u001b[0m                     0.7499        0.5292  0.0003  3.2573\n",
      "     23            0.7969                     0.8042        \u001b[35m0.4367\u001b[0m            0.7308                     0.7367        0.5274  0.0003  3.2523\n",
      "     24            \u001b[36m0.8110\u001b[0m                     \u001b[32m0.8133\u001b[0m        0.4434            0.7511                     0.7502        0.5250  0.0002  3.2543\n",
      "     25            0.8067                     0.8107        0.4393            0.7438                     0.7455        0.5244  0.0002  3.2543\n",
      "     26            \u001b[36m0.8139\u001b[0m                     \u001b[32m0.8183\u001b[0m        \u001b[35m0.4261\u001b[0m            0.7453                     0.7465        0.5273  0.0002  3.2603\n",
      "     27            \u001b[36m0.8164\u001b[0m                     \u001b[32m0.8193\u001b[0m        0.4327            0.7511                     \u001b[94m0.7511\u001b[0m        0.5253  0.0001  3.2553\n",
      "     28            0.8143                     0.8191        \u001b[35m0.4257\u001b[0m            0.7438                     0.7455        0.5266  0.0001  3.2523\n",
      "     29            0.8150                     \u001b[32m0.8199\u001b[0m        \u001b[35m0.4231\u001b[0m            0.7395                     0.7415        0.5270  0.0001  3.2553\n",
      "     30            0.8139                     0.8189        0.4251            0.7410                     0.7428        0.5283  0.0001  3.2563\n",
      "     31            0.8157                     \u001b[32m0.8201\u001b[0m        0.4290            0.7424                     0.7439        0.5280  0.0000  3.2563\n",
      "     32            0.8146                     0.8191        \u001b[35m0.4201\u001b[0m            0.7410                     0.7422        0.5276  0.0000  3.2573\n",
      "     33            0.8150                     0.8194        0.4281            0.7395                     0.7406        0.5279  0.0000  3.2613\n",
      "     34            0.8146                     0.8189        0.4270            0.7395                     0.7406        0.5278  0.0000  3.2563\n",
      "     35            0.8150                     0.8193        0.4287            0.7395                     0.7406        0.5277  0.0000  3.2543\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7100\u001b[0m                     \u001b[32m0.7108\u001b[0m        \u001b[35m0.6631\u001b[0m            \u001b[31m0.7077\u001b[0m                     \u001b[94m0.7091\u001b[0m        \u001b[36m0.6195\u001b[0m  0.0010  3.2503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            \u001b[36m0.7241\u001b[0m                     \u001b[32m0.7330\u001b[0m        \u001b[35m0.5843\u001b[0m            \u001b[31m0.7120\u001b[0m                     \u001b[94m0.7220\u001b[0m        \u001b[36m0.6148\u001b[0m  0.0010  3.2523\n",
      "      3            \u001b[36m0.7386\u001b[0m                     \u001b[32m0.7477\u001b[0m        \u001b[35m0.5551\u001b[0m            \u001b[31m0.7192\u001b[0m                     \u001b[94m0.7277\u001b[0m        \u001b[36m0.5965\u001b[0m  0.0010  3.2503\n",
      "      4            0.7219                     0.7370        \u001b[35m0.5270\u001b[0m            0.6961                     0.7115        \u001b[36m0.5925\u001b[0m  0.0010  3.2533\n",
      "      5            \u001b[36m0.7498\u001b[0m                     \u001b[32m0.7591\u001b[0m        \u001b[35m0.5239\u001b[0m            0.7091                     0.7179        \u001b[36m0.5748\u001b[0m  0.0010  3.2533\n",
      "      6            0.7368                     0.7503        \u001b[35m0.5132\u001b[0m            0.7149                     0.7276        \u001b[36m0.5580\u001b[0m  0.0009  3.2553\n",
      "      7            \u001b[36m0.7603\u001b[0m                     \u001b[32m0.7705\u001b[0m        \u001b[35m0.4962\u001b[0m            \u001b[31m0.7250\u001b[0m                     \u001b[94m0.7335\u001b[0m        \u001b[36m0.5449\u001b[0m  0.0009  3.2513\n",
      "      8            \u001b[36m0.7676\u001b[0m                     \u001b[32m0.7737\u001b[0m        \u001b[35m0.4908\u001b[0m            \u001b[31m0.7381\u001b[0m                     \u001b[94m0.7426\u001b[0m        \u001b[36m0.5420\u001b[0m  0.0009  3.2483\n",
      "      9            0.7668                     \u001b[32m0.7752\u001b[0m        \u001b[35m0.4835\u001b[0m            0.7192                     0.7265        0.5528  0.0009  3.2543\n",
      "     10            \u001b[36m0.7878\u001b[0m                     \u001b[32m0.7893\u001b[0m        \u001b[35m0.4745\u001b[0m            0.7207                     0.7221        0.5534  0.0008  3.2513\n",
      "     11            0.7839                     0.7794        0.4760            0.7279                     0.7229        0.5603  0.0008  3.2493\n",
      "     12            0.7875                     \u001b[32m0.7929\u001b[0m        \u001b[35m0.4674\u001b[0m            0.7265                     0.7324        0.5453  0.0008  3.2533\n",
      "     13            \u001b[36m0.7933\u001b[0m                     \u001b[32m0.7948\u001b[0m        0.4680            0.7352                     0.7343        0.5445  0.0007  3.2543\n",
      "     14            \u001b[36m0.7987\u001b[0m                     \u001b[32m0.7977\u001b[0m        \u001b[35m0.4666\u001b[0m            0.7294                     0.7260        \u001b[36m0.5394\u001b[0m  0.0007  3.2553\n",
      "     15            \u001b[36m0.7991\u001b[0m                     \u001b[32m0.8049\u001b[0m        \u001b[35m0.4619\u001b[0m            0.7221                     0.7264        0.5424  0.0006  3.2563\n",
      "     16            \u001b[36m0.8041\u001b[0m                     0.8045        \u001b[35m0.4546\u001b[0m            0.7149                     0.7135        0.5581  0.0006  3.2513\n",
      "     17            \u001b[36m0.8074\u001b[0m                     \u001b[32m0.8055\u001b[0m        \u001b[35m0.4476\u001b[0m            0.7178                     0.7137        0.5517  0.0005  3.2523\n",
      "     18            0.7954                     0.8020        \u001b[35m0.4466\u001b[0m            0.7164                     0.7232        0.5583  0.0005  3.2523\n",
      "     19            \u001b[36m0.8077\u001b[0m                     \u001b[32m0.8123\u001b[0m        0.4501            0.7265                     0.7288        0.5459  0.0005  3.2513\n",
      "     20            0.8001                     0.8082        0.4499            0.7149                     0.7222        0.5498  0.0004  3.2513\n",
      "     21            0.8059                     0.8107        \u001b[35m0.4368\u001b[0m            0.7279                     0.7310        0.5459  0.0004  3.2533\n",
      "     22            0.8070                     0.8109        0.4395            0.7250                     0.7281        0.5461  0.0003  3.2503\n",
      "     23            \u001b[36m0.8110\u001b[0m                     \u001b[32m0.8143\u001b[0m        \u001b[35m0.4327\u001b[0m            0.7352                     0.7379        0.5433  0.0003  3.2493\n",
      "     24            0.8059                     0.8097        \u001b[35m0.4318\u001b[0m            0.7221                     0.7246        0.5440  0.0002  3.2493\n",
      "     25            0.8096                     0.8143        \u001b[35m0.4276\u001b[0m            0.7221                     0.7258        0.5481  0.0002  3.2503\n",
      "     26            0.8099                     0.8140        \u001b[35m0.4227\u001b[0m            0.7337                     0.7366        0.5469  0.0002  3.2503\n",
      "     27            0.8103                     \u001b[32m0.8160\u001b[0m        0.4323            0.7250                     0.7290        0.5466  0.0001  3.2533\n",
      "     28            0.8092                     0.8144        0.4296            0.7279                     0.7313        0.5440  0.0001  3.2513\n",
      "     29            0.8110                     0.8153        0.4265            0.7279                     0.7307        0.5458  0.0001  3.2503\n",
      "     30            \u001b[36m0.8114\u001b[0m                     0.8151        0.4240            0.7265                     0.7288        0.5460  0.0001  3.2533\n",
      "     31            0.8114                     0.8157        \u001b[35m0.4182\u001b[0m            0.7279                     0.7307        0.5471  0.0000  3.2503\n",
      "     32            0.8114                     0.8156        0.4214            0.7279                     0.7307        0.5468  0.0000  3.2503\n",
      "     33            0.8110                     0.8153        0.4183            0.7279                     0.7307        0.5467  0.0000  3.2533\n",
      "     34            0.8110                     0.8156        0.4227            0.7294                     0.7324        0.5470  0.0000  3.2513\n",
      "     35            0.8110                     0.8156        0.4236            0.7294                     0.7327        0.5469  0.0000  3.2523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6216\u001b[0m                     \u001b[32m0.6700\u001b[0m        \u001b[35m0.7019\u001b[0m            \u001b[31m0.6226\u001b[0m                     \u001b[94m0.6652\u001b[0m        \u001b[36m0.6479\u001b[0m  0.0010  7.3942\n",
      "      2            \u001b[36m0.7116\u001b[0m                     \u001b[32m0.7178\u001b[0m        \u001b[35m0.6235\u001b[0m            \u001b[31m0.6877\u001b[0m                     \u001b[94m0.6829\u001b[0m        \u001b[36m0.6224\u001b[0m  0.0010  7.2157\n",
      "      3            0.7075                     \u001b[32m0.7336\u001b[0m        \u001b[35m0.5970\u001b[0m            \u001b[31m0.6917\u001b[0m                     \u001b[94m0.6970\u001b[0m        \u001b[36m0.5822\u001b[0m  0.0010  7.2087\n",
      "      4            \u001b[36m0.7543\u001b[0m                     \u001b[32m0.7430\u001b[0m        \u001b[35m0.5774\u001b[0m            \u001b[31m0.7369\u001b[0m                     0.6909        \u001b[36m0.5810\u001b[0m  0.0010  7.2207\n",
      "      5            \u001b[36m0.7841\u001b[0m                     \u001b[32m0.7516\u001b[0m        \u001b[35m0.5608\u001b[0m            \u001b[31m0.7548\u001b[0m                     \u001b[94m0.7003\u001b[0m        \u001b[36m0.5688\u001b[0m  0.0010  7.2107\n",
      "      6            0.7513                     0.7493        \u001b[35m0.5515\u001b[0m            0.7302                     \u001b[94m0.7073\u001b[0m        \u001b[36m0.5671\u001b[0m  0.0009  7.2237\n",
      "      7            0.7711                     \u001b[32m0.7679\u001b[0m        \u001b[35m0.5458\u001b[0m            0.7488                     \u001b[94m0.7288\u001b[0m        \u001b[36m0.5530\u001b[0m  0.0009  7.2267\n",
      "      8            \u001b[36m0.7955\u001b[0m                     0.7604        \u001b[35m0.5304\u001b[0m            \u001b[31m0.7701\u001b[0m                     0.7082        0.5641  0.0009  7.2107\n",
      "      9            0.7889                     \u001b[32m0.7794\u001b[0m        0.5393            \u001b[31m0.7708\u001b[0m                     \u001b[94m0.7349\u001b[0m        \u001b[36m0.5366\u001b[0m  0.0009  7.2177\n",
      "     10            0.7173                     0.7677        \u001b[35m0.5203\u001b[0m            0.6897                     0.7177        0.5548  0.0008  7.2267\n",
      "     11            0.7125                     0.7622        \u001b[35m0.5065\u001b[0m            0.6890                     0.7217        0.5560  0.0008  7.2207\n",
      "     12            \u001b[36m0.8058\u001b[0m                     \u001b[32m0.7853\u001b[0m        0.5090            \u001b[31m0.7827\u001b[0m                     \u001b[94m0.7407\u001b[0m        0.5378  0.0008  7.2217\n",
      "     13            0.7744                     0.7849        \u001b[35m0.5010\u001b[0m            0.7415                     0.7317        0.5420  0.0007  7.2137\n",
      "     14            0.7664                     \u001b[32m0.7892\u001b[0m        \u001b[35m0.4918\u001b[0m            0.7382                     0.7326        \u001b[36m0.5341\u001b[0m  0.0007  7.2307\n",
      "     15            0.7902                     \u001b[32m0.7959\u001b[0m        0.4933            0.7628                     0.7402        0.5368  0.0006  7.2277\n",
      "     16            0.7472                     0.7859        \u001b[35m0.4908\u001b[0m            0.7229                     \u001b[94m0.7408\u001b[0m        \u001b[36m0.5328\u001b[0m  0.0006  7.2237\n",
      "     17            0.7429                     0.7847        \u001b[35m0.4829\u001b[0m            0.7136                     0.7323        0.5367  0.0005  7.2177\n",
      "     18            0.7372                     0.7842        0.4892            0.7030                     0.7258        0.5463  0.0005  7.2237\n",
      "     19            0.7699                     0.7935        0.4863            0.7329                     0.7279        0.5398  0.0005  7.2287\n",
      "     20            0.7488                     0.7916        \u001b[35m0.4746\u001b[0m            0.7130                     0.7362        0.5411  0.0004  7.2077\n",
      "     21            \u001b[36m0.8239\u001b[0m                     \u001b[32m0.7996\u001b[0m        0.4758            \u001b[31m0.7987\u001b[0m                     \u001b[94m0.7460\u001b[0m        0.5401  0.0004  7.2187\n",
      "     22            0.7919                     0.7995        \u001b[35m0.4739\u001b[0m            0.7641                     0.7425        \u001b[36m0.5310\u001b[0m  0.0003  7.2187\n",
      "     23            0.7874                     \u001b[32m0.8008\u001b[0m        \u001b[35m0.4727\u001b[0m            0.7542                     0.7423        \u001b[36m0.5308\u001b[0m  0.0003  7.2556\n",
      "     24            0.8088                     \u001b[32m0.8032\u001b[0m        \u001b[35m0.4703\u001b[0m            0.7801                     0.7449        \u001b[36m0.5296\u001b[0m  0.0002  7.2217\n",
      "     25            0.8073                     \u001b[32m0.8049\u001b[0m        0.4751            0.7807                     \u001b[94m0.7482\u001b[0m        0.5333  0.0002  7.2157\n",
      "     26            0.7920                     0.8007        \u001b[35m0.4645\u001b[0m            0.7595                     0.7470        0.5304  0.0002  7.1997\n",
      "     27            0.7904                     0.8023        0.4672            0.7641                     \u001b[94m0.7513\u001b[0m        \u001b[36m0.5269\u001b[0m  0.0001  7.2217\n",
      "     28            0.7844                     0.8019        \u001b[35m0.4585\u001b[0m            0.7502                     0.7443        0.5281  0.0001  7.2257\n",
      "     29            0.7945                     0.8022        0.4624            0.7661                     0.7466        0.5282  0.0001  7.2077\n",
      "     30            0.7962                     0.8036        0.4601            0.7681                     \u001b[94m0.7522\u001b[0m        0.5291  0.0001  7.2037\n",
      "     31            0.8032                     0.8042        \u001b[35m0.4585\u001b[0m            0.7761                     \u001b[94m0.7527\u001b[0m        0.5297  0.0000  7.2247\n",
      "     32            0.8027                     0.8024        0.4623            0.7787                     0.7514        0.5298  0.0000  7.2177\n",
      "     33            0.8015                     0.8028        0.4597            0.7774                     0.7506        0.5297  0.0000  7.2117\n",
      "     34            0.8005                     0.8029        0.4611            0.7761                     0.7513        0.5296  0.0000  7.2077\n",
      "     35            0.8008                     0.8039        \u001b[35m0.4572\u001b[0m            0.7774                     0.7521        0.5297  0.0000  7.2127\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6196\u001b[0m                     \u001b[32m0.6673\u001b[0m        \u001b[35m0.7017\u001b[0m            \u001b[31m0.6266\u001b[0m                     \u001b[94m0.6705\u001b[0m        \u001b[36m0.6539\u001b[0m  0.0010  7.1210\n",
      "      2            \u001b[36m0.6929\u001b[0m                     \u001b[32m0.6976\u001b[0m        \u001b[35m0.6293\u001b[0m            \u001b[31m0.7056\u001b[0m                     \u001b[94m0.7040\u001b[0m        \u001b[36m0.6122\u001b[0m  0.0010  7.1110\n",
      "      3            \u001b[36m0.7482\u001b[0m                     \u001b[32m0.7283\u001b[0m        \u001b[35m0.6012\u001b[0m            \u001b[31m0.7575\u001b[0m                     \u001b[94m0.7282\u001b[0m        \u001b[36m0.5842\u001b[0m  0.0010  7.1140\n",
      "      4            \u001b[36m0.7703\u001b[0m                     \u001b[32m0.7417\u001b[0m        \u001b[35m0.5777\u001b[0m            \u001b[31m0.7694\u001b[0m                     \u001b[94m0.7341\u001b[0m        \u001b[36m0.5518\u001b[0m  0.0010  7.1060\n",
      "      5            0.7123                     \u001b[32m0.7489\u001b[0m        \u001b[35m0.5637\u001b[0m            0.7096                     0.7328        \u001b[36m0.5408\u001b[0m  0.0010  7.1070\n",
      "      6            0.6764                     0.7487        \u001b[35m0.5466\u001b[0m            0.6651                     0.7247        0.5494  0.0009  7.1090\n",
      "      7            \u001b[36m0.8007\u001b[0m                     \u001b[32m0.7537\u001b[0m        \u001b[35m0.5383\u001b[0m            \u001b[31m0.8047\u001b[0m                     \u001b[94m0.7555\u001b[0m        \u001b[36m0.5399\u001b[0m  0.0009  7.1110\n",
      "      8            0.7618                     \u001b[32m0.7695\u001b[0m        \u001b[35m0.5339\u001b[0m            0.7542                     0.7467        \u001b[36m0.5237\u001b[0m  0.0009  7.1230\n",
      "      9            0.7723                     \u001b[32m0.7752\u001b[0m        \u001b[35m0.5226\u001b[0m            0.7608                     0.7522        0.5339  0.0009  7.1758\n",
      "     10            0.7620                     0.7747        \u001b[35m0.5203\u001b[0m            0.7588                     0.7554        \u001b[36m0.5231\u001b[0m  0.0008  7.1888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            0.7525                     0.7693        \u001b[35m0.5159\u001b[0m            0.7555                     \u001b[94m0.7606\u001b[0m        0.5280  0.0008  7.1848\n",
      "     12            0.7879                     \u001b[32m0.7814\u001b[0m        \u001b[35m0.5147\u001b[0m            0.7874                     \u001b[94m0.7640\u001b[0m        \u001b[36m0.5170\u001b[0m  0.0008  7.2257\n",
      "     13            0.7286                     0.7778        \u001b[35m0.5064\u001b[0m            0.7150                     0.7448        0.5283  0.0007  7.1908\n",
      "     14            0.7601                     0.7784        \u001b[35m0.5060\u001b[0m            0.7462                     0.7506        0.5320  0.0007  7.1748\n",
      "     15            0.7934                     \u001b[32m0.7814\u001b[0m        \u001b[35m0.5012\u001b[0m            0.7960                     \u001b[94m0.7736\u001b[0m        \u001b[36m0.5168\u001b[0m  0.0006  7.2337\n",
      "     16            \u001b[36m0.8030\u001b[0m                     \u001b[32m0.7876\u001b[0m        \u001b[35m0.4967\u001b[0m            0.7953                     0.7630        0.5266  0.0006  7.1928\n",
      "     17            0.7929                     0.7873        \u001b[35m0.4940\u001b[0m            0.7794                     0.7562        0.5213  0.0005  7.1768\n",
      "     18            0.7513                     \u001b[32m0.7921\u001b[0m        \u001b[35m0.4901\u001b[0m            0.7362                     0.7650        \u001b[36m0.5160\u001b[0m  0.0005  7.2087\n",
      "     19            \u001b[36m0.8208\u001b[0m                     0.7919        \u001b[35m0.4800\u001b[0m            \u001b[31m0.8140\u001b[0m                     \u001b[94m0.7772\u001b[0m        0.5235  0.0005  7.1818\n",
      "     20            0.7264                     0.7897        0.4828            0.7056                     0.7522        0.5204  0.0004  7.1878\n",
      "     21            0.7844                     \u001b[32m0.8078\u001b[0m        \u001b[35m0.4799\u001b[0m            0.7635                     0.7582        0.5170  0.0004  7.1519\n",
      "     22            0.8086                     0.8009        \u001b[35m0.4778\u001b[0m            0.7807                     0.7512        0.5236  0.0003  7.1449\n",
      "     23            0.7822                     0.8021        \u001b[35m0.4755\u001b[0m            0.7595                     0.7601        0.5186  0.0003  7.1997\n",
      "     24            0.7754                     0.8045        0.4775            0.7581                     0.7652        \u001b[36m0.5158\u001b[0m  0.0002  7.1858\n",
      "     25            0.7859                     0.8065        \u001b[35m0.4708\u001b[0m            0.7748                     0.7709        \u001b[36m0.5139\u001b[0m  0.0002  7.2247\n",
      "     26            0.8086                     0.8031        \u001b[35m0.4657\u001b[0m            0.7973                     0.7700        0.5154  0.0002  7.2287\n",
      "     27            0.8076                     0.8047        \u001b[35m0.4644\u001b[0m            0.7940                     0.7651        0.5183  0.0001  7.2037\n",
      "     28            0.7947                     0.8038        \u001b[35m0.4609\u001b[0m            0.7781                     0.7642        0.5147  0.0001  7.2436\n",
      "     29            0.7757                     0.8043        0.4628            0.7588                     0.7597        0.5149  0.0001  7.1908\n",
      "     30            0.7822                     0.8054        0.4660            0.7654                     0.7623        0.5160  0.0001  7.1828\n",
      "     31            0.7909                     0.8037        \u001b[35m0.4599\u001b[0m            0.7734                     0.7628        0.5154  0.0000  7.1888\n",
      "     32            0.7917                     0.8042        0.4629            0.7734                     0.7584        0.5154  0.0000  7.1908\n",
      "     33            0.7922                     0.8045        0.4622            0.7754                     0.7596        0.5153  0.0000  7.1878\n",
      "     34            0.7910                     0.8052        0.4636            0.7728                     0.7580        0.5155  0.0000  7.1609\n",
      "     35            0.7899                     0.8042        0.4626            0.7728                     0.7595        0.5154  0.0000  7.1628\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5537\u001b[0m                     \u001b[32m0.6587\u001b[0m        \u001b[35m0.7021\u001b[0m            \u001b[31m0.5369\u001b[0m                     \u001b[94m0.6423\u001b[0m        \u001b[36m0.6557\u001b[0m  0.0010  7.1379\n",
      "      2            \u001b[36m0.7136\u001b[0m                     \u001b[32m0.7131\u001b[0m        \u001b[35m0.6096\u001b[0m            \u001b[31m0.6963\u001b[0m                     \u001b[94m0.6925\u001b[0m        \u001b[36m0.6189\u001b[0m  0.0010  7.1359\n",
      "      3            0.6897                     \u001b[32m0.7337\u001b[0m        \u001b[35m0.5818\u001b[0m            0.6611                     \u001b[94m0.6959\u001b[0m        \u001b[36m0.6032\u001b[0m  0.0010  7.1728\n",
      "      4            0.6771                     0.7326        \u001b[35m0.5720\u001b[0m            0.6498                     0.6949        \u001b[36m0.5961\u001b[0m  0.0010  7.1628\n",
      "      5            0.6425                     0.7259        \u001b[35m0.5642\u001b[0m            0.6120                     \u001b[94m0.6982\u001b[0m        \u001b[36m0.5959\u001b[0m  0.0010  7.1579\n",
      "      6            \u001b[36m0.7596\u001b[0m                     \u001b[32m0.7583\u001b[0m        \u001b[35m0.5446\u001b[0m            \u001b[31m0.7269\u001b[0m                     \u001b[94m0.7140\u001b[0m        \u001b[36m0.5758\u001b[0m  0.0009  7.1668\n",
      "      7            0.7158                     \u001b[32m0.7587\u001b[0m        \u001b[35m0.5411\u001b[0m            0.6850                     \u001b[94m0.7163\u001b[0m        \u001b[36m0.5709\u001b[0m  0.0009  7.1599\n",
      "      8            0.7304                     \u001b[32m0.7588\u001b[0m        \u001b[35m0.5256\u001b[0m            0.6924                     \u001b[94m0.7193\u001b[0m        \u001b[36m0.5707\u001b[0m  0.0009  7.1858\n",
      "      9            0.7530                     \u001b[32m0.7682\u001b[0m        0.5298            0.7156                     0.7189        \u001b[36m0.5611\u001b[0m  0.0009  7.1808\n",
      "     10            0.7515                     \u001b[32m0.7761\u001b[0m        \u001b[35m0.5234\u001b[0m            0.7156                     \u001b[94m0.7262\u001b[0m        \u001b[36m0.5602\u001b[0m  0.0008  7.1698\n",
      "     11            0.7151                     0.7678        \u001b[35m0.5149\u001b[0m            0.6724                     0.7174        0.5623  0.0008  7.1628\n",
      "     12            \u001b[36m0.7606\u001b[0m                     \u001b[32m0.7769\u001b[0m        \u001b[35m0.5122\u001b[0m            0.7229                     \u001b[94m0.7321\u001b[0m        \u001b[36m0.5570\u001b[0m  0.0008  7.1778\n",
      "     13            \u001b[36m0.7802\u001b[0m                     \u001b[32m0.7833\u001b[0m        \u001b[35m0.5023\u001b[0m            \u001b[31m0.7382\u001b[0m                     \u001b[94m0.7326\u001b[0m        \u001b[36m0.5514\u001b[0m  0.0007  7.1828\n",
      "     14            0.7118                     0.7768        0.5121            0.6751                     0.7220        0.5642  0.0007  7.1529\n",
      "     15            \u001b[36m0.8027\u001b[0m                     \u001b[32m0.7882\u001b[0m        \u001b[35m0.4990\u001b[0m            \u001b[31m0.7601\u001b[0m                     0.7299        0.5555  0.0006  7.1628\n",
      "     16            \u001b[36m0.8121\u001b[0m                     0.7873        \u001b[35m0.4865\u001b[0m            \u001b[31m0.7641\u001b[0m                     0.7250        0.5652  0.0006  7.1609\n",
      "     17            0.7859                     \u001b[32m0.7915\u001b[0m        0.4934            0.7322                     0.7202        0.5603  0.0005  7.1638\n",
      "     18            0.7920                     \u001b[32m0.7916\u001b[0m        0.4867            0.7389                     0.7213        0.5534  0.0005  7.1678\n",
      "     19            0.7686                     \u001b[32m0.7927\u001b[0m        \u001b[35m0.4809\u001b[0m            0.7243                     \u001b[94m0.7373\u001b[0m        \u001b[36m0.5507\u001b[0m  0.0005  7.1698\n",
      "     20            \u001b[36m0.8135\u001b[0m                     \u001b[32m0.7987\u001b[0m        \u001b[35m0.4790\u001b[0m            0.7635                     0.7348        0.5519  0.0004  7.1928\n",
      "     21            \u001b[36m0.8412\u001b[0m                     0.7900        \u001b[35m0.4768\u001b[0m            \u001b[31m0.7834\u001b[0m                     0.7235        0.5578  0.0004  7.1808\n",
      "     22            0.8066                     \u001b[32m0.8030\u001b[0m        \u001b[35m0.4576\u001b[0m            0.7575                     0.7355        \u001b[36m0.5496\u001b[0m  0.0003  7.1828\n",
      "     23            0.7470                     0.7960        0.4655            0.6983                     0.7346        0.5541  0.0003  7.1628\n",
      "     24            0.7444                     0.7999        0.4583            0.6910                     0.7258        0.5539  0.0002  7.1878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25            0.7882                     \u001b[32m0.8105\u001b[0m        0.4616            0.7269                     0.7243        \u001b[36m0.5435\u001b[0m  0.0002  7.1838\n",
      "     26            0.7774                     0.8050        \u001b[35m0.4539\u001b[0m            0.7176                     0.7244        0.5466  0.0002  7.1758\n",
      "     27            0.8150                     0.8103        0.4584            0.7522                     0.7323        \u001b[36m0.5435\u001b[0m  0.0001  7.1698\n",
      "     28            0.7797                     0.8038        0.4552            0.7209                     0.7279        0.5461  0.0001  7.1688\n",
      "     29            0.7854                     0.8065        0.4576            0.7236                     0.7252        0.5454  0.0001  7.1828\n",
      "     30            0.7874                     0.8074        0.4573            0.7236                     0.7252        0.5449  0.0001  7.1220\n",
      "     31            0.7983                     0.8097        0.4566            0.7362                     0.7314        0.5451  0.0000  7.1259\n",
      "     32            0.8002                     0.8101        0.4541            0.7349                     0.7277        0.5449  0.0000  7.1299\n",
      "     33            0.8027                     \u001b[32m0.8108\u001b[0m        \u001b[35m0.4519\u001b[0m            0.7369                     0.7259        0.5450  0.0000  7.1339\n",
      "     34            0.8017                     0.8106        0.4549            0.7369                     0.7274        0.5449  0.0000  7.1399\n",
      "     35            0.8022                     \u001b[32m0.8109\u001b[0m        0.4580            0.7349                     0.7233        0.5447  0.0000  7.1609\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6337\u001b[0m                     \u001b[32m0.6755\u001b[0m        \u001b[35m0.7045\u001b[0m            \u001b[31m0.5967\u001b[0m                     \u001b[94m0.6436\u001b[0m        \u001b[36m0.6515\u001b[0m  0.0010  7.1230\n",
      "      2            0.6244                     \u001b[32m0.6918\u001b[0m        \u001b[35m0.6213\u001b[0m            0.5847                     \u001b[94m0.6465\u001b[0m        \u001b[36m0.6226\u001b[0m  0.0010  7.1230\n",
      "      3            \u001b[36m0.6631\u001b[0m                     \u001b[32m0.7238\u001b[0m        \u001b[35m0.5965\u001b[0m            \u001b[31m0.6299\u001b[0m                     \u001b[94m0.6813\u001b[0m        \u001b[36m0.5941\u001b[0m  0.0010  7.1359\n",
      "      4            0.6478                     \u001b[32m0.7255\u001b[0m        \u001b[35m0.5764\u001b[0m            \u001b[31m0.6346\u001b[0m                     \u001b[94m0.7017\u001b[0m        \u001b[36m0.5829\u001b[0m  0.0010  7.1259\n",
      "      5            \u001b[36m0.7606\u001b[0m                     \u001b[32m0.7450\u001b[0m        \u001b[35m0.5561\u001b[0m            \u001b[31m0.7395\u001b[0m                     \u001b[94m0.7129\u001b[0m        \u001b[36m0.5624\u001b[0m  0.0010  7.1479\n",
      "      6            0.7450                     \u001b[32m0.7513\u001b[0m        \u001b[35m0.5451\u001b[0m            0.7030                     0.7024        0.5704  0.0009  7.1170\n",
      "      7            0.7193                     \u001b[32m0.7543\u001b[0m        0.5540            0.6771                     0.6954        0.5857  0.0009  7.1289\n",
      "      8            0.7008                     0.7533        \u001b[35m0.5315\u001b[0m            0.6598                     0.6907        0.5766  0.0009  7.1289\n",
      "      9            0.7445                     \u001b[32m0.7693\u001b[0m        \u001b[35m0.5277\u001b[0m            0.6850                     0.6798        0.5769  0.0009  7.1259\n",
      "     10            0.7065                     0.7655        \u001b[35m0.5173\u001b[0m            0.6598                     0.7010        0.5706  0.0008  7.1240\n",
      "     11            \u001b[36m0.7879\u001b[0m                     \u001b[32m0.7726\u001b[0m        \u001b[35m0.5104\u001b[0m            \u001b[31m0.7468\u001b[0m                     0.7101        \u001b[36m0.5530\u001b[0m  0.0008  7.1399\n",
      "     12            0.7678                     \u001b[32m0.7816\u001b[0m        \u001b[35m0.5071\u001b[0m            0.7216                     0.7079        0.5566  0.0008  7.1609\n",
      "     13            0.7704                     \u001b[32m0.7828\u001b[0m        \u001b[35m0.5054\u001b[0m            0.7302                     \u001b[94m0.7175\u001b[0m        \u001b[36m0.5520\u001b[0m  0.0007  7.1519\n",
      "     14            0.7839                     \u001b[32m0.7877\u001b[0m        0.5057            0.7402                     0.7104        0.5555  0.0007  7.1848\n",
      "     15            0.7757                     0.7806        \u001b[35m0.5015\u001b[0m            0.7296                     0.7156        0.5558  0.0006  7.1638\n",
      "     16            \u001b[36m0.8050\u001b[0m                     \u001b[32m0.7936\u001b[0m        \u001b[35m0.4926\u001b[0m            \u001b[31m0.7488\u001b[0m                     0.7084        \u001b[36m0.5456\u001b[0m  0.0006  7.3234\n",
      "     17            0.7811                     \u001b[32m0.7959\u001b[0m        \u001b[35m0.4873\u001b[0m            0.7243                     0.7110        0.5494  0.0005  7.3573\n",
      "     18            0.7955                     \u001b[32m0.8003\u001b[0m        \u001b[35m0.4834\u001b[0m            0.7455                     0.7166        0.5527  0.0005  7.3543\n",
      "     19            0.7585                     0.7902        \u001b[35m0.4821\u001b[0m            0.7063                     0.7117        0.5563  0.0005  7.2975\n",
      "     20            0.8012                     0.7997        \u001b[35m0.4812\u001b[0m            \u001b[31m0.7548\u001b[0m                     \u001b[94m0.7222\u001b[0m        0.5525  0.0004  7.2935\n",
      "     21            0.7880                     \u001b[32m0.8045\u001b[0m        0.4869            0.7389                     \u001b[94m0.7257\u001b[0m        0.5490  0.0004  7.3085\n",
      "     22            \u001b[36m0.8060\u001b[0m                     \u001b[32m0.8052\u001b[0m        \u001b[35m0.4686\u001b[0m            \u001b[31m0.7555\u001b[0m                     0.7241        0.5548  0.0003  7.2905\n",
      "     23            0.7314                     0.7916        0.4714            0.6777                     0.7177        0.5603  0.0003  7.2626\n",
      "     24            0.7719                     0.8017        0.4706            0.7209                     0.7206        0.5548  0.0002  7.2686\n",
      "     25            0.8017                     \u001b[32m0.8058\u001b[0m        \u001b[35m0.4665\u001b[0m            0.7548                     0.7179        0.5484  0.0002  7.2297\n",
      "     26            0.7970                     \u001b[32m0.8096\u001b[0m        0.4686            0.7449                     0.7249        0.5496  0.0002  7.2576\n",
      "     27            0.7836                     0.8036        0.4695            0.7329                     0.7191        0.5517  0.0001  7.2337\n",
      "     28            \u001b[36m0.8063\u001b[0m                     0.8087        \u001b[35m0.4614\u001b[0m            \u001b[31m0.7581\u001b[0m                     \u001b[94m0.7257\u001b[0m        0.5503  0.0001  7.2317\n",
      "     29            0.7937                     0.8094        0.4627            0.7422                     0.7233        0.5490  0.0001  7.2556\n",
      "     30            0.8008                     \u001b[32m0.8097\u001b[0m        \u001b[35m0.4597\u001b[0m            0.7502                     0.7209        0.5506  0.0001  7.2207\n",
      "     31            0.7958                     0.8093        \u001b[35m0.4528\u001b[0m            0.7455                     0.7224        0.5509  0.0000  7.2406\n",
      "     32            0.7942                     0.8093        0.4588            0.7468                     \u001b[94m0.7262\u001b[0m        0.5510  0.0000  7.1978\n",
      "     33            0.7950                     0.8084        0.4617            0.7475                     \u001b[94m0.7266\u001b[0m        0.5507  0.0000  7.2007\n",
      "     34            0.7937                     0.8076        0.4645            0.7468                     0.7262        0.5509  0.0000  7.2217\n",
      "     35            0.7939                     0.8077        0.4547            0.7475                     0.7266        0.5507  0.0000  7.2197\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6711\u001b[0m                     \u001b[32m0.6844\u001b[0m        \u001b[35m0.6973\u001b[0m            \u001b[31m0.6691\u001b[0m                     \u001b[94m0.6584\u001b[0m        \u001b[36m0.6548\u001b[0m  0.0010  7.1927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            \u001b[36m0.7148\u001b[0m                     \u001b[32m0.7182\u001b[0m        \u001b[35m0.6136\u001b[0m            \u001b[31m0.7030\u001b[0m                     \u001b[94m0.6834\u001b[0m        \u001b[36m0.6083\u001b[0m  0.0010  7.2067\n",
      "      3            0.7018                     \u001b[32m0.7389\u001b[0m        \u001b[35m0.5817\u001b[0m            0.6804                     \u001b[94m0.6960\u001b[0m        \u001b[36m0.5893\u001b[0m  0.0010  7.2097\n",
      "      4            \u001b[36m0.7508\u001b[0m                     \u001b[32m0.7486\u001b[0m        \u001b[35m0.5660\u001b[0m            \u001b[31m0.7243\u001b[0m                     \u001b[94m0.7095\u001b[0m        \u001b[36m0.5701\u001b[0m  0.0010  7.2257\n",
      "      5            0.6463                     0.7315        \u001b[35m0.5529\u001b[0m            0.6286                     0.6922        0.5849  0.0010  7.2376\n",
      "      6            0.6794                     0.7468        \u001b[35m0.5476\u001b[0m            0.6678                     \u001b[94m0.7102\u001b[0m        0.5798  0.0009  7.2496\n",
      "      7            0.7364                     \u001b[32m0.7705\u001b[0m        \u001b[35m0.5336\u001b[0m            0.7043                     0.7018        \u001b[36m0.5598\u001b[0m  0.0009  7.2386\n",
      "      8            0.6754                     0.7499        \u001b[35m0.5333\u001b[0m            0.6565                     0.7092        0.5862  0.0009  7.2347\n",
      "      9            0.7357                     \u001b[32m0.7774\u001b[0m        \u001b[35m0.5319\u001b[0m            0.7056                     0.7040        0.5654  0.0009  7.2696\n",
      "     10            \u001b[36m0.7565\u001b[0m                     \u001b[32m0.7787\u001b[0m        \u001b[35m0.5176\u001b[0m            \u001b[31m0.7256\u001b[0m                     \u001b[94m0.7147\u001b[0m        \u001b[36m0.5560\u001b[0m  0.0008  7.2446\n",
      "     11            0.7311                     0.7739        \u001b[35m0.5118\u001b[0m            0.6997                     0.7106        0.5695  0.0008  7.2436\n",
      "     12            0.7297                     \u001b[32m0.7826\u001b[0m        \u001b[35m0.5100\u001b[0m            0.7050                     0.7138        \u001b[36m0.5548\u001b[0m  0.0008  7.2586\n",
      "     13            0.7535                     \u001b[32m0.7871\u001b[0m        0.5150            0.7229                     \u001b[94m0.7204\u001b[0m        \u001b[36m0.5466\u001b[0m  0.0007  7.2396\n",
      "     14            \u001b[36m0.7578\u001b[0m                     \u001b[32m0.7905\u001b[0m        \u001b[35m0.4967\u001b[0m            0.7163                     0.7046        0.5577  0.0007  7.2556\n",
      "     15            \u001b[36m0.7638\u001b[0m                     0.7887        \u001b[35m0.4950\u001b[0m            0.7249                     0.7128        0.5556  0.0006  7.2745\n",
      "     16            0.7043                     0.7726        \u001b[35m0.4908\u001b[0m            0.6757                     0.7092        0.5606  0.0006  7.2765\n",
      "     17            0.7565                     0.7897        \u001b[35m0.4856\u001b[0m            0.7243                     \u001b[94m0.7212\u001b[0m        0.5612  0.0005  7.2686\n",
      "     18            \u001b[36m0.8206\u001b[0m                     \u001b[32m0.8013\u001b[0m        0.4892            \u001b[31m0.7821\u001b[0m                     \u001b[94m0.7227\u001b[0m        0.5620  0.0005  7.2566\n",
      "     19            0.7842                     0.7989        \u001b[35m0.4761\u001b[0m            0.7548                     \u001b[94m0.7310\u001b[0m        0.5555  0.0005  7.2716\n",
      "     20            0.8070                     \u001b[32m0.8043\u001b[0m        \u001b[35m0.4750\u001b[0m            0.7688                     0.7234        0.5556  0.0004  7.2297\n",
      "     21            0.7395                     0.7878        0.4783            0.7076                     0.7169        0.5596  0.0004  7.2606\n",
      "     22            0.7930                     0.7999        \u001b[35m0.4635\u001b[0m            0.7601                     0.7182        0.5517  0.0003  7.2257\n",
      "     23            0.7920                     \u001b[32m0.8062\u001b[0m        0.4734            0.7595                     0.7309        0.5522  0.0003  7.2307\n",
      "     24            0.7929                     0.8052        0.4773            0.7635                     \u001b[94m0.7333\u001b[0m        0.5527  0.0002  7.2376\n",
      "     25            0.7620                     0.8000        0.4639            0.7276                     0.7247        0.5567  0.0002  7.2546\n",
      "     26            0.7836                     0.8054        0.4719            0.7482                     0.7226        0.5513  0.0002  7.2526\n",
      "     27            0.7659                     0.8002        0.4712            0.7395                     0.7319        0.5496  0.0001  7.2277\n",
      "     28            0.7776                     0.8036        0.4669            0.7402                     0.7236        0.5538  0.0001  7.2207\n",
      "     29            0.7857                     \u001b[32m0.8064\u001b[0m        \u001b[35m0.4598\u001b[0m            0.7495                     0.7292        0.5506  0.0001  7.2526\n",
      "     30            0.7756                     0.8035        0.4668            0.7422                     0.7277        0.5501  0.0001  7.2686\n",
      "     31            0.7844                     \u001b[32m0.8070\u001b[0m        \u001b[35m0.4566\u001b[0m            0.7515                     0.7304        0.5500  0.0000  7.2297\n",
      "     32            0.7905                     \u001b[32m0.8100\u001b[0m        0.4597            0.7542                     0.7291        0.5497  0.0000  7.2386\n",
      "     33            0.7934                     \u001b[32m0.8118\u001b[0m        0.4569            0.7568                     0.7293        0.5496  0.0000  7.2815\n",
      "     34            0.7892                     0.8092        \u001b[35m0.4534\u001b[0m            0.7555                     0.7300        0.5500  0.0000  7.2755\n",
      "     35            0.7880                     0.8089        0.4634            0.7535                     0.7287        0.5502  0.0000  7.2506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 1 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6969\u001b[0m                     \u001b[32m0.6985\u001b[0m        \u001b[35m0.6820\u001b[0m            \u001b[31m0.6793\u001b[0m                     \u001b[94m0.6810\u001b[0m        \u001b[36m0.6518\u001b[0m  0.0010  5.5282\n",
      "      2            \u001b[36m0.7118\u001b[0m                     \u001b[32m0.7130\u001b[0m        \u001b[35m0.5918\u001b[0m            \u001b[31m0.7079\u001b[0m                     \u001b[94m0.7091\u001b[0m        \u001b[36m0.6178\u001b[0m  0.0010  5.4524\n",
      "      3            \u001b[36m0.7419\u001b[0m                     \u001b[32m0.7423\u001b[0m        \u001b[35m0.5637\u001b[0m            \u001b[31m0.7260\u001b[0m                     \u001b[94m0.7264\u001b[0m        \u001b[36m0.5807\u001b[0m  0.0010  5.4584\n",
      "      4            \u001b[36m0.7549\u001b[0m                     \u001b[32m0.7554\u001b[0m        \u001b[35m0.5430\u001b[0m            \u001b[31m0.7269\u001b[0m                     \u001b[94m0.7274\u001b[0m        \u001b[36m0.5592\u001b[0m  0.0010  5.4494\n",
      "      5            \u001b[36m0.7564\u001b[0m                     \u001b[32m0.7572\u001b[0m        \u001b[35m0.5335\u001b[0m            \u001b[31m0.7338\u001b[0m                     \u001b[94m0.7348\u001b[0m        \u001b[36m0.5441\u001b[0m  0.0010  5.4584\n",
      "      6            \u001b[36m0.7683\u001b[0m                     \u001b[32m0.7680\u001b[0m        \u001b[35m0.5164\u001b[0m            \u001b[31m0.7519\u001b[0m                     \u001b[94m0.7517\u001b[0m        \u001b[36m0.5238\u001b[0m  0.0009  5.4554\n",
      "      7            \u001b[36m0.7741\u001b[0m                     \u001b[32m0.7741\u001b[0m        \u001b[35m0.5109\u001b[0m            0.7476                     0.7478        \u001b[36m0.5192\u001b[0m  0.0009  5.4594\n",
      "      8            \u001b[36m0.7806\u001b[0m                     \u001b[32m0.7806\u001b[0m        \u001b[35m0.4998\u001b[0m            \u001b[31m0.7537\u001b[0m                     \u001b[94m0.7537\u001b[0m        0.5260  0.0009  5.4574\n",
      "      9            \u001b[36m0.7886\u001b[0m                     \u001b[32m0.7883\u001b[0m        \u001b[35m0.4916\u001b[0m            0.7494                     0.7490        0.5195  0.0009  5.4544\n",
      "     10            0.7851                     0.7852        0.4992            \u001b[31m0.7563\u001b[0m                     \u001b[94m0.7564\u001b[0m        0.5231  0.0008  5.4554\n",
      "     11            \u001b[36m0.7918\u001b[0m                     \u001b[32m0.7920\u001b[0m        \u001b[35m0.4873\u001b[0m            0.7537                     0.7539        0.5214  0.0008  5.4564\n",
      "     12            \u001b[36m0.7957\u001b[0m                     \u001b[32m0.7956\u001b[0m        \u001b[35m0.4798\u001b[0m            \u001b[31m0.7692\u001b[0m                     \u001b[94m0.7691\u001b[0m        \u001b[36m0.5123\u001b[0m  0.0008  5.4574\n",
      "     13            \u001b[36m0.7979\u001b[0m                     \u001b[32m0.7981\u001b[0m        \u001b[35m0.4765\u001b[0m            0.7623                     0.7626        \u001b[36m0.5079\u001b[0m  0.0007  5.4574\n",
      "     14            \u001b[36m0.7998\u001b[0m                     \u001b[32m0.8002\u001b[0m        0.4785            0.7589                     0.7592        0.5119  0.0007  5.4564\n",
      "     15            \u001b[36m0.8013\u001b[0m                     \u001b[32m0.8012\u001b[0m        \u001b[35m0.4731\u001b[0m            0.7632                     0.7631        0.5153  0.0006  5.4594\n",
      "     16            \u001b[36m0.8078\u001b[0m                     \u001b[32m0.8081\u001b[0m        \u001b[35m0.4609\u001b[0m            0.7623                     0.7626        0.5163  0.0006  5.4584\n",
      "     17            0.8070                     0.8069        \u001b[35m0.4524\u001b[0m            \u001b[31m0.7744\u001b[0m                     \u001b[94m0.7744\u001b[0m        \u001b[36m0.5051\u001b[0m  0.0005  5.4554\n",
      "     18            \u001b[36m0.8115\u001b[0m                     \u001b[32m0.8113\u001b[0m        0.4616            0.7545                     0.7544        0.5180  0.0005  5.4544\n",
      "     19            \u001b[36m0.8126\u001b[0m                     \u001b[32m0.8123\u001b[0m        \u001b[35m0.4509\u001b[0m            0.7710                     0.7708        0.5087  0.0005  5.4534\n",
      "     20            0.8024                     0.8019        \u001b[35m0.4409\u001b[0m            0.7640                     0.7636        0.5136  0.0004  5.4544\n",
      "     21            \u001b[36m0.8150\u001b[0m                     \u001b[32m0.8149\u001b[0m        0.4478            \u001b[31m0.7761\u001b[0m                     \u001b[94m0.7762\u001b[0m        \u001b[36m0.5037\u001b[0m  0.0004  5.4594\n",
      "     22            0.8145                     0.8146        0.4469            0.7666                     0.7667        0.5134  0.0003  5.4544\n",
      "     23            0.8141                     0.8141        0.4499            0.7701                     0.7701        0.5112  0.0003  5.4604\n",
      "     24            \u001b[36m0.8214\u001b[0m                     \u001b[32m0.8215\u001b[0m        0.4416            \u001b[31m0.7770\u001b[0m                     \u001b[94m0.7770\u001b[0m        0.5079  0.0002  5.4614\n",
      "     25            0.8169                     0.8168        \u001b[35m0.4307\u001b[0m            0.7736                     0.7734        0.5110  0.0002  5.4604\n",
      "     26            0.8191                     0.8192        0.4333            0.7736                     0.7737        0.5138  0.0002  5.4534\n",
      "     27            0.8191                     0.8191        0.4400            0.7744                     0.7744        0.5129  0.0001  5.4534\n",
      "     28            0.8188                     0.8189        0.4408            0.7710                     0.7710        0.5116  0.0001  5.4504\n",
      "     29            0.8212                     0.8212        0.4368            0.7736                     0.7735        0.5100  0.0001  5.4544\n",
      "     30            0.8201                     0.8201        \u001b[35m0.4275\u001b[0m            0.7744                     0.7744        0.5100  0.0001  5.4574\n",
      "     31            0.8182                     0.8182        \u001b[35m0.4233\u001b[0m            0.7692                     0.7692        0.5106  0.0000  5.4574\n",
      "     32            0.8206                     0.8206        0.4260            0.7710                     0.7710        0.5103  0.0000  5.4584\n",
      "     33            0.8201                     0.8202        0.4326            0.7710                     0.7710        0.5102  0.0000  5.4584\n",
      "     34            0.8201                     0.8202        0.4320            0.7710                     0.7710        0.5101  0.0000  5.4544\n",
      "     35            0.8206                     0.8206        0.4358            0.7710                     0.7709        0.5104  0.0000  5.4604\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7013\u001b[0m                     \u001b[32m0.7028\u001b[0m        \u001b[35m0.6755\u001b[0m            \u001b[31m0.6889\u001b[0m                     \u001b[94m0.6905\u001b[0m        \u001b[36m0.6438\u001b[0m  0.0010  5.4754\n",
      "      2            \u001b[36m0.7274\u001b[0m                     \u001b[32m0.7284\u001b[0m        \u001b[35m0.5864\u001b[0m            \u001b[31m0.7156\u001b[0m                     \u001b[94m0.7168\u001b[0m        \u001b[36m0.6071\u001b[0m  0.0010  5.4754\n",
      "      3            \u001b[36m0.7477\u001b[0m                     \u001b[32m0.7482\u001b[0m        \u001b[35m0.5664\u001b[0m            \u001b[31m0.7303\u001b[0m                     \u001b[94m0.7308\u001b[0m        \u001b[36m0.5682\u001b[0m  0.0010  5.4803\n",
      "      4            \u001b[36m0.7534\u001b[0m                     \u001b[32m0.7535\u001b[0m        \u001b[35m0.5509\u001b[0m            0.7277                     0.7281        \u001b[36m0.5442\u001b[0m  0.0010  5.4774\n",
      "      5            \u001b[36m0.7590\u001b[0m                     \u001b[32m0.7589\u001b[0m        \u001b[35m0.5320\u001b[0m            \u001b[31m0.7338\u001b[0m                     \u001b[94m0.7337\u001b[0m        \u001b[36m0.5229\u001b[0m  0.0010  5.4803\n",
      "      6            \u001b[36m0.7706\u001b[0m                     \u001b[32m0.7704\u001b[0m        \u001b[35m0.5226\u001b[0m            \u001b[31m0.7433\u001b[0m                     \u001b[94m0.7431\u001b[0m        \u001b[36m0.5090\u001b[0m  0.0009  5.4774\n",
      "      7            \u001b[36m0.7765\u001b[0m                     \u001b[32m0.7764\u001b[0m        \u001b[35m0.5094\u001b[0m            \u001b[31m0.7494\u001b[0m                     \u001b[94m0.7494\u001b[0m        \u001b[36m0.5000\u001b[0m  0.0009  5.4813\n",
      "      8            \u001b[36m0.7888\u001b[0m                     \u001b[32m0.7889\u001b[0m        \u001b[35m0.4981\u001b[0m            \u001b[31m0.7511\u001b[0m                     \u001b[94m0.7512\u001b[0m        \u001b[36m0.4938\u001b[0m  0.0009  5.4803\n",
      "      9            0.7873                     0.7869        \u001b[35m0.4920\u001b[0m            \u001b[31m0.7623\u001b[0m                     \u001b[94m0.7620\u001b[0m        \u001b[36m0.4836\u001b[0m  0.0009  5.4813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10            0.7884                     0.7886        \u001b[35m0.4864\u001b[0m            \u001b[31m0.7640\u001b[0m                     \u001b[94m0.7646\u001b[0m        0.4945  0.0008  5.4793\n",
      "     11            \u001b[36m0.8035\u001b[0m                     \u001b[32m0.8033\u001b[0m        0.4868            0.7545                     0.7545        0.4860  0.0008  5.4764\n",
      "     12            0.7964                     0.7964        \u001b[35m0.4754\u001b[0m            \u001b[31m0.7675\u001b[0m                     \u001b[94m0.7675\u001b[0m        \u001b[36m0.4784\u001b[0m  0.0008  5.4793\n",
      "     13            \u001b[36m0.8046\u001b[0m                     \u001b[32m0.8046\u001b[0m        \u001b[35m0.4732\u001b[0m            \u001b[31m0.7736\u001b[0m                     \u001b[94m0.7736\u001b[0m        \u001b[36m0.4737\u001b[0m  0.0007  5.4813\n",
      "     14            \u001b[36m0.8085\u001b[0m                     \u001b[32m0.8084\u001b[0m        \u001b[35m0.4671\u001b[0m            0.7623                     0.7623        0.4772  0.0007  5.4833\n",
      "     15            0.8083                     \u001b[32m0.8085\u001b[0m        \u001b[35m0.4596\u001b[0m            0.7701                     0.7705        0.4763  0.0006  5.4843\n",
      "     16            0.8070                     0.8067        0.4615            0.7649                     0.7647        0.4755  0.0006  5.4764\n",
      "     17            0.8048                     0.8042        \u001b[35m0.4576\u001b[0m            0.7571                     0.7565        0.4790  0.0005  5.4744\n",
      "     18            \u001b[36m0.8165\u001b[0m                     \u001b[32m0.8164\u001b[0m        \u001b[35m0.4485\u001b[0m            \u001b[31m0.7761\u001b[0m                     \u001b[94m0.7761\u001b[0m        \u001b[36m0.4708\u001b[0m  0.0005  5.4803\n",
      "     19            0.8137                     0.8140        0.4553            0.7718                     0.7724        0.4748  0.0005  5.4764\n",
      "     20            0.8165                     0.8161        \u001b[35m0.4411\u001b[0m            0.7649                     0.7645        0.4761  0.0004  5.4813\n",
      "     21            \u001b[36m0.8173\u001b[0m                     \u001b[32m0.8172\u001b[0m        \u001b[35m0.4366\u001b[0m            0.7692                     0.7692        \u001b[36m0.4706\u001b[0m  0.0004  5.4803\n",
      "     22            0.8163                     0.8161        0.4418            0.7684                     0.7683        \u001b[36m0.4701\u001b[0m  0.0003  5.4784\n",
      "     23            \u001b[36m0.8184\u001b[0m                     \u001b[32m0.8185\u001b[0m        0.4419            0.7718                     0.7720        \u001b[36m0.4680\u001b[0m  0.0003  5.4744\n",
      "     24            \u001b[36m0.8204\u001b[0m                     \u001b[32m0.8201\u001b[0m        \u001b[35m0.4363\u001b[0m            0.7649                     0.7647        0.4737  0.0002  5.4813\n",
      "     25            0.8158                     0.8160        \u001b[35m0.4289\u001b[0m            0.7675                     0.7679        0.4681  0.0002  5.4784\n",
      "     26            \u001b[36m0.8230\u001b[0m                     \u001b[32m0.8230\u001b[0m        0.4345            0.7692                     0.7695        \u001b[36m0.4679\u001b[0m  0.0002  5.4843\n",
      "     27            \u001b[36m0.8232\u001b[0m                     \u001b[32m0.8230\u001b[0m        0.4395            0.7701                     0.7702        0.4691  0.0001  5.4774\n",
      "     28            0.8214                     0.8213        \u001b[35m0.4288\u001b[0m            0.7701                     0.7701        0.4685  0.0001  5.4793\n",
      "     29            0.8225                     0.8223        0.4292            0.7666                     0.7666        0.4687  0.0001  5.4784\n",
      "     30            \u001b[36m0.8247\u001b[0m                     \u001b[32m0.8246\u001b[0m        0.4291            0.7684                     0.7684        0.4686  0.0001  5.4784\n",
      "     31            0.8240                     0.8239        0.4298            0.7675                     0.7676        0.4692  0.0000  5.4833\n",
      "     32            \u001b[36m0.8249\u001b[0m                     \u001b[32m0.8248\u001b[0m        0.4301            0.7675                     0.7676        0.4690  0.0000  5.4803\n",
      "     33            0.8238                     0.8238        0.4310            0.7684                     0.7684        0.4689  0.0000  5.4853\n",
      "     34            0.8245                     0.8244        0.4355            0.7666                     0.7667        0.4689  0.0000  5.4833\n",
      "     35            0.8230                     0.8229        \u001b[35m0.4268\u001b[0m            0.7684                     0.7684        0.4688  0.0000  5.4803\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6902\u001b[0m                     \u001b[32m0.6916\u001b[0m        \u001b[35m0.6857\u001b[0m            \u001b[31m0.6992\u001b[0m                     \u001b[94m0.7007\u001b[0m        \u001b[36m0.6510\u001b[0m  0.0010  5.4744\n",
      "      2            \u001b[36m0.7302\u001b[0m                     \u001b[32m0.7302\u001b[0m        \u001b[35m0.5953\u001b[0m            \u001b[31m0.7338\u001b[0m                     \u001b[94m0.7339\u001b[0m        \u001b[36m0.6145\u001b[0m  0.0010  5.4744\n",
      "      3            \u001b[36m0.7374\u001b[0m                     \u001b[32m0.7370\u001b[0m        \u001b[35m0.5661\u001b[0m            0.7191                     0.7188        \u001b[36m0.5859\u001b[0m  0.0010  5.4793\n",
      "      4            \u001b[36m0.7495\u001b[0m                     \u001b[32m0.7491\u001b[0m        \u001b[35m0.5469\u001b[0m            0.7277                     0.7274        \u001b[36m0.5508\u001b[0m  0.0010  5.4764\n",
      "      5            \u001b[36m0.7670\u001b[0m                     \u001b[32m0.7667\u001b[0m        \u001b[35m0.5307\u001b[0m            \u001b[31m0.7433\u001b[0m                     \u001b[94m0.7431\u001b[0m        \u001b[36m0.5449\u001b[0m  0.0010  5.4784\n",
      "      6            \u001b[36m0.7706\u001b[0m                     \u001b[32m0.7708\u001b[0m        \u001b[35m0.5183\u001b[0m            \u001b[31m0.7450\u001b[0m                     \u001b[94m0.7452\u001b[0m        \u001b[36m0.5388\u001b[0m  0.0009  5.4714\n",
      "      7            \u001b[36m0.7830\u001b[0m                     \u001b[32m0.7831\u001b[0m        \u001b[35m0.5078\u001b[0m            \u001b[31m0.7459\u001b[0m                     \u001b[94m0.7459\u001b[0m        \u001b[36m0.5318\u001b[0m  0.0009  5.4724\n",
      "      8            0.7806                     0.7807        \u001b[35m0.4992\u001b[0m            0.7424                     0.7424        0.5378  0.0009  5.4873\n",
      "      9            \u001b[36m0.7892\u001b[0m                     \u001b[32m0.7894\u001b[0m        \u001b[35m0.4956\u001b[0m            0.7424                     0.7425        \u001b[36m0.5313\u001b[0m  0.0009  5.4714\n",
      "     10            \u001b[36m0.8018\u001b[0m                     \u001b[32m0.8016\u001b[0m        \u001b[35m0.4874\u001b[0m            \u001b[31m0.7468\u001b[0m                     \u001b[94m0.7464\u001b[0m        0.5395  0.0008  5.4704\n",
      "     11            0.7972                     0.7968        \u001b[35m0.4835\u001b[0m            0.7468                     0.7463        \u001b[36m0.5284\u001b[0m  0.0008  5.4724\n",
      "     12            0.7979                     0.7974        \u001b[35m0.4792\u001b[0m            0.7407                     0.7401        \u001b[36m0.5275\u001b[0m  0.0008  5.4704\n",
      "     13            \u001b[36m0.8031\u001b[0m                     \u001b[32m0.8032\u001b[0m        \u001b[35m0.4755\u001b[0m            \u001b[31m0.7623\u001b[0m                     \u001b[94m0.7624\u001b[0m        \u001b[36m0.5021\u001b[0m  0.0007  5.4734\n",
      "     14            \u001b[36m0.8048\u001b[0m                     \u001b[32m0.8046\u001b[0m        \u001b[35m0.4732\u001b[0m            0.7511                     0.7507        0.5133  0.0007  5.4744\n",
      "     15            0.7992                     0.7986        \u001b[35m0.4667\u001b[0m            0.7459                     0.7453        0.5164  0.0006  5.4684\n",
      "     16            \u001b[36m0.8067\u001b[0m                     \u001b[32m0.8065\u001b[0m        \u001b[35m0.4587\u001b[0m            0.7580                     0.7577        0.5097  0.0006  5.4744\n",
      "     17            \u001b[36m0.8134\u001b[0m                     \u001b[32m0.8136\u001b[0m        \u001b[35m0.4553\u001b[0m            0.7589                     0.7590        0.5060  0.0005  5.4744\n",
      "     18            0.8096                     0.8096        \u001b[35m0.4502\u001b[0m            \u001b[31m0.7649\u001b[0m                     \u001b[94m0.7649\u001b[0m        0.5034  0.0005  5.4784\n",
      "     19            \u001b[36m0.8182\u001b[0m                     \u001b[32m0.8179\u001b[0m        0.4546            0.7649                     0.7646        0.5088  0.0005  5.4724\n",
      "     20            0.8169                     0.8166        \u001b[35m0.4500\u001b[0m            \u001b[31m0.7658\u001b[0m                     \u001b[94m0.7656\u001b[0m        0.5039  0.0004  5.4724\n",
      "     21            \u001b[36m0.8193\u001b[0m                     \u001b[32m0.8191\u001b[0m        \u001b[35m0.4463\u001b[0m            0.7632                     0.7630        \u001b[36m0.5015\u001b[0m  0.0004  5.4784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22            \u001b[36m0.8210\u001b[0m                     \u001b[32m0.8208\u001b[0m        \u001b[35m0.4418\u001b[0m            \u001b[31m0.7684\u001b[0m                     \u001b[94m0.7682\u001b[0m        0.5041  0.0003  5.4744\n",
      "     23            0.8182                     0.8178        0.4484            0.7666                     0.7663        0.5054  0.0003  5.4704\n",
      "     24            \u001b[36m0.8238\u001b[0m                     \u001b[32m0.8236\u001b[0m        \u001b[35m0.4381\u001b[0m            0.7666                     0.7664        0.5071  0.0002  5.4744\n",
      "     25            \u001b[36m0.8249\u001b[0m                     \u001b[32m0.8245\u001b[0m        0.4395            0.7623                     0.7620        0.5105  0.0002  5.4744\n",
      "     26            0.8247                     \u001b[32m0.8246\u001b[0m        \u001b[35m0.4376\u001b[0m            0.7658                     0.7657        0.5044  0.0002  5.4784\n",
      "     27            \u001b[36m0.8253\u001b[0m                     \u001b[32m0.8250\u001b[0m        \u001b[35m0.4296\u001b[0m            0.7666                     0.7664        0.5061  0.0001  5.4764\n",
      "     28            \u001b[36m0.8258\u001b[0m                     \u001b[32m0.8255\u001b[0m        0.4394            0.7658                     0.7657        0.5025  0.0001  5.4754\n",
      "     29            \u001b[36m0.8288\u001b[0m                     \u001b[32m0.8285\u001b[0m        0.4336            \u001b[31m0.7710\u001b[0m                     \u001b[94m0.7709\u001b[0m        \u001b[36m0.5011\u001b[0m  0.0001  5.4774\n",
      "     30            \u001b[36m0.8299\u001b[0m                     \u001b[32m0.8296\u001b[0m        0.4336            0.7692                     0.7691        0.5021  0.0001  5.4734\n",
      "     31            0.8292                     0.8290        0.4342            0.7675                     0.7674        \u001b[36m0.5011\u001b[0m  0.0000  5.4724\n",
      "     32            0.8292                     0.8290        0.4333            0.7692                     0.7691        \u001b[36m0.5004\u001b[0m  0.0000  5.4784\n",
      "     33            \u001b[36m0.8305\u001b[0m                     \u001b[32m0.8303\u001b[0m        0.4322            0.7684                     0.7683        0.5008  0.0000  5.4774\n",
      "     34            0.8301                     0.8298        0.4327            0.7684                     0.7682        0.5010  0.0000  5.4774\n",
      "     35            0.8303                     0.8301        0.4359            0.7684                     0.7682        0.5010  0.0000  5.4803\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6915\u001b[0m                     \u001b[32m0.6933\u001b[0m        \u001b[35m0.6879\u001b[0m            \u001b[31m0.6828\u001b[0m                     \u001b[94m0.6848\u001b[0m        \u001b[36m0.6507\u001b[0m  0.0010  5.5502\n",
      "      2            \u001b[36m0.7328\u001b[0m                     \u001b[32m0.7336\u001b[0m        \u001b[35m0.5879\u001b[0m            \u001b[31m0.7182\u001b[0m                     \u001b[94m0.7192\u001b[0m        \u001b[36m0.6175\u001b[0m  0.0010  5.6823\n",
      "      3            \u001b[36m0.7501\u001b[0m                     \u001b[32m0.7503\u001b[0m        \u001b[35m0.5619\u001b[0m            0.7148                     0.7152        \u001b[36m0.5759\u001b[0m  0.0010  5.4504\n",
      "      4            \u001b[36m0.7546\u001b[0m                     \u001b[32m0.7550\u001b[0m        \u001b[35m0.5415\u001b[0m            0.7165                     0.7171        \u001b[36m0.5512\u001b[0m  0.0010  5.4385\n",
      "      5            \u001b[36m0.7709\u001b[0m                     \u001b[32m0.7708\u001b[0m        \u001b[35m0.5212\u001b[0m            \u001b[31m0.7373\u001b[0m                     \u001b[94m0.7374\u001b[0m        \u001b[36m0.5419\u001b[0m  0.0010  5.4345\n",
      "      6            0.7683                     0.7677        \u001b[35m0.5145\u001b[0m            0.7303                     0.7299        \u001b[36m0.5343\u001b[0m  0.0009  5.4415\n",
      "      7            \u001b[36m0.7825\u001b[0m                     \u001b[32m0.7824\u001b[0m        \u001b[35m0.4949\u001b[0m            \u001b[31m0.7450\u001b[0m                     \u001b[94m0.7450\u001b[0m        \u001b[36m0.5175\u001b[0m  0.0009  6.0309\n",
      "      8            \u001b[36m0.7838\u001b[0m                     \u001b[32m0.7846\u001b[0m        \u001b[35m0.4912\u001b[0m            0.7312                     0.7320        0.5359  0.0009  5.5641\n",
      "      9            \u001b[36m0.7977\u001b[0m                     \u001b[32m0.7980\u001b[0m        \u001b[35m0.4821\u001b[0m            \u001b[31m0.7468\u001b[0m                     \u001b[94m0.7471\u001b[0m        0.5272  0.0009  5.5731\n",
      "     10            0.7970                     0.7967        \u001b[35m0.4808\u001b[0m            \u001b[31m0.7502\u001b[0m                     \u001b[94m0.7499\u001b[0m        0.5218  0.0008  5.5761\n",
      "     11            0.7968                     0.7966        \u001b[35m0.4722\u001b[0m            0.7468                     0.7466        \u001b[36m0.5104\u001b[0m  0.0008  5.5771\n",
      "     12            0.7953                     0.7951        \u001b[35m0.4708\u001b[0m            0.7494                     0.7490        0.5137  0.0008  5.5741\n",
      "     13            \u001b[36m0.8022\u001b[0m                     \u001b[32m0.8021\u001b[0m        \u001b[35m0.4661\u001b[0m            \u001b[31m0.7537\u001b[0m                     \u001b[94m0.7537\u001b[0m        0.5109  0.0007  5.5741\n",
      "     14            \u001b[36m0.8061\u001b[0m                     \u001b[32m0.8059\u001b[0m        \u001b[35m0.4571\u001b[0m            \u001b[31m0.7580\u001b[0m                     \u001b[94m0.7578\u001b[0m        \u001b[36m0.5060\u001b[0m  0.0007  5.6050\n",
      "     15            \u001b[36m0.8134\u001b[0m                     \u001b[32m0.8133\u001b[0m        0.4600            \u001b[31m0.7597\u001b[0m                     \u001b[94m0.7596\u001b[0m        \u001b[36m0.5014\u001b[0m  0.0006  5.5791\n",
      "     16            0.8104                     0.8102        \u001b[35m0.4463\u001b[0m            \u001b[31m0.7615\u001b[0m                     \u001b[94m0.7613\u001b[0m        \u001b[36m0.4996\u001b[0m  0.0006  5.5950\n",
      "     17            0.8126                     0.8125        \u001b[35m0.4458\u001b[0m            0.7571                     0.7571        0.5027  0.0005  5.5681\n",
      "     18            \u001b[36m0.8171\u001b[0m                     \u001b[32m0.8170\u001b[0m        \u001b[35m0.4444\u001b[0m            \u001b[31m0.7736\u001b[0m                     \u001b[94m0.7733\u001b[0m        \u001b[36m0.4986\u001b[0m  0.0005  5.5492\n",
      "     19            \u001b[36m0.8182\u001b[0m                     \u001b[32m0.8183\u001b[0m        \u001b[35m0.4411\u001b[0m            0.7666                     0.7666        \u001b[36m0.4955\u001b[0m  0.0005  5.5761\n",
      "     20            \u001b[36m0.8193\u001b[0m                     \u001b[32m0.8192\u001b[0m        \u001b[35m0.4358\u001b[0m            0.7692                     0.7692        0.4960  0.0004  5.5801\n",
      "     21            \u001b[36m0.8201\u001b[0m                     \u001b[32m0.8200\u001b[0m        \u001b[35m0.4332\u001b[0m            0.7666                     0.7665        0.5007  0.0004  5.5950\n",
      "     22            0.8163                     0.8163        0.4365            \u001b[31m0.7744\u001b[0m                     \u001b[94m0.7745\u001b[0m        \u001b[36m0.4917\u001b[0m  0.0003  5.5861\n",
      "     23            \u001b[36m0.8208\u001b[0m                     \u001b[32m0.8207\u001b[0m        0.4381            \u001b[31m0.7787\u001b[0m                     \u001b[94m0.7786\u001b[0m        0.4935  0.0003  5.6100\n",
      "     24            0.8178                     0.8177        \u001b[35m0.4293\u001b[0m            0.7710                     0.7708        0.4936  0.0002  5.6080\n",
      "     25            0.8193                     0.8190        \u001b[35m0.4248\u001b[0m            0.7779                     0.7776        0.4924  0.0002  5.5801\n",
      "     26            \u001b[36m0.8217\u001b[0m                     \u001b[32m0.8214\u001b[0m        0.4314            \u001b[31m0.7796\u001b[0m                     \u001b[94m0.7793\u001b[0m        0.4926  0.0002  5.6170\n",
      "     27            0.8201                     0.8200        \u001b[35m0.4241\u001b[0m            0.7770                     0.7769        \u001b[36m0.4905\u001b[0m  0.0001  5.5701\n",
      "     28            \u001b[36m0.8219\u001b[0m                     \u001b[32m0.8217\u001b[0m        \u001b[35m0.4221\u001b[0m            0.7761                     0.7760        0.4937  0.0001  5.6020\n",
      "     29            \u001b[36m0.8253\u001b[0m                     \u001b[32m0.8253\u001b[0m        \u001b[35m0.4215\u001b[0m            0.7710                     0.7710        \u001b[36m0.4902\u001b[0m  0.0001  5.5841\n",
      "     30            0.8221                     0.8220        \u001b[35m0.4214\u001b[0m            0.7787                     0.7786        0.4908  0.0001  5.5591\n",
      "     31            0.8234                     0.8233        0.4251            0.7779                     0.7777        0.4912  0.0000  5.5811\n",
      "     32            0.8214                     0.8214        0.4269            0.7796                     \u001b[94m0.7795\u001b[0m        0.4910  0.0000  5.5641\n",
      "     33            0.8219                     0.8218        \u001b[35m0.4147\u001b[0m            0.7787                     0.7786        0.4906  0.0000  5.5711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34            0.8223                     0.8222        0.4245            0.7787                     0.7786        0.4907  0.0000  5.5741\n",
      "     35            0.8223                     0.8222        0.4207            0.7796                     0.7795        0.4907  0.0000  5.6150\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7006\u001b[0m                     \u001b[32m0.7018\u001b[0m        \u001b[35m0.6741\u001b[0m            \u001b[31m0.6785\u001b[0m                     \u001b[94m0.6800\u001b[0m        \u001b[36m0.6422\u001b[0m  0.0010  5.5731\n",
      "      2            \u001b[36m0.7287\u001b[0m                     \u001b[32m0.7291\u001b[0m        \u001b[35m0.5956\u001b[0m            \u001b[31m0.7269\u001b[0m                     \u001b[94m0.7276\u001b[0m        \u001b[36m0.6070\u001b[0m  0.0010  5.5701\n",
      "      3            \u001b[36m0.7490\u001b[0m                     \u001b[32m0.7492\u001b[0m        \u001b[35m0.5679\u001b[0m            \u001b[31m0.7355\u001b[0m                     \u001b[94m0.7360\u001b[0m        \u001b[36m0.5732\u001b[0m  0.0010  5.5970\n",
      "      4            \u001b[36m0.7549\u001b[0m                     \u001b[32m0.7553\u001b[0m        \u001b[35m0.5456\u001b[0m            0.7329                     0.7336        \u001b[36m0.5471\u001b[0m  0.0010  5.5741\n",
      "      5            \u001b[36m0.7611\u001b[0m                     \u001b[32m0.7615\u001b[0m        \u001b[35m0.5342\u001b[0m            \u001b[31m0.7511\u001b[0m                     \u001b[94m0.7518\u001b[0m        \u001b[36m0.5306\u001b[0m  0.0010  5.5721\n",
      "      6            \u001b[36m0.7689\u001b[0m                     \u001b[32m0.7685\u001b[0m        \u001b[35m0.5179\u001b[0m            \u001b[31m0.7563\u001b[0m                     \u001b[94m0.7560\u001b[0m        \u001b[36m0.5093\u001b[0m  0.0009  5.5920\n",
      "      7            \u001b[36m0.7804\u001b[0m                     \u001b[32m0.7803\u001b[0m        \u001b[35m0.5072\u001b[0m            0.7519                     0.7522        0.5201  0.0009  5.6309\n",
      "      8            \u001b[36m0.7942\u001b[0m                     \u001b[32m0.7941\u001b[0m        \u001b[35m0.5068\u001b[0m            \u001b[31m0.7658\u001b[0m                     \u001b[94m0.7659\u001b[0m        \u001b[36m0.5040\u001b[0m  0.0009  5.6220\n",
      "      9            \u001b[36m0.7959\u001b[0m                     \u001b[32m0.7959\u001b[0m        \u001b[35m0.4910\u001b[0m            0.7615                     0.7617        0.5051  0.0009  5.6060\n",
      "     10            \u001b[36m0.7981\u001b[0m                     \u001b[32m0.7976\u001b[0m        \u001b[35m0.4831\u001b[0m            0.7494                     0.7491        \u001b[36m0.5030\u001b[0m  0.0008  5.6030\n",
      "     11            \u001b[36m0.8063\u001b[0m                     \u001b[32m0.8063\u001b[0m        \u001b[35m0.4804\u001b[0m            0.7649                     0.7652        \u001b[36m0.4951\u001b[0m  0.0008  5.5831\n",
      "     12            0.8022                     0.8019        \u001b[35m0.4724\u001b[0m            0.7632                     0.7632        \u001b[36m0.4911\u001b[0m  0.0008  5.6240\n",
      "     13            \u001b[36m0.8100\u001b[0m                     \u001b[32m0.8098\u001b[0m        \u001b[35m0.4637\u001b[0m            \u001b[31m0.7710\u001b[0m                     \u001b[94m0.7710\u001b[0m        0.4935  0.0007  5.5801\n",
      "     14            \u001b[36m0.8102\u001b[0m                     \u001b[32m0.8102\u001b[0m        0.4685            0.7649                     0.7652        \u001b[36m0.4905\u001b[0m  0.0007  5.5721\n",
      "     15            0.8061                     0.8065        \u001b[35m0.4554\u001b[0m            0.7632                     0.7639        0.4950  0.0006  5.5871\n",
      "     16            0.8057                     0.8055        0.4593            0.7701                     0.7702        \u001b[36m0.4895\u001b[0m  0.0006  5.6100\n",
      "     17            \u001b[36m0.8126\u001b[0m                     \u001b[32m0.8122\u001b[0m        \u001b[35m0.4505\u001b[0m            0.7623                     0.7622        0.4941  0.0005  5.6030\n",
      "     18            \u001b[36m0.8134\u001b[0m                     \u001b[32m0.8139\u001b[0m        \u001b[35m0.4493\u001b[0m            0.7692                     0.7700        0.4935  0.0005  5.5911\n",
      "     19            \u001b[36m0.8171\u001b[0m                     \u001b[32m0.8172\u001b[0m        0.4507            \u001b[31m0.7744\u001b[0m                     \u001b[94m0.7748\u001b[0m        0.4898  0.0005  5.5851\n",
      "     20            \u001b[36m0.8199\u001b[0m                     \u001b[32m0.8199\u001b[0m        \u001b[35m0.4454\u001b[0m            0.7640                     0.7642        \u001b[36m0.4877\u001b[0m  0.0004  5.6419\n",
      "     21            0.8176                     0.8174        \u001b[35m0.4377\u001b[0m            0.7658                     0.7659        0.4952  0.0004  5.5791\n",
      "     22            \u001b[36m0.8275\u001b[0m                     \u001b[32m0.8274\u001b[0m        \u001b[35m0.4369\u001b[0m            0.7684                     0.7685        \u001b[36m0.4870\u001b[0m  0.0003  5.5751\n",
      "     23            0.8223                     0.8223        \u001b[35m0.4360\u001b[0m            0.7684                     0.7686        \u001b[36m0.4846\u001b[0m  0.0003  5.5831\n",
      "     24            0.8227                     0.8228        \u001b[35m0.4296\u001b[0m            0.7675                     0.7679        \u001b[36m0.4833\u001b[0m  0.0002  5.5671\n",
      "     25            0.8223                     0.8223        0.4345            0.7692                     0.7694        0.4850  0.0002  5.5701\n",
      "     26            0.8273                     0.8272        0.4326            0.7736                     0.7737        0.4848  0.0002  5.5821\n",
      "     27            0.8256                     0.8256        \u001b[35m0.4283\u001b[0m            0.7692                     0.7696        0.4849  0.0001  5.5751\n",
      "     28            0.8266                     0.8266        \u001b[35m0.4276\u001b[0m            0.7736                     0.7737        0.4844  0.0001  5.5681\n",
      "     29            0.8256                     0.8255        \u001b[35m0.4248\u001b[0m            0.7727                     0.7730        0.4840  0.0001  5.5711\n",
      "     30            0.8236                     0.8236        0.4271            0.7736                     0.7738        0.4841  0.0001  5.5781\n",
      "     31            0.8258                     0.8257        0.4284            0.7744                     0.7747        0.4839  0.0000  5.6130\n",
      "     32            0.8249                     0.8249        \u001b[35m0.4161\u001b[0m            \u001b[31m0.7761\u001b[0m                     \u001b[94m0.7764\u001b[0m        0.4839  0.0000  5.5960\n",
      "     33            0.8247                     0.8247        0.4236            0.7761                     0.7764        0.4839  0.0000  5.6070\n",
      "     34            0.8245                     0.8244        0.4288            \u001b[31m0.7770\u001b[0m                     \u001b[94m0.7773\u001b[0m        0.4839  0.0000  5.4684\n",
      "     35            0.8247                     0.8247        0.4287            0.7761                     0.7764        0.4840  0.0000  5.4395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6886\u001b[0m                     \u001b[32m0.7010\u001b[0m        \u001b[35m0.6760\u001b[0m            \u001b[31m0.6946\u001b[0m                     \u001b[94m0.7114\u001b[0m        \u001b[36m0.6289\u001b[0m  0.0010  3.2603\n",
      "      2            \u001b[36m0.7096\u001b[0m                     \u001b[32m0.7200\u001b[0m        \u001b[35m0.5945\u001b[0m            \u001b[31m0.7077\u001b[0m                     \u001b[94m0.7226\u001b[0m        \u001b[36m0.6211\u001b[0m  0.0010  3.2553\n",
      "      3            \u001b[36m0.7187\u001b[0m                     \u001b[32m0.7329\u001b[0m        \u001b[35m0.5524\u001b[0m            0.7033                     0.7208        \u001b[36m0.6087\u001b[0m  0.0010  3.2603\n",
      "      4            \u001b[36m0.7390\u001b[0m                     \u001b[32m0.7487\u001b[0m        \u001b[35m0.5272\u001b[0m            \u001b[31m0.7207\u001b[0m                     \u001b[94m0.7335\u001b[0m        \u001b[36m0.5714\u001b[0m  0.0010  3.2583\n",
      "      5            0.7346                     0.7484        \u001b[35m0.5230\u001b[0m            0.7033                     0.7195        \u001b[36m0.5692\u001b[0m  0.0010  3.2573\n",
      "      6            0.7310                     0.7486        \u001b[35m0.5091\u001b[0m            0.6874                     0.7081        0.5781  0.0009  3.2603\n",
      "      7            \u001b[36m0.7694\u001b[0m                     \u001b[32m0.7726\u001b[0m        \u001b[35m0.5082\u001b[0m            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7337\u001b[0m        \u001b[36m0.5300\u001b[0m  0.0009  3.2563\n",
      "      8            \u001b[36m0.7791\u001b[0m                     \u001b[32m0.7815\u001b[0m        \u001b[35m0.4994\u001b[0m            \u001b[31m0.7337\u001b[0m                     \u001b[94m0.7390\u001b[0m        \u001b[36m0.5259\u001b[0m  0.0009  3.2623\n",
      "      9            0.7766                     0.7788        \u001b[35m0.4939\u001b[0m            0.7294                     0.7348        \u001b[36m0.5170\u001b[0m  0.0009  3.2593\n",
      "     10            0.7784                     0.7800        \u001b[35m0.4855\u001b[0m            0.7337                     0.7372        0.5181  0.0008  3.2623\n",
      "     11            \u001b[36m0.7839\u001b[0m                     \u001b[32m0.7848\u001b[0m        \u001b[35m0.4788\u001b[0m            \u001b[31m0.7467\u001b[0m                     \u001b[94m0.7493\u001b[0m        0.5208  0.0008  3.2643\n",
      "     12            0.7839                     \u001b[32m0.7888\u001b[0m        \u001b[35m0.4651\u001b[0m            0.7366                     0.7434        0.5306  0.0008  3.2553\n",
      "     13            \u001b[36m0.7886\u001b[0m                     \u001b[32m0.7893\u001b[0m        0.4730            0.7337                     0.7366        0.5273  0.0007  3.2603\n",
      "     14            \u001b[36m0.7900\u001b[0m                     \u001b[32m0.7981\u001b[0m        \u001b[35m0.4611\u001b[0m            0.7265                     0.7351        0.5495  0.0007  3.2583\n",
      "     15            \u001b[36m0.7954\u001b[0m                     0.7940        \u001b[35m0.4603\u001b[0m            0.7453                     0.7447        0.5294  0.0006  3.2653\n",
      "     16            \u001b[36m0.7987\u001b[0m                     \u001b[32m0.8065\u001b[0m        \u001b[35m0.4538\u001b[0m            0.7149                     0.7243        0.5389  0.0006  3.2593\n",
      "     17            \u001b[36m0.8020\u001b[0m                     0.8055        \u001b[35m0.4471\u001b[0m            0.7337                     0.7375        0.5364  0.0005  3.2613\n",
      "     18            \u001b[36m0.8063\u001b[0m                     \u001b[32m0.8143\u001b[0m        \u001b[35m0.4443\u001b[0m            0.7192                     0.7271        0.5447  0.0005  3.2583\n",
      "     19            \u001b[36m0.8121\u001b[0m                     0.8128        \u001b[35m0.4352\u001b[0m            0.7438                     0.7464        0.5370  0.0005  3.2603\n",
      "     20            0.8106                     \u001b[32m0.8164\u001b[0m        0.4395            0.7294                     0.7360        0.5405  0.0004  3.2613\n",
      "     21            \u001b[36m0.8175\u001b[0m                     \u001b[32m0.8201\u001b[0m        0.4433            0.7395                     0.7427        0.5384  0.0004  3.2633\n",
      "     22            \u001b[36m0.8179\u001b[0m                     \u001b[32m0.8210\u001b[0m        \u001b[35m0.4327\u001b[0m            0.7467                     \u001b[94m0.7508\u001b[0m        0.5404  0.0003  3.2613\n",
      "     23            0.8117                     0.8165        0.4354            0.7279                     0.7334        0.5437  0.0003  3.2553\n",
      "     24            0.8074                     0.8159        0.4366            0.7207                     0.7290        0.5499  0.0002  3.2573\n",
      "     25            0.8096                     0.8166        0.4328            0.7250                     0.7326        0.5421  0.0002  3.2583\n",
      "     26            0.8110                     0.8188        \u001b[35m0.4312\u001b[0m            0.7294                     0.7369        0.5452  0.0002  3.2613\n",
      "     27            \u001b[36m0.8190\u001b[0m                     \u001b[32m0.8241\u001b[0m        \u001b[35m0.4262\u001b[0m            0.7410                     0.7459        0.5400  0.0001  3.2613\n",
      "     28            \u001b[36m0.8237\u001b[0m                     \u001b[32m0.8276\u001b[0m        0.4269            \u001b[31m0.7482\u001b[0m                     \u001b[94m0.7518\u001b[0m        0.5384  0.0001  3.2633\n",
      "     29            0.8222                     0.8252        \u001b[35m0.4223\u001b[0m            0.7381                     0.7417        0.5363  0.0001  3.2623\n",
      "     30            0.8208                     0.8256        0.4240            0.7410                     0.7456        0.5385  0.0001  3.2663\n",
      "     31            0.8204                     0.8248        \u001b[35m0.4175\u001b[0m            0.7453                     0.7495        0.5385  0.0000  3.2603\n",
      "     32            0.8222                     0.8274        0.4203            0.7381                     0.7432        0.5401  0.0000  3.2603\n",
      "     33            0.8219                     0.8268        0.4192            0.7381                     0.7429        0.5394  0.0000  3.2603\n",
      "     34            0.8215                     0.8261        0.4255            0.7395                     0.7442        0.5390  0.0000  3.2613\n",
      "     35            0.8215                     0.8262        0.4274            0.7395                     0.7442        0.5394  0.0000  3.2573\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6774\u001b[0m                     \u001b[32m0.6960\u001b[0m        \u001b[35m0.6682\u001b[0m            \u001b[31m0.6802\u001b[0m                     \u001b[94m0.6964\u001b[0m        \u001b[36m0.6396\u001b[0m  0.0010  3.2533\n",
      "      2            \u001b[36m0.7219\u001b[0m                     \u001b[32m0.7318\u001b[0m        \u001b[35m0.5795\u001b[0m            \u001b[31m0.7004\u001b[0m                     \u001b[94m0.7100\u001b[0m        \u001b[36m0.6233\u001b[0m  0.0010  3.2623\n",
      "      3            \u001b[36m0.7343\u001b[0m                     \u001b[32m0.7452\u001b[0m        \u001b[35m0.5408\u001b[0m            \u001b[31m0.7106\u001b[0m                     \u001b[94m0.7201\u001b[0m        \u001b[36m0.6047\u001b[0m  0.0010  3.2533\n",
      "      4            \u001b[36m0.7451\u001b[0m                     \u001b[32m0.7543\u001b[0m        \u001b[35m0.5272\u001b[0m            \u001b[31m0.7207\u001b[0m                     \u001b[94m0.7290\u001b[0m        \u001b[36m0.5767\u001b[0m  0.0010  3.2563\n",
      "      5            \u001b[36m0.7480\u001b[0m                     \u001b[32m0.7597\u001b[0m        \u001b[35m0.5137\u001b[0m            0.7149                     0.7255        \u001b[36m0.5664\u001b[0m  0.0010  3.2503\n",
      "      6            \u001b[36m0.7549\u001b[0m                     \u001b[32m0.7643\u001b[0m        \u001b[35m0.5019\u001b[0m            0.7091                     0.7179        \u001b[36m0.5544\u001b[0m  0.0009  3.2563\n",
      "      7            \u001b[36m0.7647\u001b[0m                     \u001b[32m0.7721\u001b[0m        \u001b[35m0.4886\u001b[0m            0.7149                     0.7225        \u001b[36m0.5478\u001b[0m  0.0009  3.2553\n",
      "      8            \u001b[36m0.7748\u001b[0m                     \u001b[32m0.7804\u001b[0m        0.4901            \u001b[31m0.7236\u001b[0m                     0.7274        \u001b[36m0.5449\u001b[0m  0.0009  3.2583\n",
      "      9            \u001b[36m0.7795\u001b[0m                     \u001b[32m0.7844\u001b[0m        \u001b[35m0.4858\u001b[0m            \u001b[31m0.7250\u001b[0m                     0.7284        0.5490  0.0009  3.2533\n",
      "     10            \u001b[36m0.7893\u001b[0m                     \u001b[32m0.7943\u001b[0m        \u001b[35m0.4856\u001b[0m            0.7192                     0.7223        0.5487  0.0008  3.2533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            0.7893                     0.7943        \u001b[35m0.4808\u001b[0m            0.7221                     0.7255        \u001b[36m0.5428\u001b[0m  0.0008  3.2563\n",
      "     12            \u001b[36m0.7922\u001b[0m                     0.7908        \u001b[35m0.4670\u001b[0m            0.7178                     0.7137        0.5523  0.0008  3.2543\n",
      "     13            \u001b[36m0.7940\u001b[0m                     0.7940        \u001b[35m0.4532\u001b[0m            0.7250                     0.7239        0.5495  0.0007  3.2543\n",
      "     14            \u001b[36m0.7965\u001b[0m                     0.7940        0.4576            0.7221                     0.7168        0.5648  0.0007  3.2563\n",
      "     15            0.7965                     \u001b[32m0.8010\u001b[0m        0.4548            \u001b[31m0.7323\u001b[0m                     \u001b[94m0.7350\u001b[0m        0.5480  0.0006  3.2573\n",
      "     16            \u001b[36m0.8038\u001b[0m                     \u001b[32m0.8057\u001b[0m        0.4576            0.7294                     0.7284        0.5482  0.0006  3.2553\n",
      "     17            \u001b[36m0.8056\u001b[0m                     \u001b[32m0.8070\u001b[0m        \u001b[35m0.4500\u001b[0m            0.7265                     0.7261        0.5471  0.0005  3.2563\n",
      "     18            0.7962                     0.8062        \u001b[35m0.4457\u001b[0m            0.7207                     0.7296        0.5535  0.0005  3.2593\n",
      "     19            \u001b[36m0.8077\u001b[0m                     \u001b[32m0.8094\u001b[0m        \u001b[35m0.4411\u001b[0m            \u001b[31m0.7410\u001b[0m                     \u001b[94m0.7413\u001b[0m        0.5470  0.0005  3.2613\n",
      "     20            \u001b[36m0.8085\u001b[0m                     \u001b[32m0.8107\u001b[0m        \u001b[35m0.4397\u001b[0m            0.7308                     0.7304        0.5460  0.0004  3.2553\n",
      "     21            0.8070                     \u001b[32m0.8140\u001b[0m        \u001b[35m0.4360\u001b[0m            0.7265                     0.7321        0.5526  0.0004  3.2513\n",
      "     22            \u001b[36m0.8092\u001b[0m                     0.8115        0.4377            0.7294                     0.7284        0.5449  0.0003  3.2543\n",
      "     23            \u001b[36m0.8128\u001b[0m                     \u001b[32m0.8159\u001b[0m        0.4377            0.7337                     0.7354        0.5484  0.0003  3.2513\n",
      "     24            \u001b[36m0.8146\u001b[0m                     \u001b[32m0.8178\u001b[0m        \u001b[35m0.4264\u001b[0m            0.7294                     0.7308        0.5510  0.0002  3.2563\n",
      "     25            0.8128                     0.8151        0.4314            0.7395                     0.7403        0.5466  0.0002  3.2583\n",
      "     26            \u001b[36m0.8161\u001b[0m                     \u001b[32m0.8184\u001b[0m        0.4310            0.7294                     0.7296        0.5487  0.0002  3.2563\n",
      "     27            \u001b[36m0.8201\u001b[0m                     \u001b[32m0.8228\u001b[0m        0.4280            0.7381                     0.7402        0.5483  0.0001  3.2633\n",
      "     28            0.8150                     0.8194        \u001b[35m0.4197\u001b[0m            0.7308                     0.7349        0.5493  0.0001  3.2603\n",
      "     29            0.8128                     0.8174        0.4349            0.7352                     0.7391        0.5505  0.0001  3.2563\n",
      "     30            0.8146                     0.8183        0.4236            0.7337                     0.7366        0.5507  0.0001  3.2603\n",
      "     31            0.8132                     0.8172        0.4278            0.7352                     0.7385        0.5510  0.0000  3.2563\n",
      "     32            0.8139                     0.8178        0.4208            0.7352                     0.7382        0.5503  0.0000  3.2533\n",
      "     33            0.8150                     0.8187        \u001b[35m0.4172\u001b[0m            0.7352                     0.7379        0.5501  0.0000  3.2523\n",
      "     34            0.8150                     0.8187        0.4268            0.7352                     0.7379        0.5501  0.0000  3.2523\n",
      "     35            0.8150                     0.8187        0.4286            0.7352                     0.7379        0.5502  0.0000  3.2533\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6883\u001b[0m                     \u001b[32m0.6997\u001b[0m        \u001b[35m0.6751\u001b[0m            \u001b[31m0.7120\u001b[0m                     \u001b[94m0.7214\u001b[0m        \u001b[36m0.6269\u001b[0m  0.0010  3.2553\n",
      "      2            \u001b[36m0.7111\u001b[0m                     \u001b[32m0.7242\u001b[0m        \u001b[35m0.5831\u001b[0m            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7419\u001b[0m        \u001b[36m0.6209\u001b[0m  0.0010  3.2493\n",
      "      3            \u001b[36m0.7281\u001b[0m                     \u001b[32m0.7402\u001b[0m        \u001b[35m0.5508\u001b[0m            0.7091                     0.7218        \u001b[36m0.6006\u001b[0m  0.0010  3.2503\n",
      "      4            \u001b[36m0.7306\u001b[0m                     \u001b[32m0.7411\u001b[0m        \u001b[35m0.5451\u001b[0m            0.7236                     0.7340        \u001b[36m0.5791\u001b[0m  0.0010  3.2533\n",
      "      5            \u001b[36m0.7444\u001b[0m                     \u001b[32m0.7540\u001b[0m        \u001b[35m0.5266\u001b[0m            0.7265                     0.7357        \u001b[36m0.5655\u001b[0m  0.0010  3.2533\n",
      "      6            \u001b[36m0.7563\u001b[0m                     \u001b[32m0.7542\u001b[0m        \u001b[35m0.5166\u001b[0m            \u001b[31m0.7438\u001b[0m                     0.7410        \u001b[36m0.5284\u001b[0m  0.0009  3.2543\n",
      "      7            0.7538                     \u001b[32m0.7599\u001b[0m        \u001b[35m0.5046\u001b[0m            0.7410                     \u001b[94m0.7465\u001b[0m        \u001b[36m0.5275\u001b[0m  0.0009  3.2513\n",
      "      8            \u001b[36m0.7730\u001b[0m                     \u001b[32m0.7744\u001b[0m        \u001b[35m0.4985\u001b[0m            \u001b[31m0.7482\u001b[0m                     \u001b[94m0.7491\u001b[0m        \u001b[36m0.5124\u001b[0m  0.0009  3.2573\n",
      "      9            0.7715                     0.7721        \u001b[35m0.4938\u001b[0m            0.7482                     \u001b[94m0.7497\u001b[0m        \u001b[36m0.5050\u001b[0m  0.0009  3.2503\n",
      "     10            \u001b[36m0.7824\u001b[0m                     \u001b[32m0.7857\u001b[0m        \u001b[35m0.4870\u001b[0m            \u001b[31m0.7598\u001b[0m                     \u001b[94m0.7635\u001b[0m        \u001b[36m0.4973\u001b[0m  0.0008  3.2533\n",
      "     11            \u001b[36m0.7835\u001b[0m                     \u001b[32m0.7867\u001b[0m        \u001b[35m0.4839\u001b[0m            \u001b[31m0.7612\u001b[0m                     \u001b[94m0.7639\u001b[0m        0.5007  0.0008  3.2543\n",
      "     12            \u001b[36m0.7918\u001b[0m                     \u001b[32m0.7953\u001b[0m        \u001b[35m0.4796\u001b[0m            0.7554                     0.7593        0.5038  0.0008  3.2573\n",
      "     13            0.7918                     0.7935        \u001b[35m0.4698\u001b[0m            \u001b[31m0.7713\u001b[0m                     \u001b[94m0.7731\u001b[0m        \u001b[36m0.4971\u001b[0m  0.0007  3.2603\n",
      "     14            \u001b[36m0.7972\u001b[0m                     \u001b[32m0.7971\u001b[0m        \u001b[35m0.4657\u001b[0m            0.7685                     0.7702        0.5038  0.0007  3.2513\n",
      "     15            \u001b[36m0.7994\u001b[0m                     \u001b[32m0.8027\u001b[0m        \u001b[35m0.4578\u001b[0m            0.7612                     0.7648        0.5018  0.0006  3.2513\n",
      "     16            \u001b[36m0.8077\u001b[0m                     \u001b[32m0.8076\u001b[0m        0.4621            0.7713                     0.7722        \u001b[36m0.4967\u001b[0m  0.0006  3.2493\n",
      "     17            0.7983                     0.8030        0.4594            0.7670                     0.7722        0.4988  0.0005  3.2563\n",
      "     18            0.8030                     \u001b[32m0.8090\u001b[0m        \u001b[35m0.4517\u001b[0m            0.7598                     0.7641        \u001b[36m0.4943\u001b[0m  0.0005  3.2563\n",
      "     19            0.8056                     0.8075        \u001b[35m0.4470\u001b[0m            0.7670                     0.7692        \u001b[36m0.4938\u001b[0m  0.0005  3.2553\n",
      "     20            0.8074                     \u001b[32m0.8129\u001b[0m        0.4476            0.7540                     0.7592        0.4984  0.0004  3.2583\n",
      "     21            \u001b[36m0.8096\u001b[0m                     \u001b[32m0.8138\u001b[0m        0.4501            0.7656                     0.7697        0.5005  0.0004  3.2553\n",
      "     22            \u001b[36m0.8135\u001b[0m                     \u001b[32m0.8176\u001b[0m        \u001b[35m0.4408\u001b[0m            0.7685                     0.7717        0.4983  0.0003  3.2523\n",
      "     23            \u001b[36m0.8143\u001b[0m                     \u001b[32m0.8181\u001b[0m        0.4450            0.7641                     0.7693        0.4985  0.0003  3.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24            \u001b[36m0.8208\u001b[0m                     \u001b[32m0.8215\u001b[0m        \u001b[35m0.4321\u001b[0m            0.7713                     0.7716        0.4976  0.0002  3.2523\n",
      "     25            0.8168                     0.8184        \u001b[35m0.4279\u001b[0m            0.7713                     \u001b[94m0.7740\u001b[0m        0.5001  0.0002  3.2583\n",
      "     26            0.8164                     0.8189        0.4390            0.7685                     0.7708        0.4994  0.0002  3.2563\n",
      "     27            0.8161                     0.8189        \u001b[35m0.4269\u001b[0m            \u001b[31m0.7728\u001b[0m                     \u001b[94m0.7756\u001b[0m        0.4997  0.0001  3.2553\n",
      "     28            0.8168                     0.8199        0.4295            0.7670                     0.7704        0.5020  0.0001  3.2533\n",
      "     29            0.8182                     0.8207        0.4270            0.7713                     0.7737        0.5010  0.0001  3.2553\n",
      "     30            0.8182                     0.8210        0.4304            \u001b[31m0.7742\u001b[0m                     \u001b[94m0.7763\u001b[0m        0.5000  0.0001  3.2493\n",
      "     31            0.8175                     0.8204        0.4374            0.7742                     \u001b[94m0.7769\u001b[0m        0.4995  0.0000  3.2593\n",
      "     32            0.8175                     0.8210        0.4365            0.7699                     0.7736        0.5005  0.0000  3.2613\n",
      "     33            0.8172                     0.8203        \u001b[35m0.4252\u001b[0m            0.7728                     0.7759        0.5002  0.0000  3.2523\n",
      "     34            0.8172                     0.8202        0.4252            0.7713                     0.7743        0.5001  0.0000  3.2523\n",
      "     35            0.8175                     0.8204        0.4255            0.7713                     0.7743        0.5000  0.0000  3.2553\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7028\u001b[0m                     \u001b[32m0.7111\u001b[0m        \u001b[35m0.6705\u001b[0m            \u001b[31m0.6903\u001b[0m                     \u001b[94m0.6984\u001b[0m        \u001b[36m0.6335\u001b[0m  0.0010  3.2593\n",
      "      2            \u001b[36m0.7151\u001b[0m                     \u001b[32m0.7283\u001b[0m        \u001b[35m0.5816\u001b[0m            \u001b[31m0.6975\u001b[0m                     \u001b[94m0.7107\u001b[0m        \u001b[36m0.6253\u001b[0m  0.0010  3.2563\n",
      "      3            \u001b[36m0.7335\u001b[0m                     \u001b[32m0.7414\u001b[0m        \u001b[35m0.5519\u001b[0m            \u001b[31m0.7048\u001b[0m                     \u001b[94m0.7121\u001b[0m        \u001b[36m0.5935\u001b[0m  0.0010  3.2533\n",
      "      4            \u001b[36m0.7408\u001b[0m                     \u001b[32m0.7491\u001b[0m        \u001b[35m0.5336\u001b[0m            \u001b[31m0.7149\u001b[0m                     \u001b[94m0.7225\u001b[0m        \u001b[36m0.5747\u001b[0m  0.0010  3.2593\n",
      "      5            \u001b[36m0.7495\u001b[0m                     \u001b[32m0.7560\u001b[0m        \u001b[35m0.5280\u001b[0m            \u001b[31m0.7250\u001b[0m                     \u001b[94m0.7323\u001b[0m        \u001b[36m0.5609\u001b[0m  0.0010  3.2593\n",
      "      6            0.7462                     \u001b[32m0.7569\u001b[0m        \u001b[35m0.5146\u001b[0m            0.7091                     0.7206        \u001b[36m0.5596\u001b[0m  0.0009  3.2643\n",
      "      7            \u001b[36m0.7571\u001b[0m                     \u001b[32m0.7642\u001b[0m        \u001b[35m0.5067\u001b[0m            0.7192                     0.7262        \u001b[36m0.5398\u001b[0m  0.0009  3.2563\n",
      "      8            0.7552                     \u001b[32m0.7665\u001b[0m        \u001b[35m0.5028\u001b[0m            0.6990                     0.7108        0.5547  0.0009  3.2533\n",
      "      9            \u001b[36m0.7712\u001b[0m                     \u001b[32m0.7776\u001b[0m        \u001b[35m0.5010\u001b[0m            0.7192                     0.7247        \u001b[36m0.5392\u001b[0m  0.0009  3.2573\n",
      "     10            \u001b[36m0.7752\u001b[0m                     \u001b[32m0.7821\u001b[0m        \u001b[35m0.4794\u001b[0m            0.7221                     0.7285        \u001b[36m0.5305\u001b[0m  0.0008  3.2533\n",
      "     11            \u001b[36m0.7770\u001b[0m                     \u001b[32m0.7827\u001b[0m        0.4834            \u001b[31m0.7294\u001b[0m                     \u001b[94m0.7345\u001b[0m        0.5340  0.0008  3.2563\n",
      "     12            \u001b[36m0.7813\u001b[0m                     \u001b[32m0.7888\u001b[0m        0.4852            0.7207                     0.7275        0.5336  0.0008  3.2563\n",
      "     13            \u001b[36m0.7886\u001b[0m                     \u001b[32m0.7938\u001b[0m        \u001b[35m0.4572\u001b[0m            \u001b[31m0.7323\u001b[0m                     \u001b[94m0.7356\u001b[0m        0.5306  0.0007  3.2593\n",
      "     14            0.7864                     0.7910        0.4689            \u001b[31m0.7337\u001b[0m                     \u001b[94m0.7363\u001b[0m        \u001b[36m0.5298\u001b[0m  0.0007  3.2603\n",
      "     15            0.7828                     0.7899        0.4664            0.7250                     0.7326        \u001b[36m0.5274\u001b[0m  0.0006  3.2543\n",
      "     16            \u001b[36m0.7900\u001b[0m                     0.7937        \u001b[35m0.4519\u001b[0m            \u001b[31m0.7424\u001b[0m                     \u001b[94m0.7445\u001b[0m        \u001b[36m0.5245\u001b[0m  0.0006  3.2543\n",
      "     17            0.7896                     \u001b[32m0.7997\u001b[0m        \u001b[35m0.4451\u001b[0m            0.7048                     0.7158        0.5396  0.0005  3.2543\n",
      "     18            \u001b[36m0.8016\u001b[0m                     \u001b[32m0.8035\u001b[0m        0.4501            0.7410                     0.7416        0.5307  0.0005  3.2533\n",
      "     19            0.7998                     0.8033        0.4528            0.7424                     \u001b[94m0.7451\u001b[0m        \u001b[36m0.5228\u001b[0m  0.0005  3.2573\n",
      "     20            0.7987                     \u001b[32m0.8080\u001b[0m        0.4476            0.7207                     0.7293        0.5326  0.0004  3.2543\n",
      "     21            0.8009                     \u001b[32m0.8089\u001b[0m        \u001b[35m0.4425\u001b[0m            0.7236                     0.7322        0.5290  0.0004  3.2533\n",
      "     22            \u001b[36m0.8088\u001b[0m                     \u001b[32m0.8135\u001b[0m        \u001b[35m0.4368\u001b[0m            0.7352                     0.7391        0.5268  0.0003  3.2563\n",
      "     23            0.8052                     0.8089        \u001b[35m0.4358\u001b[0m            0.7395                     0.7418        0.5261  0.0003  3.2583\n",
      "     24            \u001b[36m0.8154\u001b[0m                     \u001b[32m0.8194\u001b[0m        0.4380            0.7395                     0.7409        0.5260  0.0002  3.2523\n",
      "     25            0.8121                     0.8165        \u001b[35m0.4357\u001b[0m            \u001b[31m0.7453\u001b[0m                     \u001b[94m0.7483\u001b[0m        0.5237  0.0002  3.2543\n",
      "     26            0.8121                     0.8166        \u001b[35m0.4307\u001b[0m            0.7395                     0.7430        \u001b[36m0.5218\u001b[0m  0.0002  3.2573\n",
      "     27            \u001b[36m0.8172\u001b[0m                     \u001b[32m0.8215\u001b[0m        \u001b[35m0.4263\u001b[0m            0.7395                     0.7421        \u001b[36m0.5214\u001b[0m  0.0001  3.2563\n",
      "     28            0.8164                     0.8214        0.4297            0.7395                     0.7424        \u001b[36m0.5207\u001b[0m  0.0001  3.2553\n",
      "     29            0.8132                     0.8183        \u001b[35m0.4234\u001b[0m            0.7395                     0.7430        0.5220  0.0001  3.2533\n",
      "     30            0.8154                     0.8212        0.4292            0.7381                     0.7429        0.5245  0.0001  3.2573\n",
      "     31            0.8132                     0.8187        0.4264            0.7395                     0.7439        0.5239  0.0000  3.2583\n",
      "     32            0.8139                     0.8195        0.4247            0.7395                     0.7439        0.5238  0.0000  3.2563\n",
      "     33            0.8146                     0.8200        0.4240            0.7381                     0.7423        0.5235  0.0000  3.2573\n",
      "     34            0.8132                     0.8184        \u001b[35m0.4190\u001b[0m            0.7352                     0.7391        0.5233  0.0000  3.2503\n",
      "     35            0.8139                     0.8191        0.4239            0.7352                     0.7391        0.5231  0.0000  3.2563\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7140\u001b[0m                     \u001b[32m0.7148\u001b[0m        \u001b[35m0.6640\u001b[0m            \u001b[31m0.7004\u001b[0m                     \u001b[94m0.7010\u001b[0m        \u001b[36m0.6170\u001b[0m  0.0010  3.2553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            \u001b[36m0.7368\u001b[0m                     \u001b[32m0.7424\u001b[0m        \u001b[35m0.5796\u001b[0m            \u001b[31m0.7077\u001b[0m                     \u001b[94m0.7124\u001b[0m        \u001b[36m0.6114\u001b[0m  0.0010  3.2533\n",
      "      3            \u001b[36m0.7415\u001b[0m                     \u001b[32m0.7484\u001b[0m        \u001b[35m0.5564\u001b[0m            \u001b[31m0.7106\u001b[0m                     \u001b[94m0.7159\u001b[0m        \u001b[36m0.5928\u001b[0m  0.0010  3.2543\n",
      "      4            0.7310                     0.7430        \u001b[35m0.5243\u001b[0m            0.6961                     0.7103        \u001b[36m0.5885\u001b[0m  0.0010  3.2493\n",
      "      5            \u001b[36m0.7531\u001b[0m                     \u001b[32m0.7598\u001b[0m        \u001b[35m0.5207\u001b[0m            \u001b[31m0.7135\u001b[0m                     \u001b[94m0.7209\u001b[0m        \u001b[36m0.5632\u001b[0m  0.0010  3.2503\n",
      "      6            \u001b[36m0.7549\u001b[0m                     \u001b[32m0.7662\u001b[0m        \u001b[35m0.5091\u001b[0m            \u001b[31m0.7164\u001b[0m                     \u001b[94m0.7260\u001b[0m        \u001b[36m0.5471\u001b[0m  0.0009  3.2543\n",
      "      7            \u001b[36m0.7654\u001b[0m                     \u001b[32m0.7756\u001b[0m        \u001b[35m0.4898\u001b[0m            \u001b[31m0.7236\u001b[0m                     \u001b[94m0.7328\u001b[0m        \u001b[36m0.5395\u001b[0m  0.0009  3.2543\n",
      "      8            \u001b[36m0.7712\u001b[0m                     \u001b[32m0.7786\u001b[0m        \u001b[35m0.4874\u001b[0m            0.7207                     0.7299        \u001b[36m0.5381\u001b[0m  0.0009  3.2503\n",
      "      9            \u001b[36m0.7788\u001b[0m                     \u001b[32m0.7882\u001b[0m        \u001b[35m0.4800\u001b[0m            0.7091                     0.7194        0.5532  0.0009  3.2623\n",
      "     10            \u001b[36m0.7929\u001b[0m                     \u001b[32m0.7949\u001b[0m        \u001b[35m0.4748\u001b[0m            \u001b[31m0.7250\u001b[0m                     0.7269        0.5426  0.0008  3.2533\n",
      "     11            0.7813                     0.7770        \u001b[35m0.4720\u001b[0m            \u001b[31m0.7279\u001b[0m                     0.7229        0.5616  0.0008  3.2523\n",
      "     12            0.7871                     0.7926        \u001b[35m0.4668\u001b[0m            0.7221                     0.7282        0.5454  0.0008  3.2533\n",
      "     13            \u001b[36m0.8001\u001b[0m                     \u001b[32m0.8014\u001b[0m        \u001b[35m0.4623\u001b[0m            \u001b[31m0.7337\u001b[0m                     \u001b[94m0.7348\u001b[0m        \u001b[36m0.5359\u001b[0m  0.0007  3.2553\n",
      "     14            0.7846                     0.7944        \u001b[35m0.4597\u001b[0m            0.7149                     0.7243        0.5520  0.0007  3.2543\n",
      "     15            0.7741                     0.7886        0.4624            0.6889                     0.7037        0.5677  0.0006  3.2523\n",
      "     16            \u001b[36m0.8056\u001b[0m                     \u001b[32m0.8091\u001b[0m        \u001b[35m0.4478\u001b[0m            0.7106                     0.7156        0.5562  0.0006  3.2573\n",
      "     17            0.8052                     \u001b[32m0.8093\u001b[0m        \u001b[35m0.4454\u001b[0m            0.7236                     0.7280        0.5498  0.0005  3.2513\n",
      "     18            0.7972                     0.8064        0.4466            0.7048                     0.7155        0.5513  0.0005  3.2523\n",
      "     19            \u001b[36m0.8125\u001b[0m                     \u001b[32m0.8173\u001b[0m        \u001b[35m0.4376\u001b[0m            0.7135                     0.7185        0.5447  0.0005  3.2523\n",
      "     20            0.8001                     0.8111        0.4452            0.6990                     0.7105        0.5600  0.0004  3.2543\n",
      "     21            \u001b[36m0.8190\u001b[0m                     \u001b[32m0.8218\u001b[0m        \u001b[35m0.4364\u001b[0m            0.7279                     0.7295        0.5410  0.0004  3.2503\n",
      "     22            \u001b[36m0.8244\u001b[0m                     \u001b[32m0.8248\u001b[0m        \u001b[35m0.4333\u001b[0m            0.7236                     0.7235        0.5430  0.0003  3.2533\n",
      "     23            0.8128                     0.8178        \u001b[35m0.4311\u001b[0m            0.7207                     0.7263        0.5436  0.0003  3.2563\n",
      "     24            0.8103                     0.8164        \u001b[35m0.4241\u001b[0m            0.7077                     0.7148        0.5486  0.0002  3.2533\n",
      "     25            0.8059                     0.8159        \u001b[35m0.4232\u001b[0m            0.7019                     0.7122        0.5609  0.0002  3.2543\n",
      "     26            0.8096                     0.8186        \u001b[35m0.4229\u001b[0m            0.7062                     0.7156        0.5563  0.0002  3.2583\n",
      "     27            0.8117                     0.8197        0.4285            0.7164                     0.7250        0.5496  0.0001  3.2553\n",
      "     28            0.8219                     \u001b[32m0.8272\u001b[0m        0.4263            0.7294                     0.7339        0.5441  0.0001  3.2513\n",
      "     29            0.8197                     0.8247        0.4259            0.7236                     0.7283        0.5466  0.0001  3.2543\n",
      "     30            0.8193                     0.8246        \u001b[35m0.4185\u001b[0m            0.7308                     \u001b[94m0.7367\u001b[0m        0.5463  0.0001  3.2493\n",
      "     31            0.8208                     0.8261        \u001b[35m0.4115\u001b[0m            0.7265                     0.7321        0.5468  0.0000  3.2513\n",
      "     32            0.8211                     0.8261        0.4135            0.7265                     0.7315        0.5466  0.0000  3.2543\n",
      "     33            0.8215                     0.8263        0.4121            0.7250                     0.7296        0.5463  0.0000  3.2503\n",
      "     34            0.8222                     0.8269        0.4129            0.7236                     0.7280        0.5462  0.0000  3.2513\n",
      "     35            0.8208                     0.8257        \u001b[35m0.4065\u001b[0m            0.7265                     0.7312        0.5464  0.0000  3.2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6919\u001b[0m                     \u001b[32m0.6842\u001b[0m        \u001b[35m0.6894\u001b[0m            \u001b[31m0.6983\u001b[0m                     \u001b[94m0.6850\u001b[0m        \u001b[36m0.6440\u001b[0m  0.0010  7.4980\n",
      "      2            \u001b[36m0.7485\u001b[0m                     \u001b[32m0.7088\u001b[0m        \u001b[35m0.6189\u001b[0m            \u001b[31m0.7355\u001b[0m                     0.6784        \u001b[36m0.6163\u001b[0m  0.0010  7.3533\n",
      "      3            0.6596                     \u001b[32m0.7235\u001b[0m        \u001b[35m0.5940\u001b[0m            0.6492                     \u001b[94m0.7004\u001b[0m        \u001b[36m0.5725\u001b[0m  0.0010  7.3863\n",
      "      4            0.6792                     \u001b[32m0.7350\u001b[0m        \u001b[35m0.5665\u001b[0m            0.6684                     \u001b[94m0.7150\u001b[0m        \u001b[36m0.5631\u001b[0m  0.0010  7.4042\n",
      "      5            0.7359                     \u001b[32m0.7516\u001b[0m        \u001b[35m0.5554\u001b[0m            0.7183                     \u001b[94m0.7190\u001b[0m        \u001b[36m0.5433\u001b[0m  0.0010  7.3723\n",
      "      6            0.7384                     \u001b[32m0.7597\u001b[0m        \u001b[35m0.5432\u001b[0m            0.7196                     \u001b[94m0.7286\u001b[0m        \u001b[36m0.5342\u001b[0m  0.0009  7.3882\n",
      "      7            0.6983                     0.7558        \u001b[35m0.5430\u001b[0m            0.6724                     0.7145        0.5438  0.0009  7.4172\n",
      "      8            0.6892                     0.7528        \u001b[35m0.5255\u001b[0m            0.6598                     0.7112        0.5520  0.0009  7.4122\n",
      "      9            0.6930                     \u001b[32m0.7599\u001b[0m        0.5327            0.6711                     0.7225        0.5391  0.0009  7.4032\n",
      "     10            0.6744                     0.7519        \u001b[35m0.5151\u001b[0m            0.6532                     0.7189        0.5431  0.0008  7.3882\n",
      "     11            0.6713                     0.7532        \u001b[35m0.5027\u001b[0m            0.6498                     0.7183        0.5477  0.0008  7.3723\n",
      "     12            \u001b[36m0.7605\u001b[0m                     \u001b[32m0.7830\u001b[0m        0.5106            \u001b[31m0.7415\u001b[0m                     \u001b[94m0.7448\u001b[0m        \u001b[36m0.5198\u001b[0m  0.0008  7.4172\n",
      "     13            0.6975                     0.7674        \u001b[35m0.5019\u001b[0m            0.6757                     0.7311        0.5321  0.0007  7.3793\n",
      "     14            0.6912                     0.7665        \u001b[35m0.4971\u001b[0m            0.6605                     0.7189        0.5353  0.0007  7.3922\n",
      "     15            0.7382                     \u001b[32m0.7833\u001b[0m        \u001b[35m0.4886\u001b[0m            0.7103                     0.7375        0.5209  0.0006  7.3573\n",
      "     16            0.6445                     0.7472        \u001b[35m0.4856\u001b[0m            0.6173                     0.7087        0.5618  0.0006  7.3663\n",
      "     17            \u001b[36m0.7988\u001b[0m                     \u001b[32m0.7928\u001b[0m        \u001b[35m0.4839\u001b[0m            \u001b[31m0.7714\u001b[0m                     0.7382        0.5213  0.0005  7.3404\n",
      "     18            0.6266                     0.7429        0.4895            0.5953                     0.7027        0.5603  0.0005  10.6321\n",
      "     19            0.6850                     0.7719        0.4875            0.6419                     0.7178        0.5387  0.0005  7.3384\n",
      "     20            0.7754                     \u001b[32m0.7965\u001b[0m        \u001b[35m0.4779\u001b[0m            0.7415                     0.7346        0.5212  0.0004  7.8131\n",
      "     21            0.7472                     0.7943        \u001b[35m0.4717\u001b[0m            0.7150                     0.7433        0.5209  0.0004  7.4650\n",
      "     22            0.7447                     \u001b[32m0.7979\u001b[0m        0.4755            0.7070                     0.7428        \u001b[36m0.5186\u001b[0m  0.0003  7.4132\n",
      "     23            0.6930                     0.7760        0.4772            0.6638                     0.7297        0.5283  0.0003  7.4800\n",
      "     24            \u001b[36m0.8191\u001b[0m                     \u001b[32m0.8117\u001b[0m        \u001b[35m0.4704\u001b[0m            \u001b[31m0.7821\u001b[0m                     \u001b[94m0.7461\u001b[0m        \u001b[36m0.5097\u001b[0m  0.0002  7.6156\n",
      "     25            0.7525                     0.8004        \u001b[35m0.4672\u001b[0m            0.7209                     \u001b[94m0.7513\u001b[0m        0.5141  0.0002  7.3633\n",
      "     26            0.7704                     0.8055        0.4686            0.7342                     0.7462        0.5101  0.0002  7.2686\n",
      "     27            0.7495                     0.8012        \u001b[35m0.4580\u001b[0m            0.7163                     0.7456        0.5127  0.0001  7.2895\n",
      "     28            0.7533                     0.8024        \u001b[35m0.4548\u001b[0m            0.7150                     0.7404        0.5160  0.0001  7.3364\n",
      "     29            0.7477                     0.8004        0.4598            0.7189                     \u001b[94m0.7545\u001b[0m        0.5140  0.0001  7.4012\n",
      "     30            0.7598                     0.8067        0.4599            0.7336                     \u001b[94m0.7605\u001b[0m        0.5111  0.0001  7.3484\n",
      "     31            0.7623                     0.8060        0.4565            0.7309                     0.7545        0.5104  0.0000  7.2815\n",
      "     32            0.7621                     0.8056        0.4614            0.7302                     0.7526        0.5111  0.0000  7.3164\n",
      "     33            0.7645                     0.8059        0.4617            0.7309                     0.7501        0.5109  0.0000  7.2745\n",
      "     34            0.7650                     0.8062        0.4564            0.7309                     0.7501        0.5109  0.0000  7.2835\n",
      "     35            0.7653                     0.8064        0.4557            0.7316                     0.7505        0.5108  0.0000  7.3284\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6568\u001b[0m                     \u001b[32m0.6727\u001b[0m        \u001b[35m0.6950\u001b[0m            \u001b[31m0.6631\u001b[0m                     \u001b[94m0.6738\u001b[0m        \u001b[36m0.6459\u001b[0m  0.0010  7.2976\n",
      "      2            \u001b[36m0.7007\u001b[0m                     \u001b[32m0.6991\u001b[0m        \u001b[35m0.6201\u001b[0m            \u001b[31m0.7156\u001b[0m                     \u001b[94m0.7042\u001b[0m        \u001b[36m0.6005\u001b[0m  0.0010  7.3853\n",
      "      3            \u001b[36m0.7455\u001b[0m                     \u001b[32m0.7249\u001b[0m        \u001b[35m0.6005\u001b[0m            \u001b[31m0.7442\u001b[0m                     \u001b[94m0.7099\u001b[0m        \u001b[36m0.5800\u001b[0m  0.0010  7.2965\n",
      "      4            0.7384                     \u001b[32m0.7436\u001b[0m        \u001b[35m0.5771\u001b[0m            0.7389                     \u001b[94m0.7374\u001b[0m        \u001b[36m0.5460\u001b[0m  0.0010  7.4830\n",
      "      5            0.5897                     0.7120        \u001b[35m0.5622\u001b[0m            0.5794                     0.6886        0.5775  0.0010  7.5588\n",
      "      6            0.6528                     0.7391        \u001b[35m0.5441\u001b[0m            0.6551                     0.7215        0.5469  0.0009  7.3304\n",
      "      7            \u001b[36m0.7568\u001b[0m                     \u001b[32m0.7636\u001b[0m        \u001b[35m0.5384\u001b[0m            \u001b[31m0.7475\u001b[0m                     \u001b[94m0.7383\u001b[0m        \u001b[36m0.5261\u001b[0m  0.0009  7.1459\n",
      "      8            0.7294                     \u001b[32m0.7663\u001b[0m        \u001b[35m0.5370\u001b[0m            0.7236                     \u001b[94m0.7412\u001b[0m        0.5297  0.0009  7.6246\n",
      "      9            \u001b[36m0.7709\u001b[0m                     \u001b[32m0.7692\u001b[0m        \u001b[35m0.5210\u001b[0m            \u001b[31m0.7661\u001b[0m                     \u001b[94m0.7496\u001b[0m        \u001b[36m0.5254\u001b[0m  0.0009  7.8296\n",
      "     10            \u001b[36m0.8322\u001b[0m                     0.7472        0.5244            \u001b[31m0.8173\u001b[0m                     0.7120        0.5599  0.0008  7.8705\n",
      "     11            0.7327                     \u001b[32m0.7753\u001b[0m        \u001b[35m0.5155\u001b[0m            0.7402                     \u001b[94m0.7645\u001b[0m        \u001b[36m0.5207\u001b[0m  0.0008  9.3197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12            0.7374                     0.7741        \u001b[35m0.5044\u001b[0m            0.7362                     0.7562        \u001b[36m0.5161\u001b[0m  0.0008  10.9819\n",
      "     13            0.7646                     \u001b[32m0.7851\u001b[0m        0.5091            0.7482                     0.7489        \u001b[36m0.5149\u001b[0m  0.0007  14.0948\n",
      "     14            0.7623                     \u001b[32m0.7892\u001b[0m        \u001b[35m0.4986\u001b[0m            0.7429                     0.7530        0.5179  0.0007  12.2147\n",
      "     15            0.7596                     0.7847        \u001b[35m0.4954\u001b[0m            0.7522                     \u001b[94m0.7674\u001b[0m        \u001b[36m0.5137\u001b[0m  0.0006  11.9717\n",
      "     16            0.7806                     \u001b[32m0.7937\u001b[0m        \u001b[35m0.4947\u001b[0m            0.7734                     \u001b[94m0.7686\u001b[0m        0.5167  0.0006  12.7955\n",
      "     17            0.7874                     0.7862        \u001b[35m0.4874\u001b[0m            0.7708                     0.7553        0.5193  0.0005  13.4863\n",
      "     18            0.7754                     \u001b[32m0.7946\u001b[0m        \u001b[35m0.4815\u001b[0m            0.7635                     0.7626        0.5138  0.0005  14.0051\n",
      "     19            0.7606                     \u001b[32m0.7952\u001b[0m        0.4820            0.7482                     0.7679        \u001b[36m0.5104\u001b[0m  0.0005  13.6875\n",
      "     20            0.7804                     \u001b[32m0.7984\u001b[0m        \u001b[35m0.4750\u001b[0m            0.7688                     \u001b[94m0.7702\u001b[0m        \u001b[36m0.5067\u001b[0m  0.0004  16.4982\n",
      "     21            0.7432                     0.7933        0.4801            0.7296                     0.7624        0.5141  0.0004  13.4815\n",
      "     22            0.7555                     0.7953        0.4761            0.7316                     0.7519        0.5181  0.0003  13.7528\n",
      "     23            0.7935                     0.7976        \u001b[35m0.4742\u001b[0m            0.7754                     0.7640        0.5123  0.0003  15.7066\n",
      "     24            0.7925                     \u001b[32m0.8017\u001b[0m        0.4742            0.7821                     \u001b[94m0.7724\u001b[0m        0.5089  0.0002  14.3267\n",
      "     25            0.7738                     \u001b[32m0.8035\u001b[0m        \u001b[35m0.4654\u001b[0m            0.7561                     0.7625        0.5103  0.0002  14.4467\n",
      "     26            0.7766                     \u001b[32m0.8052\u001b[0m        \u001b[35m0.4632\u001b[0m            0.7555                     0.7679        0.5089  0.0002  14.8652\n",
      "     27            0.7837                     \u001b[32m0.8063\u001b[0m        0.4646            0.7654                     0.7667        0.5079  0.0001  11.2166\n",
      "     28            0.7628                     0.8045        \u001b[35m0.4602\u001b[0m            0.7369                     0.7552        0.5134  0.0001  12.4936\n",
      "     29            0.7772                     0.8023        0.4623            0.7575                     0.7648        0.5082  0.0001  13.2045\n",
      "     30            0.7887                     \u001b[32m0.8064\u001b[0m        0.4639            0.7728                     0.7697        0.5090  0.0001  13.7637\n",
      "     31            0.7819                     0.8019        0.4604            0.7668                     0.7704        0.5109  0.0000  12.8349\n",
      "     32            0.7909                     \u001b[32m0.8070\u001b[0m        \u001b[35m0.4559\u001b[0m            0.7741                     0.7705        0.5101  0.0000  12.8269\n",
      "     33            0.7836                     0.8043        0.4591            0.7668                     0.7661        0.5104  0.0000  12.5996\n",
      "     34            0.7819                     0.8033        0.4663            0.7635                     0.7655        0.5103  0.0000  14.7369\n",
      "     35            0.7809                     0.8027        0.4568            0.7628                     0.7651        0.5103  0.0000  13.9783\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.6465\u001b[0m                     \u001b[32m0.6870\u001b[0m        \u001b[35m0.6814\u001b[0m            \u001b[31m0.6213\u001b[0m                     \u001b[94m0.6673\u001b[0m        \u001b[36m0.6540\u001b[0m  0.0010  14.4704\n",
      "      2            \u001b[36m0.7093\u001b[0m                     \u001b[32m0.7204\u001b[0m        \u001b[35m0.6080\u001b[0m            \u001b[31m0.7023\u001b[0m                     \u001b[94m0.7137\u001b[0m        \u001b[36m0.6175\u001b[0m  0.0010  15.0132\n",
      "      3            0.6875                     \u001b[32m0.7405\u001b[0m        \u001b[35m0.5763\u001b[0m            0.6585                     0.7016        \u001b[36m0.5902\u001b[0m  0.0010  14.4111\n",
      "      4            0.7018                     0.7389        \u001b[35m0.5581\u001b[0m            0.6684                     0.7018        \u001b[36m0.5812\u001b[0m  0.0010  14.2133\n",
      "      5            0.6766                     \u001b[32m0.7411\u001b[0m        \u001b[35m0.5542\u001b[0m            0.6465                     0.7119        0.5819  0.0010  14.8235\n",
      "      6            0.7027                     \u001b[32m0.7577\u001b[0m        \u001b[35m0.5404\u001b[0m            0.6684                     \u001b[94m0.7165\u001b[0m        \u001b[36m0.5685\u001b[0m  0.0009  14.2589\n",
      "      7            \u001b[36m0.7488\u001b[0m                     \u001b[32m0.7766\u001b[0m        \u001b[35m0.5282\u001b[0m            \u001b[31m0.7163\u001b[0m                     \u001b[94m0.7353\u001b[0m        \u001b[36m0.5518\u001b[0m  0.0009  14.7315\n",
      "      8            0.7121                     0.7711        \u001b[35m0.5165\u001b[0m            0.6797                     0.7306        0.5544  0.0009  14.7576\n",
      "      9            0.7023                     0.7641        0.5180            0.6671                     0.7288        0.5699  0.0009  14.6285\n",
      "     10            0.6711                     0.7531        \u001b[35m0.5126\u001b[0m            0.6319                     0.7088        0.5819  0.0008  14.4965\n",
      "     11            0.6487                     0.7443        \u001b[35m0.5058\u001b[0m            0.6173                     0.7043        0.6000  0.0008  14.5625\n",
      "     12            \u001b[36m0.7980\u001b[0m                     \u001b[32m0.7952\u001b[0m        \u001b[35m0.4936\u001b[0m            \u001b[31m0.7568\u001b[0m                     0.7351        0.5598  0.0008  16.2612\n",
      "     13            0.7563                     0.7903        \u001b[35m0.4918\u001b[0m            0.7196                     \u001b[94m0.7403\u001b[0m        0.5534  0.0007  15.6323\n",
      "     14            0.6739                     0.7589        0.5061            0.6445                     0.7209        0.5816  0.0007  16.0285\n",
      "     15            0.7093                     0.7804        \u001b[35m0.4880\u001b[0m            0.6731                     0.7310        0.5614  0.0006  16.0198\n",
      "     16            0.7829                     \u001b[32m0.7984\u001b[0m        \u001b[35m0.4771\u001b[0m            0.7409                     0.7298        0.5606  0.0006  15.9698\n",
      "     17            0.7507                     0.7971        0.4859            0.6997                     0.7282        0.5709  0.0005  15.2779\n",
      "     18            0.7405                     0.7928        \u001b[35m0.4738\u001b[0m            0.6910                     0.7258        0.5593  0.0005  14.9997\n",
      "     19            0.7081                     0.7801        \u001b[35m0.4706\u001b[0m            0.6645                     0.7243        0.5837  0.0005  15.4137\n",
      "     20            0.7693                     \u001b[32m0.8063\u001b[0m        0.4707            0.7243                     0.7402        \u001b[36m0.5518\u001b[0m  0.0004  16.2780\n",
      "     21            0.7701                     \u001b[32m0.8071\u001b[0m        \u001b[35m0.4681\u001b[0m            0.7209                     0.7367        \u001b[36m0.5508\u001b[0m  0.0004  15.7490\n",
      "     22            0.7724                     0.8060        \u001b[35m0.4556\u001b[0m            0.7216                     0.7342        0.5522  0.0003  15.0714\n",
      "     23            0.7060                     0.7846        0.4560            0.6691                     0.7315        0.5725  0.0003  15.1674\n",
      "     24            0.7116                     0.7869        \u001b[35m0.4502\u001b[0m            0.6698                     0.7290        0.5667  0.0002  16.2663\n",
      "     25            0.7786                     \u001b[32m0.8130\u001b[0m        0.4545            0.7223                     0.7317        0.5514  0.0002  15.1965\n",
      "     26            0.7779                     0.8122        0.4505            0.7316                     \u001b[94m0.7417\u001b[0m        0.5526  0.0002  16.2700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27            0.7869                     \u001b[32m0.8159\u001b[0m        \u001b[35m0.4490\u001b[0m            0.7355                     0.7368        0.5510  0.0001  16.3990\n",
      "     28            0.7704                     0.8117        \u001b[35m0.4489\u001b[0m            0.7176                     \u001b[94m0.7420\u001b[0m        0.5556  0.0001  15.5820\n",
      "     29            0.7704                     0.8110        0.4497            0.7143                     0.7356        0.5566  0.0001  15.7940\n",
      "     30            0.7728                     0.8120        \u001b[35m0.4488\u001b[0m            0.7176                     0.7376        0.5570  0.0001  15.5219\n",
      "     31            0.7831                     0.8154        \u001b[35m0.4436\u001b[0m            0.7262                     0.7355        0.5562  0.0000  11.6657\n",
      "     32            0.7782                     0.8143        0.4493            0.7216                     0.7342        0.5567  0.0000  14.6935\n",
      "     33            0.7777                     0.8140        0.4440            0.7223                     0.7346        0.5566  0.0000  11.1165\n",
      "     34            0.7777                     0.8143        0.4451            0.7209                     0.7338        0.5567  0.0000  14.6063\n",
      "     35            0.7774                     0.8145        0.4455            0.7209                     0.7352        0.5565  0.0000  15.2816\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.6940\u001b[0m                     \u001b[32m0.6800\u001b[0m        \u001b[35m0.6986\u001b[0m            \u001b[31m0.6711\u001b[0m                     \u001b[94m0.6684\u001b[0m        \u001b[36m0.6422\u001b[0m  0.0010  12.8661\n",
      "      2            \u001b[36m0.7022\u001b[0m                     \u001b[32m0.7226\u001b[0m        \u001b[35m0.6177\u001b[0m            \u001b[31m0.6724\u001b[0m                     \u001b[94m0.6970\u001b[0m        \u001b[36m0.6091\u001b[0m  0.0010  10.8786\n",
      "      3            0.6214                     0.7079        \u001b[35m0.5843\u001b[0m            0.6073                     0.6968        \u001b[36m0.5909\u001b[0m  0.0010  12.2690\n",
      "      4            \u001b[36m0.7061\u001b[0m                     \u001b[32m0.7419\u001b[0m        \u001b[35m0.5754\u001b[0m            \u001b[31m0.6850\u001b[0m                     \u001b[94m0.7120\u001b[0m        \u001b[36m0.5686\u001b[0m  0.0010  13.7302\n",
      "      5            \u001b[36m0.7076\u001b[0m                     \u001b[32m0.7476\u001b[0m        \u001b[35m0.5552\u001b[0m            \u001b[31m0.6904\u001b[0m                     \u001b[94m0.7269\u001b[0m        \u001b[36m0.5582\u001b[0m  0.0010  13.8638\n",
      "      6            \u001b[36m0.7259\u001b[0m                     \u001b[32m0.7550\u001b[0m        0.5566            0.6844                     0.7203        0.5586  0.0009  12.9695\n",
      "      7            \u001b[36m0.7434\u001b[0m                     \u001b[32m0.7649\u001b[0m        \u001b[35m0.5463\u001b[0m            \u001b[31m0.7070\u001b[0m                     0.7136        0.5609  0.0009  13.2292\n",
      "      8            0.6163                     0.7242        \u001b[35m0.5274\u001b[0m            0.5834                     0.6969        0.6080  0.0009  13.4050\n",
      "      9            0.7422                     0.7638        \u001b[35m0.5257\u001b[0m            0.7003                     0.7096        0.5628  0.0009  13.1380\n",
      "     10            0.6631                     0.7461        \u001b[35m0.5185\u001b[0m            0.6153                     0.7046        0.5839  0.0008  14.2166\n",
      "     11            0.7174                     \u001b[32m0.7660\u001b[0m        \u001b[35m0.5046\u001b[0m            0.6797                     0.7233        \u001b[36m0.5571\u001b[0m  0.0008  14.1638\n",
      "     12            \u001b[36m0.7980\u001b[0m                     \u001b[32m0.7740\u001b[0m        0.5084            \u001b[31m0.7615\u001b[0m                     0.7175        \u001b[36m0.5568\u001b[0m  0.0008  15.8419\n",
      "     13            0.6774                     0.7599        0.5046            0.6405                     0.7258        0.5676  0.0007  13.6496\n",
      "     14            0.6993                     0.7681        \u001b[35m0.5006\u001b[0m            0.6704                     \u001b[94m0.7323\u001b[0m        0.5634  0.0007  14.6190\n",
      "     15            0.6789                     0.7630        \u001b[35m0.4994\u001b[0m            0.6319                     0.7191        0.5724  0.0006  13.9742\n",
      "     16            0.7007                     0.7697        \u001b[35m0.4911\u001b[0m            0.6578                     0.7144        0.5630  0.0006  14.3138\n",
      "     17            0.7651                     \u001b[32m0.7873\u001b[0m        \u001b[35m0.4894\u001b[0m            0.7243                     \u001b[94m0.7402\u001b[0m        \u001b[36m0.5443\u001b[0m  0.0005  13.5143\n",
      "     18            0.7319                     0.7832        \u001b[35m0.4838\u001b[0m            0.6897                     0.7338        0.5516  0.0005  15.6902\n",
      "     19            0.7490                     \u001b[32m0.7903\u001b[0m        \u001b[35m0.4796\u001b[0m            0.6963                     0.7349        0.5522  0.0005  13.4179\n",
      "     20            \u001b[36m0.8060\u001b[0m                     \u001b[32m0.7942\u001b[0m        0.4841            \u001b[31m0.7654\u001b[0m                     0.7346        0.5518  0.0004  13.3554\n",
      "     21            0.7470                     0.7938        \u001b[35m0.4784\u001b[0m            0.7010                     0.7363        0.5534  0.0004  14.1337\n",
      "     22            0.7362                     0.7927        \u001b[35m0.4651\u001b[0m            0.6804                     0.7252        0.5537  0.0003  14.3676\n",
      "     23            0.7543                     \u001b[32m0.7975\u001b[0m        0.4710            0.7037                     0.7335        0.5492  0.0003  17.2091\n",
      "     24            0.7850                     \u001b[32m0.8042\u001b[0m        0.4725            0.7395                     0.7392        \u001b[36m0.5435\u001b[0m  0.0002  13.8449\n",
      "     25            0.7822                     0.7999        0.4654            0.7256                     0.7264        0.5467  0.0002  15.1317\n",
      "     26            \u001b[36m0.8071\u001b[0m                     0.7975        0.4671            0.7635                     0.7363        0.5438  0.0002  9.9699\n",
      "     27            0.7998                     0.8025        \u001b[35m0.4595\u001b[0m            0.7482                     0.7328        0.5454  0.0001  9.9767\n",
      "     28            0.7978                     \u001b[32m0.8086\u001b[0m        0.4627            0.7468                     0.7378        \u001b[36m0.5423\u001b[0m  0.0001  11.7076\n",
      "     29            0.7963                     \u001b[32m0.8107\u001b[0m        0.4615            0.7482                     0.7372        \u001b[36m0.5411\u001b[0m  0.0001  12.0284\n",
      "     30            0.7807                     0.8066        \u001b[35m0.4580\u001b[0m            0.7316                     0.7373        0.5424  0.0001  12.0262\n",
      "     31            0.7852                     0.8079        0.4595            0.7409                     \u001b[94m0.7430\u001b[0m        0.5427  0.0000  15.0715\n",
      "     32            0.7834                     0.8075        \u001b[35m0.4563\u001b[0m            0.7395                     0.7422        0.5428  0.0000  13.8584\n",
      "     33            0.7842                     0.8069        0.4634            0.7369                     0.7376        0.5425  0.0000  14.8103\n",
      "     34            0.7842                     0.8077        0.4672            0.7342                     0.7360        0.5426  0.0000  15.3118\n",
      "     35            0.7839                     0.8071        \u001b[35m0.4562\u001b[0m            0.7342                     0.7360        0.5426  0.0000  14.4894\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.6902\u001b[0m                     \u001b[32m0.6876\u001b[0m        \u001b[35m0.6941\u001b[0m            \u001b[31m0.6950\u001b[0m                     \u001b[94m0.6756\u001b[0m        \u001b[36m0.6500\u001b[0m  0.0010  15.4629\n",
      "      2            \u001b[36m0.7613\u001b[0m                     \u001b[32m0.6928\u001b[0m        \u001b[35m0.6188\u001b[0m            \u001b[31m0.7561\u001b[0m                     0.6704        \u001b[36m0.6047\u001b[0m  0.0010  15.4454\n",
      "      3            0.7314                     \u001b[32m0.7452\u001b[0m        \u001b[35m0.5857\u001b[0m            0.7096                     \u001b[94m0.7006\u001b[0m        \u001b[36m0.5713\u001b[0m  0.0010  14.4731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4            \u001b[36m0.7802\u001b[0m                     \u001b[32m0.7452\u001b[0m        \u001b[35m0.5629\u001b[0m            \u001b[31m0.7641\u001b[0m                     \u001b[94m0.7104\u001b[0m        0.5746  0.0010  15.3071\n",
      "      5            0.6467                     0.7332        \u001b[35m0.5509\u001b[0m            0.6326                     0.6961        0.5756  0.0010  14.3692\n",
      "      6            0.6947                     \u001b[32m0.7536\u001b[0m        \u001b[35m0.5454\u001b[0m            0.6711                     0.7035        \u001b[36m0.5707\u001b[0m  0.0009  14.9760\n",
      "      7            0.7721                     \u001b[32m0.7736\u001b[0m        \u001b[35m0.5336\u001b[0m            0.7488                     \u001b[94m0.7186\u001b[0m        \u001b[36m0.5464\u001b[0m  0.0009  14.5734\n",
      "      8            0.6772                     0.7554        \u001b[35m0.5231\u001b[0m            0.6618                     0.7110        0.5698  0.0009  15.1398\n",
      "      9            0.7503                     \u001b[32m0.7783\u001b[0m        0.5257            0.7256                     \u001b[94m0.7235\u001b[0m        \u001b[36m0.5435\u001b[0m  0.0009  14.6772\n",
      "     10            0.6545                     0.7500        \u001b[35m0.5140\u001b[0m            0.6186                     0.6905        0.5718  0.0008  16.9651\n",
      "     11            0.7527                     \u001b[32m0.7823\u001b[0m        \u001b[35m0.5104\u001b[0m            0.7269                     0.7170        0.5542  0.0008  15.2196\n",
      "     12            0.7033                     0.7727        0.5166            0.6738                     0.7095        0.5606  0.0008  15.6373\n",
      "     13            0.7733                     \u001b[32m0.7886\u001b[0m        \u001b[35m0.5021\u001b[0m            0.7382                     \u001b[94m0.7297\u001b[0m        0.5466  0.0007  15.5924\n",
      "     14            0.7766                     \u001b[32m0.7979\u001b[0m        \u001b[35m0.4956\u001b[0m            0.7409                     0.7254        0.5517  0.0007  15.9237\n",
      "     15            \u001b[36m0.8042\u001b[0m                     \u001b[32m0.7986\u001b[0m        \u001b[35m0.4882\u001b[0m            \u001b[31m0.7721\u001b[0m                     \u001b[94m0.7298\u001b[0m        \u001b[36m0.5435\u001b[0m  0.0006  15.3732\n",
      "     16            0.7432                     0.7900        \u001b[35m0.4858\u001b[0m            0.7103                     0.7142        0.5460  0.0006  16.6402\n",
      "     17            0.6849                     0.7688        \u001b[35m0.4793\u001b[0m            0.6545                     0.7138        0.5731  0.0005  12.5641\n",
      "     18            0.7711                     \u001b[32m0.7986\u001b[0m        0.4824            0.7409                     \u001b[94m0.7371\u001b[0m        \u001b[36m0.5374\u001b[0m  0.0005  15.3613\n",
      "     19            0.7558                     0.7966        \u001b[35m0.4713\u001b[0m            0.7249                     0.7304        0.5403  0.0005  14.5841\n",
      "     20            0.7277                     0.7923        0.4746            0.6944                     0.7293        0.5494  0.0004  14.5798\n",
      "     21            0.7214                     0.7870        0.4720            0.6963                     0.7320        0.5606  0.0004  15.1516\n",
      "     22            0.7963                     \u001b[32m0.8019\u001b[0m        \u001b[35m0.4667\u001b[0m            0.7635                     \u001b[94m0.7406\u001b[0m        0.5398  0.0003  14.7299\n",
      "     23            0.7910                     \u001b[32m0.8027\u001b[0m        0.4674            0.7575                     0.7341        0.5428  0.0003  14.3788\n",
      "     24            0.7749                     \u001b[32m0.8038\u001b[0m        0.4715            0.7409                     0.7328        0.5409  0.0002  15.1115\n",
      "     25            0.7668                     0.8022        \u001b[35m0.4571\u001b[0m            0.7309                     0.7325        0.5474  0.0002  15.0505\n",
      "     26            0.7814                     0.8034        0.4698            0.7482                     0.7387        \u001b[36m0.5371\u001b[0m  0.0002  14.5149\n",
      "     27            0.7789                     \u001b[32m0.8063\u001b[0m        0.4590            0.7462                     0.7389        0.5389  0.0001  14.9966\n",
      "     28            0.7726                     0.8057        \u001b[35m0.4544\u001b[0m            0.7409                     0.7386        0.5404  0.0001  15.8376\n",
      "     29            0.7809                     \u001b[32m0.8064\u001b[0m        0.4597            0.7435                     0.7329        0.5392  0.0001  14.7299\n",
      "     30            0.7802                     \u001b[32m0.8071\u001b[0m        0.4623            0.7429                     0.7296        0.5397  0.0001  15.0773\n",
      "     31            0.7919                     0.8050        \u001b[35m0.4467\u001b[0m            0.7548                     0.7295        0.5382  0.0000  15.1543\n",
      "     32            0.7927                     0.8066        0.4557            0.7548                     0.7310        0.5384  0.0000  14.9252\n",
      "     33            0.7897                     0.8066        0.4560            0.7535                     0.7317        0.5381  0.0000  14.8746\n",
      "     34            0.7882                     0.8068        0.4524            0.7488                     0.7303        0.5385  0.0000  15.3460\n",
      "     35            0.7870                     \u001b[32m0.8072\u001b[0m        0.4574            0.7482                     0.7328        0.5386  0.0000  15.4051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6862\u001b[0m                     \u001b[32m0.6873\u001b[0m        \u001b[35m0.6907\u001b[0m            \u001b[31m0.6760\u001b[0m                     \u001b[94m0.6773\u001b[0m        \u001b[36m0.6520\u001b[0m  0.0010  8.6568\n",
      "      2            \u001b[36m0.7182\u001b[0m                     \u001b[32m0.7191\u001b[0m        \u001b[35m0.6081\u001b[0m            \u001b[31m0.7042\u001b[0m                     \u001b[94m0.7051\u001b[0m        \u001b[36m0.6221\u001b[0m  0.0010  8.7712\n",
      "      3            \u001b[36m0.7430\u001b[0m                     \u001b[32m0.7430\u001b[0m        \u001b[35m0.5649\u001b[0m            \u001b[31m0.7129\u001b[0m                     \u001b[94m0.7129\u001b[0m        \u001b[36m0.5912\u001b[0m  0.0010  9.9607\n",
      "      4            \u001b[36m0.7592\u001b[0m                     \u001b[32m0.7594\u001b[0m        \u001b[35m0.5441\u001b[0m            \u001b[31m0.7245\u001b[0m                     \u001b[94m0.7247\u001b[0m        \u001b[36m0.5625\u001b[0m  0.0010  10.5444\n",
      "      5            \u001b[36m0.7709\u001b[0m                     \u001b[32m0.7711\u001b[0m        \u001b[35m0.5205\u001b[0m            \u001b[31m0.7333\u001b[0m                     \u001b[94m0.7335\u001b[0m        \u001b[36m0.5478\u001b[0m  0.0010  9.9962\n",
      "      6            \u001b[36m0.7757\u001b[0m                     \u001b[32m0.7762\u001b[0m        \u001b[35m0.5086\u001b[0m            \u001b[31m0.7381\u001b[0m                     \u001b[94m0.7385\u001b[0m        \u001b[36m0.5362\u001b[0m  0.0009  10.1664\n",
      "      7            \u001b[36m0.7879\u001b[0m                     \u001b[32m0.7879\u001b[0m        \u001b[35m0.5043\u001b[0m            \u001b[31m0.7420\u001b[0m                     \u001b[94m0.7421\u001b[0m        \u001b[36m0.5271\u001b[0m  0.0009  6.5746\n",
      "      8            0.7760                     0.7756        \u001b[35m0.4919\u001b[0m            0.7207                     0.7203        0.5584  0.0009  10.2815\n",
      "      9            \u001b[36m0.7993\u001b[0m                     \u001b[32m0.7993\u001b[0m        \u001b[35m0.4869\u001b[0m            0.7401                     0.7402        \u001b[36m0.5249\u001b[0m  0.0009  11.0413\n",
      "     10            0.7934                     0.7935        \u001b[35m0.4815\u001b[0m            0.7381                     0.7382        0.5339  0.0008  10.4678\n",
      "     11            \u001b[36m0.8046\u001b[0m                     \u001b[32m0.8046\u001b[0m        \u001b[35m0.4773\u001b[0m            0.7391                     0.7391        0.5277  0.0008  10.3700\n",
      "     12            0.8041                     0.8042        \u001b[35m0.4687\u001b[0m            0.7410                     0.7411        0.5309  0.0008  10.5131\n",
      "     13            0.8044                     0.8046        \u001b[35m0.4654\u001b[0m            \u001b[31m0.7507\u001b[0m                     \u001b[94m0.7510\u001b[0m        \u001b[36m0.5227\u001b[0m  0.0007  11.0373\n",
      "     14            \u001b[36m0.8102\u001b[0m                     \u001b[32m0.8103\u001b[0m        \u001b[35m0.4608\u001b[0m            \u001b[31m0.7536\u001b[0m                     \u001b[94m0.7538\u001b[0m        0.5250  0.0007  9.3596\n",
      "     15            \u001b[36m0.8158\u001b[0m                     \u001b[32m0.8156\u001b[0m        \u001b[35m0.4571\u001b[0m            \u001b[31m0.7662\u001b[0m                     \u001b[94m0.7662\u001b[0m        \u001b[36m0.5161\u001b[0m  0.0006  8.9703\n",
      "     16            \u001b[36m0.8163\u001b[0m                     \u001b[32m0.8159\u001b[0m        \u001b[35m0.4549\u001b[0m            0.7565                     0.7562        0.5319  0.0006  8.5148\n",
      "     17            0.8155                     0.8156        \u001b[35m0.4523\u001b[0m            0.7546                     0.7547        0.5165  0.0005  10.2828\n",
      "     18            0.8119                     0.8118        \u001b[35m0.4448\u001b[0m            0.7546                     0.7546        0.5170  0.0005  9.5650\n",
      "     19            \u001b[36m0.8184\u001b[0m                     \u001b[32m0.8187\u001b[0m        0.4467            0.7536                     0.7540        \u001b[36m0.5079\u001b[0m  0.0005  9.7267\n",
      "     20            0.8177                     0.8176        \u001b[35m0.4371\u001b[0m            0.7556                     0.7555        0.5135  0.0004  9.7355\n",
      "     21            \u001b[36m0.8257\u001b[0m                     \u001b[32m0.8258\u001b[0m        \u001b[35m0.4344\u001b[0m            0.7536                     0.7538        0.5098  0.0004  9.7447\n",
      "     22            0.8206                     0.8204        \u001b[35m0.4339\u001b[0m            0.7624                     0.7622        0.5161  0.0003  9.8477\n",
      "     23            0.8250                     0.8249        \u001b[35m0.4331\u001b[0m            0.7565                     0.7565        0.5126  0.0003  10.2712\n",
      "     24            0.8158                     0.8156        0.4360            0.7478                     0.7477        0.5176  0.0002  10.2691\n",
      "     25            0.8255                     0.8254        \u001b[35m0.4289\u001b[0m            0.7643                     0.7643        0.5088  0.0002  9.7334\n",
      "     26            \u001b[36m0.8296\u001b[0m                     \u001b[32m0.8297\u001b[0m        0.4320            0.7517                     0.7519        \u001b[36m0.5077\u001b[0m  0.0002  9.9655\n",
      "     27            0.8262                     0.8262        0.4312            0.7536                     0.7537        0.5088  0.0001  9.9764\n",
      "     28            0.8286                     0.8286        \u001b[35m0.4256\u001b[0m            0.7556                     0.7556        0.5083  0.0001  10.4529\n",
      "     29            0.8294                     0.8294        \u001b[35m0.4221\u001b[0m            0.7546                     0.7548        \u001b[36m0.5070\u001b[0m  0.0001  10.0384\n",
      "     30            \u001b[36m0.8299\u001b[0m                     \u001b[32m0.8298\u001b[0m        0.4262            0.7585                     0.7586        0.5086  0.0001  9.8192\n",
      "     31            0.8291                     0.8291        0.4234            0.7585                     0.7585        0.5088  0.0000  10.0848\n",
      "     32            0.8291                     0.8291        \u001b[35m0.4219\u001b[0m            0.7595                     0.7595        0.5087  0.0000  10.0431\n",
      "     33            0.8289                     0.8288        0.4261            0.7585                     0.7585        0.5090  0.0000  10.0424\n",
      "     34            0.8289                     0.8289        \u001b[35m0.4151\u001b[0m            0.7595                     0.7595        0.5089  0.0000  9.9472\n",
      "     35            0.8289                     0.8289        0.4193            0.7585                     0.7585        0.5089  0.0000  10.6099\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr      dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  -------\n",
      "      1            \u001b[36m0.7068\u001b[0m                     \u001b[32m0.7075\u001b[0m        \u001b[35m0.6779\u001b[0m            \u001b[31m0.6790\u001b[0m                     \u001b[94m0.6797\u001b[0m        \u001b[36m0.6448\u001b[0m  0.0010  10.0293\n",
      "      2            \u001b[36m0.7376\u001b[0m                     \u001b[32m0.7381\u001b[0m        \u001b[35m0.5890\u001b[0m            \u001b[31m0.6984\u001b[0m                     \u001b[94m0.6987\u001b[0m        \u001b[36m0.6173\u001b[0m  0.0010  10.5803\n",
      "      3            \u001b[36m0.7459\u001b[0m                     \u001b[32m0.7462\u001b[0m        \u001b[35m0.5661\u001b[0m            \u001b[31m0.7100\u001b[0m                     \u001b[94m0.7103\u001b[0m        \u001b[36m0.5820\u001b[0m  0.0010  10.6007\n",
      "      4            \u001b[36m0.7570\u001b[0m                     \u001b[32m0.7575\u001b[0m        \u001b[35m0.5432\u001b[0m            \u001b[31m0.7187\u001b[0m                     \u001b[94m0.7190\u001b[0m        \u001b[36m0.5535\u001b[0m  0.0010  10.7685\n",
      "      5            \u001b[36m0.7650\u001b[0m                     \u001b[32m0.7651\u001b[0m        \u001b[35m0.5332\u001b[0m            \u001b[31m0.7381\u001b[0m                     \u001b[94m0.7380\u001b[0m        \u001b[36m0.5348\u001b[0m  0.0010  10.1683\n",
      "      6            \u001b[36m0.7735\u001b[0m                     \u001b[32m0.7737\u001b[0m        \u001b[35m0.5167\u001b[0m            \u001b[31m0.7420\u001b[0m                     \u001b[94m0.7420\u001b[0m        \u001b[36m0.5164\u001b[0m  0.0009  10.5521\n",
      "      7            \u001b[36m0.7767\u001b[0m                     \u001b[32m0.7768\u001b[0m        \u001b[35m0.5146\u001b[0m            \u001b[31m0.7468\u001b[0m                     \u001b[94m0.7469\u001b[0m        \u001b[36m0.5090\u001b[0m  0.0009  10.3281\n",
      "      8            \u001b[36m0.7850\u001b[0m                     \u001b[32m0.7851\u001b[0m        \u001b[35m0.5012\u001b[0m            \u001b[31m0.7517\u001b[0m                     \u001b[94m0.7518\u001b[0m        0.5108  0.0009  10.3729\n",
      "      9            \u001b[36m0.7888\u001b[0m                     \u001b[32m0.7888\u001b[0m        \u001b[35m0.4970\u001b[0m            \u001b[31m0.7565\u001b[0m                     \u001b[94m0.7564\u001b[0m        \u001b[36m0.4973\u001b[0m  0.0009  9.6314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10            \u001b[36m0.7976\u001b[0m                     \u001b[32m0.7977\u001b[0m        \u001b[35m0.4888\u001b[0m            0.7565                     \u001b[94m0.7566\u001b[0m        \u001b[36m0.4935\u001b[0m  0.0008  9.8170\n",
      "     11            \u001b[36m0.7995\u001b[0m                     \u001b[32m0.7998\u001b[0m        \u001b[35m0.4748\u001b[0m            0.7536                     0.7538        0.4974  0.0008  9.6510\n",
      "     12            0.7995                     0.7996        0.4790            \u001b[31m0.7711\u001b[0m                     \u001b[94m0.7710\u001b[0m        \u001b[36m0.4898\u001b[0m  0.0008  10.4426\n",
      "     13            0.7988                     0.7988        \u001b[35m0.4652\u001b[0m            0.7643                     0.7641        0.4922  0.0007  9.6736\n",
      "     14            0.7985                     0.7983        \u001b[35m0.4624\u001b[0m            0.7604                     0.7601        0.4985  0.0007  9.8484\n",
      "     15            \u001b[36m0.8107\u001b[0m                     \u001b[32m0.8108\u001b[0m        \u001b[35m0.4477\u001b[0m            \u001b[31m0.7721\u001b[0m                     \u001b[94m0.7720\u001b[0m        \u001b[36m0.4895\u001b[0m  0.0006  9.7281\n",
      "     16            \u001b[36m0.8141\u001b[0m                     \u001b[32m0.8140\u001b[0m        0.4596            \u001b[31m0.7750\u001b[0m                     \u001b[94m0.7748\u001b[0m        \u001b[36m0.4825\u001b[0m  0.0006  10.9108\n",
      "     17            \u001b[36m0.8148\u001b[0m                     \u001b[32m0.8150\u001b[0m        \u001b[35m0.4426\u001b[0m            \u001b[31m0.7798\u001b[0m                     \u001b[94m0.7799\u001b[0m        0.4839  0.0005  10.7741\n",
      "     18            \u001b[36m0.8155\u001b[0m                     \u001b[32m0.8156\u001b[0m        0.4483            0.7779                     0.7778        \u001b[36m0.4797\u001b[0m  0.0005  10.4363\n",
      "     19            \u001b[36m0.8167\u001b[0m                     \u001b[32m0.8167\u001b[0m        0.4447            0.7789                     0.7787        0.4815  0.0005  11.7776\n",
      "     20            \u001b[36m0.8194\u001b[0m                     \u001b[32m0.8194\u001b[0m        0.4436            0.7798                     0.7796        0.4832  0.0004  7.7169\n",
      "     21            0.8189                     0.8192        \u001b[35m0.4401\u001b[0m            \u001b[31m0.7837\u001b[0m                     \u001b[94m0.7838\u001b[0m        0.4817  0.0004  8.2992\n",
      "     22            \u001b[36m0.8221\u001b[0m                     \u001b[32m0.8222\u001b[0m        \u001b[35m0.4259\u001b[0m            0.7769                     0.7769        \u001b[36m0.4791\u001b[0m  0.0003  9.1241\n",
      "     23            0.8204                     0.8205        0.4375            0.7779                     0.7778        0.4818  0.0003  8.3028\n",
      "     24            \u001b[36m0.8231\u001b[0m                     \u001b[32m0.8232\u001b[0m        0.4342            \u001b[31m0.7847\u001b[0m                     \u001b[94m0.7845\u001b[0m        \u001b[36m0.4778\u001b[0m  0.0002  5.2779\n",
      "     25            \u001b[36m0.8262\u001b[0m                     \u001b[32m0.8263\u001b[0m        \u001b[35m0.4255\u001b[0m            \u001b[31m0.7876\u001b[0m                     \u001b[94m0.7874\u001b[0m        0.4795  0.0002  5.1423\n",
      "     26            0.8257                     0.8257        0.4314            0.7769                     0.7767        0.4802  0.0002  5.1732\n",
      "     27            0.8250                     0.8250        \u001b[35m0.4214\u001b[0m            0.7769                     0.7767        0.4799  0.0001  4.9019\n",
      "     28            0.8252                     0.8253        0.4240            0.7789                     0.7787        0.4786  0.0001  4.8839\n",
      "     29            \u001b[36m0.8272\u001b[0m                     \u001b[32m0.8272\u001b[0m        0.4282            0.7818                     0.7816        0.4788  0.0001  4.9019\n",
      "     30            0.8272                     0.8272        0.4241            0.7798                     0.7796        0.4796  0.0001  5.0335\n",
      "     31            0.8269                     0.8270        \u001b[35m0.4198\u001b[0m            0.7798                     0.7796        0.4792  0.0000  4.9129\n",
      "     32            0.8269                     0.8270        0.4286            0.7818                     0.7816        0.4790  0.0000  4.8690\n",
      "     33            0.8267                     0.8268        0.4215            0.7818                     0.7816        0.4790  0.0000  4.9169\n",
      "     34            0.8265                     0.8265        0.4233            0.7818                     0.7816        0.4791  0.0000  4.9268\n",
      "     35            0.8267                     0.8268        0.4216            0.7818                     0.7816        0.4791  0.0000  4.9637\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6934\u001b[0m                     \u001b[32m0.6941\u001b[0m        \u001b[35m0.7028\u001b[0m            \u001b[31m0.7051\u001b[0m                     \u001b[94m0.7059\u001b[0m        \u001b[36m0.6478\u001b[0m  0.0010  4.9069\n",
      "      2            \u001b[36m0.7250\u001b[0m                     \u001b[32m0.7258\u001b[0m        \u001b[35m0.6027\u001b[0m            \u001b[31m0.7197\u001b[0m                     \u001b[94m0.7205\u001b[0m        \u001b[36m0.6120\u001b[0m  0.0010  5.0106\n",
      "      3            \u001b[36m0.7388\u001b[0m                     \u001b[32m0.7392\u001b[0m        \u001b[35m0.5662\u001b[0m            0.7197                     0.7201        \u001b[36m0.5801\u001b[0m  0.0010  4.9548\n",
      "      4            \u001b[36m0.7541\u001b[0m                     \u001b[32m0.7547\u001b[0m        \u001b[35m0.5492\u001b[0m            \u001b[31m0.7333\u001b[0m                     \u001b[94m0.7339\u001b[0m        \u001b[36m0.5582\u001b[0m  0.0010  5.3627\n",
      "      5            \u001b[36m0.7660\u001b[0m                     \u001b[32m0.7661\u001b[0m        \u001b[35m0.5270\u001b[0m            \u001b[31m0.7478\u001b[0m                     \u001b[94m0.7480\u001b[0m        \u001b[36m0.5265\u001b[0m  0.0010  5.3816\n",
      "      6            \u001b[36m0.7706\u001b[0m                     \u001b[32m0.7705\u001b[0m        \u001b[35m0.5212\u001b[0m            0.7323                     0.7322        \u001b[36m0.5205\u001b[0m  0.0009  5.3637\n",
      "      7            \u001b[36m0.7908\u001b[0m                     \u001b[32m0.7909\u001b[0m        \u001b[35m0.5011\u001b[0m            0.7304                     0.7306        \u001b[36m0.5127\u001b[0m  0.0009  5.4006\n",
      "      8            0.7898                     0.7900        \u001b[35m0.4979\u001b[0m            0.7468                     0.7472        \u001b[36m0.5116\u001b[0m  0.0009  5.0086\n",
      "      9            \u001b[36m0.7976\u001b[0m                     \u001b[32m0.7979\u001b[0m        \u001b[35m0.4929\u001b[0m            \u001b[31m0.7517\u001b[0m                     \u001b[94m0.7521\u001b[0m        \u001b[36m0.4994\u001b[0m  0.0009  5.0176\n",
      "     10            0.7939                     0.7938        \u001b[35m0.4864\u001b[0m            \u001b[31m0.7556\u001b[0m                     \u001b[94m0.7555\u001b[0m        \u001b[36m0.4955\u001b[0m  0.0008  5.0126\n",
      "     11            \u001b[36m0.7990\u001b[0m                     \u001b[32m0.7989\u001b[0m        \u001b[35m0.4815\u001b[0m            \u001b[31m0.7565\u001b[0m                     \u001b[94m0.7565\u001b[0m        \u001b[36m0.4906\u001b[0m  0.0008  4.9907\n",
      "     12            \u001b[36m0.8087\u001b[0m                     \u001b[32m0.8085\u001b[0m        \u001b[35m0.4663\u001b[0m            \u001b[31m0.7595\u001b[0m                     \u001b[94m0.7593\u001b[0m        0.4956  0.0008  5.3158\n",
      "     13            0.8053                     0.8054        0.4666            0.7595                     \u001b[94m0.7597\u001b[0m        0.4908  0.0007  5.2879\n",
      "     14            \u001b[36m0.8182\u001b[0m                     \u001b[32m0.8183\u001b[0m        \u001b[35m0.4605\u001b[0m            \u001b[31m0.7711\u001b[0m                     \u001b[94m0.7713\u001b[0m        \u001b[36m0.4829\u001b[0m  0.0007  5.3936\n",
      "     15            0.8114                     0.8114        \u001b[35m0.4604\u001b[0m            0.7692                     0.7692        \u001b[36m0.4763\u001b[0m  0.0006  5.4036\n",
      "     16            0.8182                     0.8183        \u001b[35m0.4566\u001b[0m            0.7643                     0.7644        \u001b[36m0.4732\u001b[0m  0.0006  5.3826\n",
      "     17            \u001b[36m0.8238\u001b[0m                     \u001b[32m0.8238\u001b[0m        \u001b[35m0.4530\u001b[0m            \u001b[31m0.7721\u001b[0m                     \u001b[94m0.7721\u001b[0m        0.4793  0.0005  5.3308\n",
      "     18            \u001b[36m0.8269\u001b[0m                     \u001b[32m0.8269\u001b[0m        \u001b[35m0.4500\u001b[0m            0.7643                     0.7644        0.4798  0.0005  4.9019\n",
      "     19            0.8233                     0.8234        \u001b[35m0.4479\u001b[0m            0.7721                     \u001b[94m0.7722\u001b[0m        \u001b[36m0.4721\u001b[0m  0.0005  4.9039\n",
      "     20            0.8211                     0.8210        \u001b[35m0.4421\u001b[0m            0.7701                     0.7701        0.4727  0.0004  4.8979\n",
      "     21            \u001b[36m0.8284\u001b[0m                     \u001b[32m0.8283\u001b[0m        \u001b[35m0.4384\u001b[0m            0.7633                     0.7633        0.4725  0.0004  4.8969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22            0.8272                     0.8272        0.4402            0.7662                     0.7662        0.4746  0.0003  4.9009\n",
      "     23            0.8277                     0.8276        0.4392            0.7614                     0.7613        \u001b[36m0.4709\u001b[0m  0.0003  4.9019\n",
      "     24            \u001b[36m0.8311\u001b[0m                     \u001b[32m0.8311\u001b[0m        \u001b[35m0.4325\u001b[0m            0.7662                     0.7662        0.4711  0.0002  4.8989\n",
      "     25            0.8269                     0.8269        \u001b[35m0.4285\u001b[0m            0.7682                     0.7681        0.4718  0.0002  4.8979\n",
      "     26            0.8250                     0.8249        \u001b[35m0.4249\u001b[0m            \u001b[31m0.7740\u001b[0m                     \u001b[94m0.7739\u001b[0m        \u001b[36m0.4681\u001b[0m  0.0002  4.9009\n",
      "     27            0.8274                     0.8273        \u001b[35m0.4216\u001b[0m            0.7653                     0.7652        0.4726  0.0001  4.8989\n",
      "     28            \u001b[36m0.8316\u001b[0m                     \u001b[32m0.8316\u001b[0m        0.4286            0.7740                     \u001b[94m0.7740\u001b[0m        0.4688  0.0001  4.8939\n",
      "     29            0.8299                     0.8299        0.4308            0.7682                     0.7682        0.4685  0.0001  4.8969\n",
      "     30            0.8301                     0.8301        \u001b[35m0.4204\u001b[0m            0.7672                     0.7672        0.4690  0.0001  4.8949\n",
      "     31            0.8308                     0.8308        0.4254            0.7682                     0.7682        0.4682  0.0000  4.8989\n",
      "     32            0.8311                     0.8311        0.4231            0.7672                     0.7672        0.4683  0.0000  4.8959\n",
      "     33            0.8311                     0.8311        0.4268            0.7653                     0.7652        0.4685  0.0000  4.8969\n",
      "     34            0.8311                     0.8311        0.4226            0.7643                     0.7643        0.4686  0.0000  4.8949\n",
      "     35            0.8306                     0.8306        0.4255            0.7662                     0.7662        0.4686  0.0000  4.8959\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6971\u001b[0m                     \u001b[32m0.6981\u001b[0m        \u001b[35m0.6733\u001b[0m            \u001b[31m0.6644\u001b[0m                     \u001b[94m0.6655\u001b[0m        \u001b[36m0.6534\u001b[0m  0.0010  4.8909\n",
      "      2            \u001b[36m0.7282\u001b[0m                     \u001b[32m0.7286\u001b[0m        \u001b[35m0.5984\u001b[0m            \u001b[31m0.7071\u001b[0m                     \u001b[94m0.7074\u001b[0m        \u001b[36m0.6241\u001b[0m  0.0010  4.8879\n",
      "      3            \u001b[36m0.7425\u001b[0m                     \u001b[32m0.7428\u001b[0m        \u001b[35m0.5586\u001b[0m            \u001b[31m0.7100\u001b[0m                     \u001b[94m0.7103\u001b[0m        \u001b[36m0.5893\u001b[0m  0.0010  4.8889\n",
      "      4            \u001b[36m0.7551\u001b[0m                     \u001b[32m0.7557\u001b[0m        \u001b[35m0.5493\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7271\u001b[0m        \u001b[36m0.5637\u001b[0m  0.0010  4.8909\n",
      "      5            \u001b[36m0.7619\u001b[0m                     \u001b[32m0.7621\u001b[0m        \u001b[35m0.5335\u001b[0m            \u001b[31m0.7371\u001b[0m                     \u001b[94m0.7372\u001b[0m        \u001b[36m0.5420\u001b[0m  0.0010  4.8889\n",
      "      6            \u001b[36m0.7697\u001b[0m                     \u001b[32m0.7698\u001b[0m        \u001b[35m0.5246\u001b[0m            \u001b[31m0.7478\u001b[0m                     \u001b[94m0.7478\u001b[0m        \u001b[36m0.5274\u001b[0m  0.0009  4.8979\n",
      "      7            \u001b[36m0.7881\u001b[0m                     \u001b[32m0.7884\u001b[0m        \u001b[35m0.5037\u001b[0m            \u001b[31m0.7536\u001b[0m                     \u001b[94m0.7538\u001b[0m        \u001b[36m0.5156\u001b[0m  0.0009  4.8869\n",
      "      8            0.7864                     0.7865        \u001b[35m0.4978\u001b[0m            0.7498                     0.7498        \u001b[36m0.5147\u001b[0m  0.0009  4.8889\n",
      "      9            \u001b[36m0.7903\u001b[0m                     \u001b[32m0.7903\u001b[0m        \u001b[35m0.4974\u001b[0m            \u001b[31m0.7565\u001b[0m                     \u001b[94m0.7565\u001b[0m        \u001b[36m0.5125\u001b[0m  0.0009  4.8899\n",
      "     10            \u001b[36m0.7939\u001b[0m                     \u001b[32m0.7940\u001b[0m        \u001b[35m0.4825\u001b[0m            0.7498                     0.7498        \u001b[36m0.5008\u001b[0m  0.0008  4.8919\n",
      "     11            0.7937                     0.7939        \u001b[35m0.4815\u001b[0m            0.7565                     \u001b[94m0.7569\u001b[0m        \u001b[36m0.4993\u001b[0m  0.0008  4.8859\n",
      "     12            \u001b[36m0.8066\u001b[0m                     \u001b[32m0.8068\u001b[0m        \u001b[35m0.4751\u001b[0m            \u001b[31m0.7604\u001b[0m                     \u001b[94m0.7607\u001b[0m        \u001b[36m0.4991\u001b[0m  0.0008  4.8929\n",
      "     13            0.8012                     0.8011        \u001b[35m0.4659\u001b[0m            0.7488                     0.7486        0.5015  0.0007  4.8909\n",
      "     14            0.7988                     0.7986        \u001b[35m0.4590\u001b[0m            0.7527                     0.7524        \u001b[36m0.4977\u001b[0m  0.0007  4.8899\n",
      "     15            \u001b[36m0.8107\u001b[0m                     \u001b[32m0.8108\u001b[0m        \u001b[35m0.4566\u001b[0m            \u001b[31m0.7672\u001b[0m                     \u001b[94m0.7674\u001b[0m        \u001b[36m0.4826\u001b[0m  0.0006  4.8909\n",
      "     16            \u001b[36m0.8121\u001b[0m                     \u001b[32m0.8122\u001b[0m        \u001b[35m0.4516\u001b[0m            0.7653                     0.7653        0.4839  0.0006  4.8949\n",
      "     17            \u001b[36m0.8172\u001b[0m                     \u001b[32m0.8173\u001b[0m        \u001b[35m0.4483\u001b[0m            \u001b[31m0.7711\u001b[0m                     \u001b[94m0.7712\u001b[0m        \u001b[36m0.4816\u001b[0m  0.0005  4.8959\n",
      "     18            \u001b[36m0.8211\u001b[0m                     \u001b[32m0.8214\u001b[0m        0.4485            \u001b[31m0.7721\u001b[0m                     \u001b[94m0.7724\u001b[0m        \u001b[36m0.4793\u001b[0m  0.0005  4.8919\n",
      "     19            \u001b[36m0.8238\u001b[0m                     \u001b[32m0.8240\u001b[0m        \u001b[35m0.4421\u001b[0m            0.7692                     0.7694        \u001b[36m0.4773\u001b[0m  0.0005  4.8949\n",
      "     20            \u001b[36m0.8260\u001b[0m                     \u001b[32m0.8260\u001b[0m        \u001b[35m0.4395\u001b[0m            0.7672                     0.7673        0.4808  0.0004  4.9119\n",
      "     21            0.8243                     0.8243        0.4401            0.7624                     0.7624        0.4824  0.0004  4.8969\n",
      "     22            0.8206                     0.8208        \u001b[35m0.4257\u001b[0m            0.7614                     0.7615        \u001b[36m0.4745\u001b[0m  0.0003  4.8909\n",
      "     23            \u001b[36m0.8284\u001b[0m                     \u001b[32m0.8284\u001b[0m        0.4293            0.7672                     0.7672        0.4796  0.0003  4.9129\n",
      "     24            0.8226                     0.8226        0.4303            0.7653                     0.7653        0.4759  0.0002  4.8919\n",
      "     25            0.8252                     0.8253        0.4276            0.7653                     0.7653        0.4756  0.0002  4.8899\n",
      "     26            0.8252                     0.8252        0.4280            0.7633                     0.7634        0.4748  0.0002  4.8949\n",
      "     27            0.8260                     0.8260        \u001b[35m0.4194\u001b[0m            0.7643                     0.7643        0.4746  0.0001  4.8979\n",
      "     28            0.8284                     \u001b[32m0.8284\u001b[0m        \u001b[35m0.4187\u001b[0m            0.7624                     0.7624        \u001b[36m0.4736\u001b[0m  0.0001  4.8899\n",
      "     29            \u001b[36m0.8296\u001b[0m                     \u001b[32m0.8297\u001b[0m        0.4198            0.7682                     0.7683        \u001b[36m0.4728\u001b[0m  0.0001  4.8919\n",
      "     30            0.8294                     0.8294        \u001b[35m0.4183\u001b[0m            0.7653                     0.7653        0.4732  0.0001  4.8929\n",
      "     31            \u001b[36m0.8301\u001b[0m                     \u001b[32m0.8302\u001b[0m        \u001b[35m0.4133\u001b[0m            0.7653                     0.7654        0.4733  0.0000  4.8969\n",
      "     32            \u001b[36m0.8306\u001b[0m                     \u001b[32m0.8306\u001b[0m        0.4177            0.7643                     0.7644        0.4733  0.0000  4.8869\n",
      "     33            \u001b[36m0.8308\u001b[0m                     \u001b[32m0.8309\u001b[0m        0.4186            0.7633                     0.7634        0.4733  0.0000  4.8979\n",
      "     34            0.8308                     \u001b[32m0.8309\u001b[0m        0.4254            0.7643                     0.7644        0.4734  0.0000  4.8999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35            0.8308                     0.8309        0.4150            0.7643                     0.7644        0.4734  0.0000  4.8919\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6782\u001b[0m                     \u001b[32m0.6796\u001b[0m        \u001b[35m0.6834\u001b[0m            \u001b[31m0.6731\u001b[0m                     \u001b[94m0.6745\u001b[0m        \u001b[36m0.6452\u001b[0m  0.0010  4.8969\n",
      "      2            \u001b[36m0.7126\u001b[0m                     \u001b[32m0.7136\u001b[0m        \u001b[35m0.6020\u001b[0m            \u001b[31m0.7110\u001b[0m                     \u001b[94m0.7120\u001b[0m        \u001b[36m0.6139\u001b[0m  0.0010  4.8929\n",
      "      3            \u001b[36m0.7294\u001b[0m                     \u001b[32m0.7301\u001b[0m        \u001b[35m0.5720\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7273\u001b[0m        \u001b[36m0.5745\u001b[0m  0.0010  4.8919\n",
      "      4            \u001b[36m0.7481\u001b[0m                     \u001b[32m0.7485\u001b[0m        \u001b[35m0.5537\u001b[0m            0.7236                     0.7240        \u001b[36m0.5397\u001b[0m  0.0010  4.8979\n",
      "      5            \u001b[36m0.7604\u001b[0m                     \u001b[32m0.7608\u001b[0m        \u001b[35m0.5391\u001b[0m            \u001b[31m0.7401\u001b[0m                     \u001b[94m0.7405\u001b[0m        \u001b[36m0.5174\u001b[0m  0.0010  4.8929\n",
      "      6            \u001b[36m0.7658\u001b[0m                     \u001b[32m0.7657\u001b[0m        \u001b[35m0.5227\u001b[0m            \u001b[31m0.7517\u001b[0m                     \u001b[94m0.7518\u001b[0m        \u001b[36m0.5026\u001b[0m  0.0009  4.8979\n",
      "      7            \u001b[36m0.7779\u001b[0m                     \u001b[32m0.7778\u001b[0m        \u001b[35m0.5027\u001b[0m            \u001b[31m0.7662\u001b[0m                     \u001b[94m0.7663\u001b[0m        \u001b[36m0.4962\u001b[0m  0.0009  4.8969\n",
      "      8            \u001b[36m0.7816\u001b[0m                     \u001b[32m0.7816\u001b[0m        \u001b[35m0.5014\u001b[0m            0.7633                     0.7634        \u001b[36m0.4894\u001b[0m  0.0009  4.8969\n",
      "      9            \u001b[36m0.7859\u001b[0m                     \u001b[32m0.7856\u001b[0m        \u001b[35m0.4949\u001b[0m            \u001b[31m0.7682\u001b[0m                     \u001b[94m0.7680\u001b[0m        \u001b[36m0.4835\u001b[0m  0.0009  4.8969\n",
      "     10            \u001b[36m0.7896\u001b[0m                     \u001b[32m0.7895\u001b[0m        \u001b[35m0.4851\u001b[0m            0.7614                     0.7614        \u001b[36m0.4808\u001b[0m  0.0008  4.8959\n",
      "     11            \u001b[36m0.7993\u001b[0m                     \u001b[32m0.7992\u001b[0m        \u001b[35m0.4784\u001b[0m            \u001b[31m0.7701\u001b[0m                     \u001b[94m0.7701\u001b[0m        \u001b[36m0.4759\u001b[0m  0.0008  4.8999\n",
      "     12            \u001b[36m0.8032\u001b[0m                     \u001b[32m0.8033\u001b[0m        0.4838            \u001b[31m0.7740\u001b[0m                     \u001b[94m0.7741\u001b[0m        0.4764  0.0008  4.8999\n",
      "     13            0.8024                     0.8025        \u001b[35m0.4737\u001b[0m            \u001b[31m0.7779\u001b[0m                     \u001b[94m0.7779\u001b[0m        \u001b[36m0.4738\u001b[0m  0.0007  4.9009\n",
      "     14            \u001b[36m0.8066\u001b[0m                     \u001b[32m0.8067\u001b[0m        \u001b[35m0.4692\u001b[0m            0.7779                     \u001b[94m0.7780\u001b[0m        \u001b[36m0.4716\u001b[0m  0.0007  4.8979\n",
      "     15            \u001b[36m0.8109\u001b[0m                     \u001b[32m0.8109\u001b[0m        \u001b[35m0.4598\u001b[0m            0.7759                     0.7759        0.4722  0.0006  4.8909\n",
      "     16            \u001b[36m0.8155\u001b[0m                     \u001b[32m0.8156\u001b[0m        0.4609            0.7769                     0.7770        \u001b[36m0.4692\u001b[0m  0.0006  4.8939\n",
      "     17            0.8146                     0.8143        \u001b[35m0.4570\u001b[0m            0.7711                     0.7709        0.4760  0.0005  4.8989\n",
      "     18            \u001b[36m0.8158\u001b[0m                     \u001b[32m0.8158\u001b[0m        \u001b[35m0.4511\u001b[0m            \u001b[31m0.7837\u001b[0m                     \u001b[94m0.7837\u001b[0m        0.4706  0.0005  4.9039\n",
      "     19            \u001b[36m0.8201\u001b[0m                     \u001b[32m0.8202\u001b[0m        0.4526            0.7662                     0.7663        0.4702  0.0005  4.9009\n",
      "     20            0.8167                     0.8166        \u001b[35m0.4446\u001b[0m            0.7672                     0.7672        0.4739  0.0004  4.8919\n",
      "     21            \u001b[36m0.8226\u001b[0m                     \u001b[32m0.8224\u001b[0m        \u001b[35m0.4440\u001b[0m            0.7837                     0.7836        \u001b[36m0.4689\u001b[0m  0.0004  4.8999\n",
      "     22            \u001b[36m0.8267\u001b[0m                     \u001b[32m0.8267\u001b[0m        \u001b[35m0.4401\u001b[0m            0.7818                     0.7818        \u001b[36m0.4678\u001b[0m  0.0003  4.8969\n",
      "     23            \u001b[36m0.8269\u001b[0m                     \u001b[32m0.8268\u001b[0m        \u001b[35m0.4308\u001b[0m            0.7837                     0.7836        0.4687  0.0003  4.8929\n",
      "     24            0.8209                     0.8207        0.4318            0.7721                     0.7720        0.4726  0.0002  4.8979\n",
      "     25            0.8250                     0.8251        0.4319            0.7789                     0.7790        0.4688  0.0002  4.8919\n",
      "     26            0.8257                     0.8258        0.4357            0.7759                     0.7760        0.4697  0.0002  4.8979\n",
      "     27            0.8238                     0.8239        \u001b[35m0.4302\u001b[0m            0.7740                     0.7741        0.4707  0.0001  4.8999\n",
      "     28            \u001b[36m0.8284\u001b[0m                     \u001b[32m0.8284\u001b[0m        \u001b[35m0.4230\u001b[0m            0.7711                     0.7711        0.4713  0.0001  4.8959\n",
      "     29            0.8284                     \u001b[32m0.8285\u001b[0m        0.4277            0.7789                     0.7789        0.4700  0.0001  4.9029\n",
      "     30            \u001b[36m0.8291\u001b[0m                     \u001b[32m0.8292\u001b[0m        \u001b[35m0.4223\u001b[0m            0.7750                     0.7750        0.4705  0.0001  4.8989\n",
      "     31            \u001b[36m0.8299\u001b[0m                     \u001b[32m0.8299\u001b[0m        \u001b[35m0.4158\u001b[0m            0.7750                     0.7750        0.4706  0.0000  4.9019\n",
      "     32            \u001b[36m0.8306\u001b[0m                     \u001b[32m0.8306\u001b[0m        0.4272            0.7759                     0.7760        0.4705  0.0000  4.8989\n",
      "     33            0.8301                     0.8301        0.4259            0.7759                     0.7760        0.4705  0.0000  4.8989\n",
      "     34            0.8299                     0.8299        0.4255            0.7759                     0.7760        0.4706  0.0000  4.9039\n",
      "     35            0.8299                     0.8299        0.4256            0.7750                     0.7750        0.4706  0.0000  4.9009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6812\u001b[0m                     \u001b[32m0.6915\u001b[0m        \u001b[35m0.6845\u001b[0m            \u001b[31m0.6763\u001b[0m                     \u001b[94m0.6851\u001b[0m        \u001b[36m0.6371\u001b[0m  0.0010  3.0538\n",
      "      2            \u001b[36m0.7263\u001b[0m                     \u001b[32m0.7316\u001b[0m        \u001b[35m0.5772\u001b[0m            \u001b[31m0.7101\u001b[0m                     \u001b[94m0.7128\u001b[0m        \u001b[36m0.6080\u001b[0m  0.0010  2.9391\n",
      "      3            \u001b[36m0.7324\u001b[0m                     \u001b[32m0.7403\u001b[0m        \u001b[35m0.5523\u001b[0m            0.7069                     0.7107        \u001b[36m0.5995\u001b[0m  0.0010  2.9431\n",
      "      4            \u001b[36m0.7368\u001b[0m                     \u001b[32m0.7441\u001b[0m        \u001b[35m0.5381\u001b[0m            \u001b[31m0.7198\u001b[0m                     \u001b[94m0.7243\u001b[0m        \u001b[36m0.5821\u001b[0m  0.0010  2.9391\n",
      "      5            \u001b[36m0.7404\u001b[0m                     \u001b[32m0.7527\u001b[0m        \u001b[35m0.5226\u001b[0m            0.7037                     0.7122        \u001b[36m0.5754\u001b[0m  0.0010  2.9431\n",
      "      6            \u001b[36m0.7598\u001b[0m                     \u001b[32m0.7646\u001b[0m        \u001b[35m0.5110\u001b[0m            0.7037                     0.7069        \u001b[36m0.5592\u001b[0m  0.0009  2.9431\n",
      "      7            0.7541                     \u001b[32m0.7656\u001b[0m        \u001b[35m0.5032\u001b[0m            0.7005                     0.7090        0.5596  0.0009  2.9411\n",
      "      8            0.7553                     \u001b[32m0.7681\u001b[0m        \u001b[35m0.4829\u001b[0m            0.7053                     0.7146        0.5629  0.0009  2.9411\n",
      "      9            \u001b[36m0.7634\u001b[0m                     \u001b[32m0.7733\u001b[0m        0.4881            0.7101                     0.7160        \u001b[36m0.5542\u001b[0m  0.0009  2.9421\n",
      "     10            \u001b[36m0.7852\u001b[0m                     \u001b[32m0.7890\u001b[0m        \u001b[35m0.4792\u001b[0m            0.7069                     0.7083        0.5577  0.0008  2.9391\n",
      "     11            \u001b[36m0.7908\u001b[0m                     \u001b[32m0.7938\u001b[0m        \u001b[35m0.4764\u001b[0m            0.7053                     0.7062        0.5548  0.0008  2.9441\n",
      "     12            0.7823                     0.7912        \u001b[35m0.4696\u001b[0m            0.7069                     0.7134        \u001b[36m0.5540\u001b[0m  0.0008  2.9411\n",
      "     13            0.7904                     \u001b[32m0.7989\u001b[0m        0.4710            0.7053                     0.7104        \u001b[36m0.5491\u001b[0m  0.0007  2.9401\n",
      "     14            \u001b[36m0.7956\u001b[0m                     \u001b[32m0.8037\u001b[0m        \u001b[35m0.4559\u001b[0m            0.7005                     0.7051        0.5505  0.0007  2.9401\n",
      "     15            \u001b[36m0.7977\u001b[0m                     \u001b[32m0.8054\u001b[0m        0.4575            0.7069                     0.7131        0.5533  0.0006  2.9401\n",
      "     16            \u001b[36m0.8033\u001b[0m                     0.8020        \u001b[35m0.4507\u001b[0m            0.7150                     0.7124        0.5651  0.0006  2.9471\n",
      "     17            0.7960                     0.8041        \u001b[35m0.4417\u001b[0m            0.7118                     0.7172        0.5612  0.0005  2.9451\n",
      "     18            \u001b[36m0.8102\u001b[0m                     \u001b[32m0.8125\u001b[0m        0.4472            0.7134                     0.7136        0.5583  0.0005  2.9411\n",
      "     19            \u001b[36m0.8154\u001b[0m                     \u001b[32m0.8189\u001b[0m        \u001b[35m0.4398\u001b[0m            0.7150                     0.7157        0.5584  0.0005  2.9421\n",
      "     20            0.8122                     0.8117        \u001b[35m0.4347\u001b[0m            0.7182                     0.7162        0.5650  0.0004  2.9421\n",
      "     21            \u001b[36m0.8190\u001b[0m                     \u001b[32m0.8226\u001b[0m        \u001b[35m0.4342\u001b[0m            0.7150                     0.7160        0.5562  0.0004  2.9371\n",
      "     22            \u001b[36m0.8194\u001b[0m                     0.8214        \u001b[35m0.4333\u001b[0m            0.7150                     0.7148        0.5602  0.0003  2.9411\n",
      "     23            0.8170                     0.8215        \u001b[35m0.4262\u001b[0m            0.7134                     0.7157        0.5581  0.0003  2.9411\n",
      "     24            0.8178                     0.8222        0.4327            0.7198                     0.7219        0.5563  0.0002  2.9411\n",
      "     25            \u001b[36m0.8231\u001b[0m                     \u001b[32m0.8268\u001b[0m        \u001b[35m0.4186\u001b[0m            0.7150                     0.7166        0.5592  0.0002  2.9441\n",
      "     26            0.8198                     0.8243        0.4217            0.7166                     0.7195        0.5619  0.0002  2.9441\n",
      "     27            0.8214                     0.8240        \u001b[35m0.4185\u001b[0m            \u001b[31m0.7214\u001b[0m                     0.7222        0.5629  0.0001  2.9391\n",
      "     28            \u001b[36m0.8255\u001b[0m                     \u001b[32m0.8278\u001b[0m        0.4210            0.7166                     0.7181        0.5609  0.0001  2.9441\n",
      "     29            0.8255                     \u001b[32m0.8279\u001b[0m        \u001b[35m0.4176\u001b[0m            0.7150                     0.7154        0.5616  0.0001  2.9441\n",
      "     30            0.8231                     0.8262        0.4188            0.7150                     0.7166        0.5616  0.0001  2.9411\n",
      "     31            0.8239                     0.8270        \u001b[35m0.4101\u001b[0m            0.7166                     0.7181        0.5622  0.0000  2.9441\n",
      "     32            0.8222                     0.8256        0.4183            0.7101                     0.7119        0.5623  0.0000  2.9461\n",
      "     33            0.8227                     0.8260        0.4164            0.7085                     0.7107        0.5622  0.0000  2.9431\n",
      "     34            0.8222                     0.8257        0.4193            0.7085                     0.7107        0.5623  0.0000  2.9411\n",
      "     35            0.8214                     0.8251        0.4143            0.7085                     0.7107        0.5623  0.0000  2.9401\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6969\u001b[0m                     \u001b[32m0.7073\u001b[0m        \u001b[35m0.6744\u001b[0m            \u001b[31m0.6812\u001b[0m                     \u001b[94m0.6895\u001b[0m        \u001b[36m0.6251\u001b[0m  0.0010  2.9311\n",
      "      2            \u001b[36m0.7231\u001b[0m                     \u001b[32m0.7327\u001b[0m        \u001b[35m0.5677\u001b[0m            \u001b[31m0.7037\u001b[0m                     \u001b[94m0.7122\u001b[0m        \u001b[36m0.6189\u001b[0m  0.0010  2.9312\n",
      "      3            \u001b[36m0.7332\u001b[0m                     \u001b[32m0.7433\u001b[0m        \u001b[35m0.5550\u001b[0m            0.6876                     0.6972        \u001b[36m0.6049\u001b[0m  0.0010  2.9302\n",
      "      4            \u001b[36m0.7469\u001b[0m                     \u001b[32m0.7564\u001b[0m        \u001b[35m0.5279\u001b[0m            0.6940                     0.7025        \u001b[36m0.5939\u001b[0m  0.0010  2.9302\n",
      "      5            \u001b[36m0.7505\u001b[0m                     \u001b[32m0.7608\u001b[0m        \u001b[35m0.5110\u001b[0m            0.6973                     0.7069        \u001b[36m0.5713\u001b[0m  0.0010  2.9272\n",
      "      6            \u001b[36m0.7626\u001b[0m                     \u001b[32m0.7693\u001b[0m        \u001b[35m0.5037\u001b[0m            \u001b[31m0.7214\u001b[0m                     \u001b[94m0.7267\u001b[0m        \u001b[36m0.5521\u001b[0m  0.0009  2.9342\n",
      "      7            0.7570                     0.7661        \u001b[35m0.4976\u001b[0m            0.7069                     0.7140        0.5548  0.0009  2.9391\n",
      "      8            \u001b[36m0.7832\u001b[0m                     \u001b[32m0.7866\u001b[0m        \u001b[35m0.4852\u001b[0m            \u001b[31m0.7262\u001b[0m                     \u001b[94m0.7281\u001b[0m        \u001b[36m0.5467\u001b[0m  0.0009  2.9292\n",
      "      9            \u001b[36m0.7880\u001b[0m                     \u001b[32m0.7948\u001b[0m        \u001b[35m0.4787\u001b[0m            0.7166                     0.7207        0.5516  0.0009  2.9312\n",
      "     10            \u001b[36m0.7936\u001b[0m                     \u001b[32m0.8011\u001b[0m        \u001b[35m0.4648\u001b[0m            0.7134                     0.7181        0.5534  0.0008  2.9342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            0.7771                     0.7887        \u001b[35m0.4623\u001b[0m            0.6940                     0.7040        0.5836  0.0008  2.9302\n",
      "     12            \u001b[36m0.7969\u001b[0m                     \u001b[32m0.8035\u001b[0m        \u001b[35m0.4622\u001b[0m            0.7118                     0.7163        0.5509  0.0008  2.9282\n",
      "     13            \u001b[36m0.8025\u001b[0m                     \u001b[32m0.8102\u001b[0m        \u001b[35m0.4511\u001b[0m            0.7198                     0.7252        0.5595  0.0007  2.9361\n",
      "     14            \u001b[36m0.8110\u001b[0m                     \u001b[32m0.8132\u001b[0m        \u001b[35m0.4478\u001b[0m            0.7182                     0.7195        0.5653  0.0007  2.9322\n",
      "     15            0.8009                     0.8072        \u001b[35m0.4417\u001b[0m            0.7085                     0.7143        0.5769  0.0006  2.9332\n",
      "     16            \u001b[36m0.8142\u001b[0m                     \u001b[32m0.8197\u001b[0m        0.4489            0.7198                     0.7249        0.5657  0.0006  2.9342\n",
      "     17            \u001b[36m0.8227\u001b[0m                     \u001b[32m0.8224\u001b[0m        \u001b[35m0.4397\u001b[0m            \u001b[31m0.7279\u001b[0m                     0.7269        0.5693  0.0005  2.9332\n",
      "     18            \u001b[36m0.8235\u001b[0m                     \u001b[32m0.8255\u001b[0m        \u001b[35m0.4387\u001b[0m            0.7262                     0.7275        0.5649  0.0005  2.9332\n",
      "     19            0.8227                     0.8237        \u001b[35m0.4296\u001b[0m            0.7262                     0.7257        0.5696  0.0005  2.9322\n",
      "     20            0.8235                     0.8247        0.4337            \u001b[31m0.7295\u001b[0m                     \u001b[94m0.7287\u001b[0m        0.5672  0.0004  2.9391\n",
      "     21            \u001b[36m0.8275\u001b[0m                     \u001b[32m0.8293\u001b[0m        \u001b[35m0.4209\u001b[0m            \u001b[31m0.7343\u001b[0m                     \u001b[94m0.7346\u001b[0m        0.5670  0.0004  2.9332\n",
      "     22            0.8243                     0.8288        0.4230            0.7311                     0.7340        0.5693  0.0003  2.9342\n",
      "     23            \u001b[36m0.8279\u001b[0m                     \u001b[32m0.8317\u001b[0m        0.4222            \u001b[31m0.7359\u001b[0m                     \u001b[94m0.7375\u001b[0m        0.5678  0.0003  2.9342\n",
      "     24            \u001b[36m0.8295\u001b[0m                     0.8316        \u001b[35m0.4179\u001b[0m            0.7359                     0.7366        0.5689  0.0002  2.9342\n",
      "     25            0.8287                     0.8308        \u001b[35m0.4128\u001b[0m            \u001b[31m0.7375\u001b[0m                     \u001b[94m0.7387\u001b[0m        0.5701  0.0002  2.9352\n",
      "     26            \u001b[36m0.8311\u001b[0m                     \u001b[32m0.8342\u001b[0m        0.4197            0.7359                     \u001b[94m0.7387\u001b[0m        0.5691  0.0002  2.9322\n",
      "     27            0.8247                     0.8296        \u001b[35m0.4038\u001b[0m            0.7327                     0.7367        0.5729  0.0001  2.9361\n",
      "     28            0.8239                     0.8288        0.4053            0.7295                     0.7337        0.5738  0.0001  2.9342\n",
      "     29            0.8275                     0.8315        0.4045            0.7359                     \u001b[94m0.7396\u001b[0m        0.5718  0.0001  2.9332\n",
      "     30            0.8247                     0.8295        0.4095            0.7311                     0.7352        0.5738  0.0001  2.9332\n",
      "     31            0.8255                     0.8297        \u001b[35m0.4012\u001b[0m            0.7327                     0.7364        0.5726  0.0000  2.9292\n",
      "     32            0.8263                     0.8303        \u001b[35m0.3964\u001b[0m            0.7327                     0.7361        0.5720  0.0000  2.9352\n",
      "     33            0.8263                     0.8304        0.4133            0.7311                     0.7346        0.5722  0.0000  2.9361\n",
      "     34            0.8259                     0.8300        0.4140            0.7295                     0.7331        0.5723  0.0000  2.9401\n",
      "     35            0.8259                     0.8300        0.4047            0.7295                     0.7331        0.5722  0.0000  2.9342\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7001\u001b[0m                     \u001b[32m0.7115\u001b[0m        \u001b[35m0.6698\u001b[0m            \u001b[31m0.6876\u001b[0m                     \u001b[94m0.6978\u001b[0m        \u001b[36m0.6252\u001b[0m  0.0010  2.9441\n",
      "      2            \u001b[36m0.7215\u001b[0m                     \u001b[32m0.7326\u001b[0m        \u001b[35m0.5698\u001b[0m            \u001b[31m0.7101\u001b[0m                     \u001b[94m0.7190\u001b[0m        \u001b[36m0.6186\u001b[0m  0.0010  2.9431\n",
      "      3            \u001b[36m0.7384\u001b[0m                     \u001b[32m0.7468\u001b[0m        \u001b[35m0.5509\u001b[0m            0.7085                     0.7154        \u001b[36m0.5967\u001b[0m  0.0010  2.9441\n",
      "      4            0.7259                     0.7378        \u001b[35m0.5334\u001b[0m            0.7069                     0.7176        \u001b[36m0.5798\u001b[0m  0.0010  2.9491\n",
      "      5            \u001b[36m0.7416\u001b[0m                     \u001b[32m0.7510\u001b[0m        \u001b[35m0.5204\u001b[0m            \u001b[31m0.7118\u001b[0m                     0.7187        \u001b[36m0.5726\u001b[0m  0.0010  2.9481\n",
      "      6            \u001b[36m0.7457\u001b[0m                     \u001b[32m0.7557\u001b[0m        \u001b[35m0.5099\u001b[0m            0.7101                     \u001b[94m0.7199\u001b[0m        \u001b[36m0.5539\u001b[0m  0.0009  2.9481\n",
      "      7            \u001b[36m0.7618\u001b[0m                     \u001b[32m0.7693\u001b[0m        \u001b[35m0.4958\u001b[0m            \u001b[31m0.7230\u001b[0m                     \u001b[94m0.7287\u001b[0m        \u001b[36m0.5478\u001b[0m  0.0009  2.9451\n",
      "      8            0.7537                     0.7646        0.4999            0.7037                     0.7143        0.5480  0.0009  2.9471\n",
      "      9            \u001b[36m0.7759\u001b[0m                     \u001b[32m0.7815\u001b[0m        \u001b[35m0.4921\u001b[0m            0.7069                     0.7101        \u001b[36m0.5356\u001b[0m  0.0009  2.9491\n",
      "     10            \u001b[36m0.7783\u001b[0m                     \u001b[32m0.7822\u001b[0m        \u001b[35m0.4881\u001b[0m            \u001b[31m0.7246\u001b[0m                     0.7278        \u001b[36m0.5342\u001b[0m  0.0008  2.9441\n",
      "     11            \u001b[36m0.7832\u001b[0m                     \u001b[32m0.7827\u001b[0m        \u001b[35m0.4839\u001b[0m            \u001b[31m0.7295\u001b[0m                     0.7278        0.5490  0.0008  2.9511\n",
      "     12            \u001b[36m0.7977\u001b[0m                     \u001b[32m0.7988\u001b[0m        \u001b[35m0.4705\u001b[0m            0.7246                     0.7245        \u001b[36m0.5274\u001b[0m  0.0008  2.9481\n",
      "     13            0.7956                     0.7953        \u001b[35m0.4647\u001b[0m            \u001b[31m0.7375\u001b[0m                     \u001b[94m0.7369\u001b[0m        \u001b[36m0.5232\u001b[0m  0.0007  2.9431\n",
      "     14            \u001b[36m0.7989\u001b[0m                     \u001b[32m0.8037\u001b[0m        \u001b[35m0.4607\u001b[0m            0.7311                     0.7352        \u001b[36m0.5213\u001b[0m  0.0007  2.9551\n",
      "     15            \u001b[36m0.8033\u001b[0m                     \u001b[32m0.8057\u001b[0m        0.4623            0.7375                     \u001b[94m0.7384\u001b[0m        0.5248  0.0006  2.9441\n",
      "     16            \u001b[36m0.8053\u001b[0m                     0.8051        \u001b[35m0.4461\u001b[0m            0.7295                     0.7290        0.5350  0.0006  2.9501\n",
      "     17            \u001b[36m0.8081\u001b[0m                     \u001b[32m0.8121\u001b[0m        0.4565            0.7262                     0.7296        0.5222  0.0005  2.9451\n",
      "     18            0.8053                     0.8041        \u001b[35m0.4426\u001b[0m            0.7327                     0.7295        0.5236  0.0005  2.9451\n",
      "     19            \u001b[36m0.8094\u001b[0m                     0.8061        \u001b[35m0.4413\u001b[0m            0.7262                     0.7212        0.5480  0.0005  2.9511\n",
      "     20            \u001b[36m0.8158\u001b[0m                     \u001b[32m0.8185\u001b[0m        \u001b[35m0.4405\u001b[0m            0.7343                     0.7352        0.5234  0.0004  2.9461\n",
      "     21            \u001b[36m0.8247\u001b[0m                     \u001b[32m0.8260\u001b[0m        \u001b[35m0.4354\u001b[0m            0.7343                     0.7346        0.5215  0.0004  2.9601\n",
      "     22            0.8206                     0.8210        0.4367            0.7343                     0.7337        0.5229  0.0003  2.9631\n",
      "     23            0.8227                     0.8231        0.4395            0.7311                     0.7304        \u001b[36m0.5211\u001b[0m  0.0003  2.9531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24            0.8227                     0.8238        \u001b[35m0.4289\u001b[0m            0.7262                     0.7272        \u001b[36m0.5191\u001b[0m  0.0002  2.9511\n",
      "     25            \u001b[36m0.8267\u001b[0m                     \u001b[32m0.8286\u001b[0m        0.4320            0.7327                     0.7337        0.5209  0.0002  2.9451\n",
      "     26            0.8251                     0.8274        \u001b[35m0.4209\u001b[0m            \u001b[31m0.7391\u001b[0m                     \u001b[94m0.7399\u001b[0m        \u001b[36m0.5179\u001b[0m  0.0002  2.9531\n",
      "     27            \u001b[36m0.8275\u001b[0m                     \u001b[32m0.8298\u001b[0m        \u001b[35m0.4199\u001b[0m            0.7359                     0.7369        0.5208  0.0001  2.9431\n",
      "     28            0.8247                     0.8267        \u001b[35m0.4193\u001b[0m            0.7327                     0.7337        0.5188  0.0001  2.9451\n",
      "     29            0.8259                     0.8283        \u001b[35m0.4131\u001b[0m            0.7327                     0.7340        \u001b[36m0.5179\u001b[0m  0.0001  2.9461\n",
      "     30            0.8275                     \u001b[32m0.8300\u001b[0m        0.4140            0.7359                     0.7375        0.5187  0.0001  2.9461\n",
      "     31            0.8243                     0.8274        \u001b[35m0.4125\u001b[0m            0.7391                     \u001b[94m0.7411\u001b[0m        \u001b[36m0.5175\u001b[0m  0.0000  2.9471\n",
      "     32            0.8255                     0.8286        0.4180            0.7359                     0.7378        \u001b[36m0.5174\u001b[0m  0.0000  2.9521\n",
      "     33            0.8251                     0.8282        0.4137            0.7359                     0.7378        \u001b[36m0.5173\u001b[0m  0.0000  2.9471\n",
      "     34            0.8259                     0.8291        0.4204            0.7359                     0.7378        0.5174  0.0000  2.9501\n",
      "     35            0.8255                     0.8288        0.4183            0.7359                     0.7378        0.5174  0.0000  2.9501\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6965\u001b[0m                     \u001b[32m0.7085\u001b[0m        \u001b[35m0.6711\u001b[0m            \u001b[31m0.6812\u001b[0m                     \u001b[94m0.6943\u001b[0m        \u001b[36m0.6305\u001b[0m  0.0010  2.9352\n",
      "      2            \u001b[36m0.7118\u001b[0m                     \u001b[32m0.7254\u001b[0m        \u001b[35m0.5840\u001b[0m            \u001b[31m0.6876\u001b[0m                     \u001b[94m0.7019\u001b[0m        \u001b[36m0.6179\u001b[0m  0.0010  2.9371\n",
      "      3            \u001b[36m0.7259\u001b[0m                     \u001b[32m0.7372\u001b[0m        \u001b[35m0.5571\u001b[0m            \u001b[31m0.7150\u001b[0m                     \u001b[94m0.7273\u001b[0m        \u001b[36m0.5967\u001b[0m  0.0010  2.9312\n",
      "      4            \u001b[36m0.7344\u001b[0m                     \u001b[32m0.7419\u001b[0m        \u001b[35m0.5370\u001b[0m            0.7150                     0.7240        \u001b[36m0.5752\u001b[0m  0.0010  2.9411\n",
      "      5            \u001b[36m0.7437\u001b[0m                     \u001b[32m0.7499\u001b[0m        \u001b[35m0.5273\u001b[0m            0.7118                     0.7202        \u001b[36m0.5634\u001b[0m  0.0010  2.9332\n",
      "      6            0.7396                     \u001b[32m0.7508\u001b[0m        \u001b[35m0.5099\u001b[0m            0.7021                     0.7140        \u001b[36m0.5620\u001b[0m  0.0009  2.9381\n",
      "      7            \u001b[36m0.7630\u001b[0m                     \u001b[32m0.7680\u001b[0m        \u001b[35m0.5094\u001b[0m            \u001b[31m0.7166\u001b[0m                     0.7249        \u001b[36m0.5342\u001b[0m  0.0009  2.9342\n",
      "      8            \u001b[36m0.7662\u001b[0m                     \u001b[32m0.7713\u001b[0m        \u001b[35m0.4959\u001b[0m            0.7166                     0.7249        0.5371  0.0009  2.9361\n",
      "      9            \u001b[36m0.7743\u001b[0m                     \u001b[32m0.7808\u001b[0m        \u001b[35m0.4896\u001b[0m            \u001b[31m0.7214\u001b[0m                     \u001b[94m0.7305\u001b[0m        \u001b[36m0.5257\u001b[0m  0.0009  2.9371\n",
      "     10            \u001b[36m0.7759\u001b[0m                     0.7807        \u001b[35m0.4776\u001b[0m            \u001b[31m0.7407\u001b[0m                     \u001b[94m0.7482\u001b[0m        \u001b[36m0.5191\u001b[0m  0.0008  2.9381\n",
      "     11            \u001b[36m0.7852\u001b[0m                     \u001b[32m0.7895\u001b[0m        0.4785            0.7359                     0.7411        \u001b[36m0.5183\u001b[0m  0.0008  2.9342\n",
      "     12            0.7735                     0.7829        \u001b[35m0.4715\u001b[0m            0.7375                     \u001b[94m0.7483\u001b[0m        0.5443  0.0008  2.9371\n",
      "     13            \u001b[36m0.7876\u001b[0m                     \u001b[32m0.7933\u001b[0m        0.4742            \u001b[31m0.7424\u001b[0m                     \u001b[94m0.7509\u001b[0m        0.5218  0.0007  2.9332\n",
      "     14            0.7832                     0.7922        \u001b[35m0.4660\u001b[0m            0.7166                     0.7267        0.5307  0.0007  2.9381\n",
      "     15            \u001b[36m0.8013\u001b[0m                     \u001b[32m0.8063\u001b[0m        \u001b[35m0.4621\u001b[0m            0.7295                     0.7358        0.5193  0.0006  2.9401\n",
      "     16            \u001b[36m0.8041\u001b[0m                     \u001b[32m0.8077\u001b[0m        \u001b[35m0.4572\u001b[0m            0.7375                     0.7420        \u001b[36m0.5136\u001b[0m  0.0006  2.9431\n",
      "     17            0.7948                     0.8025        \u001b[35m0.4461\u001b[0m            0.7359                     0.7444        0.5229  0.0005  2.9401\n",
      "     18            0.8037                     \u001b[32m0.8085\u001b[0m        0.4495            \u001b[31m0.7440\u001b[0m                     0.7491        0.5170  0.0005  2.9391\n",
      "     19            0.7965                     0.8043        \u001b[35m0.4398\u001b[0m            0.7359                     0.7447        0.5174  0.0005  2.9421\n",
      "     20            \u001b[36m0.8053\u001b[0m                     \u001b[32m0.8097\u001b[0m        0.4421            0.7327                     0.7382        \u001b[36m0.5087\u001b[0m  0.0004  2.9371\n",
      "     21            \u001b[36m0.8094\u001b[0m                     \u001b[32m0.8126\u001b[0m        0.4445            0.7440                     0.7482        \u001b[36m0.4998\u001b[0m  0.0004  2.9421\n",
      "     22            0.8069                     0.8113        0.4418            0.7440                     0.7500        0.5085  0.0003  2.9361\n",
      "     23            0.8081                     \u001b[32m0.8134\u001b[0m        \u001b[35m0.4370\u001b[0m            0.7359                     0.7426        0.5170  0.0003  2.9361\n",
      "     24            0.8057                     0.8115        \u001b[35m0.4279\u001b[0m            \u001b[31m0.7456\u001b[0m                     \u001b[94m0.7518\u001b[0m        0.5052  0.0002  2.9352\n",
      "     25            0.8089                     \u001b[32m0.8139\u001b[0m        0.4294            0.7440                     0.7491        0.5015  0.0002  2.9371\n",
      "     26            \u001b[36m0.8122\u001b[0m                     \u001b[32m0.8162\u001b[0m        0.4296            0.7440                     0.7491        0.5018  0.0002  2.9352\n",
      "     27            0.8114                     \u001b[32m0.8165\u001b[0m        0.4289            \u001b[31m0.7488\u001b[0m                     \u001b[94m0.7550\u001b[0m        0.5034  0.0001  2.9361\n",
      "     28            \u001b[36m0.8130\u001b[0m                     \u001b[32m0.8173\u001b[0m        0.4293            0.7456                     0.7509        0.5029  0.0001  2.9361\n",
      "     29            0.8130                     \u001b[32m0.8175\u001b[0m        \u001b[35m0.4192\u001b[0m            0.7440                     0.7497        0.5040  0.0001  2.9361\n",
      "     30            0.8122                     0.8167        0.4268            0.7440                     0.7494        0.5040  0.0001  2.9352\n",
      "     31            0.8106                     0.8150        0.4250            0.7424                     0.7476        0.5034  0.0000  2.9361\n",
      "     32            0.8110                     0.8152        \u001b[35m0.4159\u001b[0m            0.7424                     0.7476        0.5026  0.0000  2.9401\n",
      "     33            0.8110                     0.8153        \u001b[35m0.4154\u001b[0m            0.7424                     0.7476        0.5026  0.0000  2.9381\n",
      "     34            0.8110                     0.8153        0.4159            0.7424                     0.7476        0.5026  0.0000  2.9371\n",
      "     35            0.8110                     0.8153        0.4283            0.7424                     0.7476        0.5028  0.0000  2.9391\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6969\u001b[0m                     \u001b[32m0.7072\u001b[0m        \u001b[35m0.6855\u001b[0m            \u001b[31m0.6860\u001b[0m                     \u001b[94m0.6981\u001b[0m        \u001b[36m0.6293\u001b[0m  0.0010  2.9341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            \u001b[36m0.7110\u001b[0m                     \u001b[32m0.7245\u001b[0m        \u001b[35m0.5873\u001b[0m            0.6812                     0.6957        \u001b[36m0.6206\u001b[0m  0.0010  2.9332\n",
      "      3            \u001b[36m0.7183\u001b[0m                     \u001b[32m0.7332\u001b[0m        \u001b[35m0.5419\u001b[0m            0.6763                     0.6925        \u001b[36m0.6106\u001b[0m  0.0010  2.9352\n",
      "      4            0.7102                     0.7275        \u001b[35m0.5361\u001b[0m            0.6667                     0.6849        \u001b[36m0.6028\u001b[0m  0.0010  2.9302\n",
      "      5            \u001b[36m0.7404\u001b[0m                     \u001b[32m0.7518\u001b[0m        \u001b[35m0.5205\u001b[0m            \u001b[31m0.7037\u001b[0m                     \u001b[94m0.7167\u001b[0m        \u001b[36m0.5747\u001b[0m  0.0010  2.9342\n",
      "      6            \u001b[36m0.7473\u001b[0m                     \u001b[32m0.7576\u001b[0m        \u001b[35m0.5121\u001b[0m            \u001b[31m0.7101\u001b[0m                     \u001b[94m0.7223\u001b[0m        \u001b[36m0.5640\u001b[0m  0.0009  2.9352\n",
      "      7            \u001b[36m0.7485\u001b[0m                     \u001b[32m0.7609\u001b[0m        \u001b[35m0.4978\u001b[0m            0.6989                     0.7129        0.5676  0.0009  2.9352\n",
      "      8            \u001b[36m0.7602\u001b[0m                     \u001b[32m0.7698\u001b[0m        \u001b[35m0.4967\u001b[0m            \u001b[31m0.7214\u001b[0m                     \u001b[94m0.7326\u001b[0m        \u001b[36m0.5555\u001b[0m  0.0009  2.9342\n",
      "      9            \u001b[36m0.7719\u001b[0m                     \u001b[32m0.7799\u001b[0m        \u001b[35m0.4867\u001b[0m            \u001b[31m0.7230\u001b[0m                     0.7323        \u001b[36m0.5544\u001b[0m  0.0009  2.9302\n",
      "     10            \u001b[36m0.7767\u001b[0m                     \u001b[32m0.7822\u001b[0m        \u001b[35m0.4811\u001b[0m            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7337\u001b[0m        \u001b[36m0.5449\u001b[0m  0.0008  2.9322\n",
      "     11            0.7767                     \u001b[32m0.7841\u001b[0m        \u001b[35m0.4733\u001b[0m            0.7262                     \u001b[94m0.7341\u001b[0m        0.5544  0.0008  2.9292\n",
      "     12            \u001b[36m0.7932\u001b[0m                     \u001b[32m0.7969\u001b[0m        \u001b[35m0.4618\u001b[0m            \u001b[31m0.7391\u001b[0m                     \u001b[94m0.7435\u001b[0m        \u001b[36m0.5348\u001b[0m  0.0008  2.9302\n",
      "     13            \u001b[36m0.7960\u001b[0m                     \u001b[32m0.8012\u001b[0m        0.4680            0.7327                     0.7385        0.5381  0.0007  2.9272\n",
      "     14            0.7904                     0.7962        0.4656            0.7295                     0.7355        0.5512  0.0007  2.9322\n",
      "     15            \u001b[36m0.7993\u001b[0m                     0.7987        \u001b[35m0.4601\u001b[0m            0.7391                     0.7408        0.5438  0.0006  2.9322\n",
      "     16            \u001b[36m0.8110\u001b[0m                     \u001b[32m0.8133\u001b[0m        \u001b[35m0.4534\u001b[0m            \u001b[31m0.7440\u001b[0m                     \u001b[94m0.7482\u001b[0m        \u001b[36m0.5315\u001b[0m  0.0006  2.9282\n",
      "     17            0.8049                     0.8036        \u001b[35m0.4505\u001b[0m            0.7343                     0.7352        0.5400  0.0005  4.0043\n",
      "     18            0.8110                     0.8125        \u001b[35m0.4472\u001b[0m            \u001b[31m0.7504\u001b[0m                     \u001b[94m0.7541\u001b[0m        0.5378  0.0005  2.9716\n",
      "     19            \u001b[36m0.8146\u001b[0m                     \u001b[32m0.8208\u001b[0m        \u001b[35m0.4405\u001b[0m            0.7391                     0.7465        0.5442  0.0005  2.9312\n",
      "     20            \u001b[36m0.8231\u001b[0m                     \u001b[32m0.8276\u001b[0m        \u001b[35m0.4349\u001b[0m            0.7343                     0.7399        0.5374  0.0004  2.9242\n",
      "     21            \u001b[36m0.8271\u001b[0m                     \u001b[32m0.8295\u001b[0m        0.4390            0.7311                     0.7355        0.5354  0.0004  2.9302\n",
      "     22            0.8174                     0.8217        \u001b[35m0.4343\u001b[0m            0.7359                     0.7411        0.5403  0.0003  2.9232\n",
      "     23            0.8166                     0.8212        \u001b[35m0.4284\u001b[0m            0.7424                     0.7479        0.5376  0.0003  2.9262\n",
      "     24            0.8194                     0.8218        0.4309            0.7407                     0.7435        0.5369  0.0002  2.9222\n",
      "     25            0.8210                     0.8239        \u001b[35m0.4222\u001b[0m            0.7424                     0.7464        0.5322  0.0002  2.9322\n",
      "     26            0.8247                     0.8284        0.4228            0.7391                     0.7447        0.5342  0.0002  2.9212\n",
      "     27            0.8263                     0.8290        \u001b[35m0.4187\u001b[0m            0.7359                     0.7399        0.5318  0.0001  2.9262\n",
      "     28            0.8218                     0.8252        0.4191            0.7391                     0.7441        \u001b[36m0.5304\u001b[0m  0.0001  2.9222\n",
      "     29            0.8239                     0.8269        0.4209            0.7375                     0.7420        0.5306  0.0001  2.9232\n",
      "     30            0.8255                     0.8291        \u001b[35m0.4180\u001b[0m            0.7391                     0.7444        0.5323  0.0001  2.9242\n",
      "     31            0.8259                     0.8290        \u001b[35m0.4178\u001b[0m            0.7407                     0.7452        0.5315  0.0000  2.9272\n",
      "     32            0.8255                     0.8286        \u001b[35m0.4136\u001b[0m            0.7375                     0.7423        0.5321  0.0000  2.9282\n",
      "     33            0.8267                     \u001b[32m0.8302\u001b[0m        0.4165            0.7375                     0.7426        0.5326  0.0000  2.9242\n",
      "     34            0.8263                     0.8299        0.4197            0.7359                     0.7411        0.5328  0.0000  2.9282\n",
      "     35            0.8263                     0.8300        \u001b[35m0.4111\u001b[0m            0.7359                     0.7411        0.5330  0.0000  2.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6176\u001b[0m                     \u001b[32m0.6846\u001b[0m        \u001b[35m0.6843\u001b[0m            \u001b[31m0.6135\u001b[0m                     \u001b[94m0.6521\u001b[0m        \u001b[36m0.6432\u001b[0m  0.0010  6.5654\n",
      "      2            0.6157                     \u001b[32m0.6956\u001b[0m        \u001b[35m0.6043\u001b[0m            \u001b[31m0.6352\u001b[0m                     \u001b[94m0.6954\u001b[0m        \u001b[36m0.6014\u001b[0m  0.0010  6.2902\n",
      "      3            \u001b[36m0.7248\u001b[0m                     \u001b[32m0.7333\u001b[0m        \u001b[35m0.5792\u001b[0m            \u001b[31m0.7366\u001b[0m                     \u001b[94m0.7222\u001b[0m        \u001b[36m0.5641\u001b[0m  0.0010  6.2932\n",
      "      4            0.7155                     \u001b[32m0.7477\u001b[0m        \u001b[35m0.5505\u001b[0m            0.7157                     \u001b[94m0.7329\u001b[0m        \u001b[36m0.5367\u001b[0m  0.0010  6.2902\n",
      "      5            \u001b[36m0.7655\u001b[0m                     \u001b[32m0.7573\u001b[0m        \u001b[35m0.5422\u001b[0m            \u001b[31m0.7692\u001b[0m                     0.7320        \u001b[36m0.5310\u001b[0m  0.0010  6.3161\n",
      "      6            0.7335                     \u001b[32m0.7658\u001b[0m        \u001b[35m0.5271\u001b[0m            0.7382                     \u001b[94m0.7516\u001b[0m        \u001b[36m0.5260\u001b[0m  0.0009  6.2812\n",
      "      7            \u001b[36m0.8083\u001b[0m                     0.7641        \u001b[35m0.5253\u001b[0m            \u001b[31m0.7924\u001b[0m                     0.7161        0.5413  0.0009  6.3031\n",
      "      8            0.7328                     \u001b[32m0.7679\u001b[0m        \u001b[35m0.5174\u001b[0m            0.7328                     0.7483        \u001b[36m0.5248\u001b[0m  0.0009  6.3291\n",
      "      9            0.7671                     \u001b[32m0.7817\u001b[0m        \u001b[35m0.5144\u001b[0m            0.7637                     0.7488        0.5261  0.0009  6.3161\n",
      "     10            0.7360                     \u001b[32m0.7833\u001b[0m        \u001b[35m0.4995\u001b[0m            0.7281                     0.7454        \u001b[36m0.5221\u001b[0m  0.0008  6.3580\n",
      "     11            0.7651                     \u001b[32m0.7893\u001b[0m        \u001b[35m0.4987\u001b[0m            0.7529                     \u001b[94m0.7522\u001b[0m        \u001b[36m0.5184\u001b[0m  0.0008  6.3351\n",
      "     12            0.7554                     \u001b[32m0.7909\u001b[0m        \u001b[35m0.4942\u001b[0m            0.7483                     0.7494        0.5207  0.0008  6.2722\n",
      "     13            0.7496                     0.7853        0.4960            0.7366                     0.7473        \u001b[36m0.5166\u001b[0m  0.0007  6.2273\n",
      "     14            0.7971                     0.7904        \u001b[35m0.4850\u001b[0m            0.7816                     0.7412        \u001b[36m0.5145\u001b[0m  0.0007  6.2403\n",
      "     15            \u001b[36m0.8283\u001b[0m                     0.7901        \u001b[35m0.4737\u001b[0m            \u001b[31m0.8125\u001b[0m                     0.7334        0.5402  0.0006  6.2303\n",
      "     16            0.7864                     \u001b[32m0.8048\u001b[0m        \u001b[35m0.4726\u001b[0m            0.7870                     \u001b[94m0.7730\u001b[0m        \u001b[36m0.5014\u001b[0m  0.0006  6.2204\n",
      "     17            0.7690                     0.8004        \u001b[35m0.4716\u001b[0m            0.7576                     0.7517        0.5067  0.0005  6.2473\n",
      "     18            0.7849                     0.8030        \u001b[35m0.4704\u001b[0m            0.7785                     0.7678        0.5062  0.0005  6.2373\n",
      "     19            0.7998                     \u001b[32m0.8142\u001b[0m        \u001b[35m0.4679\u001b[0m            0.7800                     0.7587        \u001b[36m0.5008\u001b[0m  0.0005  6.2383\n",
      "     20            0.7841                     0.8046        \u001b[35m0.4580\u001b[0m            0.7777                     0.7673        0.5068  0.0004  6.2573\n",
      "     21            0.7574                     0.8030        \u001b[35m0.4557\u001b[0m            0.7514                     0.7663        0.5089  0.0004  6.2313\n",
      "     22            0.7952                     0.8126        \u001b[35m0.4525\u001b[0m            0.7738                     0.7549        0.5063  0.0003  6.2782\n",
      "     23            0.7829                     0.8081        0.4570            0.7746                     0.7671        0.5023  0.0003  6.3081\n",
      "     24            0.7833                     0.8125        \u001b[35m0.4488\u001b[0m            0.7707                     0.7614        0.5035  0.0002  6.3002\n",
      "     25            0.7928                     \u001b[32m0.8183\u001b[0m        \u001b[35m0.4479\u001b[0m            0.7754                     0.7625        0.5036  0.0002  6.4398\n",
      "     26            0.8107                     0.8129        \u001b[35m0.4430\u001b[0m            0.7909                     0.7536        0.5121  0.0002  6.5834\n",
      "     27            0.8074                     0.8150        0.4496            0.7885                     0.7538        0.5112  0.0001  6.7200\n",
      "     28            0.8033                     0.8168        0.4453            0.7816                     0.7596        0.5073  0.0001  6.3680\n",
      "     29            0.8039                     0.8171        \u001b[35m0.4334\u001b[0m            0.7808                     0.7592        0.5080  0.0001  6.3809\n",
      "     30            0.7984                     0.8155        0.4482            0.7777                     0.7589        0.5067  0.0001  6.4278\n",
      "     31            0.8006                     0.8164        0.4358            0.7800                     0.7620        0.5069  0.0000  6.4866\n",
      "     32            0.8023                     0.8166        \u001b[35m0.4310\u001b[0m            0.7785                     0.7577        0.5069  0.0000  6.9609\n",
      "     33            0.8017                     0.8162        0.4370            0.7792                     0.7582        0.5069  0.0000  6.6782\n",
      "     34            0.8021                     0.8169        0.4356            0.7800                     0.7604        0.5068  0.0000  6.3448\n",
      "     35            0.8025                     0.8171        0.4465            0.7808                     0.7608        0.5068  0.0000  6.3647\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5552\u001b[0m                     \u001b[32m0.6667\u001b[0m        \u001b[35m0.6889\u001b[0m            \u001b[31m0.5515\u001b[0m                     \u001b[94m0.6578\u001b[0m        \u001b[36m0.6407\u001b[0m  0.0010  8.1858\n",
      "      2            \u001b[36m0.6589\u001b[0m                     \u001b[32m0.7090\u001b[0m        \u001b[35m0.6062\u001b[0m            \u001b[31m0.6390\u001b[0m                     \u001b[94m0.6827\u001b[0m        \u001b[36m0.6109\u001b[0m  0.0010  6.7767\n",
      "      3            \u001b[36m0.6603\u001b[0m                     \u001b[32m0.7274\u001b[0m        \u001b[35m0.5692\u001b[0m            \u001b[31m0.6437\u001b[0m                     \u001b[94m0.7006\u001b[0m        \u001b[36m0.5875\u001b[0m  0.0010  6.1227\n",
      "      4            \u001b[36m0.7116\u001b[0m                     \u001b[32m0.7558\u001b[0m        \u001b[35m0.5592\u001b[0m            \u001b[31m0.6971\u001b[0m                     \u001b[94m0.7299\u001b[0m        \u001b[36m0.5569\u001b[0m  0.0010  6.8772\n",
      "      5            \u001b[36m0.7479\u001b[0m                     0.7457        \u001b[35m0.5372\u001b[0m            \u001b[31m0.7304\u001b[0m                     0.7151        0.5747  0.0010  7.3248\n",
      "      6            0.7085                     \u001b[32m0.7669\u001b[0m        \u001b[35m0.5357\u001b[0m            0.6832                     0.7230        \u001b[36m0.5544\u001b[0m  0.0009  7.1945\n",
      "      7            \u001b[36m0.7756\u001b[0m                     0.7630        \u001b[35m0.5236\u001b[0m            \u001b[31m0.7599\u001b[0m                     \u001b[94m0.7380\u001b[0m        \u001b[36m0.5517\u001b[0m  0.0009  6.4291\n",
      "      8            0.7353                     \u001b[32m0.7761\u001b[0m        \u001b[35m0.5128\u001b[0m            0.7142                     0.7302        0.5664  0.0009  7.2236\n",
      "      9            \u001b[36m0.7922\u001b[0m                     \u001b[32m0.7912\u001b[0m        \u001b[35m0.5127\u001b[0m            0.7599                     0.7280        \u001b[36m0.5500\u001b[0m  0.0009  7.5223\n",
      "     10            0.7192                     0.7776        \u001b[35m0.4970\u001b[0m            0.6902                     0.7206        0.5618  0.0008  7.3708\n",
      "     11            0.7764                     \u001b[32m0.7974\u001b[0m        \u001b[35m0.4797\u001b[0m            0.7444                     0.7303        \u001b[36m0.5471\u001b[0m  0.0008  8.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12            0.6988                     0.7752        0.4844            0.6692                     0.7279        0.5757  0.0008  7.7449\n",
      "     13            0.7831                     \u001b[32m0.8003\u001b[0m        \u001b[35m0.4776\u001b[0m            0.7537                     0.7359        0.5519  0.0007  7.7955\n",
      "     14            0.7364                     0.7948        \u001b[35m0.4682\u001b[0m            0.6995                     0.7363        0.5635  0.0007  7.7771\n",
      "     15            0.7508                     \u001b[32m0.8048\u001b[0m        0.4697            0.7134                     0.7331        0.5628  0.0006  7.4672\n",
      "     16            0.6915                     0.7816        0.4687            0.6499                     0.7161        0.5744  0.0006  6.5247\n",
      "     17            \u001b[36m0.8035\u001b[0m                     \u001b[32m0.8206\u001b[0m        \u001b[35m0.4586\u001b[0m            \u001b[31m0.7730\u001b[0m                     \u001b[94m0.7544\u001b[0m        \u001b[36m0.5414\u001b[0m  0.0005  6.2461\n",
      "     18            0.7864                     0.8165        \u001b[35m0.4552\u001b[0m            0.7521                     0.7500        0.5431  0.0005  6.4741\n",
      "     19            0.7744                     0.8138        \u001b[35m0.4536\u001b[0m            0.7366                     0.7389        0.5538  0.0005  6.1952\n",
      "     20            0.8027                     \u001b[32m0.8210\u001b[0m        \u001b[35m0.4364\u001b[0m            0.7591                     0.7342        0.5538  0.0004  6.2234\n",
      "     21            0.7764                     0.8183        0.4578            0.7289                     0.7392        \u001b[36m0.5389\u001b[0m  0.0004  6.3258\n",
      "     22            0.7638                     0.8157        0.4380            0.7188                     0.7414        0.5391  0.0003  6.1464\n",
      "     23            0.7610                     0.8153        0.4430            0.7180                     0.7393        0.5523  0.0003  7.5488\n",
      "     24            0.7955                     0.8208        0.4449            0.7529                     0.7405        0.5447  0.0002  7.3766\n",
      "     25            0.7769                     \u001b[32m0.8216\u001b[0m        0.4443            0.7304                     0.7402        0.5461  0.0002  7.3705\n",
      "     26            0.7913                     \u001b[32m0.8245\u001b[0m        \u001b[35m0.4337\u001b[0m            0.7428                     0.7377        0.5451  0.0002  6.9765\n",
      "     27            0.7917                     0.8214        \u001b[35m0.4298\u001b[0m            0.7514                     0.7462        0.5487  0.0001  6.3161\n",
      "     28            0.7843                     \u001b[32m0.8249\u001b[0m        0.4301            0.7436                     0.7465        0.5453  0.0001  6.2835\n",
      "     29            0.7862                     0.8218        \u001b[35m0.4292\u001b[0m            0.7467                     0.7467        0.5449  0.0001  6.1348\n",
      "     30            0.7921                     0.8229        0.4296            0.7537                     0.7460        0.5467  0.0001  6.2533\n",
      "     31            0.7897                     0.8215        \u001b[35m0.4248\u001b[0m            0.7514                     0.7479        0.5463  0.0000  6.5545\n",
      "     32            0.7901                     0.8225        \u001b[35m0.4238\u001b[0m            0.7506                     0.7474        0.5464  0.0000  6.9186\n",
      "     33            0.7899                     0.8224        \u001b[35m0.4212\u001b[0m            0.7498                     0.7470        0.5462  0.0000  6.8835\n",
      "     34            0.7895                     0.8222        0.4427            0.7498                     0.7470        0.5462  0.0000  6.8917\n",
      "     35            0.7905                     0.8228        0.4331            0.7498                     0.7470        0.5462  0.0000  6.9150\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5762\u001b[0m                     \u001b[32m0.6711\u001b[0m        \u001b[35m0.6922\u001b[0m            \u001b[31m0.5895\u001b[0m                     \u001b[94m0.6642\u001b[0m        \u001b[36m0.6438\u001b[0m  0.0010  6.1532\n",
      "      2            \u001b[36m0.7033\u001b[0m                     \u001b[32m0.7160\u001b[0m        \u001b[35m0.6191\u001b[0m            \u001b[31m0.6770\u001b[0m                     \u001b[94m0.6724\u001b[0m        \u001b[36m0.6129\u001b[0m  0.0010  6.2159\n",
      "      3            0.6829                     \u001b[32m0.7308\u001b[0m        \u001b[35m0.5780\u001b[0m            0.6499                     \u001b[94m0.6944\u001b[0m        \u001b[36m0.5756\u001b[0m  0.0010  6.2582\n",
      "      4            0.6965                     \u001b[32m0.7369\u001b[0m        \u001b[35m0.5692\u001b[0m            \u001b[31m0.6801\u001b[0m                     \u001b[94m0.7245\u001b[0m        \u001b[36m0.5522\u001b[0m  0.0010  6.1152\n",
      "      5            \u001b[36m0.7440\u001b[0m                     \u001b[32m0.7592\u001b[0m        \u001b[35m0.5598\u001b[0m            \u001b[31m0.7165\u001b[0m                     \u001b[94m0.7400\u001b[0m        \u001b[36m0.5342\u001b[0m  0.0010  6.1520\n",
      "      6            \u001b[36m0.7655\u001b[0m                     0.7556        \u001b[35m0.5350\u001b[0m            \u001b[31m0.7483\u001b[0m                     \u001b[94m0.7427\u001b[0m        0.5413  0.0009  6.2998\n",
      "      7            0.7275                     \u001b[32m0.7726\u001b[0m        \u001b[35m0.5283\u001b[0m            0.7002                     \u001b[94m0.7452\u001b[0m        \u001b[36m0.5305\u001b[0m  0.0009  6.3314\n",
      "      8            \u001b[36m0.7921\u001b[0m                     \u001b[32m0.7735\u001b[0m        \u001b[35m0.5246\u001b[0m            \u001b[31m0.7545\u001b[0m                     0.7331        \u001b[36m0.5280\u001b[0m  0.0009  6.1438\n",
      "      9            0.7605                     \u001b[32m0.7797\u001b[0m        \u001b[35m0.5135\u001b[0m            0.7343                     \u001b[94m0.7609\u001b[0m        \u001b[36m0.5151\u001b[0m  0.0009  6.4294\n",
      "     10            0.7016                     0.7677        0.5139            0.6816                     0.7472        0.5366  0.0008  6.4863\n",
      "     11            0.7647                     \u001b[32m0.7890\u001b[0m        \u001b[35m0.5068\u001b[0m            0.7242                     0.7498        0.5203  0.0008  6.5034\n",
      "     12            0.7890                     \u001b[32m0.7929\u001b[0m        \u001b[35m0.4978\u001b[0m            \u001b[31m0.7614\u001b[0m                     \u001b[94m0.7658\u001b[0m        0.5179  0.0008  6.4822\n",
      "     13            0.7347                     0.7862        \u001b[35m0.4957\u001b[0m            0.7049                     0.7530        0.5361  0.0007  6.3048\n",
      "     14            0.7267                     0.7889        \u001b[35m0.4858\u001b[0m            0.6964                     0.7428        0.5281  0.0007  6.3200\n",
      "     15            0.7866                     \u001b[32m0.7978\u001b[0m        0.4868            0.7506                     0.7575        \u001b[36m0.5119\u001b[0m  0.0006  6.1326\n",
      "     16            \u001b[36m0.8035\u001b[0m                     \u001b[32m0.8060\u001b[0m        0.4986            0.7591                     0.7510        0.5132  0.0006  6.1022\n",
      "     17            0.7405                     0.8002        \u001b[35m0.4750\u001b[0m            0.7018                     0.7461        0.5251  0.0005  6.1062\n",
      "     18            0.7484                     0.8017        \u001b[35m0.4695\u001b[0m            0.7088                     0.7453        0.5189  0.0005  6.0965\n",
      "     19            0.8012                     \u001b[32m0.8104\u001b[0m        0.4726            0.7560                     0.7491        \u001b[36m0.5095\u001b[0m  0.0005  6.0975\n",
      "     20            \u001b[36m0.8120\u001b[0m                     \u001b[32m0.8124\u001b[0m        \u001b[35m0.4625\u001b[0m            0.7583                     0.7488        \u001b[36m0.5094\u001b[0m  0.0004  6.1110\n",
      "     21            0.8097                     0.8085        \u001b[35m0.4586\u001b[0m            0.7614                     0.7524        \u001b[36m0.5086\u001b[0m  0.0004  6.1334\n",
      "     22            0.7473                     0.8002        0.4597            0.7103                     0.7496        0.5226  0.0003  6.1179\n",
      "     23            0.7548                     0.8065        0.4637            0.7157                     0.7546        0.5169  0.0003  6.0963\n",
      "     24            0.7977                     0.8108        0.4632            0.7514                     0.7512        0.5095  0.0002  6.1092\n",
      "     25            \u001b[36m0.8254\u001b[0m                     0.8114        \u001b[35m0.4538\u001b[0m            \u001b[31m0.7715\u001b[0m                     0.7401        \u001b[36m0.5061\u001b[0m  0.0002  6.3311\n",
      "     26            0.7967                     \u001b[32m0.8152\u001b[0m        0.4578            0.7490                     0.7498        0.5072  0.0002  6.3602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27            0.7870                     \u001b[32m0.8156\u001b[0m        \u001b[35m0.4480\u001b[0m            0.7397                     0.7575        0.5084  0.0001  6.3452\n",
      "     28            0.7928                     \u001b[32m0.8179\u001b[0m        0.4489            0.7452                     0.7575        0.5078  0.0001  6.6024\n",
      "     29            0.7880                     0.8150        0.4485            0.7444                     0.7554        0.5076  0.0001  7.0857\n",
      "     30            0.8010                     0.8166        0.4505            0.7521                     0.7534        0.5063  0.0001  6.7938\n",
      "     31            0.8012                     \u001b[32m0.8180\u001b[0m        \u001b[35m0.4412\u001b[0m            0.7498                     0.7520        0.5065  0.0000  6.9467\n",
      "     32            0.7996                     \u001b[32m0.8183\u001b[0m        0.4435            0.7490                     0.7515        0.5067  0.0000  6.8617\n",
      "     33            0.7998                     \u001b[32m0.8192\u001b[0m        0.4432            0.7490                     0.7515        0.5067  0.0000  6.7281\n",
      "     34            0.7998                     0.8188        0.4427            0.7490                     0.7515        0.5066  0.0000  6.8629\n",
      "     35            0.8000                     0.8189        0.4421            0.7490                     0.7515        0.5066  0.0000  6.6062\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6516\u001b[0m                     \u001b[32m0.6919\u001b[0m        \u001b[35m0.6847\u001b[0m            \u001b[31m0.6181\u001b[0m                     \u001b[94m0.6516\u001b[0m        \u001b[36m0.6468\u001b[0m  0.0010  6.6094\n",
      "      2            \u001b[36m0.7033\u001b[0m                     \u001b[32m0.7210\u001b[0m        \u001b[35m0.5974\u001b[0m            \u001b[31m0.6863\u001b[0m                     \u001b[94m0.6948\u001b[0m        \u001b[36m0.6107\u001b[0m  0.0010  6.7921\n",
      "      3            \u001b[36m0.7355\u001b[0m                     \u001b[32m0.7477\u001b[0m        \u001b[35m0.5749\u001b[0m            \u001b[31m0.7033\u001b[0m                     \u001b[94m0.7002\u001b[0m        \u001b[36m0.5795\u001b[0m  0.0010  6.8558\n",
      "      4            0.6434                     0.7301        \u001b[35m0.5526\u001b[0m            0.6204                     0.6948        0.5839  0.0010  6.4767\n",
      "      5            0.6967                     \u001b[32m0.7576\u001b[0m        \u001b[35m0.5434\u001b[0m            0.6754                     \u001b[94m0.7150\u001b[0m        \u001b[36m0.5681\u001b[0m  0.0010  6.6075\n",
      "      6            0.6998                     0.7557        \u001b[35m0.5277\u001b[0m            0.6731                     0.7136        0.5780  0.0009  6.4435\n",
      "      7            0.7339                     \u001b[32m0.7765\u001b[0m        \u001b[35m0.5082\u001b[0m            \u001b[31m0.7111\u001b[0m                     \u001b[94m0.7233\u001b[0m        0.5714  0.0009  6.4766\n",
      "      8            \u001b[36m0.7773\u001b[0m                     \u001b[32m0.7913\u001b[0m        0.5104            \u001b[31m0.7413\u001b[0m                     \u001b[94m0.7317\u001b[0m        \u001b[36m0.5483\u001b[0m  0.0009  6.1954\n",
      "      9            0.7421                     0.7794        \u001b[35m0.5030\u001b[0m            0.7126                     0.7276        0.5641  0.0009  6.2930\n",
      "     10            \u001b[36m0.7922\u001b[0m                     \u001b[32m0.7924\u001b[0m        \u001b[35m0.5019\u001b[0m            \u001b[31m0.7545\u001b[0m                     0.7297        0.5627  0.0008  6.3316\n",
      "     11            0.6921                     0.7702        \u001b[35m0.4874\u001b[0m            0.6692                     0.7179        0.5811  0.0008  6.1229\n",
      "     12            0.6748                     0.7631        \u001b[35m0.4860\u001b[0m            0.6336                     0.7028        0.6042  0.0008  6.1496\n",
      "     13            \u001b[36m0.8176\u001b[0m                     \u001b[32m0.8083\u001b[0m        0.4861            \u001b[31m0.7738\u001b[0m                     \u001b[94m0.7399\u001b[0m        0.5653  0.0007  6.3751\n",
      "     14            0.7771                     0.8067        \u001b[35m0.4752\u001b[0m            0.7297                     0.7330        0.5679  0.0007  6.2668\n",
      "     15            0.6607                     0.7586        0.4807            0.6297                     0.7088        0.6071  0.0006  6.2739\n",
      "     16            0.7004                     0.7783        0.4766            0.6545                     0.7106        0.5845  0.0006  6.3943\n",
      "     17            0.7847                     0.8075        \u001b[35m0.4640\u001b[0m            0.7421                     0.7339        0.5624  0.0005  6.4012\n",
      "     18            0.7926                     \u001b[32m0.8111\u001b[0m        0.4704            0.7637                     \u001b[94m0.7555\u001b[0m        0.5601  0.0005  6.2263\n",
      "     19            0.7260                     0.7922        0.4654            0.6925                     0.7337        0.5834  0.0005  6.1326\n",
      "     20            0.7595                     0.8076        \u001b[35m0.4607\u001b[0m            0.7204                     0.7524        0.5662  0.0004  6.1907\n",
      "     21            0.7506                     0.8026        \u001b[35m0.4548\u001b[0m            0.7149                     0.7441        0.5719  0.0004  6.2852\n",
      "     22            0.8068                     \u001b[32m0.8189\u001b[0m        \u001b[35m0.4546\u001b[0m            0.7676                     0.7511        0.5636  0.0003  6.1964\n",
      "     23            \u001b[36m0.8225\u001b[0m                     \u001b[32m0.8218\u001b[0m        0.4585            \u001b[31m0.7792\u001b[0m                     0.7398        0.5650  0.0003  6.3932\n",
      "     24            0.7438                     0.8018        \u001b[35m0.4510\u001b[0m            0.7072                     0.7293        0.5731  0.0002  6.3445\n",
      "     25            0.7826                     0.8162        \u001b[35m0.4418\u001b[0m            0.7498                     0.7503        0.5695  0.0002  6.1918\n",
      "     26            0.7738                     0.8126        0.4535            0.7374                     0.7478        0.5664  0.0002  6.1628\n",
      "     27            0.7994                     0.8211        0.4505            0.7576                     0.7433        0.5647  0.0001  6.1476\n",
      "     28            0.7893                     0.8212        0.4427            0.7436                     0.7415        0.5619  0.0001  6.1397\n",
      "     29            0.7795                     0.8198        \u001b[35m0.4402\u001b[0m            0.7351                     0.7447        0.5663  0.0001  6.1385\n",
      "     30            0.7921                     \u001b[32m0.8225\u001b[0m        \u001b[35m0.4375\u001b[0m            0.7428                     0.7427        0.5636  0.0001  6.1717\n",
      "     31            0.7940                     \u001b[32m0.8228\u001b[0m        0.4434            0.7459                     0.7446        0.5648  0.0000  6.1535\n",
      "     32            0.7917                     \u001b[32m0.8235\u001b[0m        0.4417            0.7428                     0.7444        0.5652  0.0000  6.1958\n",
      "     33            0.7919                     \u001b[32m0.8240\u001b[0m        0.4392            0.7421                     0.7439        0.5652  0.0000  6.3036\n",
      "     34            0.7924                     0.8240        0.4412            0.7421                     0.7439        0.5652  0.0000  6.2235\n",
      "     35            0.7926                     0.8237        0.4375            0.7421                     0.7439        0.5653  0.0000  6.1443\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7198\u001b[0m                     \u001b[32m0.6812\u001b[0m        \u001b[35m0.6779\u001b[0m            \u001b[31m0.7173\u001b[0m                     \u001b[94m0.6836\u001b[0m        \u001b[36m0.6464\u001b[0m  0.0010  6.1416\n",
      "      2            \u001b[36m0.7862\u001b[0m                     \u001b[32m0.7042\u001b[0m        \u001b[35m0.6012\u001b[0m            \u001b[31m0.7591\u001b[0m                     0.6773        \u001b[36m0.6311\u001b[0m  0.0010  6.1249\n",
      "      3            0.6612                     \u001b[32m0.7284\u001b[0m        \u001b[35m0.5816\u001b[0m            0.6569                     \u001b[94m0.7153\u001b[0m        \u001b[36m0.5619\u001b[0m  0.0010  6.1000\n",
      "      4            0.6926                     \u001b[32m0.7455\u001b[0m        \u001b[35m0.5631\u001b[0m            0.6801                     \u001b[94m0.7278\u001b[0m        \u001b[36m0.5504\u001b[0m  0.0010  6.1035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5            \u001b[36m0.7967\u001b[0m                     \u001b[32m0.7679\u001b[0m        \u001b[35m0.5533\u001b[0m            \u001b[31m0.7637\u001b[0m                     0.7153        \u001b[36m0.5453\u001b[0m  0.0010  6.1271\n",
      "      6            0.7267                     0.7659        \u001b[35m0.5332\u001b[0m            0.7111                     \u001b[94m0.7367\u001b[0m        \u001b[36m0.5347\u001b[0m  0.0009  6.1077\n",
      "      7            0.7514                     \u001b[32m0.7805\u001b[0m        \u001b[35m0.5128\u001b[0m            0.7235                     \u001b[94m0.7443\u001b[0m        \u001b[36m0.5290\u001b[0m  0.0009  6.1037\n",
      "      8            0.7045                     0.7661        0.5137            0.6894                     0.7302        0.5336  0.0009  6.1065\n",
      "      9            0.7754                     \u001b[32m0.7817\u001b[0m        \u001b[35m0.5105\u001b[0m            0.7506                     0.7374        0.5341  0.0009  6.1391\n",
      "     10            0.7403                     \u001b[32m0.7859\u001b[0m        \u001b[35m0.4981\u001b[0m            0.7165                     0.7417        0.5378  0.0008  6.1100\n",
      "     11            0.7118                     0.7760        \u001b[35m0.4980\u001b[0m            0.7026                     \u001b[94m0.7482\u001b[0m        0.5381  0.0008  6.1405\n",
      "     12            0.6944                     0.7721        \u001b[35m0.4807\u001b[0m            0.6840                     0.7419        0.5554  0.0008  6.1276\n",
      "     13            0.7547                     \u001b[32m0.7921\u001b[0m        0.4822            0.7436                     0.7465        0.5385  0.0007  6.1503\n",
      "     14            0.7860                     \u001b[32m0.7991\u001b[0m        0.4841            \u001b[31m0.7723\u001b[0m                     \u001b[94m0.7523\u001b[0m        \u001b[36m0.5269\u001b[0m  0.0007  6.1122\n",
      "     15            0.7703                     \u001b[32m0.8071\u001b[0m        \u001b[35m0.4803\u001b[0m            0.7498                     0.7486        \u001b[36m0.5183\u001b[0m  0.0006  6.1268\n",
      "     16            0.7748                     0.8002        \u001b[35m0.4722\u001b[0m            0.7637                     0.7521        0.5193  0.0006  6.3999\n",
      "     17            \u001b[36m0.8275\u001b[0m                     0.8018        0.4734            \u001b[31m0.8087\u001b[0m                     \u001b[94m0.7528\u001b[0m        0.5392  0.0005  6.2951\n",
      "     18            0.7905                     \u001b[32m0.8148\u001b[0m        0.4762            0.7668                     \u001b[94m0.7557\u001b[0m        0.5210  0.0005  6.1126\n",
      "     19            0.7773                     0.8139        \u001b[35m0.4684\u001b[0m            0.7521                     0.7534        0.5241  0.0005  6.1413\n",
      "     20            0.7025                     0.7854        \u001b[35m0.4549\u001b[0m            0.6871                     0.7288        0.5579  0.0004  6.2572\n",
      "     21            0.8087                     \u001b[32m0.8150\u001b[0m        \u001b[35m0.4545\u001b[0m            0.7862                     0.7508        0.5296  0.0004  6.2112\n",
      "     22            0.8203                     \u001b[32m0.8234\u001b[0m        \u001b[35m0.4539\u001b[0m            0.7994                     \u001b[94m0.7655\u001b[0m        0.5301  0.0003  6.1127\n",
      "     23            0.7709                     0.8138        0.4615            0.7552                     0.7570        0.5316  0.0003  6.1120\n",
      "     24            0.7965                     0.8193        \u001b[35m0.4464\u001b[0m            0.7699                     0.7609        0.5231  0.0002  6.1445\n",
      "     25            0.7986                     0.8185        0.4497            0.7723                     0.7540        0.5263  0.0002  6.1079\n",
      "     26            0.7940                     0.8203        0.4521            0.7816                     \u001b[94m0.7730\u001b[0m        0.5197  0.0002  6.1126\n",
      "     27            0.8047                     0.8213        \u001b[35m0.4402\u001b[0m            0.7885                     0.7622        0.5272  0.0001  6.1174\n",
      "     28            0.7983                     0.8208        0.4426            0.7885                     0.7672        0.5259  0.0001  6.1516\n",
      "     29            0.7806                     0.8184        \u001b[35m0.4331\u001b[0m            0.7692                     0.7655        0.5267  0.0001  6.1904\n",
      "     30            0.7955                     0.8204        0.4331            0.7870                     0.7646        0.5259  0.0001  6.2470\n",
      "     31            0.7839                     0.8162        \u001b[35m0.4331\u001b[0m            0.7754                     0.7642        0.5263  0.0000  6.3464\n",
      "     32            0.7866                     0.8166        0.4457            0.7785                     0.7644        0.5261  0.0000  6.3014\n",
      "     33            0.7895                     0.8176        0.4342            0.7800                     0.7620        0.5264  0.0000  6.2336\n",
      "     34            0.7917                     0.8180        0.4357            0.7823                     0.7635        0.5265  0.0000  6.4719\n",
      "     35            0.7926                     0.8182        0.4356            0.7839                     0.7644        0.5266  0.0000  6.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 1 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5612\u001b[0m                     \u001b[32m0.5637\u001b[0m        \u001b[35m1.2570\u001b[0m            \u001b[31m0.5203\u001b[0m                     \u001b[94m0.5232\u001b[0m        \u001b[36m0.7804\u001b[0m  0.0006  3.3290\n",
      "      2            \u001b[36m0.6366\u001b[0m                     \u001b[32m0.6374\u001b[0m        \u001b[35m0.9869\u001b[0m            \u001b[31m0.5808\u001b[0m                     \u001b[94m0.5817\u001b[0m        \u001b[36m0.6957\u001b[0m  0.0006  2.4678\n",
      "      3            \u001b[36m0.6762\u001b[0m                     \u001b[32m0.6763\u001b[0m        \u001b[35m0.8168\u001b[0m            \u001b[31m0.6128\u001b[0m                     \u001b[94m0.6128\u001b[0m        \u001b[36m0.6585\u001b[0m  0.0006  2.5163\n",
      "      4            \u001b[36m0.6954\u001b[0m                     \u001b[32m0.6959\u001b[0m        \u001b[35m0.7776\u001b[0m            \u001b[31m0.6422\u001b[0m                     \u001b[94m0.6427\u001b[0m        \u001b[36m0.6448\u001b[0m  0.0006  2.4317\n",
      "      5            \u001b[36m0.7010\u001b[0m                     \u001b[32m0.7025\u001b[0m        \u001b[35m0.7046\u001b[0m            \u001b[31m0.6482\u001b[0m                     \u001b[94m0.6499\u001b[0m        0.6458  0.0006  2.2949\n",
      "      6            0.6976                     0.6989        \u001b[35m0.6969\u001b[0m            0.6404                     0.6420        0.6871  0.0006  2.3038\n",
      "      7            0.6837                     0.6819        \u001b[35m0.6408\u001b[0m            0.6180                     0.6157        0.6906  0.0006  2.2810\n",
      "      8            \u001b[36m0.7825\u001b[0m                     \u001b[32m0.7826\u001b[0m        0.6599            \u001b[31m0.7001\u001b[0m                     \u001b[94m0.7003\u001b[0m        \u001b[36m0.5777\u001b[0m  0.0006  2.2726\n",
      "      9            0.7815                     0.7808        \u001b[35m0.5936\u001b[0m            0.6914                     0.6905        0.5905  0.0005  2.3229\n",
      "     10            \u001b[36m0.8005\u001b[0m                     \u001b[32m0.8005\u001b[0m        \u001b[35m0.5595\u001b[0m            \u001b[31m0.7105\u001b[0m                     \u001b[94m0.7104\u001b[0m        \u001b[36m0.5685\u001b[0m  0.0005  2.3780\n",
      "     11            0.7624                     0.7636        \u001b[35m0.5503\u001b[0m            0.6914                     0.6929        0.6223  0.0005  2.3430\n",
      "     12            \u001b[36m0.8258\u001b[0m                     \u001b[32m0.8254\u001b[0m        \u001b[35m0.5419\u001b[0m            \u001b[31m0.7234\u001b[0m                     \u001b[94m0.7229\u001b[0m        \u001b[36m0.5531\u001b[0m  0.0005  2.3038\n",
      "     13            0.8096                     0.8098        \u001b[35m0.5070\u001b[0m            \u001b[31m0.7347\u001b[0m                     \u001b[94m0.7350\u001b[0m        0.5608  0.0005  2.3253\n",
      "     14            \u001b[36m0.8426\u001b[0m                     \u001b[32m0.8425\u001b[0m        \u001b[35m0.4965\u001b[0m            \u001b[31m0.7373\u001b[0m                     \u001b[94m0.7370\u001b[0m        \u001b[36m0.5351\u001b[0m  0.0004  2.3592\n",
      "     15            0.8390                     0.8385        \u001b[35m0.4857\u001b[0m            0.7260                     0.7253        0.5446  0.0004  2.4171\n",
      "     16            \u001b[36m0.8493\u001b[0m                     \u001b[32m0.8495\u001b[0m        \u001b[35m0.4754\u001b[0m            0.7295                     0.7296        0.5496  0.0004  2.6140\n",
      "     17            \u001b[36m0.8588\u001b[0m                     \u001b[32m0.8588\u001b[0m        \u001b[35m0.4559\u001b[0m            0.7312                     0.7311        0.5375  0.0003  2.6016\n",
      "     18            0.8588                     \u001b[32m0.8588\u001b[0m        \u001b[35m0.4464\u001b[0m            0.7355                     0.7354        \u001b[36m0.5330\u001b[0m  0.0003  2.5690\n",
      "     19            0.8543                     0.8547        \u001b[35m0.4378\u001b[0m            0.7338                     0.7342        0.5487  0.0003  2.3742\n",
      "     20            \u001b[36m0.8768\u001b[0m                     \u001b[32m0.8768\u001b[0m        \u001b[35m0.4322\u001b[0m            \u001b[31m0.7468\u001b[0m                     \u001b[94m0.7468\u001b[0m        \u001b[36m0.5296\u001b[0m  0.0003  2.4862\n",
      "     21            \u001b[36m0.8772\u001b[0m                     \u001b[32m0.8774\u001b[0m        0.4323            0.7407                     0.7410        0.5332  0.0002  2.3725\n",
      "     22            \u001b[36m0.8774\u001b[0m                     \u001b[32m0.8779\u001b[0m        \u001b[35m0.4002\u001b[0m            0.7416                     0.7422        0.5366  0.0002  2.3846\n",
      "     23            \u001b[36m0.8850\u001b[0m                     \u001b[32m0.8852\u001b[0m        0.4082            0.7424                     0.7427        0.5404  0.0002  2.3675\n",
      "     24            \u001b[36m0.8887\u001b[0m                     \u001b[32m0.8885\u001b[0m        \u001b[35m0.3917\u001b[0m            0.7442                     0.7438        0.5313  0.0001  2.3954\n",
      "     25            \u001b[36m0.8906\u001b[0m                     \u001b[32m0.8907\u001b[0m        \u001b[35m0.3911\u001b[0m            \u001b[31m0.7519\u001b[0m                     \u001b[94m0.7518\u001b[0m        0.5332  0.0001  2.3938\n",
      "     26            0.8898                     0.8896        \u001b[35m0.3816\u001b[0m            0.7364                     0.7361        0.5425  0.0001  2.4007\n",
      "     27            \u001b[36m0.8911\u001b[0m                     \u001b[32m0.8912\u001b[0m        \u001b[35m0.3811\u001b[0m            0.7390                     0.7392        0.5407  0.0001  2.3950\n",
      "     28            \u001b[36m0.8969\u001b[0m                     \u001b[32m0.8970\u001b[0m        \u001b[35m0.3660\u001b[0m            0.7433                     0.7434        \u001b[36m0.5295\u001b[0m  0.0001  2.3915\n",
      "     29            0.8965                     0.8964        \u001b[35m0.3621\u001b[0m            0.7502                     0.7501        0.5304  0.0000  2.3849\n",
      "     30            0.8967                     0.8968        \u001b[35m0.3557\u001b[0m            0.7459                     0.7462        0.5325  0.0000  2.4101\n",
      "     31            \u001b[36m0.8980\u001b[0m                     \u001b[32m0.8980\u001b[0m        0.3602            0.7450                     0.7450        0.5330  0.0000  2.3782\n",
      "     32            \u001b[36m0.8993\u001b[0m                     \u001b[32m0.8994\u001b[0m        \u001b[35m0.3555\u001b[0m            0.7494                     0.7495        0.5320  0.0000  2.3678\n",
      "     33            \u001b[36m0.8995\u001b[0m                     \u001b[32m0.8995\u001b[0m        0.3596            0.7485                     0.7485        0.5315  0.0000  2.3650\n",
      "     34            0.8993                     0.8993        0.3568            0.7476                     0.7476        0.5317  0.0000  2.3775\n",
      "     35            \u001b[36m0.8997\u001b[0m                     \u001b[32m0.8997\u001b[0m        \u001b[35m0.3541\u001b[0m            0.7494                     0.7493        0.5313  0.0000  2.3929\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5620\u001b[0m                     \u001b[32m0.5627\u001b[0m        \u001b[35m1.2410\u001b[0m            \u001b[31m0.5272\u001b[0m                     \u001b[94m0.5281\u001b[0m        \u001b[36m0.7452\u001b[0m  0.0006  2.4646\n",
      "      2            \u001b[36m0.6379\u001b[0m                     \u001b[32m0.6380\u001b[0m        \u001b[35m0.9752\u001b[0m            \u001b[31m0.6171\u001b[0m                     \u001b[94m0.6173\u001b[0m        \u001b[36m0.6629\u001b[0m  0.0006  2.6092\n",
      "      3            \u001b[36m0.6723\u001b[0m                     \u001b[32m0.6721\u001b[0m        \u001b[35m0.8696\u001b[0m            \u001b[31m0.6396\u001b[0m                     \u001b[94m0.6396\u001b[0m        \u001b[36m0.6500\u001b[0m  0.0006  2.6134\n",
      "      4            \u001b[36m0.6941\u001b[0m                     \u001b[32m0.6952\u001b[0m        \u001b[35m0.7980\u001b[0m            0.6396                     \u001b[94m0.6407\u001b[0m        \u001b[36m0.6370\u001b[0m  0.0006  2.5939\n",
      "      5            0.6909                     0.6915        \u001b[35m0.7465\u001b[0m            0.6335                     0.6344        0.6554  0.0006  2.5892\n",
      "      6            \u001b[36m0.7358\u001b[0m                     \u001b[32m0.7361\u001b[0m        \u001b[35m0.7183\u001b[0m            \u001b[31m0.6863\u001b[0m                     \u001b[94m0.6866\u001b[0m        \u001b[36m0.5929\u001b[0m  0.0006  2.5908\n",
      "      7            \u001b[36m0.7441\u001b[0m                     \u001b[32m0.7430\u001b[0m        \u001b[35m0.6497\u001b[0m            0.6828                     0.6817        0.5940  0.0006  2.5795\n",
      "      8            \u001b[36m0.7479\u001b[0m                     \u001b[32m0.7477\u001b[0m        \u001b[35m0.6299\u001b[0m            \u001b[31m0.6906\u001b[0m                     \u001b[94m0.6904\u001b[0m        \u001b[36m0.5861\u001b[0m  0.0006  2.4004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9            0.7466                     0.7457        \u001b[35m0.6125\u001b[0m            0.6837                     0.6827        0.5950  0.0005  2.3911\n",
      "     10            \u001b[36m0.7858\u001b[0m                     \u001b[32m0.7856\u001b[0m        \u001b[35m0.5741\u001b[0m            \u001b[31m0.7096\u001b[0m                     \u001b[94m0.7096\u001b[0m        \u001b[36m0.5518\u001b[0m  0.0005  2.3868\n",
      "     11            0.7786                     0.7779        \u001b[35m0.5565\u001b[0m            0.7035                     0.7028        0.5726  0.0005  2.3638\n",
      "     12            \u001b[36m0.8186\u001b[0m                     \u001b[32m0.8191\u001b[0m        \u001b[35m0.5193\u001b[0m            \u001b[31m0.7398\u001b[0m                     \u001b[94m0.7405\u001b[0m        \u001b[36m0.5324\u001b[0m  0.0005  2.3677\n",
      "     13            \u001b[36m0.8279\u001b[0m                     \u001b[32m0.8282\u001b[0m        0.5343            0.7321                     0.7322        \u001b[36m0.5306\u001b[0m  0.0005  2.3697\n",
      "     14            \u001b[36m0.8374\u001b[0m                     \u001b[32m0.8373\u001b[0m        \u001b[35m0.5066\u001b[0m            \u001b[31m0.7511\u001b[0m                     \u001b[94m0.7509\u001b[0m        \u001b[36m0.5272\u001b[0m  0.0004  2.3929\n",
      "     15            0.8156                     0.8149        \u001b[35m0.4989\u001b[0m            0.7208                     0.7199        0.5590  0.0004  2.4395\n",
      "     16            \u001b[36m0.8411\u001b[0m                     \u001b[32m0.8406\u001b[0m        \u001b[35m0.4832\u001b[0m            0.7476                     0.7471        \u001b[36m0.5240\u001b[0m  0.0004  2.5598\n",
      "     17            \u001b[36m0.8571\u001b[0m                     \u001b[32m0.8572\u001b[0m        \u001b[35m0.4687\u001b[0m            0.7468                     0.7468        \u001b[36m0.5105\u001b[0m  0.0003  2.3740\n",
      "     18            0.8256                     0.8266        \u001b[35m0.4588\u001b[0m            0.7407                     0.7419        0.5464  0.0003  2.3963\n",
      "     19            \u001b[36m0.8677\u001b[0m                     \u001b[32m0.8676\u001b[0m        \u001b[35m0.4362\u001b[0m            0.7468                     0.7467        \u001b[36m0.5073\u001b[0m  0.0003  2.5663\n",
      "     20            0.8651                     0.8648        \u001b[35m0.4318\u001b[0m            0.7476                     0.7473        0.5216  0.0003  2.5671\n",
      "     21            \u001b[36m0.8770\u001b[0m                     \u001b[32m0.8774\u001b[0m        \u001b[35m0.4272\u001b[0m            \u001b[31m0.7545\u001b[0m                     \u001b[94m0.7549\u001b[0m        \u001b[36m0.5039\u001b[0m  0.0002  2.5571\n",
      "     22            \u001b[36m0.8800\u001b[0m                     \u001b[32m0.8800\u001b[0m        0.4275            0.7519                     0.7520        0.5082  0.0002  2.5181\n",
      "     23            \u001b[36m0.8859\u001b[0m                     \u001b[32m0.8858\u001b[0m        \u001b[35m0.4083\u001b[0m            \u001b[31m0.7606\u001b[0m                     \u001b[94m0.7604\u001b[0m        \u001b[36m0.5006\u001b[0m  0.0002  2.5045\n",
      "     24            0.8787                     0.8792        \u001b[35m0.4018\u001b[0m            0.7528                     0.7534        0.5094  0.0001  2.4580\n",
      "     25            \u001b[36m0.8928\u001b[0m                     \u001b[32m0.8930\u001b[0m        \u001b[35m0.3839\u001b[0m            \u001b[31m0.7710\u001b[0m                     \u001b[94m0.7710\u001b[0m        \u001b[36m0.5000\u001b[0m  0.0001  2.6268\n",
      "     26            \u001b[36m0.8932\u001b[0m                     \u001b[32m0.8935\u001b[0m        0.3894            0.7537                     0.7540        0.5034  0.0001  2.6061\n",
      "     27            \u001b[36m0.8980\u001b[0m                     \u001b[32m0.8979\u001b[0m        \u001b[35m0.3824\u001b[0m            0.7554                     0.7551        \u001b[36m0.4988\u001b[0m  0.0001  2.5373\n",
      "     28            0.8967                     0.8967        0.3836            0.7666                     0.7666        \u001b[36m0.4960\u001b[0m  0.0001  2.5307\n",
      "     29            \u001b[36m0.9012\u001b[0m                     \u001b[32m0.9012\u001b[0m        \u001b[35m0.3761\u001b[0m            0.7615                     0.7614        0.5012  0.0000  2.5440\n",
      "     30            \u001b[36m0.9027\u001b[0m                     \u001b[32m0.9027\u001b[0m        \u001b[35m0.3731\u001b[0m            0.7692                     0.7692        0.4990  0.0000  2.5073\n",
      "     31            0.8960                     0.8963        \u001b[35m0.3719\u001b[0m            0.7666                     0.7669        0.5003  0.0000  2.5482\n",
      "     32            \u001b[36m0.9042\u001b[0m                     \u001b[32m0.9042\u001b[0m        \u001b[35m0.3665\u001b[0m            0.7632                     0.7631        0.4984  0.0000  2.5632\n",
      "     33            0.9036                     0.9038        0.3714            0.7640                     0.7641        0.4989  0.0000  2.5139\n",
      "     34            \u001b[36m0.9055\u001b[0m                     \u001b[32m0.9057\u001b[0m        \u001b[35m0.3644\u001b[0m            0.7649                     0.7650        0.4987  0.0000  2.5168\n",
      "     35            0.9042                     0.9043        \u001b[35m0.3633\u001b[0m            0.7623                     0.7623        0.4987  0.0000  2.5811\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5757\u001b[0m                     \u001b[32m0.5735\u001b[0m        \u001b[35m1.2113\u001b[0m            \u001b[31m0.5480\u001b[0m                     \u001b[94m0.5458\u001b[0m        \u001b[36m0.7472\u001b[0m  0.0006  2.4068\n",
      "      2            \u001b[36m0.6518\u001b[0m                     \u001b[32m0.6521\u001b[0m        \u001b[35m0.9403\u001b[0m            \u001b[31m0.6171\u001b[0m                     \u001b[94m0.6178\u001b[0m        \u001b[36m0.6641\u001b[0m  0.0006  2.3592\n",
      "      3            0.5986                     0.5959        \u001b[35m0.8442\u001b[0m            0.5635                     0.5609        0.7782  0.0006  2.3447\n",
      "      4            \u001b[36m0.6853\u001b[0m                     \u001b[32m0.6858\u001b[0m        \u001b[35m0.7599\u001b[0m            \u001b[31m0.6474\u001b[0m                     \u001b[94m0.6481\u001b[0m        \u001b[36m0.6548\u001b[0m  0.0006  2.3820\n",
      "      5            \u001b[36m0.7227\u001b[0m                     \u001b[32m0.7232\u001b[0m        \u001b[35m0.7236\u001b[0m            \u001b[31m0.6690\u001b[0m                     \u001b[94m0.6698\u001b[0m        \u001b[36m0.6232\u001b[0m  0.0006  2.3555\n",
      "      6            \u001b[36m0.7648\u001b[0m                     \u001b[32m0.7650\u001b[0m        \u001b[35m0.6689\u001b[0m            0.6655                     0.6657        \u001b[36m0.6064\u001b[0m  0.0006  2.3876\n",
      "      7            \u001b[36m0.7765\u001b[0m                     \u001b[32m0.7766\u001b[0m        \u001b[35m0.6430\u001b[0m            \u001b[31m0.6914\u001b[0m                     \u001b[94m0.6916\u001b[0m        \u001b[36m0.5877\u001b[0m  0.0006  2.3831\n",
      "      8            \u001b[36m0.7905\u001b[0m                     \u001b[32m0.7905\u001b[0m        \u001b[35m0.6121\u001b[0m            \u001b[31m0.7044\u001b[0m                     \u001b[94m0.7043\u001b[0m        \u001b[36m0.5671\u001b[0m  0.0006  2.3218\n",
      "      9            \u001b[36m0.7936\u001b[0m                     \u001b[32m0.7940\u001b[0m        \u001b[35m0.5696\u001b[0m            \u001b[31m0.7105\u001b[0m                     \u001b[94m0.7111\u001b[0m        0.5763  0.0005  2.3418\n",
      "     10            \u001b[36m0.7996\u001b[0m                     \u001b[32m0.8004\u001b[0m        \u001b[35m0.5599\u001b[0m            \u001b[31m0.7148\u001b[0m                     \u001b[94m0.7157\u001b[0m        0.5712  0.0005  2.3255\n",
      "     11            0.7985                     0.7981        0.5638            0.7053                     0.7047        0.5763  0.0005  2.3276\n",
      "     12            \u001b[36m0.8176\u001b[0m                     \u001b[32m0.8177\u001b[0m        \u001b[35m0.5342\u001b[0m            0.7131                     0.7130        \u001b[36m0.5589\u001b[0m  0.0005  2.3373\n",
      "     13            \u001b[36m0.8368\u001b[0m                     \u001b[32m0.8371\u001b[0m        \u001b[35m0.5095\u001b[0m            \u001b[31m0.7303\u001b[0m                     \u001b[94m0.7305\u001b[0m        \u001b[36m0.5482\u001b[0m  0.0005  2.3309\n",
      "     14            \u001b[36m0.8463\u001b[0m                     \u001b[32m0.8463\u001b[0m        \u001b[35m0.4970\u001b[0m            0.7122                     0.7122        0.5544  0.0004  2.3408\n",
      "     15            0.8381                     0.8376        0.4996            0.7148                     0.7143        0.5630  0.0004  2.3432\n",
      "     16            \u001b[36m0.8597\u001b[0m                     \u001b[32m0.8598\u001b[0m        \u001b[35m0.4622\u001b[0m            \u001b[31m0.7355\u001b[0m                     \u001b[94m0.7357\u001b[0m        0.5499  0.0004  2.3301\n",
      "     17            0.8558                     0.8553        \u001b[35m0.4533\u001b[0m            0.7122                     0.7115        0.5499  0.0003  2.3298\n",
      "     18            \u001b[36m0.8690\u001b[0m                     \u001b[32m0.8690\u001b[0m        \u001b[35m0.4510\u001b[0m            \u001b[31m0.7459\u001b[0m                     \u001b[94m0.7461\u001b[0m        \u001b[36m0.5451\u001b[0m  0.0003  2.3223\n",
      "     19            \u001b[36m0.8714\u001b[0m                     \u001b[32m0.8717\u001b[0m        \u001b[35m0.4259\u001b[0m            0.7329                     0.7333        0.5501  0.0003  2.3283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20            \u001b[36m0.8744\u001b[0m                     \u001b[32m0.8747\u001b[0m        \u001b[35m0.4185\u001b[0m            0.7416                     0.7421        \u001b[36m0.5437\u001b[0m  0.0003  2.3317\n",
      "     21            \u001b[36m0.8846\u001b[0m                     \u001b[32m0.8847\u001b[0m        0.4199            0.7355                     0.7357        0.5487  0.0002  2.3318\n",
      "     22            0.8802                     0.8806        \u001b[35m0.4049\u001b[0m            0.7373                     0.7375        0.5550  0.0002  2.3234\n",
      "     23            \u001b[36m0.8926\u001b[0m                     \u001b[32m0.8925\u001b[0m        \u001b[35m0.3910\u001b[0m            0.7312                     0.7313        \u001b[36m0.5385\u001b[0m  0.0002  2.3315\n",
      "     24            \u001b[36m0.8936\u001b[0m                     \u001b[32m0.8937\u001b[0m        \u001b[35m0.3858\u001b[0m            0.7303                     0.7306        0.5460  0.0001  2.3357\n",
      "     25            \u001b[36m0.9019\u001b[0m                     \u001b[32m0.9019\u001b[0m        0.3891            0.7338                     0.7340        0.5427  0.0001  2.3271\n",
      "     26            0.8954                     0.8957        0.3865            0.7329                     0.7333        0.5621  0.0001  2.3313\n",
      "     27            \u001b[36m0.9036\u001b[0m                     \u001b[32m0.9037\u001b[0m        \u001b[35m0.3683\u001b[0m            0.7424                     0.7427        0.5405  0.0001  2.3280\n",
      "     28            \u001b[36m0.9051\u001b[0m                     \u001b[32m0.9051\u001b[0m        \u001b[35m0.3676\u001b[0m            0.7398                     0.7398        0.5432  0.0001  2.3260\n",
      "     29            \u001b[36m0.9077\u001b[0m                     \u001b[32m0.9077\u001b[0m        0.3749            0.7398                     0.7400        0.5427  0.0000  2.3268\n",
      "     30            \u001b[36m0.9096\u001b[0m                     \u001b[32m0.9097\u001b[0m        \u001b[35m0.3566\u001b[0m            0.7407                     0.7410        0.5436  0.0000  2.3309\n",
      "     31            0.9070                     0.9073        \u001b[35m0.3506\u001b[0m            0.7450                     0.7455        0.5478  0.0000  2.3409\n",
      "     32            0.9094                     0.9093        0.3523            0.7355                     0.7356        0.5437  0.0000  2.3288\n",
      "     33            \u001b[36m0.9116\u001b[0m                     \u001b[32m0.9116\u001b[0m        0.3604            0.7390                     0.7392        0.5438  0.0000  2.3314\n",
      "     34            \u001b[36m0.9122\u001b[0m                     \u001b[32m0.9122\u001b[0m        \u001b[35m0.3447\u001b[0m            0.7329                     0.7330        0.5442  0.0000  2.3345\n",
      "     35            0.9118                     0.9118        0.3468            0.7364                     0.7365        0.5441  0.0000  2.3328\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5776\u001b[0m                     \u001b[32m0.5774\u001b[0m        \u001b[35m1.2192\u001b[0m            \u001b[31m0.5488\u001b[0m                     \u001b[94m0.5485\u001b[0m        \u001b[36m0.7285\u001b[0m  0.0006  2.3390\n",
      "      2            \u001b[36m0.6144\u001b[0m                     \u001b[32m0.6144\u001b[0m        \u001b[35m0.9715\u001b[0m            \u001b[31m0.5886\u001b[0m                     \u001b[94m0.5887\u001b[0m        \u001b[36m0.7119\u001b[0m  0.0006  2.3248\n",
      "      3            \u001b[36m0.6327\u001b[0m                     \u001b[32m0.6357\u001b[0m        \u001b[35m0.8793\u001b[0m            0.5670                     0.5703        \u001b[36m0.7059\u001b[0m  0.0006  2.3228\n",
      "      4            \u001b[36m0.7023\u001b[0m                     \u001b[32m0.7030\u001b[0m        \u001b[35m0.7865\u001b[0m            \u001b[31m0.6404\u001b[0m                     \u001b[94m0.6412\u001b[0m        \u001b[36m0.6324\u001b[0m  0.0006  2.3262\n",
      "      5            0.6965                     0.6955        \u001b[35m0.7209\u001b[0m            \u001b[31m0.6456\u001b[0m                     \u001b[94m0.6446\u001b[0m        0.6618  0.0006  2.3221\n",
      "      6            0.6576                     0.6556        \u001b[35m0.6837\u001b[0m            0.6292                     0.6272        0.7009  0.0006  2.3283\n",
      "      7            \u001b[36m0.7691\u001b[0m                     \u001b[32m0.7689\u001b[0m        \u001b[35m0.6565\u001b[0m            \u001b[31m0.6811\u001b[0m                     \u001b[94m0.6806\u001b[0m        \u001b[36m0.5829\u001b[0m  0.0006  2.3343\n",
      "      8            \u001b[36m0.7799\u001b[0m                     \u001b[32m0.7798\u001b[0m        \u001b[35m0.6142\u001b[0m            0.6785                     0.6782        0.5898  0.0006  2.3426\n",
      "      9            \u001b[36m0.7981\u001b[0m                     \u001b[32m0.7980\u001b[0m        \u001b[35m0.6028\u001b[0m            \u001b[31m0.7139\u001b[0m                     \u001b[94m0.7137\u001b[0m        \u001b[36m0.5627\u001b[0m  0.0005  2.3243\n",
      "     10            0.7760                     0.7755        \u001b[35m0.5810\u001b[0m            0.6984                     0.6977        0.5944  0.0005  2.3278\n",
      "     11            \u001b[36m0.8143\u001b[0m                     \u001b[32m0.8138\u001b[0m        \u001b[35m0.5528\u001b[0m            0.7079                     0.7070        0.5645  0.0005  2.3254\n",
      "     12            \u001b[36m0.8208\u001b[0m                     \u001b[32m0.8206\u001b[0m        \u001b[35m0.5471\u001b[0m            \u001b[31m0.7260\u001b[0m                     \u001b[94m0.7256\u001b[0m        \u001b[36m0.5564\u001b[0m  0.0005  2.3261\n",
      "     13            \u001b[36m0.8294\u001b[0m                     \u001b[32m0.8298\u001b[0m        \u001b[35m0.5055\u001b[0m            \u001b[31m0.7269\u001b[0m                     \u001b[94m0.7273\u001b[0m        \u001b[36m0.5465\u001b[0m  0.0005  2.3348\n",
      "     14            \u001b[36m0.8361\u001b[0m                     \u001b[32m0.8367\u001b[0m        \u001b[35m0.4966\u001b[0m            0.7269                     \u001b[94m0.7274\u001b[0m        0.5517  0.0004  2.3547\n",
      "     15            \u001b[36m0.8411\u001b[0m                     \u001b[32m0.8409\u001b[0m        \u001b[35m0.4854\u001b[0m            0.7122                     0.7117        0.5682  0.0004  2.3309\n",
      "     16            \u001b[36m0.8446\u001b[0m                     \u001b[32m0.8451\u001b[0m        0.4855            0.7226                     0.7231        0.5612  0.0004  2.3373\n",
      "     17            \u001b[36m0.8608\u001b[0m                     \u001b[32m0.8605\u001b[0m        \u001b[35m0.4398\u001b[0m            0.7269                     0.7265        \u001b[36m0.5451\u001b[0m  0.0003  2.3379\n",
      "     18            0.8582                     0.8578        0.4467            0.7252                     0.7246        0.5528  0.0003  2.3507\n",
      "     19            0.8595                     0.8599        0.4485            0.7243                     0.7247        0.5614  0.0003  2.3532\n",
      "     20            \u001b[36m0.8807\u001b[0m                     \u001b[32m0.8809\u001b[0m        \u001b[35m0.4281\u001b[0m            \u001b[31m0.7476\u001b[0m                     \u001b[94m0.7479\u001b[0m        \u001b[36m0.5415\u001b[0m  0.0003  2.4148\n",
      "     21            \u001b[36m0.8841\u001b[0m                     \u001b[32m0.8842\u001b[0m        \u001b[35m0.4114\u001b[0m            0.7416                     0.7417        \u001b[36m0.5346\u001b[0m  0.0002  2.5073\n",
      "     22            0.8811                     0.8812        \u001b[35m0.4052\u001b[0m            0.7416                     0.7417        0.5406  0.0002  2.5100\n",
      "     23            \u001b[36m0.8915\u001b[0m                     \u001b[32m0.8915\u001b[0m        \u001b[35m0.4029\u001b[0m            \u001b[31m0.7519\u001b[0m                     \u001b[94m0.7518\u001b[0m        \u001b[36m0.5338\u001b[0m  0.0002  2.5492\n",
      "     24            \u001b[36m0.8921\u001b[0m                     \u001b[32m0.8922\u001b[0m        \u001b[35m0.3930\u001b[0m            0.7424                     0.7424        0.5347  0.0001  2.5677\n",
      "     25            0.8913                     0.8913        0.3974            \u001b[31m0.7537\u001b[0m                     \u001b[94m0.7536\u001b[0m        \u001b[36m0.5313\u001b[0m  0.0001  2.5339\n",
      "     26            \u001b[36m0.9025\u001b[0m                     \u001b[32m0.9025\u001b[0m        \u001b[35m0.3818\u001b[0m            0.7511                     0.7511        0.5342  0.0001  2.5169\n",
      "     27            \u001b[36m0.9036\u001b[0m                     \u001b[32m0.9036\u001b[0m        \u001b[35m0.3665\u001b[0m            0.7502                     0.7502        0.5351  0.0001  2.4614\n",
      "     28            0.9012                     0.9014        0.3699            0.7511                     0.7514        0.5359  0.0001  2.4950\n",
      "     29            \u001b[36m0.9064\u001b[0m                     \u001b[32m0.9065\u001b[0m        0.3680            0.7511                     0.7513        0.5354  0.0000  2.5712\n",
      "     30            \u001b[36m0.9073\u001b[0m                     \u001b[32m0.9073\u001b[0m        \u001b[35m0.3624\u001b[0m            0.7519                     0.7520        0.5354  0.0000  2.5084\n",
      "     31            \u001b[36m0.9086\u001b[0m                     \u001b[32m0.9086\u001b[0m        \u001b[35m0.3536\u001b[0m            0.7485                     0.7487        0.5358  0.0000  2.4558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     32            \u001b[36m0.9101\u001b[0m                     \u001b[32m0.9101\u001b[0m        \u001b[35m0.3463\u001b[0m            0.7485                     0.7485        0.5365  0.0000  2.5414\n",
      "     33            0.9094                     0.9095        0.3571            0.7476                     0.7478        0.5367  0.0000  2.4927\n",
      "     34            \u001b[36m0.9103\u001b[0m                     \u001b[32m0.9103\u001b[0m        0.3500            0.7494                     0.7494        0.5365  0.0000  2.5866\n",
      "     35            0.9101                     0.9101        0.3551            0.7502                     0.7502        0.5365  0.0000  2.6109\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5707\u001b[0m                     \u001b[32m0.5727\u001b[0m        \u001b[35m1.1915\u001b[0m            \u001b[31m0.5462\u001b[0m                     \u001b[94m0.5483\u001b[0m        \u001b[36m0.7831\u001b[0m  0.0006  2.5502\n",
      "      2            \u001b[36m0.6405\u001b[0m                     \u001b[32m0.6404\u001b[0m        \u001b[35m0.9340\u001b[0m            \u001b[31m0.6041\u001b[0m                     \u001b[94m0.6042\u001b[0m        \u001b[36m0.6786\u001b[0m  0.0006  2.4874\n",
      "      3            \u001b[36m0.6749\u001b[0m                     \u001b[32m0.6758\u001b[0m        \u001b[35m0.8560\u001b[0m            0.6007                     0.6019        \u001b[36m0.6738\u001b[0m  0.0006  2.4994\n",
      "      4            \u001b[36m0.7015\u001b[0m                     \u001b[32m0.7006\u001b[0m        \u001b[35m0.7482\u001b[0m            \u001b[31m0.6275\u001b[0m                     \u001b[94m0.6268\u001b[0m        \u001b[36m0.6461\u001b[0m  0.0006  2.5298\n",
      "      5            \u001b[36m0.7168\u001b[0m                     \u001b[32m0.7169\u001b[0m        \u001b[35m0.7358\u001b[0m            \u001b[31m0.6301\u001b[0m                     \u001b[94m0.6303\u001b[0m        \u001b[36m0.6437\u001b[0m  0.0006  2.5721\n",
      "      6            \u001b[36m0.7257\u001b[0m                     \u001b[32m0.7263\u001b[0m        \u001b[35m0.7138\u001b[0m            \u001b[31m0.6629\u001b[0m                     \u001b[94m0.6638\u001b[0m        0.6572  0.0006  2.6165\n",
      "      7            \u001b[36m0.7527\u001b[0m                     \u001b[32m0.7519\u001b[0m        \u001b[35m0.6504\u001b[0m            0.6603                     0.6598        \u001b[36m0.5981\u001b[0m  0.0006  2.5699\n",
      "      8            \u001b[36m0.7776\u001b[0m                     \u001b[32m0.7783\u001b[0m        \u001b[35m0.6076\u001b[0m            \u001b[31m0.6854\u001b[0m                     \u001b[94m0.6863\u001b[0m        0.6006  0.0006  2.6175\n",
      "      9            \u001b[36m0.7888\u001b[0m                     \u001b[32m0.7881\u001b[0m        \u001b[35m0.5895\u001b[0m            0.6629                     0.6625        0.5994  0.0005  2.5614\n",
      "     10            \u001b[36m0.8065\u001b[0m                     \u001b[32m0.8067\u001b[0m        \u001b[35m0.5797\u001b[0m            \u001b[31m0.7035\u001b[0m                     \u001b[94m0.7041\u001b[0m        \u001b[36m0.5840\u001b[0m  0.0005  2.5598\n",
      "     11            0.7709                     0.7716        \u001b[35m0.5503\u001b[0m            0.6897                     0.6908        0.6337  0.0005  2.5631\n",
      "     12            \u001b[36m0.8206\u001b[0m                     \u001b[32m0.8212\u001b[0m        \u001b[35m0.5300\u001b[0m            \u001b[31m0.7044\u001b[0m                     \u001b[94m0.7053\u001b[0m        \u001b[36m0.5628\u001b[0m  0.0005  2.5579\n",
      "     13            \u001b[36m0.8335\u001b[0m                     \u001b[32m0.8339\u001b[0m        \u001b[35m0.5184\u001b[0m            \u001b[31m0.7131\u001b[0m                     \u001b[94m0.7138\u001b[0m        \u001b[36m0.5599\u001b[0m  0.0005  2.5733\n",
      "     14            0.8290                     0.8291        \u001b[35m0.5076\u001b[0m            \u001b[31m0.7156\u001b[0m                     \u001b[94m0.7161\u001b[0m        \u001b[36m0.5585\u001b[0m  0.0004  2.5432\n",
      "     15            \u001b[36m0.8446\u001b[0m                     \u001b[32m0.8447\u001b[0m        \u001b[35m0.4784\u001b[0m            \u001b[31m0.7174\u001b[0m                     \u001b[94m0.7177\u001b[0m        0.5601  0.0004  2.5057\n",
      "     16            0.8446                     0.8447        \u001b[35m0.4766\u001b[0m            0.7061                     0.7065        0.5616  0.0004  2.4329\n",
      "     17            \u001b[36m0.8495\u001b[0m                     \u001b[32m0.8503\u001b[0m        \u001b[35m0.4523\u001b[0m            0.7027                     0.7039        0.5725  0.0003  2.4355\n",
      "     18            \u001b[36m0.8623\u001b[0m                     \u001b[32m0.8621\u001b[0m        \u001b[35m0.4473\u001b[0m            0.7105                     0.7105        \u001b[36m0.5544\u001b[0m  0.0003  2.4772\n",
      "     19            \u001b[36m0.8740\u001b[0m                     \u001b[32m0.8744\u001b[0m        \u001b[35m0.4330\u001b[0m            \u001b[31m0.7243\u001b[0m                     \u001b[94m0.7251\u001b[0m        \u001b[36m0.5521\u001b[0m  0.0003  2.5781\n",
      "     20            0.8738                     0.8741        \u001b[35m0.4306\u001b[0m            \u001b[31m0.7260\u001b[0m                     \u001b[94m0.7266\u001b[0m        0.5554  0.0003  2.5622\n",
      "     21            0.8666                     0.8669        \u001b[35m0.4240\u001b[0m            0.7226                     0.7231        0.5694  0.0002  2.5999\n",
      "     22            0.8677                     0.8683        \u001b[35m0.4120\u001b[0m            0.7200                     0.7209        0.5644  0.0002  2.6061\n",
      "     23            \u001b[36m0.8820\u001b[0m                     \u001b[32m0.8822\u001b[0m        \u001b[35m0.4119\u001b[0m            0.7191                     0.7196        0.5602  0.0002  2.6652\n",
      "     24            \u001b[36m0.8878\u001b[0m                     \u001b[32m0.8882\u001b[0m        \u001b[35m0.3900\u001b[0m            \u001b[31m0.7355\u001b[0m                     \u001b[94m0.7364\u001b[0m        \u001b[36m0.5490\u001b[0m  0.0001  2.5852\n",
      "     25            \u001b[36m0.8923\u001b[0m                     \u001b[32m0.8926\u001b[0m        0.3969            0.7226                     0.7233        0.5540  0.0001  2.6799\n",
      "     26            \u001b[36m0.8941\u001b[0m                     \u001b[32m0.8941\u001b[0m        \u001b[35m0.3888\u001b[0m            0.7252                     0.7255        0.5520  0.0001  2.5496\n",
      "     27            \u001b[36m0.9010\u001b[0m                     \u001b[32m0.9012\u001b[0m        \u001b[35m0.3759\u001b[0m            0.7217                     0.7223        0.5528  0.0001  2.4764\n",
      "     28            0.8930                     0.8935        \u001b[35m0.3713\u001b[0m            0.7243                     0.7253        0.5613  0.0001  2.4410\n",
      "     29            \u001b[36m0.9042\u001b[0m                     \u001b[32m0.9043\u001b[0m        \u001b[35m0.3706\u001b[0m            0.7252                     0.7256        0.5531  0.0000  2.5872\n",
      "     30            \u001b[36m0.9053\u001b[0m                     \u001b[32m0.9055\u001b[0m        \u001b[35m0.3645\u001b[0m            0.7303                     0.7309        0.5525  0.0000  2.5243\n",
      "     31            \u001b[36m0.9062\u001b[0m                     \u001b[32m0.9063\u001b[0m        \u001b[35m0.3539\u001b[0m            0.7260                     0.7266        0.5530  0.0000  2.5622\n",
      "     32            \u001b[36m0.9083\u001b[0m                     \u001b[32m0.9083\u001b[0m        0.3571            0.7303                     0.7307        0.5508  0.0000  2.5222\n",
      "     33            0.9073                     0.9074        0.3576            0.7303                     0.7308        0.5517  0.0000  2.5686\n",
      "     34            0.9070                     0.9071        0.3625            0.7312                     0.7316        0.5515  0.0000  2.6034\n",
      "     35            0.9068                     0.9070        \u001b[35m0.3523\u001b[0m            0.7286                     0.7291        0.5519  0.0000  2.5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6260\u001b[0m                     \u001b[32m0.6466\u001b[0m        \u001b[35m1.3031\u001b[0m            \u001b[31m0.6281\u001b[0m                     \u001b[94m0.6498\u001b[0m        \u001b[36m0.7650\u001b[0m  0.0006  1.8130\n",
      "      2            \u001b[36m0.6912\u001b[0m                     \u001b[32m0.6934\u001b[0m        \u001b[35m0.9451\u001b[0m            \u001b[31m0.6570\u001b[0m                     \u001b[94m0.6595\u001b[0m        \u001b[36m0.6355\u001b[0m  0.0006  1.4556\n",
      "      3            \u001b[36m0.7125\u001b[0m                     \u001b[32m0.7162\u001b[0m        \u001b[35m0.8171\u001b[0m            0.6541                     0.6581        \u001b[36m0.6219\u001b[0m  0.0006  1.4494\n",
      "      4            0.6510                     0.6724        \u001b[35m0.7552\u001b[0m            0.6252                     0.6460        0.7072  0.0006  1.4460\n",
      "      5            \u001b[36m0.7169\u001b[0m                     \u001b[32m0.7360\u001b[0m        \u001b[35m0.7316\u001b[0m            0.6469                     \u001b[94m0.6681\u001b[0m        0.6252  0.0006  1.4481\n",
      "      6            \u001b[36m0.7361\u001b[0m                     \u001b[32m0.7480\u001b[0m        \u001b[35m0.6787\u001b[0m            \u001b[31m0.6831\u001b[0m                     \u001b[94m0.6952\u001b[0m        \u001b[36m0.6048\u001b[0m  0.0006  1.4508\n",
      "      7            \u001b[36m0.7419\u001b[0m                     \u001b[32m0.7571\u001b[0m        \u001b[35m0.6396\u001b[0m            \u001b[31m0.6918\u001b[0m                     \u001b[94m0.7078\u001b[0m        \u001b[36m0.5967\u001b[0m  0.0006  1.4547\n",
      "      8            \u001b[36m0.7639\u001b[0m                     0.7567        \u001b[35m0.6082\u001b[0m            0.6570                     0.6511        0.6323  0.0006  1.4666\n",
      "      9            \u001b[36m0.8215\u001b[0m                     \u001b[32m0.8137\u001b[0m        \u001b[35m0.5715\u001b[0m            \u001b[31m0.7164\u001b[0m                     \u001b[94m0.7091\u001b[0m        \u001b[36m0.5630\u001b[0m  0.0005  1.4332\n",
      "     10            \u001b[36m0.8251\u001b[0m                     \u001b[32m0.8265\u001b[0m        \u001b[35m0.5334\u001b[0m            \u001b[31m0.7192\u001b[0m                     \u001b[94m0.7208\u001b[0m        \u001b[36m0.5443\u001b[0m  0.0005  1.4460\n",
      "     11            \u001b[36m0.8461\u001b[0m                     \u001b[32m0.8506\u001b[0m        \u001b[35m0.5035\u001b[0m            \u001b[31m0.7337\u001b[0m                     \u001b[94m0.7390\u001b[0m        \u001b[36m0.5346\u001b[0m  0.0005  1.4384\n",
      "     12            0.8436                     0.8386        \u001b[35m0.4987\u001b[0m            0.6903                     0.6873        0.5755  0.0005  1.4403\n",
      "     13            0.8266                     0.8359        \u001b[35m0.4740\u001b[0m            0.7062                     0.7165        0.5628  0.0005  1.4506\n",
      "     14            \u001b[36m0.8733\u001b[0m                     \u001b[32m0.8721\u001b[0m        0.4791            0.7164                     0.7163        0.5555  0.0004  1.4374\n",
      "     15            \u001b[36m0.8740\u001b[0m                     \u001b[32m0.8796\u001b[0m        \u001b[35m0.4486\u001b[0m            0.7207                     0.7260        0.5442  0.0004  1.4432\n",
      "     16            0.8718                     0.8749        \u001b[35m0.4222\u001b[0m            0.7106                     0.7144        0.5459  0.0004  1.4407\n",
      "     17            0.8718                     0.8766        \u001b[35m0.3972\u001b[0m            0.7250                     0.7284        \u001b[36m0.5339\u001b[0m  0.0003  1.4585\n",
      "     18            0.8726                     0.8788        0.4044            0.7207                     0.7266        0.5551  0.0003  1.4397\n",
      "     19            \u001b[36m0.8997\u001b[0m                     \u001b[32m0.9016\u001b[0m        \u001b[35m0.3854\u001b[0m            0.7164                     0.7181        0.5443  0.0003  1.4418\n",
      "     20            0.8896                     0.8932        \u001b[35m0.3764\u001b[0m            0.7236                     0.7295        0.5663  0.0003  1.4461\n",
      "     21            \u001b[36m0.9207\u001b[0m                     \u001b[32m0.9219\u001b[0m        \u001b[35m0.3705\u001b[0m            0.7250                     0.7260        0.5475  0.0002  1.4477\n",
      "     22            0.9182                     0.9191        \u001b[35m0.3531\u001b[0m            0.7077                     0.7106        0.5708  0.0002  1.4404\n",
      "     23            0.9207                     0.9210        \u001b[35m0.3365\u001b[0m            0.7265                     0.7279        0.5535  0.0002  1.4377\n",
      "     24            \u001b[36m0.9236\u001b[0m                     \u001b[32m0.9248\u001b[0m        \u001b[35m0.3333\u001b[0m            0.7323                     0.7347        0.5504  0.0001  1.4527\n",
      "     25            \u001b[36m0.9290\u001b[0m                     \u001b[32m0.9302\u001b[0m        \u001b[35m0.3261\u001b[0m            0.7323                     0.7329        0.5561  0.0001  1.4442\n",
      "     26            0.9280                     0.9281        \u001b[35m0.3049\u001b[0m            0.7279                     0.7277        0.5553  0.0001  1.4470\n",
      "     27            \u001b[36m0.9334\u001b[0m                     \u001b[32m0.9347\u001b[0m        0.3110            0.7149                     0.7165        0.5539  0.0001  1.4571\n",
      "     28            \u001b[36m0.9341\u001b[0m                     0.9333        0.3135            0.7308                     0.7301        0.5585  0.0001  1.4501\n",
      "     29            \u001b[36m0.9352\u001b[0m                     \u001b[32m0.9357\u001b[0m        0.3054            0.7250                     0.7257        0.5537  0.0000  1.4479\n",
      "     30            0.9337                     0.9354        \u001b[35m0.2999\u001b[0m            0.7236                     0.7265        0.5546  0.0000  1.4571\n",
      "     31            0.9341                     0.9355        \u001b[35m0.2968\u001b[0m            0.7236                     0.7262        0.5583  0.0000  1.4441\n",
      "     32            0.9334                     0.9354        \u001b[35m0.2860\u001b[0m            0.7250                     0.7278        0.5555  0.0000  1.4616\n",
      "     33            \u001b[36m0.9356\u001b[0m                     \u001b[32m0.9367\u001b[0m        0.2914            0.7279                     0.7295        0.5545  0.0000  1.4751\n",
      "     34            0.9345                     0.9363        0.2864            0.7250                     0.7272        0.5564  0.0000  1.4452\n",
      "     35            0.9356                     0.9365        0.2960            0.7308                     0.7322        0.5546  0.0000  1.4471\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6510\u001b[0m                     \u001b[32m0.6634\u001b[0m        \u001b[35m1.2756\u001b[0m            \u001b[31m0.6122\u001b[0m                     \u001b[94m0.6221\u001b[0m        \u001b[36m0.6690\u001b[0m  0.0006  1.4425\n",
      "      2            \u001b[36m0.7082\u001b[0m                     \u001b[32m0.7087\u001b[0m        \u001b[35m0.9342\u001b[0m            \u001b[31m0.6368\u001b[0m                     \u001b[94m0.6390\u001b[0m        \u001b[36m0.6213\u001b[0m  0.0006  1.4347\n",
      "      3            \u001b[36m0.7085\u001b[0m                     \u001b[32m0.7260\u001b[0m        \u001b[35m0.7928\u001b[0m            \u001b[31m0.6628\u001b[0m                     \u001b[94m0.6795\u001b[0m        \u001b[36m0.6143\u001b[0m  0.0006  1.4395\n",
      "      4            \u001b[36m0.7552\u001b[0m                     \u001b[32m0.7594\u001b[0m        \u001b[35m0.7539\u001b[0m            \u001b[31m0.6874\u001b[0m                     \u001b[94m0.6916\u001b[0m        \u001b[36m0.5827\u001b[0m  0.0006  1.4541\n",
      "      5            \u001b[36m0.7857\u001b[0m                     \u001b[32m0.7901\u001b[0m        \u001b[35m0.7353\u001b[0m            \u001b[31m0.7019\u001b[0m                     \u001b[94m0.7068\u001b[0m        \u001b[36m0.5627\u001b[0m  0.0006  1.4621\n",
      "      6            \u001b[36m0.7911\u001b[0m                     \u001b[32m0.7995\u001b[0m        \u001b[35m0.6482\u001b[0m            \u001b[31m0.7048\u001b[0m                     \u001b[94m0.7124\u001b[0m        0.5672  0.0006  1.4793\n",
      "      7            \u001b[36m0.7915\u001b[0m                     \u001b[32m0.8040\u001b[0m        \u001b[35m0.6116\u001b[0m            0.6946                     0.7084        \u001b[36m0.5624\u001b[0m  0.0006  1.4232\n",
      "      8            0.7849                     0.7877        \u001b[35m0.5850\u001b[0m            0.7048                     0.7091        0.5923  0.0006  1.4262\n",
      "      9            \u001b[36m0.8190\u001b[0m                     \u001b[32m0.8267\u001b[0m        \u001b[35m0.5734\u001b[0m            \u001b[31m0.7149\u001b[0m                     \u001b[94m0.7252\u001b[0m        \u001b[36m0.5558\u001b[0m  0.0005  1.4953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10            \u001b[36m0.8374\u001b[0m                     \u001b[32m0.8400\u001b[0m        \u001b[35m0.5173\u001b[0m            0.7106                     0.7144        \u001b[36m0.5479\u001b[0m  0.0005  1.4997\n",
      "     11            \u001b[36m0.8450\u001b[0m                     \u001b[32m0.8512\u001b[0m        0.5250            \u001b[31m0.7294\u001b[0m                     \u001b[94m0.7339\u001b[0m        0.5541  0.0005  1.4488\n",
      "     12            0.8421                     \u001b[32m0.8527\u001b[0m        \u001b[35m0.4691\u001b[0m            0.7062                     0.7195        0.5591  0.0005  1.4514\n",
      "     13            \u001b[36m0.8671\u001b[0m                     \u001b[32m0.8731\u001b[0m        0.4872            \u001b[31m0.7352\u001b[0m                     \u001b[94m0.7424\u001b[0m        \u001b[36m0.5277\u001b[0m  0.0005  1.4072\n",
      "     14            \u001b[36m0.8678\u001b[0m                     \u001b[32m0.8743\u001b[0m        \u001b[35m0.4326\u001b[0m            \u001b[31m0.7395\u001b[0m                     \u001b[94m0.7460\u001b[0m        0.5323  0.0004  1.4232\n",
      "     15            0.8657                     0.8714        \u001b[35m0.4254\u001b[0m            0.7381                     0.7429        0.5291  0.0004  1.4531\n",
      "     16            \u001b[36m0.8805\u001b[0m                     \u001b[32m0.8852\u001b[0m        \u001b[35m0.4178\u001b[0m            \u001b[31m0.7511\u001b[0m                     \u001b[94m0.7562\u001b[0m        0.5340  0.0004  1.4303\n",
      "     17            \u001b[36m0.8809\u001b[0m                     \u001b[32m0.8857\u001b[0m        \u001b[35m0.3851\u001b[0m            \u001b[31m0.7540\u001b[0m                     \u001b[94m0.7589\u001b[0m        0.5301  0.0003  1.4451\n",
      "     18            \u001b[36m0.8932\u001b[0m                     \u001b[32m0.8942\u001b[0m        \u001b[35m0.3805\u001b[0m            0.7511                     0.7511        0.5316  0.0003  1.4481\n",
      "     19            \u001b[36m0.9098\u001b[0m                     \u001b[32m0.9122\u001b[0m        \u001b[35m0.3745\u001b[0m            0.7424                     0.7439        0.5281  0.0003  1.4282\n",
      "     20            \u001b[36m0.9142\u001b[0m                     \u001b[32m0.9165\u001b[0m        \u001b[35m0.3666\u001b[0m            0.7482                     0.7494        0.5333  0.0003  1.4242\n",
      "     21            0.9102                     0.9124        \u001b[35m0.3471\u001b[0m            0.7366                     0.7374        0.5392  0.0002  1.4266\n",
      "     22            \u001b[36m0.9203\u001b[0m                     \u001b[32m0.9216\u001b[0m        \u001b[35m0.3413\u001b[0m            0.7438                     0.7443        0.5334  0.0002  1.4392\n",
      "     23            0.9153                     0.9201        0.3517            0.7511                     0.7562        \u001b[36m0.5276\u001b[0m  0.0002  1.4356\n",
      "     24            \u001b[36m0.9298\u001b[0m                     \u001b[32m0.9298\u001b[0m        \u001b[35m0.3232\u001b[0m            \u001b[31m0.7656\u001b[0m                     \u001b[94m0.7625\u001b[0m        0.5315  0.0001  1.4322\n",
      "     25            \u001b[36m0.9316\u001b[0m                     \u001b[32m0.9333\u001b[0m        \u001b[35m0.3123\u001b[0m            0.7554                     0.7554        \u001b[36m0.5276\u001b[0m  0.0001  1.4212\n",
      "     26            \u001b[36m0.9345\u001b[0m                     \u001b[32m0.9354\u001b[0m        \u001b[35m0.3118\u001b[0m            0.7467                     0.7469        0.5321  0.0001  1.4362\n",
      "     27            0.9319                     0.9351        \u001b[35m0.3095\u001b[0m            0.7554                     0.7587        \u001b[36m0.5271\u001b[0m  0.0001  1.4541\n",
      "     28            \u001b[36m0.9432\u001b[0m                     \u001b[32m0.9442\u001b[0m        \u001b[35m0.2865\u001b[0m            0.7569                     0.7555        \u001b[36m0.5260\u001b[0m  0.0001  1.4267\n",
      "     29            0.9359                     0.9370        0.2889            0.7525                     0.7515        0.5332  0.0000  1.4342\n",
      "     30            0.9370                     0.9397        0.3070            0.7641                     \u001b[94m0.7666\u001b[0m        0.5268  0.0000  1.4312\n",
      "     31            0.9381                     0.9402        \u001b[35m0.2803\u001b[0m            0.7496                     0.7507        0.5291  0.0000  1.4516\n",
      "     32            0.9413                     0.9424        0.2840            0.7511                     0.7511        0.5311  0.0000  1.4674\n",
      "     33            0.9413                     0.9422        \u001b[35m0.2748\u001b[0m            0.7540                     0.7529        0.5307  0.0000  1.4441\n",
      "     34            0.9424                     0.9434        0.2809            0.7583                     0.7571        0.5309  0.0000  1.4290\n",
      "     35            0.9413                     0.9427        \u001b[35m0.2735\u001b[0m            0.7569                     0.7573        0.5301  0.0000  1.4225\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6079\u001b[0m                     \u001b[32m0.6335\u001b[0m        \u001b[35m1.1987\u001b[0m            \u001b[31m0.6078\u001b[0m                     \u001b[94m0.6320\u001b[0m        \u001b[36m0.7668\u001b[0m  0.0006  1.4352\n",
      "      2            \u001b[36m0.7035\u001b[0m                     \u001b[32m0.7065\u001b[0m        \u001b[35m0.9158\u001b[0m            \u001b[31m0.6397\u001b[0m                     \u001b[94m0.6387\u001b[0m        \u001b[36m0.6411\u001b[0m  0.0006  1.4631\n",
      "      3            \u001b[36m0.7129\u001b[0m                     \u001b[32m0.7160\u001b[0m        \u001b[35m0.8245\u001b[0m            \u001b[31m0.6440\u001b[0m                     \u001b[94m0.6447\u001b[0m        0.6533  0.0006  1.4508\n",
      "      4            0.6970                     0.7138        \u001b[35m0.7154\u001b[0m            \u001b[31m0.6512\u001b[0m                     \u001b[94m0.6672\u001b[0m        0.6739  0.0006  1.4574\n",
      "      5            \u001b[36m0.7719\u001b[0m                     \u001b[32m0.7780\u001b[0m        \u001b[35m0.6975\u001b[0m            \u001b[31m0.6816\u001b[0m                     \u001b[94m0.6854\u001b[0m        \u001b[36m0.5925\u001b[0m  0.0006  1.4853\n",
      "      6            \u001b[36m0.7755\u001b[0m                     \u001b[32m0.7868\u001b[0m        \u001b[35m0.6675\u001b[0m            0.6700                     0.6791        0.5950  0.0006  1.4900\n",
      "      7            0.7661                     0.7803        \u001b[35m0.6171\u001b[0m            \u001b[31m0.6889\u001b[0m                     \u001b[94m0.7031\u001b[0m        0.6018  0.0006  1.4731\n",
      "      8            \u001b[36m0.8067\u001b[0m                     \u001b[32m0.8045\u001b[0m        \u001b[35m0.5801\u001b[0m            0.6874                     0.6814        0.6004  0.0006  1.4691\n",
      "      9            \u001b[36m0.8345\u001b[0m                     \u001b[32m0.8349\u001b[0m        \u001b[35m0.5564\u001b[0m            \u001b[31m0.6903\u001b[0m                     0.6861        \u001b[36m0.5837\u001b[0m  0.0005  1.4591\n",
      "     10            \u001b[36m0.8360\u001b[0m                     \u001b[32m0.8413\u001b[0m        \u001b[35m0.5286\u001b[0m            \u001b[31m0.6975\u001b[0m                     0.6996        \u001b[36m0.5671\u001b[0m  0.0005  1.4646\n",
      "     11            \u001b[36m0.8432\u001b[0m                     \u001b[32m0.8479\u001b[0m        \u001b[35m0.5097\u001b[0m            \u001b[31m0.7062\u001b[0m                     \u001b[94m0.7065\u001b[0m        \u001b[36m0.5590\u001b[0m  0.0005  1.4641\n",
      "     12            \u001b[36m0.8650\u001b[0m                     \u001b[32m0.8691\u001b[0m        \u001b[35m0.4845\u001b[0m            \u001b[31m0.7149\u001b[0m                     \u001b[94m0.7147\u001b[0m        0.5642  0.0005  1.4726\n",
      "     13            \u001b[36m0.8773\u001b[0m                     \u001b[32m0.8776\u001b[0m        \u001b[35m0.4594\u001b[0m            0.7106                     0.7078        0.5599  0.0005  1.4751\n",
      "     14            \u001b[36m0.8776\u001b[0m                     \u001b[32m0.8812\u001b[0m        \u001b[35m0.4366\u001b[0m            \u001b[31m0.7221\u001b[0m                     \u001b[94m0.7231\u001b[0m        \u001b[36m0.5541\u001b[0m  0.0004  1.4162\n",
      "     15            \u001b[36m0.8917\u001b[0m                     \u001b[32m0.8920\u001b[0m        \u001b[35m0.4179\u001b[0m            \u001b[31m0.7366\u001b[0m                     \u001b[94m0.7344\u001b[0m        \u001b[36m0.5525\u001b[0m  0.0004  1.4282\n",
      "     16            0.8881                     0.8915        \u001b[35m0.4071\u001b[0m            0.7265                     0.7261        0.5558  0.0004  1.4501\n",
      "     17            \u001b[36m0.8961\u001b[0m                     \u001b[32m0.9017\u001b[0m        \u001b[35m0.3866\u001b[0m            0.7164                     0.7202        0.5617  0.0003  1.4380\n",
      "     18            \u001b[36m0.9113\u001b[0m                     \u001b[32m0.9138\u001b[0m        \u001b[35m0.3788\u001b[0m            0.7192                     0.7187        0.5553  0.0003  1.4401\n",
      "     19            0.9070                     0.9096        \u001b[35m0.3646\u001b[0m            0.7221                     0.7231        0.5576  0.0003  1.4362\n",
      "     20            \u001b[36m0.9167\u001b[0m                     \u001b[32m0.9193\u001b[0m        \u001b[35m0.3566\u001b[0m            0.7250                     0.7245        0.5619  0.0003  1.4362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     21            \u001b[36m0.9171\u001b[0m                     \u001b[32m0.9203\u001b[0m        \u001b[35m0.3485\u001b[0m            0.7178                     0.7188        0.5693  0.0002  1.4322\n",
      "     22            \u001b[36m0.9280\u001b[0m                     \u001b[32m0.9301\u001b[0m        \u001b[35m0.3356\u001b[0m            0.7192                     0.7190        0.5714  0.0002  1.4508\n",
      "     23            0.9272                     0.9295        0.3362            0.7106                     0.7093        0.5695  0.0002  1.4372\n",
      "     24            \u001b[36m0.9334\u001b[0m                     \u001b[32m0.9349\u001b[0m        \u001b[35m0.3211\u001b[0m            0.7091                     0.7062        0.5667  0.0001  1.4204\n",
      "     25            \u001b[36m0.9341\u001b[0m                     0.9345        \u001b[35m0.2943\u001b[0m            0.7106                     0.7069        0.5842  0.0001  1.4322\n",
      "     26            0.9312                     0.9344        0.3131            0.7265                     0.7291        0.5747  0.0001  1.4202\n",
      "     27            \u001b[36m0.9457\u001b[0m                     \u001b[32m0.9471\u001b[0m        0.3001            0.7106                     0.7090        0.5759  0.0001  1.4501\n",
      "     28            0.9388                     0.9416        \u001b[35m0.2838\u001b[0m            0.7135                     0.7137        0.5750  0.0001  1.4332\n",
      "     29            \u001b[36m0.9461\u001b[0m                     \u001b[32m0.9472\u001b[0m        0.2946            0.7149                     0.7129        0.5817  0.0000  1.4194\n",
      "     30            0.9417                     0.9440        0.2849            0.7135                     0.7128        0.5767  0.0000  1.4322\n",
      "     31            0.9428                     0.9448        \u001b[35m0.2834\u001b[0m            0.7178                     0.7158        0.5763  0.0000  1.4451\n",
      "     32            0.9461                     \u001b[32m0.9473\u001b[0m        \u001b[35m0.2822\u001b[0m            0.7149                     0.7117        0.5786  0.0000  1.4299\n",
      "     33            \u001b[36m0.9471\u001b[0m                     \u001b[32m0.9483\u001b[0m        \u001b[35m0.2730\u001b[0m            0.7149                     0.7117        0.5791  0.0000  1.4451\n",
      "     34            0.9432                     0.9455        0.2757            0.7120                     0.7115        0.5754  0.0000  1.4483\n",
      "     35            0.9453                     0.9467        0.2731            0.7149                     0.7120        0.5784  0.0000  1.4571\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6401\u001b[0m                     \u001b[32m0.6227\u001b[0m        \u001b[35m1.3233\u001b[0m            \u001b[31m0.5832\u001b[0m                     \u001b[94m0.5646\u001b[0m        \u001b[36m0.7651\u001b[0m  0.0006  1.4337\n",
      "      2            \u001b[36m0.6745\u001b[0m                     \u001b[32m0.6874\u001b[0m        \u001b[35m0.9415\u001b[0m            \u001b[31m0.6397\u001b[0m                     \u001b[94m0.6531\u001b[0m        \u001b[36m0.6719\u001b[0m  0.0006  1.4611\n",
      "      3            \u001b[36m0.7107\u001b[0m                     \u001b[32m0.7201\u001b[0m        \u001b[35m0.8198\u001b[0m            \u001b[31m0.6599\u001b[0m                     \u001b[94m0.6691\u001b[0m        \u001b[36m0.6278\u001b[0m  0.0006  1.4357\n",
      "      4            \u001b[36m0.7379\u001b[0m                     \u001b[32m0.7411\u001b[0m        \u001b[35m0.7447\u001b[0m            \u001b[31m0.6744\u001b[0m                     \u001b[94m0.6774\u001b[0m        \u001b[36m0.6084\u001b[0m  0.0006  1.4541\n",
      "      5            \u001b[36m0.7701\u001b[0m                     \u001b[32m0.7788\u001b[0m        \u001b[35m0.7129\u001b[0m            0.6686                     0.6772        0.6118  0.0006  1.4382\n",
      "      6            \u001b[36m0.7940\u001b[0m                     \u001b[32m0.7847\u001b[0m        \u001b[35m0.6453\u001b[0m            0.6570                     0.6442        0.6208  0.0006  1.4411\n",
      "      7            0.7864                     \u001b[32m0.7954\u001b[0m        \u001b[35m0.6360\u001b[0m            \u001b[31m0.6773\u001b[0m                     \u001b[94m0.6857\u001b[0m        \u001b[36m0.6075\u001b[0m  0.0006  1.4312\n",
      "      8            \u001b[36m0.8114\u001b[0m                     \u001b[32m0.8112\u001b[0m        \u001b[35m0.5766\u001b[0m            \u001b[31m0.6816\u001b[0m                     0.6824        \u001b[36m0.5979\u001b[0m  0.0006  1.4316\n",
      "      9            0.8020                     \u001b[32m0.8146\u001b[0m        \u001b[35m0.5723\u001b[0m            \u001b[31m0.6831\u001b[0m                     \u001b[94m0.6988\u001b[0m        0.5993  0.0005  1.4352\n",
      "     10            \u001b[36m0.8400\u001b[0m                     \u001b[32m0.8400\u001b[0m        \u001b[35m0.5402\u001b[0m            \u001b[31m0.6961\u001b[0m                     0.6962        \u001b[36m0.5776\u001b[0m  0.0005  1.4292\n",
      "     11            \u001b[36m0.8613\u001b[0m                     \u001b[32m0.8622\u001b[0m        0.5493            0.6773                     0.6761        \u001b[36m0.5642\u001b[0m  0.0005  1.4317\n",
      "     12            0.8501                     0.8557        \u001b[35m0.4994\u001b[0m            0.6802                     0.6835        0.5729  0.0005  1.4463\n",
      "     13            0.8411                     0.8458        0.5058            \u001b[31m0.6975\u001b[0m                     \u001b[94m0.7032\u001b[0m        0.5991  0.0005  1.4302\n",
      "     14            \u001b[36m0.8646\u001b[0m                     \u001b[32m0.8687\u001b[0m        \u001b[35m0.4535\u001b[0m            0.6845                     0.6905        0.5883  0.0004  1.4461\n",
      "     15            \u001b[36m0.8899\u001b[0m                     \u001b[32m0.8918\u001b[0m        \u001b[35m0.4366\u001b[0m            0.6787                     0.6780        0.5844  0.0004  1.4681\n",
      "     16            0.8744                     0.8790        \u001b[35m0.4184\u001b[0m            \u001b[31m0.7077\u001b[0m                     \u001b[94m0.7127\u001b[0m        0.5985  0.0004  1.4731\n",
      "     17            0.8856                     0.8825        \u001b[35m0.4100\u001b[0m            \u001b[31m0.7091\u001b[0m                     0.7014        0.5701  0.0003  1.4611\n",
      "     18            \u001b[36m0.8979\u001b[0m                     \u001b[32m0.8977\u001b[0m        \u001b[35m0.3804\u001b[0m            0.6932                     0.6893        0.5796  0.0003  1.4739\n",
      "     19            \u001b[36m0.9106\u001b[0m                     \u001b[32m0.9113\u001b[0m        0.3961            0.7033                     0.7012        \u001b[36m0.5603\u001b[0m  0.0003  1.4591\n",
      "     20            \u001b[36m0.9171\u001b[0m                     \u001b[32m0.9169\u001b[0m        \u001b[35m0.3644\u001b[0m            0.7062                     0.7023        0.5656  0.0003  1.4457\n",
      "     21            0.9138                     \u001b[32m0.9184\u001b[0m        0.3694            0.6932                     0.6962        0.5816  0.0002  1.4459\n",
      "     22            \u001b[36m0.9203\u001b[0m                     \u001b[32m0.9224\u001b[0m        \u001b[35m0.3536\u001b[0m            0.6990                     0.6997        0.5633  0.0002  1.4504\n",
      "     23            \u001b[36m0.9236\u001b[0m                     0.9223        \u001b[35m0.3343\u001b[0m            0.6889                     0.6836        0.5833  0.0002  1.4421\n",
      "     24            \u001b[36m0.9348\u001b[0m                     \u001b[32m0.9359\u001b[0m        \u001b[35m0.3310\u001b[0m            0.6889                     0.6866        0.5749  0.0001  1.4601\n",
      "     25            0.9287                     0.9315        \u001b[35m0.3184\u001b[0m            0.7019                     0.7017        0.5666  0.0001  1.4536\n",
      "     26            0.9330                     0.9353        \u001b[35m0.3054\u001b[0m            0.7077                     0.7067        0.5705  0.0001  1.4471\n",
      "     27            0.9334                     0.9359        0.3106            0.7077                     0.7076        0.5719  0.0001  1.4501\n",
      "     28            \u001b[36m0.9370\u001b[0m                     \u001b[32m0.9386\u001b[0m        \u001b[35m0.3020\u001b[0m            0.7077                     0.7064        0.5741  0.0001  1.4421\n",
      "     29            0.9341                     0.9368        \u001b[35m0.2950\u001b[0m            0.7033                     0.7036        0.5704  0.0000  1.4491\n",
      "     30            0.9363                     \u001b[32m0.9387\u001b[0m        \u001b[35m0.2871\u001b[0m            0.7033                     0.7027        0.5776  0.0000  1.4407\n",
      "     31            \u001b[36m0.9374\u001b[0m                     0.9376        0.2919            0.7019                     0.6975        0.5825  0.0000  1.4611\n",
      "     32            \u001b[36m0.9413\u001b[0m                     \u001b[32m0.9432\u001b[0m        \u001b[35m0.2868\u001b[0m            0.7062                     0.7041        0.5787  0.0000  1.4302\n",
      "     33            \u001b[36m0.9417\u001b[0m                     \u001b[32m0.9440\u001b[0m        0.3056            0.7048                     0.7037        0.5772  0.0000  1.4411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34            0.9417                     0.9440        \u001b[35m0.2847\u001b[0m            0.7048                     0.7040        0.5764  0.0000  1.4471\n",
      "     35            0.9399                     0.9428        0.2898            0.7048                     0.7061        0.5772  0.0000  1.4541\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6398\u001b[0m                     \u001b[32m0.6543\u001b[0m        \u001b[35m1.2616\u001b[0m            \u001b[31m0.5962\u001b[0m                     \u001b[94m0.6080\u001b[0m        \u001b[36m0.7299\u001b[0m  0.0006  1.4299\n",
      "      2            \u001b[36m0.6618\u001b[0m                     \u001b[32m0.6683\u001b[0m        \u001b[35m0.8769\u001b[0m            \u001b[31m0.6107\u001b[0m                     \u001b[94m0.6118\u001b[0m        \u001b[36m0.7097\u001b[0m  0.0006  1.4382\n",
      "      3            \u001b[36m0.7042\u001b[0m                     \u001b[32m0.7138\u001b[0m        \u001b[35m0.8152\u001b[0m            \u001b[31m0.6339\u001b[0m                     \u001b[94m0.6451\u001b[0m        \u001b[36m0.6870\u001b[0m  0.0006  1.4342\n",
      "      4            0.6901                     0.7090        \u001b[35m0.7487\u001b[0m            0.6223                     0.6425        0.7288  0.0006  1.4187\n",
      "      5            \u001b[36m0.7509\u001b[0m                     \u001b[32m0.7544\u001b[0m        \u001b[35m0.6994\u001b[0m            \u001b[31m0.6671\u001b[0m                     \u001b[94m0.6648\u001b[0m        \u001b[36m0.6265\u001b[0m  0.0006  1.4560\n",
      "      6            0.7386                     0.7233        \u001b[35m0.6340\u001b[0m            0.6411                     0.6186        0.7129  0.0006  1.4990\n",
      "      7            \u001b[36m0.7994\u001b[0m                     \u001b[32m0.8035\u001b[0m        \u001b[35m0.6183\u001b[0m            \u001b[31m0.6860\u001b[0m                     \u001b[94m0.6867\u001b[0m        \u001b[36m0.6063\u001b[0m  0.0006  1.4426\n",
      "      8            0.7904                     0.7858        \u001b[35m0.5993\u001b[0m            0.6686                     0.6577        0.6533  0.0006  1.4620\n",
      "      9            \u001b[36m0.8219\u001b[0m                     \u001b[32m0.8285\u001b[0m        \u001b[35m0.5914\u001b[0m            \u001b[31m0.7077\u001b[0m                     \u001b[94m0.7130\u001b[0m        \u001b[36m0.5798\u001b[0m  0.0005  1.4451\n",
      "     10            \u001b[36m0.8248\u001b[0m                     \u001b[32m0.8307\u001b[0m        \u001b[35m0.5356\u001b[0m            0.6946                     0.6997        0.5877  0.0005  1.4461\n",
      "     11            \u001b[36m0.8349\u001b[0m                     \u001b[32m0.8379\u001b[0m        \u001b[35m0.5215\u001b[0m            \u001b[31m0.7106\u001b[0m                     0.7105        0.5908  0.0005  1.4581\n",
      "     12            \u001b[36m0.8454\u001b[0m                     \u001b[32m0.8515\u001b[0m        \u001b[35m0.4729\u001b[0m            0.6903                     0.6972        \u001b[36m0.5744\u001b[0m  0.0005  1.4360\n",
      "     13            \u001b[36m0.8472\u001b[0m                     0.8491        \u001b[35m0.4654\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7270\u001b[0m        \u001b[36m0.5707\u001b[0m  0.0005  1.4652\n",
      "     14            \u001b[36m0.8497\u001b[0m                     \u001b[32m0.8553\u001b[0m        \u001b[35m0.4524\u001b[0m            0.6961                     0.6992        0.5847  0.0004  1.4812\n",
      "     15            \u001b[36m0.8628\u001b[0m                     \u001b[32m0.8678\u001b[0m        \u001b[35m0.4428\u001b[0m            0.7164                     0.7196        \u001b[36m0.5608\u001b[0m  0.0004  1.4636\n",
      "     16            0.8552                     0.8645        \u001b[35m0.4032\u001b[0m            0.6918                     0.7009        0.5862  0.0004  1.4202\n",
      "     17            \u001b[36m0.8885\u001b[0m                     \u001b[32m0.8906\u001b[0m        0.4081            0.7135                     0.7134        0.5743  0.0003  1.4541\n",
      "     18            0.8885                     \u001b[32m0.8939\u001b[0m        \u001b[35m0.3722\u001b[0m            0.7221                     0.7255        0.5690  0.0003  1.4312\n",
      "     19            0.8870                     \u001b[32m0.8942\u001b[0m        0.3868            0.6975                     0.7044        0.5901  0.0003  1.4160\n",
      "     20            0.8823                     0.8892        \u001b[35m0.3714\u001b[0m            0.6874                     0.6937        0.5934  0.0003  1.4586\n",
      "     21            \u001b[36m0.9175\u001b[0m                     \u001b[32m0.9187\u001b[0m        \u001b[35m0.3425\u001b[0m            0.7265                     0.7222        0.5748  0.0002  1.5169\n",
      "     22            0.9164                     0.9177        \u001b[35m0.3402\u001b[0m            0.7221                     0.7198        0.5791  0.0002  1.4431\n",
      "     23            0.9156                     0.9120        \u001b[35m0.3196\u001b[0m            \u001b[31m0.7294\u001b[0m                     0.7167        0.6108  0.0002  1.5508\n",
      "     24            \u001b[36m0.9247\u001b[0m                     \u001b[32m0.9248\u001b[0m        0.3330            0.7265                     0.7207        0.5767  0.0001  1.4578\n",
      "     25            \u001b[36m0.9287\u001b[0m                     \u001b[32m0.9303\u001b[0m        \u001b[35m0.3161\u001b[0m            0.7178                     0.7149        0.5739  0.0001  1.5287\n",
      "     26            \u001b[36m0.9377\u001b[0m                     \u001b[32m0.9379\u001b[0m        \u001b[35m0.3127\u001b[0m            \u001b[31m0.7308\u001b[0m                     0.7264        0.5784  0.0001  1.4766\n",
      "     27            0.9377                     \u001b[32m0.9380\u001b[0m        \u001b[35m0.2879\u001b[0m            \u001b[31m0.7352\u001b[0m                     \u001b[94m0.7307\u001b[0m        0.5829  0.0001  1.4621\n",
      "     28            0.9323                     0.9336        0.2988            0.7279                     0.7244        0.5744  0.0001  1.4818\n",
      "     29            0.9352                     0.9377        0.2926            0.7279                     0.7271        0.5742  0.0000  1.4682\n",
      "     30            0.9348                     0.9376        0.2924            0.7308                     \u001b[94m0.7313\u001b[0m        0.5705  0.0000  1.4741\n",
      "     31            0.9377                     \u001b[32m0.9386\u001b[0m        \u001b[35m0.2874\u001b[0m            0.7308                     0.7264        0.5746  0.0000  1.5127\n",
      "     32            0.9363                     \u001b[32m0.9393\u001b[0m        0.2927            0.7221                     0.7222        0.5707  0.0000  1.4840\n",
      "     33            0.9377                     \u001b[32m0.9399\u001b[0m        \u001b[35m0.2872\u001b[0m            0.7294                     0.7275        0.5721  0.0000  1.4802\n",
      "     34            0.9377                     0.9396        \u001b[35m0.2848\u001b[0m            0.7308                     0.7283        0.5726  0.0000  1.4755\n",
      "     35            0.9377                     0.9386        0.2848            0.7294                     0.7251        0.5751  0.0000  1.4215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7982\u001b[0m                     \u001b[32m0.5458\u001b[0m        \u001b[35m1.2230\u001b[0m            \u001b[31m0.7880\u001b[0m                     \u001b[94m0.5218\u001b[0m        \u001b[36m1.0496\u001b[0m  0.0006  3.5098\n",
      "      2            0.6694                     \u001b[32m0.6914\u001b[0m        \u001b[35m0.8499\u001b[0m            0.6359                     \u001b[94m0.6455\u001b[0m        \u001b[36m0.6713\u001b[0m  0.0006  3.1465\n",
      "      3            0.7681                     \u001b[32m0.7035\u001b[0m        \u001b[35m0.7734\u001b[0m            0.7236                     0.6360        0.6793  0.0006  3.1097\n",
      "      4            0.7844                     0.6563        \u001b[35m0.7403\u001b[0m            0.7369                     0.5900        0.7682  0.0006  3.1157\n",
      "      5            0.7164                     \u001b[32m0.7628\u001b[0m        \u001b[35m0.7277\u001b[0m            0.6724                     \u001b[94m0.6882\u001b[0m        \u001b[36m0.6006\u001b[0m  0.0006  3.3536\n",
      "      6            0.6970                     \u001b[32m0.7656\u001b[0m        \u001b[35m0.6516\u001b[0m            0.6598                     \u001b[94m0.6922\u001b[0m        0.6157  0.0006  3.2515\n",
      "      7            0.7601                     0.7568        \u001b[35m0.6290\u001b[0m            0.7183                     0.6810        0.6431  0.0006  3.1877\n",
      "      8            0.7360                     0.6811        \u001b[35m0.6109\u001b[0m            0.7063                     0.6240        0.8074  0.0006  3.2699\n",
      "      9            \u001b[36m0.8061\u001b[0m                     \u001b[32m0.8020\u001b[0m        0.6319            0.7395                     \u001b[94m0.6969\u001b[0m        \u001b[36m0.5811\u001b[0m  0.0005  3.2224\n",
      "     10            \u001b[36m0.8272\u001b[0m                     \u001b[32m0.8192\u001b[0m        \u001b[35m0.5606\u001b[0m            0.7608                     \u001b[94m0.7010\u001b[0m        \u001b[36m0.5782\u001b[0m  0.0005  3.4882\n",
      "     11            0.8198                     \u001b[32m0.8264\u001b[0m        \u001b[35m0.5306\u001b[0m            0.7442                     0.6880        0.5855  0.0005  3.4449\n",
      "     12            0.8201                     0.8127        \u001b[35m0.5121\u001b[0m            0.7375                     0.6840        0.6215  0.0005  3.6890\n",
      "     13            0.8131                     \u001b[32m0.8421\u001b[0m        0.5549            0.7269                     0.6863        0.5826  0.0005  3.3901\n",
      "     14            0.8199                     \u001b[32m0.8451\u001b[0m        \u001b[35m0.4578\u001b[0m            0.7535                     \u001b[94m0.7214\u001b[0m        \u001b[36m0.5725\u001b[0m  0.0004  3.5700\n",
      "     15            0.8145                     \u001b[32m0.8539\u001b[0m        \u001b[35m0.4570\u001b[0m            0.7336                     0.7152        \u001b[36m0.5717\u001b[0m  0.0004  3.3897\n",
      "     16            0.8218                     \u001b[32m0.8594\u001b[0m        0.4570            0.7302                     0.7087        0.5766  0.0004  3.2600\n",
      "     17            \u001b[36m0.8575\u001b[0m                     0.8562        0.4654            0.7701                     0.6994        0.5982  0.0003  3.2136\n",
      "     18            \u001b[36m0.8606\u001b[0m                     \u001b[32m0.8688\u001b[0m        \u001b[35m0.4316\u001b[0m            0.7601                     0.6831        0.6041  0.0003  3.1641\n",
      "     19            0.7854                     0.8263        \u001b[35m0.4213\u001b[0m            0.6990                     0.6737        0.6611  0.0003  3.2112\n",
      "     20            \u001b[36m0.8661\u001b[0m                     \u001b[32m0.8717\u001b[0m        0.4538            0.7694                     0.7077        0.6083  0.0003  3.1759\n",
      "     21            \u001b[36m0.8885\u001b[0m                     \u001b[32m0.8799\u001b[0m        \u001b[35m0.3986\u001b[0m            0.7854                     0.7087        0.6123  0.0002  3.1596\n",
      "     22            \u001b[36m0.8904\u001b[0m                     \u001b[32m0.9037\u001b[0m        \u001b[35m0.3802\u001b[0m            0.7774                     0.7068        0.5865  0.0002  3.5567\n",
      "     23            0.8852                     0.8987        \u001b[35m0.3721\u001b[0m            0.7674                     0.7022        0.5844  0.0002  3.1791\n",
      "     24            0.8631                     0.9010        0.3747            0.7495                     \u001b[94m0.7219\u001b[0m        0.5718  0.0001  3.1696\n",
      "     25            \u001b[36m0.8944\u001b[0m                     \u001b[32m0.9094\u001b[0m        \u001b[35m0.3695\u001b[0m            0.7741                     0.7047        0.5938  0.0001  3.3017\n",
      "     26            \u001b[36m0.9012\u001b[0m                     \u001b[32m0.9154\u001b[0m        \u001b[35m0.3501\u001b[0m            0.7874                     0.7114        0.5951  0.0001  3.3003\n",
      "     27            0.8995                     \u001b[32m0.9158\u001b[0m        \u001b[35m0.3370\u001b[0m            0.7827                     0.7129        0.5911  0.0001  3.4951\n",
      "     28            \u001b[36m0.9068\u001b[0m                     0.9144        0.3383            \u001b[31m0.7900\u001b[0m                     0.7130        0.6013  0.0001  3.2929\n",
      "     29            0.9030                     \u001b[32m0.9169\u001b[0m        0.3377            0.7814                     0.7106        0.5970  0.0000  3.5924\n",
      "     30            0.9013                     \u001b[32m0.9177\u001b[0m        \u001b[35m0.3289\u001b[0m            0.7867                     0.7197        0.5989  0.0000  3.6052\n",
      "     31            0.9025                     0.9176        \u001b[35m0.3192\u001b[0m            0.7794                     0.7094        0.5901  0.0000  3.7124\n",
      "     32            \u001b[36m0.9106\u001b[0m                     \u001b[32m0.9204\u001b[0m        0.3228            0.7887                     0.7122        0.5976  0.0000  3.6443\n",
      "     33            0.8983                     0.9188        0.3242            0.7767                     0.7151        0.5851  0.0000  3.6318\n",
      "     34            0.9058                     \u001b[32m0.9208\u001b[0m        0.3278            0.7874                     0.7143        0.5926  0.0000  3.6847\n",
      "     35            0.9056                     0.9207        \u001b[35m0.3165\u001b[0m            0.7854                     0.7131        0.5921  0.0000  3.6857\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7199\u001b[0m                     \u001b[32m0.6548\u001b[0m        \u001b[35m1.2160\u001b[0m            \u001b[31m0.7156\u001b[0m                     \u001b[94m0.6385\u001b[0m        \u001b[36m0.6792\u001b[0m  0.0006  3.8812\n",
      "      2            \u001b[36m0.7631\u001b[0m                     \u001b[32m0.6738\u001b[0m        \u001b[35m0.8908\u001b[0m            \u001b[31m0.7621\u001b[0m                     \u001b[94m0.6551\u001b[0m        \u001b[36m0.6603\u001b[0m  0.0006  3.6047\n",
      "      3            0.5228                     0.6556        \u001b[35m0.7602\u001b[0m            0.4897                     0.6194        0.7335  0.0006  3.2303\n",
      "      4            \u001b[36m0.7978\u001b[0m                     \u001b[32m0.7318\u001b[0m        0.8152            \u001b[31m0.7681\u001b[0m                     \u001b[94m0.6748\u001b[0m        \u001b[36m0.6152\u001b[0m  0.0006  3.2318\n",
      "      5            0.7510                     \u001b[32m0.7538\u001b[0m        \u001b[35m0.7209\u001b[0m            0.7090                     \u001b[94m0.6827\u001b[0m        \u001b[36m0.5995\u001b[0m  0.0006  3.2357\n",
      "      6            0.7834                     0.7384        \u001b[35m0.6488\u001b[0m            0.7502                     0.6697        0.6431  0.0006  3.2513\n",
      "      7            0.7939                     \u001b[32m0.7956\u001b[0m        \u001b[35m0.6338\u001b[0m            0.7209                     0.6826        \u001b[36m0.5988\u001b[0m  0.0006  3.4505\n",
      "      8            0.7331                     0.7711        \u001b[35m0.5816\u001b[0m            0.6651                     0.6647        0.6386  0.0006  3.2997\n",
      "      9            0.7754                     \u001b[32m0.8129\u001b[0m        0.5913            0.7103                     \u001b[94m0.7068\u001b[0m        \u001b[36m0.5749\u001b[0m  0.0005  3.3189\n",
      "     10            \u001b[36m0.8113\u001b[0m                     \u001b[32m0.8333\u001b[0m        \u001b[35m0.5326\u001b[0m            0.7429                     \u001b[94m0.7120\u001b[0m        \u001b[36m0.5702\u001b[0m  0.0005  3.3072\n",
      "     11            \u001b[36m0.8249\u001b[0m                     0.8302        \u001b[35m0.5089\u001b[0m            0.7375                     0.6957        0.5870  0.0005  3.3202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12            0.7930                     \u001b[32m0.8342\u001b[0m        0.5171            0.7116                     \u001b[94m0.7150\u001b[0m        0.5817  0.0005  3.3869\n",
      "     13            \u001b[36m0.8512\u001b[0m                     \u001b[32m0.8433\u001b[0m        0.5113            \u001b[31m0.7767\u001b[0m                     0.7122        0.5804  0.0005  3.7362\n",
      "     14            0.8355                     0.8400        \u001b[35m0.4680\u001b[0m            0.7635                     \u001b[94m0.7260\u001b[0m        \u001b[36m0.5698\u001b[0m  0.0004  3.6114\n",
      "     15            0.8432                     \u001b[32m0.8615\u001b[0m        0.4868            0.7528                     0.7210        0.5742  0.0004  3.6229\n",
      "     16            \u001b[36m0.8684\u001b[0m                     0.8593        \u001b[35m0.4400\u001b[0m            \u001b[31m0.7860\u001b[0m                     0.7193        0.5936  0.0004  3.7101\n",
      "     17            0.8344                     0.8601        0.4441            0.7522                     0.7235        \u001b[36m0.5604\u001b[0m  0.0003  3.3331\n",
      "     18            0.8510                     \u001b[32m0.8757\u001b[0m        \u001b[35m0.4265\u001b[0m            0.7362                     0.7095        0.5715  0.0003  3.3846\n",
      "     19            0.8653                     \u001b[32m0.8851\u001b[0m        0.4274            0.7641                     0.7221        0.5848  0.0003  3.3209\n",
      "     20            \u001b[36m0.8814\u001b[0m                     0.8745        \u001b[35m0.4122\u001b[0m            \u001b[31m0.7987\u001b[0m                     \u001b[94m0.7285\u001b[0m        0.5932  0.0003  2.9711\n",
      "     21            \u001b[36m0.8834\u001b[0m                     \u001b[32m0.8881\u001b[0m        \u001b[35m0.4098\u001b[0m            0.7887                     0.7253        0.6057  0.0002  2.9415\n",
      "     22            0.8822                     \u001b[32m0.8885\u001b[0m        \u001b[35m0.3860\u001b[0m            0.7920                     \u001b[94m0.7361\u001b[0m        0.5905  0.0002  2.9451\n",
      "     23            0.8827                     \u001b[32m0.9064\u001b[0m        \u001b[35m0.3834\u001b[0m            0.7701                     0.7301        0.5797  0.0002  3.1743\n",
      "     24            \u001b[36m0.9056\u001b[0m                     \u001b[32m0.9082\u001b[0m        \u001b[35m0.3725\u001b[0m            0.7934                     0.7165        0.5939  0.0001  3.0080\n",
      "     25            0.8919                     \u001b[32m0.9086\u001b[0m        \u001b[35m0.3526\u001b[0m            0.7827                     0.7275        0.5816  0.0001  3.3043\n",
      "     26            \u001b[36m0.9076\u001b[0m                     \u001b[32m0.9157\u001b[0m        \u001b[35m0.3420\u001b[0m            0.7973                     0.7233        0.5929  0.0001  3.2722\n",
      "     27            0.9035                     0.9146        0.3457            0.7907                     0.7251        0.5886  0.0001  3.2924\n",
      "     28            0.8944                     \u001b[32m0.9178\u001b[0m        \u001b[35m0.3324\u001b[0m            0.7767                     0.7224        0.5817  0.0001  3.3231\n",
      "     29            0.9028                     \u001b[32m0.9186\u001b[0m        \u001b[35m0.3295\u001b[0m            0.7887                     0.7268        0.5929  0.0000  3.2972\n",
      "     30            0.9045                     \u001b[32m0.9233\u001b[0m        \u001b[35m0.3275\u001b[0m            0.7854                     0.7248        0.5881  0.0000  3.2986\n",
      "     31            \u001b[36m0.9085\u001b[0m                     0.9198        \u001b[35m0.3265\u001b[0m            0.7947                     0.7290        0.5919  0.0000  3.3018\n",
      "     32            0.9043                     \u001b[32m0.9235\u001b[0m        \u001b[35m0.3205\u001b[0m            0.7854                     0.7262        0.5887  0.0000  3.2943\n",
      "     33            \u001b[36m0.9123\u001b[0m                     0.9232        \u001b[35m0.3141\u001b[0m            0.7947                     0.7275        0.5946  0.0000  3.1369\n",
      "     34            0.9103                     0.9224        0.3219            0.7953                     0.7294        0.5933  0.0000  3.1866\n",
      "     35            0.9121                     0.9231        0.3215            0.7940                     0.7271        0.5949  0.0000  3.2232\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6028\u001b[0m                     \u001b[32m0.6392\u001b[0m        \u001b[35m1.2220\u001b[0m            \u001b[31m0.5462\u001b[0m                     \u001b[94m0.5719\u001b[0m        \u001b[36m0.7136\u001b[0m  0.0006  3.0432\n",
      "      2            \u001b[36m0.6311\u001b[0m                     \u001b[32m0.6992\u001b[0m        \u001b[35m0.8264\u001b[0m            \u001b[31m0.5874\u001b[0m                     \u001b[94m0.6467\u001b[0m        \u001b[36m0.6350\u001b[0m  0.0006  3.1209\n",
      "      3            \u001b[36m0.7460\u001b[0m                     \u001b[32m0.7032\u001b[0m        \u001b[35m0.7557\u001b[0m            \u001b[31m0.7136\u001b[0m                     \u001b[94m0.6592\u001b[0m        0.6493  0.0006  3.1036\n",
      "      4            \u001b[36m0.7565\u001b[0m                     \u001b[32m0.7590\u001b[0m        \u001b[35m0.7124\u001b[0m            0.6997                     \u001b[94m0.6668\u001b[0m        \u001b[36m0.6022\u001b[0m  0.0006  3.2118\n",
      "      5            \u001b[36m0.8111\u001b[0m                     \u001b[32m0.7648\u001b[0m        \u001b[35m0.6387\u001b[0m            \u001b[31m0.7455\u001b[0m                     0.6625        0.6150  0.0006  3.1458\n",
      "      6            \u001b[36m0.8166\u001b[0m                     0.7586        \u001b[35m0.6335\u001b[0m            \u001b[31m0.7648\u001b[0m                     \u001b[94m0.6859\u001b[0m        0.6057  0.0006  3.1418\n",
      "      7            0.7179                     \u001b[32m0.7703\u001b[0m        \u001b[35m0.6048\u001b[0m            0.6359                     0.6572        0.6432  0.0006  3.1556\n",
      "      8            0.7714                     \u001b[32m0.7973\u001b[0m        \u001b[35m0.5758\u001b[0m            0.6837                     0.6819        \u001b[36m0.6015\u001b[0m  0.0006  3.1112\n",
      "      9            0.8101                     \u001b[32m0.8103\u001b[0m        \u001b[35m0.5440\u001b[0m            0.7296                     \u001b[94m0.6996\u001b[0m        \u001b[36m0.5776\u001b[0m  0.0005  3.1526\n",
      "     10            0.8047                     \u001b[32m0.8238\u001b[0m        \u001b[35m0.5153\u001b[0m            0.7189                     \u001b[94m0.7019\u001b[0m        \u001b[36m0.5677\u001b[0m  0.0005  3.2249\n",
      "     11            \u001b[36m0.8472\u001b[0m                     \u001b[32m0.8324\u001b[0m        \u001b[35m0.5023\u001b[0m            \u001b[31m0.7681\u001b[0m                     \u001b[94m0.7055\u001b[0m        0.5955  0.0005  3.0977\n",
      "     12            0.8198                     \u001b[32m0.8450\u001b[0m        \u001b[35m0.4966\u001b[0m            0.7296                     \u001b[94m0.7113\u001b[0m        0.5682  0.0005  3.1714\n",
      "     13            \u001b[36m0.8543\u001b[0m                     \u001b[32m0.8481\u001b[0m        \u001b[35m0.4842\u001b[0m            0.7561                     0.6967        0.5852  0.0005  3.2100\n",
      "     14            0.8281                     \u001b[32m0.8567\u001b[0m        \u001b[35m0.4510\u001b[0m            0.7110                     0.6853        0.5965  0.0004  3.2725\n",
      "     15            0.8439                     \u001b[32m0.8674\u001b[0m        \u001b[35m0.4378\u001b[0m            0.7316                     0.6949        0.5968  0.0004  3.1037\n",
      "     16            \u001b[36m0.8944\u001b[0m                     \u001b[32m0.8794\u001b[0m        \u001b[35m0.4104\u001b[0m            \u001b[31m0.7953\u001b[0m                     \u001b[94m0.7118\u001b[0m        0.5897  0.0004  3.2298\n",
      "     17            0.8412                     0.8727        0.4183            0.7455                     \u001b[94m0.7180\u001b[0m        0.5797  0.0003  3.3346\n",
      "     18            0.8872                     \u001b[32m0.8985\u001b[0m        \u001b[35m0.3933\u001b[0m            0.7694                     0.7092        0.5747  0.0003  3.2043\n",
      "     19            \u001b[36m0.8978\u001b[0m                     0.8969        \u001b[35m0.3790\u001b[0m            0.7907                     0.7046        0.5948  0.0003  3.2785\n",
      "     20            \u001b[36m0.9015\u001b[0m                     \u001b[32m0.9002\u001b[0m        \u001b[35m0.3647\u001b[0m            0.7794                     0.6977        0.5917  0.0003  3.2830\n",
      "     21            0.8859                     \u001b[32m0.9116\u001b[0m        \u001b[35m0.3530\u001b[0m            0.7581                     0.7126        0.5914  0.0002  3.3226\n",
      "     22            0.8962                     \u001b[32m0.9215\u001b[0m        \u001b[35m0.3466\u001b[0m            0.7701                     0.7169        0.5745  0.0002  3.3092\n",
      "     23            \u001b[36m0.9141\u001b[0m                     0.9148        \u001b[35m0.3353\u001b[0m            \u001b[31m0.7980\u001b[0m                     0.6988        0.5914  0.0002  3.2966\n",
      "     24            \u001b[36m0.9243\u001b[0m                     \u001b[32m0.9276\u001b[0m        \u001b[35m0.3186\u001b[0m            \u001b[31m0.8007\u001b[0m                     0.7077        0.6171  0.0001  3.3121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25            \u001b[36m0.9274\u001b[0m                     0.9266        0.3243            \u001b[31m0.8027\u001b[0m                     0.6973        0.6014  0.0001  3.2896\n",
      "     26            0.9189                     \u001b[32m0.9328\u001b[0m        \u001b[35m0.3130\u001b[0m            0.7887                     0.7107        0.5897  0.0001  3.2823\n",
      "     27            0.8985                     0.9291        \u001b[35m0.3077\u001b[0m            0.7681                     \u001b[94m0.7201\u001b[0m        0.5781  0.0001  3.2697\n",
      "     28            \u001b[36m0.9349\u001b[0m                     \u001b[32m0.9425\u001b[0m        \u001b[35m0.3073\u001b[0m            0.8007                     0.7019        0.6011  0.0001  3.2271\n",
      "     29            0.9248                     0.9396        \u001b[35m0.2933\u001b[0m            0.7927                     0.7102        0.5948  0.0000  3.2139\n",
      "     30            0.9159                     0.9364        \u001b[35m0.2911\u001b[0m            0.7787                     0.7105        0.5872  0.0000  3.2028\n",
      "     31            0.9279                     0.9412        \u001b[35m0.2840\u001b[0m            0.7940                     0.7066        0.5973  0.0000  3.1990\n",
      "     32            0.9178                     0.9397        \u001b[35m0.2826\u001b[0m            0.7794                     0.7094        0.5874  0.0000  3.1926\n",
      "     33            0.9309                     \u001b[32m0.9430\u001b[0m        0.2895            0.7934                     0.6989        0.6031  0.0000  3.1763\n",
      "     34            0.9327                     0.9426        \u001b[35m0.2778\u001b[0m            0.7980                     0.6988        0.6073  0.0000  3.1914\n",
      "     35            0.9299                     0.9424        0.2808            0.7920                     0.6996        0.6005  0.0000  3.1670\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7050\u001b[0m                     \u001b[32m0.6431\u001b[0m        \u001b[35m1.2279\u001b[0m            \u001b[31m0.6884\u001b[0m                     \u001b[94m0.6117\u001b[0m        \u001b[36m0.7117\u001b[0m  0.0006  3.1357\n",
      "      2            0.4135                     0.5738        \u001b[35m0.8722\u001b[0m            0.4246                     0.5754        0.9658  0.0006  3.1830\n",
      "      3            \u001b[36m0.8017\u001b[0m                     \u001b[32m0.6976\u001b[0m        \u001b[35m0.8157\u001b[0m            \u001b[31m0.7794\u001b[0m                     \u001b[94m0.6568\u001b[0m        \u001b[36m0.6748\u001b[0m  0.0006  3.1791\n",
      "      4            0.7267                     \u001b[32m0.7252\u001b[0m        \u001b[35m0.7279\u001b[0m            0.6963                     \u001b[94m0.6764\u001b[0m        \u001b[36m0.6320\u001b[0m  0.0006  3.2190\n",
      "      5            0.7425                     \u001b[32m0.7615\u001b[0m        \u001b[35m0.7180\u001b[0m            0.6917                     \u001b[94m0.6853\u001b[0m        \u001b[36m0.5957\u001b[0m  0.0006  3.2623\n",
      "      6            0.7955                     0.7586        \u001b[35m0.6184\u001b[0m            0.7601                     \u001b[94m0.6889\u001b[0m        0.6294  0.0006  3.2496\n",
      "      7            0.7940                     \u001b[32m0.7708\u001b[0m        \u001b[35m0.5949\u001b[0m            0.7409                     0.6845        0.6361  0.0006  2.9809\n",
      "      8            0.7779                     \u001b[32m0.7910\u001b[0m        \u001b[35m0.5927\u001b[0m            0.7196                     \u001b[94m0.7008\u001b[0m        \u001b[36m0.5852\u001b[0m  0.0006  3.2048\n",
      "      9            \u001b[36m0.8537\u001b[0m                     \u001b[32m0.7994\u001b[0m        \u001b[35m0.5649\u001b[0m            \u001b[31m0.7947\u001b[0m                     \u001b[94m0.7012\u001b[0m        0.5994  0.0005  3.3116\n",
      "     10            0.7957                     \u001b[32m0.8234\u001b[0m        \u001b[35m0.5251\u001b[0m            0.7269                     \u001b[94m0.7140\u001b[0m        0.5884  0.0005  3.1911\n",
      "     11            0.8193                     \u001b[32m0.8272\u001b[0m        \u001b[35m0.5168\u001b[0m            0.7482                     0.7124        0.5908  0.0005  3.1815\n",
      "     12            0.7404                     0.7590        0.5339            0.6764                     0.6570        0.6726  0.0005  3.1240\n",
      "     13            0.7096                     0.7660        0.5357            0.6671                     0.6893        0.6679  0.0005  3.1230\n",
      "     14            \u001b[36m0.8704\u001b[0m                     0.8188        \u001b[35m0.5113\u001b[0m            0.7914                     0.6802        0.6117  0.0004  3.0160\n",
      "     15            0.8327                     \u001b[32m0.8459\u001b[0m        \u001b[35m0.4822\u001b[0m            0.7502                     \u001b[94m0.7150\u001b[0m        0.5946  0.0004  3.0640\n",
      "     16            0.8419                     \u001b[32m0.8650\u001b[0m        \u001b[35m0.4593\u001b[0m            0.7575                     \u001b[94m0.7180\u001b[0m        0.5919  0.0004  3.1690\n",
      "     17            0.8645                     0.8576        \u001b[35m0.4348\u001b[0m            0.7841                     0.7137        0.6160  0.0003  3.1003\n",
      "     18            0.8364                     \u001b[32m0.8727\u001b[0m        \u001b[35m0.4170\u001b[0m            0.7455                     0.7064        0.5932  0.0003  3.1412\n",
      "     19            \u001b[36m0.8872\u001b[0m                     \u001b[32m0.8853\u001b[0m        \u001b[35m0.4053\u001b[0m            \u001b[31m0.8027\u001b[0m                     \u001b[94m0.7250\u001b[0m        0.5993  0.0003  3.1337\n",
      "     20            \u001b[36m0.9040\u001b[0m                     0.8714        \u001b[35m0.3980\u001b[0m            \u001b[31m0.8140\u001b[0m                     0.7041        0.6272  0.0003  3.1543\n",
      "     21            0.8706                     \u001b[32m0.8946\u001b[0m        \u001b[35m0.3833\u001b[0m            0.7714                     0.7221        0.5968  0.0002  3.1380\n",
      "     22            0.8874                     0.8946        0.3860            0.7920                     0.7230        0.6033  0.0002  3.1548\n",
      "     23            0.8787                     \u001b[32m0.9003\u001b[0m        \u001b[35m0.3798\u001b[0m            0.7708                     0.7144        0.5938  0.0002  3.1817\n",
      "     24            0.9005                     \u001b[32m0.9095\u001b[0m        \u001b[35m0.3740\u001b[0m            0.7887                     0.7195        0.6114  0.0001  3.1990\n",
      "     25            0.8987                     \u001b[32m0.9161\u001b[0m        \u001b[35m0.3483\u001b[0m            0.7847                     0.7185        0.6013  0.0001  3.1853\n",
      "     26            0.9007                     \u001b[32m0.9202\u001b[0m        0.3565            0.7787                     0.7105        0.6029  0.0001  3.1875\n",
      "     27            0.8862                     0.9136        \u001b[35m0.3304\u001b[0m            0.7794                     0.7240        0.5990  0.0001  3.1361\n",
      "     28            \u001b[36m0.9055\u001b[0m                     0.9184        \u001b[35m0.3276\u001b[0m            0.7860                     0.7105        0.6198  0.0001  3.0089\n",
      "     29            0.8963                     0.9183        0.3367            0.7854                     0.7145        0.6076  0.0000  3.1844\n",
      "     30            \u001b[36m0.9101\u001b[0m                     \u001b[32m0.9241\u001b[0m        \u001b[35m0.3192\u001b[0m            0.7953                     0.7147        0.6185  0.0000  3.1870\n",
      "     31            0.9068                     0.9239        0.3269            0.7934                     0.7135        0.6164  0.0000  3.2566\n",
      "     32            0.9078                     \u001b[32m0.9242\u001b[0m        0.3265            0.7934                     0.7135        0.6174  0.0000  3.2571\n",
      "     33            0.8953                     0.9228        0.3193            0.7801                     0.7186        0.6047  0.0000  3.2597\n",
      "     34            0.9023                     \u001b[32m0.9252\u001b[0m        0.3246            0.7854                     0.7145        0.6101  0.0000  3.2502\n",
      "     35            0.9045                     \u001b[32m0.9254\u001b[0m        0.3267            0.7894                     0.7140        0.6126  0.0000  3.3337\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6713\u001b[0m                     \u001b[32m0.6336\u001b[0m        \u001b[35m1.2111\u001b[0m            \u001b[31m0.6611\u001b[0m                     \u001b[94m0.6068\u001b[0m        \u001b[36m0.7411\u001b[0m  0.0006  3.0728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            \u001b[36m0.6844\u001b[0m                     \u001b[32m0.6979\u001b[0m        \u001b[35m0.8376\u001b[0m            0.6571                     \u001b[94m0.6643\u001b[0m        \u001b[36m0.6183\u001b[0m  0.0006  3.0668\n",
      "      3            \u001b[36m0.7944\u001b[0m                     0.6938        \u001b[35m0.7895\u001b[0m            \u001b[31m0.7728\u001b[0m                     0.6572        0.6620  0.0006  3.0659\n",
      "      4            0.7870                     \u001b[32m0.7512\u001b[0m        \u001b[35m0.6877\u001b[0m            0.7502                     \u001b[94m0.6902\u001b[0m        \u001b[36m0.6046\u001b[0m  0.0006  3.0410\n",
      "      5            0.7206                     \u001b[32m0.7551\u001b[0m        \u001b[35m0.6537\u001b[0m            0.6824                     0.6811        \u001b[36m0.6003\u001b[0m  0.0006  3.4157\n",
      "      6            \u001b[36m0.8161\u001b[0m                     \u001b[32m0.7682\u001b[0m        \u001b[35m0.6200\u001b[0m            \u001b[31m0.7867\u001b[0m                     \u001b[94m0.7022\u001b[0m        0.6151  0.0006  3.0552\n",
      "      7            \u001b[36m0.8191\u001b[0m                     \u001b[32m0.7905\u001b[0m        \u001b[35m0.6134\u001b[0m            0.7688                     \u001b[94m0.7059\u001b[0m        \u001b[36m0.5856\u001b[0m  0.0006  2.9730\n",
      "      8            \u001b[36m0.8322\u001b[0m                     0.7666        \u001b[35m0.5826\u001b[0m            0.7814                     0.6712        0.6663  0.0006  2.9644\n",
      "      9            0.7638                     \u001b[32m0.7923\u001b[0m        \u001b[35m0.5619\u001b[0m            0.7130                     \u001b[94m0.7070\u001b[0m        0.5872  0.0005  2.9634\n",
      "     10            \u001b[36m0.8377\u001b[0m                     \u001b[32m0.8303\u001b[0m        \u001b[35m0.5340\u001b[0m            0.7641                     0.7016        \u001b[36m0.5749\u001b[0m  0.0005  2.9747\n",
      "     11            0.8259                     \u001b[32m0.8513\u001b[0m        \u001b[35m0.4848\u001b[0m            0.7542                     \u001b[94m0.7160\u001b[0m        \u001b[36m0.5554\u001b[0m  0.0005  2.9558\n",
      "     12            \u001b[36m0.8648\u001b[0m                     \u001b[32m0.8603\u001b[0m        \u001b[35m0.4701\u001b[0m            0.7774                     0.7082        0.5703  0.0005  2.9552\n",
      "     13            0.8532                     0.8419        0.4706            \u001b[31m0.7894\u001b[0m                     \u001b[94m0.7228\u001b[0m        0.5893  0.0005  2.9700\n",
      "     14            0.8498                     \u001b[32m0.8710\u001b[0m        \u001b[35m0.4539\u001b[0m            0.7608                     0.7215        0.5585  0.0004  3.1938\n",
      "     15            \u001b[36m0.8674\u001b[0m                     \u001b[32m0.8773\u001b[0m        \u001b[35m0.4369\u001b[0m            0.7761                     0.7191        0.5786  0.0004  3.4487\n",
      "     16            \u001b[36m0.8676\u001b[0m                     0.8686        \u001b[35m0.4255\u001b[0m            0.7860                     0.7179        0.5836  0.0004  3.4113\n",
      "     17            \u001b[36m0.8698\u001b[0m                     \u001b[32m0.8904\u001b[0m        \u001b[35m0.4091\u001b[0m            0.7621                     0.7150        \u001b[36m0.5519\u001b[0m  0.0003  3.1244\n",
      "     18            \u001b[36m0.8920\u001b[0m                     \u001b[32m0.9029\u001b[0m        \u001b[35m0.3946\u001b[0m            \u001b[31m0.7934\u001b[0m                     \u001b[94m0.7252\u001b[0m        0.5852  0.0003  3.0698\n",
      "     19            0.8884                     \u001b[32m0.9043\u001b[0m        \u001b[35m0.3739\u001b[0m            0.7854                     0.7248        0.5760  0.0003  3.0158\n",
      "     20            \u001b[36m0.8953\u001b[0m                     \u001b[32m0.9064\u001b[0m        \u001b[35m0.3627\u001b[0m            0.7867                     0.7124        0.5790  0.0003  2.9764\n",
      "     21            \u001b[36m0.9043\u001b[0m                     \u001b[32m0.9155\u001b[0m        \u001b[35m0.3597\u001b[0m            0.7894                     0.7170        0.5888  0.0002  2.9611\n",
      "     22            0.8937                     0.9116        \u001b[35m0.3475\u001b[0m            0.7900                     \u001b[94m0.7305\u001b[0m        0.5831  0.0002  2.9646\n",
      "     23            \u001b[36m0.9213\u001b[0m                     \u001b[32m0.9221\u001b[0m        \u001b[35m0.3390\u001b[0m            \u001b[31m0.8080\u001b[0m                     0.7166        0.5969  0.0002  2.9608\n",
      "     24            0.9204                     0.9198        \u001b[35m0.3334\u001b[0m            0.8033                     0.7196        0.6090  0.0001  2.9627\n",
      "     25            0.8995                     \u001b[32m0.9261\u001b[0m        \u001b[35m0.3240\u001b[0m            0.7734                     0.7175        0.5799  0.0001  2.9356\n",
      "     26            0.9203                     \u001b[32m0.9292\u001b[0m        \u001b[35m0.3216\u001b[0m            0.8073                     0.7293        0.6112  0.0001  2.9531\n",
      "     27            0.9146                     \u001b[32m0.9334\u001b[0m        \u001b[35m0.3137\u001b[0m            0.7934                     0.7267        0.5970  0.0001  2.9535\n",
      "     28            0.9151                     \u001b[32m0.9341\u001b[0m        0.3209            0.7920                     0.7244        0.5946  0.0001  2.9511\n",
      "     29            \u001b[36m0.9256\u001b[0m                     \u001b[32m0.9361\u001b[0m        \u001b[35m0.3016\u001b[0m            0.8066                     0.7202        0.6108  0.0000  2.9650\n",
      "     30            \u001b[36m0.9257\u001b[0m                     \u001b[32m0.9376\u001b[0m        0.3034            0.8040                     0.7244        0.6063  0.0000  2.9723\n",
      "     31            0.9256                     0.9364        \u001b[35m0.2921\u001b[0m            0.8047                     0.7204        0.6087  0.0000  2.9564\n",
      "     32            0.9244                     \u001b[32m0.9383\u001b[0m        0.3030            0.8007                     0.7165        0.6060  0.0000  2.9434\n",
      "     33            0.9206                     0.9378        0.3007            0.7967                     0.7199        0.6003  0.0000  3.0612\n",
      "     34            \u001b[36m0.9282\u001b[0m                     \u001b[32m0.9392\u001b[0m        0.2937            0.8047                     0.7189        0.6087  0.0000  2.9890\n",
      "     35            0.9266                     0.9389        0.2979            0.8040                     0.7200        0.6069  0.0000  2.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 1 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5683\u001b[0m                     \u001b[32m0.5705\u001b[0m        \u001b[35m1.3723\u001b[0m            \u001b[31m0.5376\u001b[0m                     \u001b[94m0.5396\u001b[0m        \u001b[36m0.8184\u001b[0m  0.0006  2.5011\n",
      "      2            \u001b[36m0.6487\u001b[0m                     \u001b[32m0.6492\u001b[0m        \u001b[35m1.0679\u001b[0m            \u001b[31m0.5843\u001b[0m                     \u001b[94m0.5846\u001b[0m        \u001b[36m0.7068\u001b[0m  0.0006  2.2460\n",
      "      3            \u001b[36m0.6734\u001b[0m                     \u001b[32m0.6732\u001b[0m        \u001b[35m0.8469\u001b[0m            \u001b[31m0.6379\u001b[0m                     \u001b[94m0.6375\u001b[0m        \u001b[36m0.6553\u001b[0m  0.0006  2.3123\n",
      "      4            \u001b[36m0.7095\u001b[0m                     \u001b[32m0.7097\u001b[0m        \u001b[35m0.7818\u001b[0m            0.6361                     0.6366        \u001b[36m0.6433\u001b[0m  0.0006  2.3712\n",
      "      5            \u001b[36m0.7242\u001b[0m                     \u001b[32m0.7254\u001b[0m        \u001b[35m0.7191\u001b[0m            0.6327                     0.6343        \u001b[36m0.6396\u001b[0m  0.0006  2.4711\n",
      "      6            \u001b[36m0.7363\u001b[0m                     \u001b[32m0.7369\u001b[0m        \u001b[35m0.7025\u001b[0m            \u001b[31m0.6603\u001b[0m                     \u001b[94m0.6611\u001b[0m        \u001b[36m0.6242\u001b[0m  0.0006  2.3966\n",
      "      7            0.7073                     0.7060        \u001b[35m0.6383\u001b[0m            0.6404                     0.6389        0.6608  0.0006  2.3956\n",
      "      8            \u001b[36m0.7815\u001b[0m                     \u001b[32m0.7812\u001b[0m        0.6421            \u001b[31m0.6949\u001b[0m                     \u001b[94m0.6947\u001b[0m        \u001b[36m0.5798\u001b[0m  0.0006  2.3995\n",
      "      9            \u001b[36m0.7962\u001b[0m                     \u001b[32m0.7957\u001b[0m        \u001b[35m0.5768\u001b[0m            \u001b[31m0.7018\u001b[0m                     \u001b[94m0.7014\u001b[0m        \u001b[36m0.5792\u001b[0m  0.0005  2.4235\n",
      "     10            \u001b[36m0.7966\u001b[0m                     \u001b[32m0.7964\u001b[0m        \u001b[35m0.5628\u001b[0m            \u001b[31m0.7087\u001b[0m                     \u001b[94m0.7086\u001b[0m        \u001b[36m0.5676\u001b[0m  0.0005  2.4374\n",
      "     11            0.7160                     0.7185        \u001b[35m0.5580\u001b[0m            0.6413                     0.6444        0.7135  0.0005  2.4206\n",
      "     12            \u001b[36m0.8083\u001b[0m                     \u001b[32m0.8090\u001b[0m        0.5832            0.7035                     0.7047        0.5805  0.0005  2.2749\n",
      "     13            \u001b[36m0.8191\u001b[0m                     \u001b[32m0.8195\u001b[0m        \u001b[35m0.5227\u001b[0m            0.7018                     0.7023        \u001b[36m0.5656\u001b[0m  0.0005  2.2854\n",
      "     14            \u001b[36m0.8366\u001b[0m                     \u001b[32m0.8367\u001b[0m        \u001b[35m0.4966\u001b[0m            \u001b[31m0.7286\u001b[0m                     \u001b[94m0.7286\u001b[0m        \u001b[36m0.5382\u001b[0m  0.0004  2.2844\n",
      "     15            \u001b[36m0.8459\u001b[0m                     \u001b[32m0.8458\u001b[0m        \u001b[35m0.4837\u001b[0m            0.7217                     0.7215        \u001b[36m0.5374\u001b[0m  0.0004  2.2907\n",
      "     16            \u001b[36m0.8534\u001b[0m                     \u001b[32m0.8533\u001b[0m        \u001b[35m0.4742\u001b[0m            0.7260                     0.7260        0.5399  0.0004  2.2733\n",
      "     17            \u001b[36m0.8547\u001b[0m                     \u001b[32m0.8549\u001b[0m        \u001b[35m0.4627\u001b[0m            0.7286                     \u001b[94m0.7287\u001b[0m        \u001b[36m0.5372\u001b[0m  0.0003  2.3060\n",
      "     18            \u001b[36m0.8649\u001b[0m                     \u001b[32m0.8650\u001b[0m        \u001b[35m0.4462\u001b[0m            \u001b[31m0.7364\u001b[0m                     \u001b[94m0.7366\u001b[0m        0.5442  0.0003  2.3094\n",
      "     19            \u001b[36m0.8662\u001b[0m                     \u001b[32m0.8664\u001b[0m        \u001b[35m0.4407\u001b[0m            \u001b[31m0.7485\u001b[0m                     \u001b[94m0.7489\u001b[0m        \u001b[36m0.5255\u001b[0m  0.0003  2.4544\n",
      "     20            \u001b[36m0.8692\u001b[0m                     \u001b[32m0.8695\u001b[0m        \u001b[35m0.4346\u001b[0m            0.7442                     0.7445        0.5262  0.0003  2.3926\n",
      "     21            \u001b[36m0.8735\u001b[0m                     \u001b[32m0.8736\u001b[0m        \u001b[35m0.4205\u001b[0m            0.7442                     0.7443        \u001b[36m0.5229\u001b[0m  0.0002  2.3030\n",
      "     22            \u001b[36m0.8759\u001b[0m                     \u001b[32m0.8763\u001b[0m        \u001b[35m0.4070\u001b[0m            \u001b[31m0.7545\u001b[0m                     \u001b[94m0.7549\u001b[0m        0.5332  0.0002  2.2889\n",
      "     23            \u001b[36m0.8779\u001b[0m                     \u001b[32m0.8783\u001b[0m        \u001b[35m0.3958\u001b[0m            0.7407                     0.7414        0.5345  0.0002  2.3019\n",
      "     24            \u001b[36m0.8911\u001b[0m                     \u001b[32m0.8911\u001b[0m        0.3965            0.7502                     0.7503        0.5245  0.0001  2.3011\n",
      "     25            0.8848                     0.8851        \u001b[35m0.3835\u001b[0m            0.7433                     0.7438        0.5267  0.0001  2.2783\n",
      "     26            \u001b[36m0.8926\u001b[0m                     \u001b[32m0.8927\u001b[0m        0.3857            0.7502                     0.7505        0.5241  0.0001  2.2988\n",
      "     27            0.8893                     0.8897        \u001b[35m0.3710\u001b[0m            0.7442                     0.7447        0.5318  0.0001  2.2784\n",
      "     28            0.8923                     0.8927        \u001b[35m0.3628\u001b[0m            0.7494                     0.7498        0.5285  0.0001  2.2924\n",
      "     29            \u001b[36m0.9010\u001b[0m                     \u001b[32m0.9011\u001b[0m        \u001b[35m0.3618\u001b[0m            \u001b[31m0.7580\u001b[0m                     \u001b[94m0.7580\u001b[0m        \u001b[36m0.5190\u001b[0m  0.0000  2.2969\n",
      "     30            0.8982                     0.8984        \u001b[35m0.3611\u001b[0m            0.7563                     0.7566        0.5238  0.0000  2.2960\n",
      "     31            \u001b[36m0.9023\u001b[0m                     \u001b[32m0.9024\u001b[0m        \u001b[35m0.3540\u001b[0m            0.7571                     0.7572        0.5217  0.0000  2.2820\n",
      "     32            0.9012                     0.9014        0.3543            0.7554                     0.7556        0.5234  0.0000  2.3000\n",
      "     33            0.8997                     0.8999        \u001b[35m0.3485\u001b[0m            0.7528                     0.7531        0.5238  0.0000  2.2806\n",
      "     34            \u001b[36m0.9036\u001b[0m                     \u001b[32m0.9036\u001b[0m        0.3495            0.7554                     0.7555        0.5222  0.0000  2.2679\n",
      "     35            0.9016                     0.9018        0.3558            \u001b[31m0.7589\u001b[0m                     \u001b[94m0.7590\u001b[0m        0.5220  0.0000  2.2785\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5774\u001b[0m                     \u001b[32m0.5777\u001b[0m        \u001b[35m1.3932\u001b[0m            \u001b[31m0.5687\u001b[0m                     \u001b[94m0.5690\u001b[0m        \u001b[36m0.7574\u001b[0m  0.0006  2.3113\n",
      "      2            \u001b[36m0.5960\u001b[0m                     \u001b[32m0.5971\u001b[0m        \u001b[35m1.0172\u001b[0m            \u001b[31m0.5825\u001b[0m                     \u001b[94m0.5838\u001b[0m        \u001b[36m0.7052\u001b[0m  0.0006  2.2829\n",
      "      3            \u001b[36m0.6790\u001b[0m                     \u001b[32m0.6789\u001b[0m        \u001b[35m0.9484\u001b[0m            \u001b[31m0.6309\u001b[0m                     \u001b[94m0.6308\u001b[0m        \u001b[36m0.6464\u001b[0m  0.0006  2.3055\n",
      "      4            \u001b[36m0.6820\u001b[0m                     \u001b[32m0.6833\u001b[0m        \u001b[35m0.8554\u001b[0m            \u001b[31m0.6370\u001b[0m                     \u001b[94m0.6386\u001b[0m        0.6465  0.0006  2.3104\n",
      "      5            \u001b[36m0.7054\u001b[0m                     \u001b[32m0.7055\u001b[0m        \u001b[35m0.7451\u001b[0m            \u001b[31m0.6655\u001b[0m                     \u001b[94m0.6660\u001b[0m        \u001b[36m0.6095\u001b[0m  0.0006  2.2769\n",
      "      6            \u001b[36m0.7319\u001b[0m                     \u001b[32m0.7315\u001b[0m        \u001b[35m0.7169\u001b[0m            \u001b[31m0.6793\u001b[0m                     \u001b[94m0.6788\u001b[0m        \u001b[36m0.5931\u001b[0m  0.0006  2.3038\n",
      "      7            0.7287                     0.7271        \u001b[35m0.6666\u001b[0m            \u001b[31m0.6880\u001b[0m                     \u001b[94m0.6864\u001b[0m        0.5951  0.0006  2.3233\n",
      "      8            \u001b[36m0.7748\u001b[0m                     \u001b[32m0.7753\u001b[0m        \u001b[35m0.6312\u001b[0m            \u001b[31m0.7113\u001b[0m                     \u001b[94m0.7120\u001b[0m        \u001b[36m0.5686\u001b[0m  0.0006  2.5399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9            0.7043                     0.7026        \u001b[35m0.6253\u001b[0m            0.6500                     0.6482        0.6418  0.0005  2.4305\n",
      "     10            \u001b[36m0.7895\u001b[0m                     \u001b[32m0.7892\u001b[0m        \u001b[35m0.5936\u001b[0m            \u001b[31m0.7295\u001b[0m                     \u001b[94m0.7293\u001b[0m        \u001b[36m0.5490\u001b[0m  0.0005  2.3716\n",
      "     11            \u001b[36m0.7944\u001b[0m                     \u001b[32m0.7939\u001b[0m        \u001b[35m0.5873\u001b[0m            0.7105                     0.7099        0.5553  0.0005  2.4368\n",
      "     12            \u001b[36m0.8176\u001b[0m                     \u001b[32m0.8173\u001b[0m        \u001b[35m0.5295\u001b[0m            \u001b[31m0.7381\u001b[0m                     \u001b[94m0.7379\u001b[0m        \u001b[36m0.5331\u001b[0m  0.0005  2.4721\n",
      "     13            0.8165                     0.8167        0.5489            0.7364                     0.7368        0.5434  0.0005  2.3946\n",
      "     14            \u001b[36m0.8342\u001b[0m                     \u001b[32m0.8342\u001b[0m        \u001b[35m0.5215\u001b[0m            \u001b[31m0.7606\u001b[0m                     \u001b[94m0.7607\u001b[0m        \u001b[36m0.5298\u001b[0m  0.0004  2.4462\n",
      "     15            0.8329                     0.8326        \u001b[35m0.4912\u001b[0m            0.7407                     0.7404        0.5435  0.0004  2.4329\n",
      "     16            \u001b[36m0.8405\u001b[0m                     \u001b[32m0.8407\u001b[0m        \u001b[35m0.4826\u001b[0m            0.7476                     0.7479        \u001b[36m0.5272\u001b[0m  0.0004  2.3856\n",
      "     17            0.8379                     0.8377        0.4963            0.7398                     0.7397        0.5350  0.0003  2.3587\n",
      "     18            0.8372                     0.8382        \u001b[35m0.4596\u001b[0m            0.7381                     0.7392        0.5400  0.0003  2.3474\n",
      "     19            \u001b[36m0.8625\u001b[0m                     \u001b[32m0.8624\u001b[0m        \u001b[35m0.4388\u001b[0m            0.7502                     0.7501        \u001b[36m0.5223\u001b[0m  0.0003  2.5829\n",
      "     20            0.8623                     0.8620        \u001b[35m0.4260\u001b[0m            0.7312                     0.7310        0.5319  0.0003  2.5332\n",
      "     21            \u001b[36m0.8714\u001b[0m                     \u001b[32m0.8716\u001b[0m        0.4503            0.7450                     0.7453        \u001b[36m0.5180\u001b[0m  0.0002  2.4330\n",
      "     22            \u001b[36m0.8757\u001b[0m                     \u001b[32m0.8756\u001b[0m        0.4412            0.7468                     0.7466        0.5181  0.0002  2.3387\n",
      "     23            \u001b[36m0.8813\u001b[0m                     \u001b[32m0.8815\u001b[0m        \u001b[35m0.4183\u001b[0m            0.7571                     0.7573        \u001b[36m0.5101\u001b[0m  0.0002  2.3499\n",
      "     24            0.8796                     0.8801        \u001b[35m0.3970\u001b[0m            0.7502                     0.7507        0.5281  0.0001  2.3654\n",
      "     25            0.8751                     0.8758        \u001b[35m0.3907\u001b[0m            0.7433                     0.7443        0.5376  0.0001  2.4483\n",
      "     26            \u001b[36m0.8882\u001b[0m                     \u001b[32m0.8884\u001b[0m        \u001b[35m0.3907\u001b[0m            0.7597                     0.7600        0.5229  0.0001  2.4245\n",
      "     27            \u001b[36m0.8887\u001b[0m                     0.8884        0.3966            0.7476                     0.7473        0.5213  0.0001  2.3730\n",
      "     28            \u001b[36m0.8936\u001b[0m                     \u001b[32m0.8936\u001b[0m        \u001b[35m0.3841\u001b[0m            0.7528                     0.7528        0.5175  0.0001  2.3243\n",
      "     29            \u001b[36m0.8969\u001b[0m                     \u001b[32m0.8970\u001b[0m        \u001b[35m0.3722\u001b[0m            0.7476                     0.7478        0.5162  0.0000  2.3344\n",
      "     30            \u001b[36m0.8971\u001b[0m                     \u001b[32m0.8973\u001b[0m        0.3734            0.7511                     0.7513        0.5189  0.0000  2.3338\n",
      "     31            0.8928                     0.8931        0.3753            0.7528                     0.7533        0.5262  0.0000  2.3292\n",
      "     32            0.8969                     0.8970        \u001b[35m0.3692\u001b[0m            0.7528                     0.7529        0.5189  0.0000  2.3185\n",
      "     33            \u001b[36m0.8982\u001b[0m                     \u001b[32m0.8983\u001b[0m        \u001b[35m0.3674\u001b[0m            0.7485                     0.7487        0.5188  0.0000  2.3267\n",
      "     34            0.8980                     0.8981        0.3682            0.7485                     0.7487        0.5189  0.0000  2.3292\n",
      "     35            0.8975                     0.8977        \u001b[35m0.3674\u001b[0m            0.7494                     0.7496        0.5190  0.0000  2.3362\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5845\u001b[0m                     \u001b[32m0.5844\u001b[0m        \u001b[35m1.3730\u001b[0m            \u001b[31m0.5748\u001b[0m                     \u001b[94m0.5751\u001b[0m        \u001b[36m0.7784\u001b[0m  0.0006  2.3425\n",
      "      2            \u001b[36m0.5992\u001b[0m                     \u001b[32m0.6016\u001b[0m        \u001b[35m1.0583\u001b[0m            0.5704                     0.5731        \u001b[36m0.7756\u001b[0m  0.0006  2.3286\n",
      "      3            \u001b[36m0.6587\u001b[0m                     \u001b[32m0.6568\u001b[0m        \u001b[35m0.8890\u001b[0m            \u001b[31m0.6102\u001b[0m                     \u001b[94m0.6081\u001b[0m        \u001b[36m0.6787\u001b[0m  0.0006  2.4329\n",
      "      4            \u001b[36m0.7077\u001b[0m                     \u001b[32m0.7080\u001b[0m        \u001b[35m0.8128\u001b[0m            \u001b[31m0.6577\u001b[0m                     \u001b[94m0.6580\u001b[0m        \u001b[36m0.6459\u001b[0m  0.0006  2.3491\n",
      "      5            0.7056                     0.7064        \u001b[35m0.7403\u001b[0m            0.6534                     0.6542        0.6537  0.0006  2.3379\n",
      "      6            \u001b[36m0.7549\u001b[0m                     \u001b[32m0.7553\u001b[0m        \u001b[35m0.6943\u001b[0m            \u001b[31m0.6906\u001b[0m                     \u001b[94m0.6910\u001b[0m        \u001b[36m0.6021\u001b[0m  0.0006  2.3259\n",
      "      7            \u001b[36m0.7642\u001b[0m                     \u001b[32m0.7643\u001b[0m        \u001b[35m0.6532\u001b[0m            \u001b[31m0.7010\u001b[0m                     \u001b[94m0.7012\u001b[0m        \u001b[36m0.5794\u001b[0m  0.0006  2.3255\n",
      "      8            0.7514                     0.7505        \u001b[35m0.6165\u001b[0m            0.6932                     0.6922        0.5831  0.0006  2.3146\n",
      "      9            \u001b[36m0.7838\u001b[0m                     \u001b[32m0.7845\u001b[0m        \u001b[35m0.5958\u001b[0m            \u001b[31m0.7139\u001b[0m                     \u001b[94m0.7147\u001b[0m        \u001b[36m0.5681\u001b[0m  0.0005  2.3304\n",
      "     10            \u001b[36m0.8039\u001b[0m                     \u001b[32m0.8045\u001b[0m        \u001b[35m0.5726\u001b[0m            \u001b[31m0.7269\u001b[0m                     \u001b[94m0.7275\u001b[0m        \u001b[36m0.5593\u001b[0m  0.0005  2.3359\n",
      "     11            0.8009                     0.8006        \u001b[35m0.5435\u001b[0m            0.7208                     0.7205        \u001b[36m0.5581\u001b[0m  0.0005  2.3300\n",
      "     12            0.7897                     0.7895        \u001b[35m0.5346\u001b[0m            0.7010                     0.7007        0.5721  0.0005  2.3723\n",
      "     13            \u001b[36m0.8271\u001b[0m                     \u001b[32m0.8269\u001b[0m        \u001b[35m0.5121\u001b[0m            \u001b[31m0.7347\u001b[0m                     \u001b[94m0.7344\u001b[0m        \u001b[36m0.5385\u001b[0m  0.0005  2.4312\n",
      "     14            \u001b[36m0.8320\u001b[0m                     \u001b[32m0.8321\u001b[0m        0.5185            0.7303                     0.7305        0.5387  0.0004  2.3493\n",
      "     15            \u001b[36m0.8409\u001b[0m                     \u001b[32m0.8414\u001b[0m        \u001b[35m0.4972\u001b[0m            0.7338                     0.7342        \u001b[36m0.5356\u001b[0m  0.0004  2.3433\n",
      "     16            \u001b[36m0.8571\u001b[0m                     \u001b[32m0.8572\u001b[0m        \u001b[35m0.4753\u001b[0m            \u001b[31m0.7442\u001b[0m                     \u001b[94m0.7443\u001b[0m        0.5358  0.0004  2.3273\n",
      "     17            0.8528                     0.8525        \u001b[35m0.4619\u001b[0m            0.7416                     0.7412        0.5465  0.0003  2.3362\n",
      "     18            0.8545                     0.8546        \u001b[35m0.4456\u001b[0m            0.7347                     0.7347        0.5403  0.0003  2.3328\n",
      "     19            \u001b[36m0.8718\u001b[0m                     \u001b[32m0.8721\u001b[0m        \u001b[35m0.4427\u001b[0m            0.7381                     0.7385        0.5366  0.0003  2.3302\n",
      "     20            0.8653                     0.8657        \u001b[35m0.4296\u001b[0m            0.7407                     0.7413        0.5390  0.0003  2.3362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     21            \u001b[36m0.8748\u001b[0m                     \u001b[32m0.8748\u001b[0m        \u001b[35m0.4140\u001b[0m            0.7433                     0.7433        0.5372  0.0002  2.2951\n",
      "     22            \u001b[36m0.8768\u001b[0m                     \u001b[32m0.8770\u001b[0m        0.4148            0.7398                     0.7401        \u001b[36m0.5337\u001b[0m  0.0002  2.2836\n",
      "     23            \u001b[36m0.8843\u001b[0m                     \u001b[32m0.8844\u001b[0m        0.4181            \u001b[31m0.7468\u001b[0m                     \u001b[94m0.7468\u001b[0m        \u001b[36m0.5308\u001b[0m  0.0002  2.2973\n",
      "     24            0.8824                     0.8826        \u001b[35m0.4004\u001b[0m            0.7459                     0.7462        0.5338  0.0001  2.2850\n",
      "     25            \u001b[36m0.8921\u001b[0m                     \u001b[32m0.8924\u001b[0m        \u001b[35m0.3993\u001b[0m            0.7459                     0.7463        \u001b[36m0.5291\u001b[0m  0.0001  2.4068\n",
      "     26            \u001b[36m0.8923\u001b[0m                     \u001b[32m0.8927\u001b[0m        \u001b[35m0.3873\u001b[0m            0.7442                     0.7448        0.5365  0.0001  2.3654\n",
      "     27            \u001b[36m0.8984\u001b[0m                     \u001b[32m0.8987\u001b[0m        \u001b[35m0.3758\u001b[0m            0.7459                     0.7463        0.5328  0.0001  2.2560\n",
      "     28            \u001b[36m0.8986\u001b[0m                     0.8987        \u001b[35m0.3687\u001b[0m            0.7312                     0.7313        0.5369  0.0001  2.2881\n",
      "     29            \u001b[36m0.8995\u001b[0m                     \u001b[32m0.8996\u001b[0m        0.3725            0.7450                     0.7451        0.5326  0.0000  2.2835\n",
      "     30            0.8990                     0.8994        \u001b[35m0.3642\u001b[0m            0.7424                     0.7430        0.5316  0.0000  2.2781\n",
      "     31            0.8908                     0.8914        \u001b[35m0.3552\u001b[0m            0.7433                     0.7442        0.5413  0.0000  2.2677\n",
      "     32            \u001b[36m0.9053\u001b[0m                     \u001b[32m0.9054\u001b[0m        0.3557            0.7433                     0.7433        \u001b[36m0.5285\u001b[0m  0.0000  2.2618\n",
      "     33            0.8954                     0.8959        0.3592            0.7433                     0.7440        0.5360  0.0000  2.3011\n",
      "     34            0.9016                     0.9019        \u001b[35m0.3470\u001b[0m            0.7381                     0.7386        0.5316  0.0000  2.2982\n",
      "     35            0.9045                     0.9046        0.3564            0.7424                     0.7426        0.5296  0.0000  2.2708\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5832\u001b[0m                     \u001b[32m0.5844\u001b[0m        \u001b[35m1.3876\u001b[0m            \u001b[31m0.5549\u001b[0m                     \u001b[94m0.5563\u001b[0m        \u001b[36m0.8313\u001b[0m  0.0006  2.2667\n",
      "      2            \u001b[36m0.6226\u001b[0m                     \u001b[32m0.6235\u001b[0m        \u001b[35m1.0574\u001b[0m            \u001b[31m0.5998\u001b[0m                     \u001b[94m0.6008\u001b[0m        \u001b[36m0.7339\u001b[0m  0.0006  2.3869\n",
      "      3            \u001b[36m0.6442\u001b[0m                     \u001b[32m0.6465\u001b[0m        \u001b[35m0.8929\u001b[0m            0.5998                     \u001b[94m0.6023\u001b[0m        \u001b[36m0.7105\u001b[0m  0.0006  2.2665\n",
      "      4            \u001b[36m0.7010\u001b[0m                     \u001b[32m0.7011\u001b[0m        \u001b[35m0.8230\u001b[0m            \u001b[31m0.6387\u001b[0m                     \u001b[94m0.6388\u001b[0m        \u001b[36m0.6336\u001b[0m  0.0006  2.2819\n",
      "      5            \u001b[36m0.7227\u001b[0m                     \u001b[32m0.7217\u001b[0m        \u001b[35m0.7425\u001b[0m            \u001b[31m0.6534\u001b[0m                     \u001b[94m0.6524\u001b[0m        \u001b[36m0.6274\u001b[0m  0.0006  2.4462\n",
      "      6            \u001b[36m0.7324\u001b[0m                     \u001b[32m0.7311\u001b[0m        \u001b[35m0.6889\u001b[0m            \u001b[31m0.6716\u001b[0m                     \u001b[94m0.6702\u001b[0m        \u001b[36m0.6163\u001b[0m  0.0006  2.3068\n",
      "      7            \u001b[36m0.7605\u001b[0m                     \u001b[32m0.7599\u001b[0m        \u001b[35m0.6445\u001b[0m            \u001b[31m0.6854\u001b[0m                     \u001b[94m0.6847\u001b[0m        \u001b[36m0.5874\u001b[0m  0.0006  2.2616\n",
      "      8            \u001b[36m0.7871\u001b[0m                     \u001b[32m0.7872\u001b[0m        \u001b[35m0.6205\u001b[0m            \u001b[31m0.6871\u001b[0m                     \u001b[94m0.6873\u001b[0m        \u001b[36m0.5810\u001b[0m  0.0006  2.2859\n",
      "      9            \u001b[36m0.7914\u001b[0m                     \u001b[32m0.7916\u001b[0m        \u001b[35m0.5980\u001b[0m            0.6819                     0.6822        0.5824  0.0005  2.2889\n",
      "     10            \u001b[36m0.8067\u001b[0m                     \u001b[32m0.8068\u001b[0m        \u001b[35m0.5728\u001b[0m            \u001b[31m0.6906\u001b[0m                     \u001b[94m0.6905\u001b[0m        \u001b[36m0.5618\u001b[0m  0.0005  2.2575\n",
      "     11            \u001b[36m0.8106\u001b[0m                     \u001b[32m0.8106\u001b[0m        \u001b[35m0.5403\u001b[0m            \u001b[31m0.7122\u001b[0m                     \u001b[94m0.7120\u001b[0m        0.5684  0.0005  2.2856\n",
      "     12            \u001b[36m0.8262\u001b[0m                     \u001b[32m0.8263\u001b[0m        \u001b[35m0.5312\u001b[0m            0.7010                     0.7010        \u001b[36m0.5615\u001b[0m  0.0005  2.2675\n",
      "     13            \u001b[36m0.8266\u001b[0m                     0.8263        \u001b[35m0.5258\u001b[0m            \u001b[31m0.7191\u001b[0m                     \u001b[94m0.7188\u001b[0m        \u001b[36m0.5571\u001b[0m  0.0005  2.2749\n",
      "     14            \u001b[36m0.8385\u001b[0m                     \u001b[32m0.8390\u001b[0m        \u001b[35m0.4976\u001b[0m            0.7182                     0.7187        \u001b[36m0.5452\u001b[0m  0.0004  2.2811\n",
      "     15            0.8359                     0.8357        \u001b[35m0.4799\u001b[0m            0.7182                     0.7178        0.5596  0.0004  2.2767\n",
      "     16            \u001b[36m0.8493\u001b[0m                     \u001b[32m0.8491\u001b[0m        0.4842            0.7182                     0.7181        0.5565  0.0004  2.2657\n",
      "     17            \u001b[36m0.8508\u001b[0m                     \u001b[32m0.8508\u001b[0m        \u001b[35m0.4567\u001b[0m            \u001b[31m0.7226\u001b[0m                     \u001b[94m0.7225\u001b[0m        0.5499  0.0003  2.2644\n",
      "     18            0.8472                     0.8471        0.4695            0.7226                     0.7223        0.5540  0.0003  2.2709\n",
      "     19            \u001b[36m0.8547\u001b[0m                     \u001b[32m0.8551\u001b[0m        0.4667            \u001b[31m0.7277\u001b[0m                     \u001b[94m0.7281\u001b[0m        0.5624  0.0003  2.2674\n",
      "     20            \u001b[36m0.8679\u001b[0m                     \u001b[32m0.8682\u001b[0m        \u001b[35m0.4329\u001b[0m            \u001b[31m0.7286\u001b[0m                     \u001b[94m0.7290\u001b[0m        0.5493  0.0003  2.2455\n",
      "     21            \u001b[36m0.8753\u001b[0m                     \u001b[32m0.8755\u001b[0m        \u001b[35m0.4116\u001b[0m            \u001b[31m0.7312\u001b[0m                     \u001b[94m0.7315\u001b[0m        0.5526  0.0002  2.2538\n",
      "     22            \u001b[36m0.8811\u001b[0m                     \u001b[32m0.8811\u001b[0m        \u001b[35m0.4109\u001b[0m            \u001b[31m0.7364\u001b[0m                     \u001b[94m0.7363\u001b[0m        0.5480  0.0002  2.2917\n",
      "     23            \u001b[36m0.8813\u001b[0m                     \u001b[32m0.8813\u001b[0m        \u001b[35m0.4087\u001b[0m            0.7303                     0.7302        0.5511  0.0002  2.2904\n",
      "     24            0.8776                     0.8779        \u001b[35m0.4018\u001b[0m            0.7165                     0.7170        0.5568  0.0001  2.3000\n",
      "     25            \u001b[36m0.8947\u001b[0m                     \u001b[32m0.8947\u001b[0m        0.4030            0.7355                     0.7354        0.5489  0.0001  2.2729\n",
      "     26            0.8943                     0.8942        \u001b[35m0.3811\u001b[0m            \u001b[31m0.7450\u001b[0m                     \u001b[94m0.7448\u001b[0m        0.5486  0.0001  2.2605\n",
      "     27            \u001b[36m0.9003\u001b[0m                     \u001b[32m0.9003\u001b[0m        \u001b[35m0.3792\u001b[0m            0.7321                     0.7320        0.5476  0.0001  2.2819\n",
      "     28            0.9001                     0.9003        \u001b[35m0.3718\u001b[0m            0.7303                     0.7305        0.5496  0.0001  2.3644\n",
      "     29            \u001b[36m0.9029\u001b[0m                     \u001b[32m0.9028\u001b[0m        \u001b[35m0.3608\u001b[0m            0.7338                     0.7336        0.5503  0.0000  2.2520\n",
      "     30            \u001b[36m0.9049\u001b[0m                     \u001b[32m0.9048\u001b[0m        0.3707            0.7329                     0.7328        0.5508  0.0000  2.2831\n",
      "     31            \u001b[36m0.9062\u001b[0m                     \u001b[32m0.9062\u001b[0m        \u001b[35m0.3511\u001b[0m            0.7329                     0.7330        0.5509  0.0000  2.2653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     32            \u001b[36m0.9077\u001b[0m                     \u001b[32m0.9077\u001b[0m        \u001b[35m0.3497\u001b[0m            0.7286                     0.7287        0.5518  0.0000  2.3250\n",
      "     33            0.9025                     0.9026        0.3515            0.7277                     0.7279        0.5502  0.0000  2.4390\n",
      "     34            0.9070                     0.9071        0.3508            0.7277                     0.7278        0.5513  0.0000  2.3940\n",
      "     35            0.9060                     0.9060        0.3534            0.7286                     0.7287        0.5512  0.0000  2.3374\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5804\u001b[0m                     \u001b[32m0.5790\u001b[0m        \u001b[35m1.3479\u001b[0m            \u001b[31m0.5445\u001b[0m                     \u001b[94m0.5431\u001b[0m        \u001b[36m0.7896\u001b[0m  0.0006  2.2702\n",
      "      2            \u001b[36m0.6087\u001b[0m                     \u001b[32m0.6061\u001b[0m        \u001b[35m1.0234\u001b[0m            \u001b[31m0.5834\u001b[0m                     \u001b[94m0.5810\u001b[0m        \u001b[36m0.7602\u001b[0m  0.0006  2.2764\n",
      "      3            \u001b[36m0.6476\u001b[0m                     \u001b[32m0.6490\u001b[0m        \u001b[35m0.9438\u001b[0m            \u001b[31m0.5869\u001b[0m                     \u001b[94m0.5886\u001b[0m        \u001b[36m0.7232\u001b[0m  0.0006  2.2629\n",
      "      4            \u001b[36m0.7054\u001b[0m                     \u001b[32m0.7049\u001b[0m        \u001b[35m0.8211\u001b[0m            \u001b[31m0.6517\u001b[0m                     \u001b[94m0.6516\u001b[0m        \u001b[36m0.6281\u001b[0m  0.0006  2.2534\n",
      "      5            0.6987                     0.6995        \u001b[35m0.7682\u001b[0m            0.6214                     0.6224        0.6625  0.0006  2.2659\n",
      "      6            \u001b[36m0.7525\u001b[0m                     \u001b[32m0.7530\u001b[0m        \u001b[35m0.7045\u001b[0m            \u001b[31m0.6845\u001b[0m                     \u001b[94m0.6852\u001b[0m        \u001b[36m0.6137\u001b[0m  0.0006  2.2829\n",
      "      7            0.7374                     0.7361        \u001b[35m0.6661\u001b[0m            0.6525                     0.6515        0.6150  0.0006  2.2951\n",
      "      8            0.7365                     0.7379        \u001b[35m0.6258\u001b[0m            0.6776                     0.6792        0.6232  0.0006  2.2745\n",
      "      9            \u001b[36m0.7949\u001b[0m                     \u001b[32m0.7944\u001b[0m        \u001b[35m0.5983\u001b[0m            \u001b[31m0.7010\u001b[0m                     \u001b[94m0.7008\u001b[0m        \u001b[36m0.5783\u001b[0m  0.0005  2.2887\n",
      "     10            0.7795                     0.7801        \u001b[35m0.5789\u001b[0m            0.6923                     0.6933        0.6167  0.0005  2.2639\n",
      "     11            \u001b[36m0.7974\u001b[0m                     \u001b[32m0.7980\u001b[0m        \u001b[35m0.5540\u001b[0m            \u001b[31m0.7156\u001b[0m                     \u001b[94m0.7165\u001b[0m        \u001b[36m0.5684\u001b[0m  0.0005  2.2739\n",
      "     12            \u001b[36m0.8223\u001b[0m                     \u001b[32m0.8226\u001b[0m        \u001b[35m0.5405\u001b[0m            \u001b[31m0.7243\u001b[0m                     \u001b[94m0.7246\u001b[0m        \u001b[36m0.5413\u001b[0m  0.0005  2.2659\n",
      "     13            \u001b[36m0.8355\u001b[0m                     \u001b[32m0.8355\u001b[0m        \u001b[35m0.5346\u001b[0m            0.7226                     0.7226        \u001b[36m0.5351\u001b[0m  0.0005  2.2779\n",
      "     14            0.8301                     0.8304        \u001b[35m0.5050\u001b[0m            0.7182                     0.7185        0.5536  0.0004  2.2700\n",
      "     15            \u001b[36m0.8374\u001b[0m                     \u001b[32m0.8371\u001b[0m        \u001b[35m0.4815\u001b[0m            0.7174                     0.7168        0.5427  0.0004  2.2605\n",
      "     16            \u001b[36m0.8428\u001b[0m                     \u001b[32m0.8427\u001b[0m        \u001b[35m0.4768\u001b[0m            0.7200                     0.7198        0.5391  0.0004  2.2711\n",
      "     17            \u001b[36m0.8465\u001b[0m                     \u001b[32m0.8467\u001b[0m        \u001b[35m0.4588\u001b[0m            0.7182                     0.7186        0.5538  0.0003  2.2743\n",
      "     18            \u001b[36m0.8571\u001b[0m                     \u001b[32m0.8568\u001b[0m        0.4614            0.7217                     0.7214        0.5408  0.0003  2.2863\n",
      "     19            \u001b[36m0.8679\u001b[0m                     \u001b[32m0.8683\u001b[0m        \u001b[35m0.4515\u001b[0m            \u001b[31m0.7416\u001b[0m                     \u001b[94m0.7420\u001b[0m        0.5368  0.0003  2.2794\n",
      "     20            \u001b[36m0.8684\u001b[0m                     \u001b[32m0.8687\u001b[0m        \u001b[35m0.4276\u001b[0m            0.7303                     0.7307        0.5406  0.0003  2.2922\n",
      "     21            0.8541                     0.8546        0.4291            0.7139                     0.7146        0.5717  0.0002  2.2639\n",
      "     22            \u001b[36m0.8811\u001b[0m                     \u001b[32m0.8812\u001b[0m        \u001b[35m0.4114\u001b[0m            0.7252                     0.7251        0.5363  0.0002  2.3479\n",
      "     23            \u001b[36m0.8822\u001b[0m                     \u001b[32m0.8822\u001b[0m        \u001b[35m0.4059\u001b[0m            0.7174                     0.7174        0.5380  0.0002  2.2682\n",
      "     24            0.8800                     0.8805        \u001b[35m0.3942\u001b[0m            0.7381                     0.7387        \u001b[36m0.5350\u001b[0m  0.0001  2.2758\n",
      "     25            \u001b[36m0.8872\u001b[0m                     \u001b[32m0.8874\u001b[0m        \u001b[35m0.3886\u001b[0m            0.7312                     0.7316        0.5391  0.0001  2.2900\n",
      "     26            \u001b[36m0.8926\u001b[0m                     \u001b[32m0.8928\u001b[0m        0.3896            0.7269                     0.7272        0.5382  0.0001  2.2921\n",
      "     27            \u001b[36m0.8936\u001b[0m                     \u001b[32m0.8939\u001b[0m        \u001b[35m0.3787\u001b[0m            0.7355                     0.7358        0.5358  0.0001  2.2644\n",
      "     28            0.8757                     0.8765        \u001b[35m0.3712\u001b[0m            0.7373                     0.7384        0.5547  0.0001  2.2869\n",
      "     29            \u001b[36m0.9001\u001b[0m                     \u001b[32m0.9003\u001b[0m        0.3734            0.7312                     0.7314        0.5366  0.0000  2.2794\n",
      "     30            \u001b[36m0.9008\u001b[0m                     \u001b[32m0.9009\u001b[0m        \u001b[35m0.3695\u001b[0m            0.7252                     0.7253        \u001b[36m0.5345\u001b[0m  0.0000  2.2758\n",
      "     31            0.8988                     0.8990        \u001b[35m0.3600\u001b[0m            0.7303                     0.7306        0.5371  0.0000  2.2843\n",
      "     32            0.9006                     0.9006        0.3602            0.7243                     0.7244        0.5354  0.0000  2.2852\n",
      "     33            0.8995                     0.8996        \u001b[35m0.3557\u001b[0m            0.7277                     0.7279        0.5361  0.0000  2.2715\n",
      "     34            0.9001                     0.9002        0.3613            0.7269                     0.7270        0.5356  0.0000  2.2834\n",
      "     35            0.8990                     0.8992        \u001b[35m0.3553\u001b[0m            0.7269                     0.7271        0.5358  0.0000  2.3017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6506\u001b[0m                     \u001b[32m0.6683\u001b[0m        \u001b[35m1.4178\u001b[0m            \u001b[31m0.6237\u001b[0m                     \u001b[94m0.6405\u001b[0m        \u001b[36m0.7999\u001b[0m  0.0006  1.3609\n",
      "      2            \u001b[36m0.6731\u001b[0m                     \u001b[32m0.6865\u001b[0m        \u001b[35m1.0355\u001b[0m            \u001b[31m0.6252\u001b[0m                     0.6382        \u001b[36m0.6856\u001b[0m  0.0006  1.3693\n",
      "      3            \u001b[36m0.7277\u001b[0m                     \u001b[32m0.7267\u001b[0m        \u001b[35m0.8721\u001b[0m            \u001b[31m0.6512\u001b[0m                     \u001b[94m0.6477\u001b[0m        \u001b[36m0.6703\u001b[0m  0.0006  1.3444\n",
      "      4            0.6846                     0.7033        \u001b[35m0.7734\u001b[0m            0.6425                     \u001b[94m0.6617\u001b[0m        0.7152  0.0006  1.3474\n",
      "      5            \u001b[36m0.7723\u001b[0m                     \u001b[32m0.7792\u001b[0m        \u001b[35m0.7193\u001b[0m            \u001b[31m0.6773\u001b[0m                     \u001b[94m0.6848\u001b[0m        \u001b[36m0.6075\u001b[0m  0.0006  1.3639\n",
      "      6            \u001b[36m0.7726\u001b[0m                     0.7789        0.7376            \u001b[31m0.6903\u001b[0m                     \u001b[94m0.6996\u001b[0m        0.6185  0.0006  1.3610\n",
      "      7            \u001b[36m0.7755\u001b[0m                     \u001b[32m0.7860\u001b[0m        \u001b[35m0.6805\u001b[0m            \u001b[31m0.6990\u001b[0m                     \u001b[94m0.7099\u001b[0m        \u001b[36m0.5850\u001b[0m  0.0006  1.3793\n",
      "      8            \u001b[36m0.7998\u001b[0m                     \u001b[32m0.7946\u001b[0m        \u001b[35m0.6108\u001b[0m            \u001b[31m0.7048\u001b[0m                     0.6989        0.6078  0.0006  1.3564\n",
      "      9            \u001b[36m0.8316\u001b[0m                     \u001b[32m0.8329\u001b[0m        \u001b[35m0.5844\u001b[0m            \u001b[31m0.7077\u001b[0m                     0.7067        \u001b[36m0.5796\u001b[0m  0.0005  1.3457\n",
      "     10            \u001b[36m0.8374\u001b[0m                     \u001b[32m0.8390\u001b[0m        \u001b[35m0.5352\u001b[0m            0.6860                     0.6867        0.5869  0.0005  1.3783\n",
      "     11            \u001b[36m0.8490\u001b[0m                     \u001b[32m0.8481\u001b[0m        \u001b[35m0.5138\u001b[0m            \u001b[31m0.7221\u001b[0m                     \u001b[94m0.7222\u001b[0m        \u001b[36m0.5734\u001b[0m  0.0005  1.3462\n",
      "     12            0.8429                     0.8370        \u001b[35m0.5033\u001b[0m            0.6831                     0.6792        0.6392  0.0005  1.3424\n",
      "     13            \u001b[36m0.8606\u001b[0m                     \u001b[32m0.8647\u001b[0m        \u001b[35m0.4869\u001b[0m            0.7091                     0.7122        0.5966  0.0005  1.3534\n",
      "     14            \u001b[36m0.8722\u001b[0m                     \u001b[32m0.8688\u001b[0m        \u001b[35m0.4593\u001b[0m            0.7048                     0.6995        0.5998  0.0004  1.4366\n",
      "     15            0.8577                     0.8647        \u001b[35m0.4536\u001b[0m            0.7062                     0.7129        0.6024  0.0004  1.4288\n",
      "     16            0.8660                     0.8615        \u001b[35m0.4169\u001b[0m            0.7062                     0.7011        0.6197  0.0004  1.4936\n",
      "     17            0.8537                     0.8639        \u001b[35m0.4067\u001b[0m            0.6889                     0.7007        0.6025  0.0003  1.4804\n",
      "     18            0.8671                     \u001b[32m0.8754\u001b[0m        \u001b[35m0.4014\u001b[0m            0.7033                     0.7117        0.6041  0.0003  1.4417\n",
      "     19            \u001b[36m0.8972\u001b[0m                     \u001b[32m0.8939\u001b[0m        \u001b[35m0.3810\u001b[0m            0.7120                     0.7070        0.6209  0.0003  1.4003\n",
      "     20            \u001b[36m0.9070\u001b[0m                     \u001b[32m0.9072\u001b[0m        \u001b[35m0.3659\u001b[0m            0.7062                     0.7068        0.6043  0.0003  1.4256\n",
      "     21            0.9070                     \u001b[32m0.9102\u001b[0m        \u001b[35m0.3652\u001b[0m            0.7033                     0.7051        0.5973  0.0002  1.4392\n",
      "     22            \u001b[36m0.9084\u001b[0m                     0.9070        \u001b[35m0.3493\u001b[0m            0.7120                     0.7106        0.6288  0.0002  1.3858\n",
      "     23            \u001b[36m0.9240\u001b[0m                     \u001b[32m0.9229\u001b[0m        \u001b[35m0.3424\u001b[0m            0.7091                     0.7074        0.6111  0.0002  1.4430\n",
      "     24            0.9218                     0.9214        \u001b[35m0.3331\u001b[0m            0.7048                     0.7019        0.6211  0.0001  1.3961\n",
      "     25            \u001b[36m0.9280\u001b[0m                     \u001b[32m0.9298\u001b[0m        \u001b[35m0.3063\u001b[0m            0.7149                     0.7156        0.5998  0.0001  1.3905\n",
      "     26            \u001b[36m0.9316\u001b[0m                     \u001b[32m0.9332\u001b[0m        \u001b[35m0.3049\u001b[0m            0.7135                     0.7161        0.6094  0.0001  1.3923\n",
      "     27            \u001b[36m0.9323\u001b[0m                     \u001b[32m0.9335\u001b[0m        \u001b[35m0.2974\u001b[0m            0.7077                     0.7085        0.6097  0.0001  1.4628\n",
      "     28            \u001b[36m0.9374\u001b[0m                     \u001b[32m0.9385\u001b[0m        0.3060            0.7120                     0.7127        0.6119  0.0001  1.4372\n",
      "     29            \u001b[36m0.9410\u001b[0m                     \u001b[32m0.9425\u001b[0m        0.3103            0.7106                     0.7111        0.6067  0.0000  1.3833\n",
      "     30            0.9377                     0.9398        \u001b[35m0.2927\u001b[0m            0.7106                     0.7114        0.6053  0.0000  1.3974\n",
      "     31            0.9395                     0.9414        \u001b[35m0.2880\u001b[0m            0.7135                     0.7140        0.6049  0.0000  1.5137\n",
      "     32            0.9370                     0.9395        0.2906            0.7221                     \u001b[94m0.7246\u001b[0m        0.6045  0.0000  1.3728\n",
      "     33            0.9392                     0.9407        \u001b[35m0.2836\u001b[0m            0.7178                     0.7185        0.6029  0.0000  1.3504\n",
      "     34            0.9385                     0.9406        0.2847            0.7164                     0.7181        0.6047  0.0000  1.4448\n",
      "     35            0.9381                     0.9400        0.2852            0.7221                     0.7234        0.6026  0.0000  1.3974\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6575\u001b[0m                     \u001b[32m0.6680\u001b[0m        \u001b[35m1.4471\u001b[0m            \u001b[31m0.6107\u001b[0m                     \u001b[94m0.6229\u001b[0m        \u001b[36m0.7593\u001b[0m  0.0006  1.3567\n",
      "      2            \u001b[36m0.7140\u001b[0m                     \u001b[32m0.7201\u001b[0m        \u001b[35m1.0494\u001b[0m            \u001b[31m0.6469\u001b[0m                     \u001b[94m0.6545\u001b[0m        \u001b[36m0.6591\u001b[0m  0.0006  1.3784\n",
      "      3            \u001b[36m0.7263\u001b[0m                     \u001b[32m0.7308\u001b[0m        \u001b[35m0.8098\u001b[0m            \u001b[31m0.6556\u001b[0m                     \u001b[94m0.6597\u001b[0m        0.6629  0.0006  1.3414\n",
      "      4            \u001b[36m0.7581\u001b[0m                     \u001b[32m0.7668\u001b[0m        \u001b[35m0.7729\u001b[0m            \u001b[31m0.6744\u001b[0m                     \u001b[94m0.6831\u001b[0m        \u001b[36m0.6389\u001b[0m  0.0006  1.3666\n",
      "      5            \u001b[36m0.7686\u001b[0m                     \u001b[32m0.7714\u001b[0m        \u001b[35m0.7245\u001b[0m            \u001b[31m0.6874\u001b[0m                     \u001b[94m0.6919\u001b[0m        \u001b[36m0.6178\u001b[0m  0.0006  1.3564\n",
      "      6            \u001b[36m0.7864\u001b[0m                     \u001b[32m0.7931\u001b[0m        \u001b[35m0.6776\u001b[0m            \u001b[31m0.6932\u001b[0m                     \u001b[94m0.7016\u001b[0m        \u001b[36m0.5968\u001b[0m  0.0006  1.4181\n",
      "      7            \u001b[36m0.7918\u001b[0m                     \u001b[32m0.8023\u001b[0m        \u001b[35m0.6427\u001b[0m            0.6831                     0.6949        \u001b[36m0.5904\u001b[0m  0.0006  1.3550\n",
      "      8            \u001b[36m0.8005\u001b[0m                     \u001b[32m0.8083\u001b[0m        \u001b[35m0.5960\u001b[0m            \u001b[31m0.6961\u001b[0m                     \u001b[94m0.7046\u001b[0m        0.6018  0.0006  1.3660\n",
      "      9            \u001b[36m0.8269\u001b[0m                     \u001b[32m0.8294\u001b[0m        \u001b[35m0.5655\u001b[0m            \u001b[31m0.7048\u001b[0m                     \u001b[94m0.7079\u001b[0m        \u001b[36m0.5892\u001b[0m  0.0005  1.3520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10            \u001b[36m0.8356\u001b[0m                     \u001b[32m0.8353\u001b[0m        \u001b[35m0.5101\u001b[0m            0.6932                     0.6923        0.6084  0.0005  1.3698\n",
      "     11            \u001b[36m0.8418\u001b[0m                     \u001b[32m0.8484\u001b[0m        \u001b[35m0.5073\u001b[0m            \u001b[31m0.7135\u001b[0m                     \u001b[94m0.7200\u001b[0m        \u001b[36m0.5884\u001b[0m  0.0005  1.3649\n",
      "     12            0.8309                     0.8416        \u001b[35m0.4680\u001b[0m            0.7019                     0.7152        0.5932  0.0005  1.3923\n",
      "     13            \u001b[36m0.8602\u001b[0m                     \u001b[32m0.8614\u001b[0m        0.4680            \u001b[31m0.7149\u001b[0m                     0.7165        0.5912  0.0005  1.4304\n",
      "     14            \u001b[36m0.8805\u001b[0m                     \u001b[32m0.8817\u001b[0m        \u001b[35m0.4471\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7279\u001b[0m        \u001b[36m0.5757\u001b[0m  0.0004  1.4762\n",
      "     15            0.8646                     0.8715        \u001b[35m0.4272\u001b[0m            0.7236                     \u001b[94m0.7313\u001b[0m        0.5806  0.0004  1.5086\n",
      "     16            \u001b[36m0.8888\u001b[0m                     \u001b[32m0.8920\u001b[0m        \u001b[35m0.3939\u001b[0m            \u001b[31m0.7352\u001b[0m                     \u001b[94m0.7376\u001b[0m        \u001b[36m0.5544\u001b[0m  0.0004  1.5126\n",
      "     17            \u001b[36m0.8892\u001b[0m                     \u001b[32m0.8933\u001b[0m        \u001b[35m0.3912\u001b[0m            0.7337                     \u001b[94m0.7390\u001b[0m        0.5573  0.0003  1.4245\n",
      "     18            \u001b[36m0.8979\u001b[0m                     \u001b[32m0.8947\u001b[0m        \u001b[35m0.3743\u001b[0m            0.7221                     0.7177        0.5878  0.0003  1.3979\n",
      "     19            \u001b[36m0.9084\u001b[0m                     \u001b[32m0.9091\u001b[0m        \u001b[35m0.3729\u001b[0m            0.7236                     0.7244        0.5598  0.0003  1.4379\n",
      "     20            \u001b[36m0.9113\u001b[0m                     \u001b[32m0.9124\u001b[0m        \u001b[35m0.3615\u001b[0m            0.7323                     0.7332        0.5698  0.0003  1.3808\n",
      "     21            \u001b[36m0.9131\u001b[0m                     \u001b[32m0.9161\u001b[0m        \u001b[35m0.3263\u001b[0m            0.7279                     0.7322        0.5805  0.0002  1.3819\n",
      "     22            \u001b[36m0.9247\u001b[0m                     \u001b[32m0.9270\u001b[0m        0.3296            0.7323                     0.7344        0.5706  0.0002  1.3803\n",
      "     23            0.9200                     0.9239        0.3284            \u001b[31m0.7424\u001b[0m                     \u001b[94m0.7481\u001b[0m        0.5708  0.0002  1.3851\n",
      "     24            \u001b[36m0.9334\u001b[0m                     \u001b[32m0.9340\u001b[0m        \u001b[35m0.3166\u001b[0m            0.7424                     0.7427        0.5667  0.0001  1.3888\n",
      "     25            0.9301                     0.9320        \u001b[35m0.3016\u001b[0m            0.7337                     0.7348        0.5758  0.0001  1.3996\n",
      "     26            0.9334                     \u001b[32m0.9359\u001b[0m        \u001b[35m0.3009\u001b[0m            0.7424                     0.7457        0.5624  0.0001  1.4114\n",
      "     27            \u001b[36m0.9377\u001b[0m                     \u001b[32m0.9398\u001b[0m        \u001b[35m0.2870\u001b[0m            0.7410                     0.7441        0.5704  0.0001  1.4117\n",
      "     28            0.9377                     0.9395        \u001b[35m0.2739\u001b[0m            0.7352                     0.7370        0.5688  0.0001  1.3868\n",
      "     29            \u001b[36m0.9442\u001b[0m                     \u001b[32m0.9446\u001b[0m        0.2866            0.7323                     0.7317        0.5729  0.0000  1.3888\n",
      "     30            0.9395                     0.9415        0.2783            0.7410                     0.7438        0.5724  0.0000  1.3778\n",
      "     31            0.9385                     0.9408        \u001b[35m0.2663\u001b[0m            0.7424                     0.7463        0.5708  0.0000  1.3810\n",
      "     32            0.9442                     \u001b[32m0.9462\u001b[0m        \u001b[35m0.2634\u001b[0m            0.7337                     0.7363        0.5696  0.0000  1.3848\n",
      "     33            \u001b[36m0.9475\u001b[0m                     \u001b[32m0.9486\u001b[0m        0.2733            0.7381                     0.7390        0.5687  0.0000  1.3943\n",
      "     34            0.9450                     0.9463        0.2748            0.7366                     0.7380        0.5688  0.0000  1.3863\n",
      "     35            0.9432                     0.9449        0.2701            0.7337                     0.7360        0.5691  0.0000  1.3837\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6412\u001b[0m                     \u001b[32m0.6603\u001b[0m        \u001b[35m1.3463\u001b[0m            \u001b[31m0.6208\u001b[0m                     \u001b[94m0.6366\u001b[0m        \u001b[36m0.8238\u001b[0m  0.0006  1.4935\n",
      "      2            \u001b[36m0.6999\u001b[0m                     \u001b[32m0.7086\u001b[0m        \u001b[35m1.0792\u001b[0m            \u001b[31m0.6614\u001b[0m                     \u001b[94m0.6662\u001b[0m        \u001b[36m0.6534\u001b[0m  0.0006  1.3814\n",
      "      3            \u001b[36m0.7187\u001b[0m                     \u001b[32m0.7280\u001b[0m        \u001b[35m0.8937\u001b[0m            \u001b[31m0.6700\u001b[0m                     \u001b[94m0.6773\u001b[0m        \u001b[36m0.6221\u001b[0m  0.0006  1.3681\n",
      "      4            \u001b[36m0.7306\u001b[0m                     \u001b[32m0.7444\u001b[0m        \u001b[35m0.7859\u001b[0m            \u001b[31m0.6816\u001b[0m                     \u001b[94m0.6942\u001b[0m        \u001b[36m0.6170\u001b[0m  0.0006  1.3506\n",
      "      5            \u001b[36m0.7668\u001b[0m                     \u001b[32m0.7746\u001b[0m        \u001b[35m0.7467\u001b[0m            0.6671                     0.6726        \u001b[36m0.6035\u001b[0m  0.0006  1.4195\n",
      "      6            \u001b[36m0.7918\u001b[0m                     \u001b[32m0.7964\u001b[0m        \u001b[35m0.6877\u001b[0m            \u001b[31m0.7135\u001b[0m                     \u001b[94m0.7134\u001b[0m        \u001b[36m0.5709\u001b[0m  0.0006  1.4282\n",
      "      7            0.7762                     0.7862        \u001b[35m0.6275\u001b[0m            0.7077                     \u001b[94m0.7166\u001b[0m        0.5781  0.0006  1.4447\n",
      "      8            \u001b[36m0.8164\u001b[0m                     \u001b[32m0.8146\u001b[0m        \u001b[35m0.5939\u001b[0m            0.7077                     0.7006        0.5710  0.0006  1.3514\n",
      "      9            \u001b[36m0.8251\u001b[0m                     \u001b[32m0.8250\u001b[0m        \u001b[35m0.5792\u001b[0m            \u001b[31m0.7192\u001b[0m                     0.7147        \u001b[36m0.5664\u001b[0m  0.0005  1.5060\n",
      "     10            \u001b[36m0.8418\u001b[0m                     \u001b[32m0.8451\u001b[0m        \u001b[35m0.5314\u001b[0m            0.7192                     \u001b[94m0.7172\u001b[0m        \u001b[36m0.5347\u001b[0m  0.0005  1.4950\n",
      "     11            0.8302                     0.8387        \u001b[35m0.5268\u001b[0m            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7346\u001b[0m        0.5377  0.0005  1.5049\n",
      "     12            \u001b[36m0.8516\u001b[0m                     \u001b[32m0.8594\u001b[0m        \u001b[35m0.4828\u001b[0m            0.7221                     0.7267        0.5430  0.0005  1.3803\n",
      "     13            \u001b[36m0.8613\u001b[0m                     0.8569        \u001b[35m0.4805\u001b[0m            \u001b[31m0.7294\u001b[0m                     0.7200        0.5425  0.0005  1.4551\n",
      "     14            \u001b[36m0.8635\u001b[0m                     \u001b[32m0.8698\u001b[0m        \u001b[35m0.4439\u001b[0m            0.7294                     \u001b[94m0.7360\u001b[0m        \u001b[36m0.5183\u001b[0m  0.0004  1.3539\n",
      "     15            \u001b[36m0.8780\u001b[0m                     \u001b[32m0.8733\u001b[0m        \u001b[35m0.4304\u001b[0m            0.7250                     0.7161        0.5554  0.0004  1.3750\n",
      "     16            0.8780                     \u001b[32m0.8799\u001b[0m        \u001b[35m0.4125\u001b[0m            0.7294                     0.7272        0.5399  0.0004  1.3646\n",
      "     17            0.8650                     0.8748        \u001b[35m0.3975\u001b[0m            0.7178                     0.7267        0.5547  0.0003  1.3444\n",
      "     18            \u001b[36m0.8907\u001b[0m                     \u001b[32m0.8869\u001b[0m        \u001b[35m0.3806\u001b[0m            \u001b[31m0.7366\u001b[0m                     0.7266        0.5765  0.0003  1.3957\n",
      "     19            \u001b[36m0.9073\u001b[0m                     \u001b[32m0.9084\u001b[0m        \u001b[35m0.3738\u001b[0m            0.7337                     0.7291        0.5426  0.0003  1.5200\n",
      "     20            0.9026                     0.9046        \u001b[35m0.3681\u001b[0m            0.7308                     0.7292        0.5391  0.0003  1.4431\n",
      "     21            \u001b[36m0.9200\u001b[0m                     \u001b[32m0.9220\u001b[0m        \u001b[35m0.3584\u001b[0m            0.7308                     0.7280        0.5300  0.0002  1.4741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22            0.9189                     0.9203        \u001b[35m0.3542\u001b[0m            \u001b[31m0.7395\u001b[0m                     \u001b[94m0.7376\u001b[0m        0.5337  0.0002  1.5253\n",
      "     23            0.9189                     0.9218        \u001b[35m0.3443\u001b[0m            \u001b[31m0.7410\u001b[0m                     \u001b[94m0.7410\u001b[0m        0.5316  0.0002  1.4409\n",
      "     24            \u001b[36m0.9312\u001b[0m                     \u001b[32m0.9325\u001b[0m        \u001b[35m0.3322\u001b[0m            0.7410                     0.7374        0.5285  0.0001  1.4088\n",
      "     25            \u001b[36m0.9316\u001b[0m                     0.9323        \u001b[35m0.3004\u001b[0m            0.7395                     0.7358        0.5327  0.0001  1.4005\n",
      "     26            0.9290                     0.9322        0.3146            \u001b[31m0.7424\u001b[0m                     \u001b[94m0.7442\u001b[0m        0.5438  0.0001  1.4580\n",
      "     27            \u001b[36m0.9413\u001b[0m                     \u001b[32m0.9434\u001b[0m        0.3096            0.7337                     0.7315        0.5374  0.0001  1.3813\n",
      "     28            0.9370                     0.9402        \u001b[35m0.2965\u001b[0m            0.7424                     0.7433        0.5458  0.0001  1.3839\n",
      "     29            0.9406                     0.9422        \u001b[35m0.2951\u001b[0m            0.7308                     0.7283        0.5431  0.0000  1.4244\n",
      "     30            \u001b[36m0.9450\u001b[0m                     \u001b[32m0.9460\u001b[0m        \u001b[35m0.2893\u001b[0m            0.7279                     0.7238        0.5441  0.0000  1.4254\n",
      "     31            0.9388                     0.9414        0.2899            0.7323                     0.7314        0.5385  0.0000  1.4253\n",
      "     32            \u001b[36m0.9475\u001b[0m                     \u001b[32m0.9486\u001b[0m        0.2978            0.7250                     0.7206        0.5419  0.0000  1.4010\n",
      "     33            0.9471                     0.9480        \u001b[35m0.2784\u001b[0m            0.7250                     0.7197        0.5423  0.0000  1.3974\n",
      "     34            0.9471                     0.9485        0.2865            0.7250                     0.7209        0.5411  0.0000  1.4579\n",
      "     35            0.9475                     0.9481        0.2810            0.7265                     0.7204        0.5445  0.0000  1.3494\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6647\u001b[0m                     \u001b[32m0.6553\u001b[0m        \u001b[35m1.3933\u001b[0m            \u001b[31m0.6122\u001b[0m                     \u001b[94m0.6008\u001b[0m        \u001b[36m0.7601\u001b[0m  0.0006  1.5397\n",
      "      2            \u001b[36m0.7085\u001b[0m                     \u001b[32m0.7137\u001b[0m        \u001b[35m1.0219\u001b[0m            \u001b[31m0.6831\u001b[0m                     \u001b[94m0.6886\u001b[0m        \u001b[36m0.6349\u001b[0m  0.0006  1.5700\n",
      "      3            0.6995                     0.6855        \u001b[35m0.8670\u001b[0m            0.6368                     0.6195        0.6758  0.0006  1.6003\n",
      "      4            \u001b[36m0.7458\u001b[0m                     \u001b[32m0.7501\u001b[0m        \u001b[35m0.7602\u001b[0m            \u001b[31m0.6889\u001b[0m                     \u001b[94m0.6932\u001b[0m        \u001b[36m0.5798\u001b[0m  0.0006  1.6102\n",
      "      5            \u001b[36m0.7480\u001b[0m                     \u001b[32m0.7620\u001b[0m        \u001b[35m0.7522\u001b[0m            \u001b[31m0.7236\u001b[0m                     \u001b[94m0.7355\u001b[0m        \u001b[36m0.5632\u001b[0m  0.0006  1.6125\n",
      "      6            \u001b[36m0.7509\u001b[0m                     \u001b[32m0.7621\u001b[0m        \u001b[35m0.6869\u001b[0m            0.6758                     0.6865        0.6204  0.0006  1.5958\n",
      "      7            \u001b[36m0.7828\u001b[0m                     \u001b[32m0.7846\u001b[0m        \u001b[35m0.6773\u001b[0m            0.6816                     0.6803        0.6059  0.0006  1.6027\n",
      "      8            0.7741                     \u001b[32m0.7858\u001b[0m        \u001b[35m0.6263\u001b[0m            0.7033                     0.7144        0.5986  0.0006  1.6104\n",
      "      9            \u001b[36m0.8016\u001b[0m                     \u001b[32m0.8114\u001b[0m        \u001b[35m0.5857\u001b[0m            0.7106                     0.7201        0.5796  0.0005  1.5926\n",
      "     10            \u001b[36m0.8508\u001b[0m                     \u001b[32m0.8517\u001b[0m        \u001b[35m0.5533\u001b[0m            0.7120                     0.7109        0.5737  0.0005  1.6028\n",
      "     11            0.8204                     0.8312        \u001b[35m0.5153\u001b[0m            0.6990                     0.7099        0.6031  0.0005  1.6081\n",
      "     12            \u001b[36m0.8592\u001b[0m                     \u001b[32m0.8630\u001b[0m        \u001b[35m0.5022\u001b[0m            0.7091                     0.7128        0.5690  0.0005  1.5937\n",
      "     13            0.8429                     0.8486        \u001b[35m0.4635\u001b[0m            0.6975                     0.7032        0.6056  0.0005  1.5913\n",
      "     14            \u001b[36m0.8606\u001b[0m                     \u001b[32m0.8674\u001b[0m        \u001b[35m0.4353\u001b[0m            0.7019                     0.7092        0.5910  0.0004  1.5984\n",
      "     15            \u001b[36m0.8791\u001b[0m                     \u001b[32m0.8844\u001b[0m        0.4420            0.6918                     0.6991        0.6031  0.0004  1.5227\n",
      "     16            0.8327                     0.8458        \u001b[35m0.4219\u001b[0m            0.7091                     0.7245        0.6391  0.0004  1.4145\n",
      "     17            \u001b[36m0.9008\u001b[0m                     \u001b[32m0.8986\u001b[0m        \u001b[35m0.3946\u001b[0m            0.7062                     0.7011        0.5803  0.0003  1.4283\n",
      "     18            \u001b[36m0.9062\u001b[0m                     \u001b[32m0.9079\u001b[0m        \u001b[35m0.3859\u001b[0m            0.7135                     0.7140        0.5730  0.0003  1.4572\n",
      "     19            0.9022                     0.9066        \u001b[35m0.3786\u001b[0m            \u001b[31m0.7265\u001b[0m                     0.7303        0.5680  0.0003  1.4488\n",
      "     20            \u001b[36m0.9156\u001b[0m                     \u001b[32m0.9158\u001b[0m        \u001b[35m0.3681\u001b[0m            0.7120                     0.7109        0.5662  0.0003  1.4134\n",
      "     21            \u001b[36m0.9222\u001b[0m                     \u001b[32m0.9249\u001b[0m        \u001b[35m0.3502\u001b[0m            0.6932                     0.6950        0.5828  0.0002  1.3822\n",
      "     22            0.9160                     0.9194        \u001b[35m0.3452\u001b[0m            0.7019                     0.7059        0.5844  0.0002  1.3574\n",
      "     23            \u001b[36m0.9316\u001b[0m                     \u001b[32m0.9316\u001b[0m        \u001b[35m0.3354\u001b[0m            0.7120                     0.7106        0.5757  0.0002  1.3755\n",
      "     24            \u001b[36m0.9327\u001b[0m                     \u001b[32m0.9340\u001b[0m        \u001b[35m0.3211\u001b[0m            0.7019                     0.7014        0.5755  0.0001  1.3663\n",
      "     25            0.9290                     0.9326        \u001b[35m0.3085\u001b[0m            0.7221                     0.7270        0.5786  0.0001  1.6093\n",
      "     26            \u001b[36m0.9334\u001b[0m                     \u001b[32m0.9357\u001b[0m        0.3102            0.7178                     0.7197        0.5748  0.0001  1.6145\n",
      "     27            \u001b[36m0.9366\u001b[0m                     \u001b[32m0.9397\u001b[0m        \u001b[35m0.2913\u001b[0m            0.7004                     0.7040        0.5861  0.0001  1.6070\n",
      "     28            \u001b[36m0.9374\u001b[0m                     0.9391        \u001b[35m0.2845\u001b[0m            0.7192                     0.7202        0.5842  0.0001  1.5656\n",
      "     29            \u001b[36m0.9395\u001b[0m                     \u001b[32m0.9421\u001b[0m        \u001b[35m0.2769\u001b[0m            0.7091                     0.7107        0.5883  0.0000  1.4697\n",
      "     30            \u001b[36m0.9399\u001b[0m                     0.9414        0.2873            0.7135                     0.7137        0.5885  0.0000  1.4147\n",
      "     31            \u001b[36m0.9424\u001b[0m                     \u001b[32m0.9434\u001b[0m        0.2774            0.7149                     0.7135        0.5859  0.0000  1.4288\n",
      "     32            0.9421                     \u001b[32m0.9441\u001b[0m        \u001b[35m0.2754\u001b[0m            0.7192                     0.7208        0.5875  0.0000  1.4197\n",
      "     33            \u001b[36m0.9439\u001b[0m                     \u001b[32m0.9459\u001b[0m        0.2849            0.7149                     0.7162        0.5881  0.0000  1.4222\n",
      "     34            0.9413                     0.9436        \u001b[35m0.2734\u001b[0m            0.7192                     0.7211        0.5874  0.0000  1.4187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35            0.9424                     0.9447        0.2770            0.7178                     0.7194        0.5882  0.0000  1.4137\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6499\u001b[0m                     \u001b[32m0.6680\u001b[0m        \u001b[35m1.4115\u001b[0m            \u001b[31m0.6179\u001b[0m                     \u001b[94m0.6319\u001b[0m        \u001b[36m0.7828\u001b[0m  0.0006  1.4271\n",
      "      2            \u001b[36m0.6919\u001b[0m                     \u001b[32m0.6970\u001b[0m        \u001b[35m0.9991\u001b[0m            \u001b[31m0.6368\u001b[0m                     \u001b[94m0.6387\u001b[0m        \u001b[36m0.7041\u001b[0m  0.0006  1.4137\n",
      "      3            0.6383                     0.6603        \u001b[35m0.8745\u001b[0m            0.5890                     0.6120        0.8594  0.0006  1.4149\n",
      "      4            \u001b[36m0.7183\u001b[0m                     \u001b[32m0.7313\u001b[0m        \u001b[35m0.8189\u001b[0m            \u001b[31m0.6425\u001b[0m                     \u001b[94m0.6533\u001b[0m        \u001b[36m0.6584\u001b[0m  0.0006  1.4197\n",
      "      5            \u001b[36m0.7567\u001b[0m                     \u001b[32m0.7591\u001b[0m        \u001b[35m0.7227\u001b[0m            \u001b[31m0.6961\u001b[0m                     \u001b[94m0.6950\u001b[0m        \u001b[36m0.6245\u001b[0m  0.0006  1.4088\n",
      "      6            \u001b[36m0.7907\u001b[0m                     \u001b[32m0.7871\u001b[0m        \u001b[35m0.6614\u001b[0m            0.6802                     0.6724        \u001b[36m0.6217\u001b[0m  0.0006  1.4209\n",
      "      7            0.7534                     0.7342        \u001b[35m0.6563\u001b[0m            0.6295                     0.6024        0.7584  0.0006  1.4102\n",
      "      8            \u001b[36m0.8063\u001b[0m                     \u001b[32m0.8010\u001b[0m        \u001b[35m0.6085\u001b[0m            \u001b[31m0.6975\u001b[0m                     0.6875        \u001b[36m0.6193\u001b[0m  0.0006  1.4207\n",
      "      9            \u001b[36m0.8287\u001b[0m                     \u001b[32m0.8323\u001b[0m        \u001b[35m0.5695\u001b[0m            0.6946                     \u001b[94m0.6960\u001b[0m        \u001b[36m0.5782\u001b[0m  0.0005  1.4180\n",
      "     10            \u001b[36m0.8306\u001b[0m                     \u001b[32m0.8339\u001b[0m        \u001b[35m0.5330\u001b[0m            \u001b[31m0.7106\u001b[0m                     \u001b[94m0.7105\u001b[0m        0.5827  0.0005  1.5115\n",
      "     11            \u001b[36m0.8335\u001b[0m                     \u001b[32m0.8371\u001b[0m        \u001b[35m0.4865\u001b[0m            \u001b[31m0.7135\u001b[0m                     \u001b[94m0.7161\u001b[0m        0.5829  0.0005  1.4178\n",
      "     12            \u001b[36m0.8403\u001b[0m                     \u001b[32m0.8476\u001b[0m        \u001b[35m0.4773\u001b[0m            0.6889                     0.6956        0.6025  0.0005  1.4188\n",
      "     13            0.8331                     0.8352        \u001b[35m0.4773\u001b[0m            0.7106                     0.7117        0.5900  0.0005  1.4247\n",
      "     14            \u001b[36m0.8704\u001b[0m                     \u001b[32m0.8723\u001b[0m        \u001b[35m0.4684\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7270\u001b[0m        \u001b[36m0.5779\u001b[0m  0.0004  1.4541\n",
      "     15            \u001b[36m0.8787\u001b[0m                     \u001b[32m0.8769\u001b[0m        \u001b[35m0.4507\u001b[0m            0.7265                     0.7213        0.5982  0.0004  1.6122\n",
      "     16            0.8783                     \u001b[32m0.8841\u001b[0m        \u001b[35m0.4191\u001b[0m            0.7207                     0.7260        \u001b[36m0.5766\u001b[0m  0.0004  1.5199\n",
      "     17            \u001b[36m0.8860\u001b[0m                     \u001b[32m0.8921\u001b[0m        \u001b[35m0.4066\u001b[0m            0.7004                     0.7052        0.5955  0.0003  1.5479\n",
      "     18            \u001b[36m0.8928\u001b[0m                     \u001b[32m0.8958\u001b[0m        \u001b[35m0.3775\u001b[0m            0.7135                     0.7167        0.5770  0.0003  1.6079\n",
      "     19            \u001b[36m0.9059\u001b[0m                     \u001b[32m0.9056\u001b[0m        0.3814            0.6932                     0.6917        0.6231  0.0003  1.5998\n",
      "     20            0.8682                     0.8771        \u001b[35m0.3684\u001b[0m            0.7033                     0.7144        0.6086  0.0003  1.6097\n",
      "     21            \u001b[36m0.9156\u001b[0m                     \u001b[32m0.9132\u001b[0m        \u001b[35m0.3530\u001b[0m            0.7236                     0.7172        0.6047  0.0002  1.6033\n",
      "     22            \u001b[36m0.9178\u001b[0m                     \u001b[32m0.9206\u001b[0m        \u001b[35m0.3362\u001b[0m            0.7236                     0.7259        0.5839  0.0002  1.6007\n",
      "     23            \u001b[36m0.9276\u001b[0m                     \u001b[32m0.9259\u001b[0m        \u001b[35m0.3194\u001b[0m            0.7265                     0.7189        0.6060  0.0002  1.6045\n",
      "     24            \u001b[36m0.9305\u001b[0m                     \u001b[32m0.9324\u001b[0m        0.3314            0.7192                     0.7178        0.5991  0.0001  1.5978\n",
      "     25            \u001b[36m0.9392\u001b[0m                     \u001b[32m0.9412\u001b[0m        \u001b[35m0.3150\u001b[0m            \u001b[31m0.7323\u001b[0m                     \u001b[94m0.7326\u001b[0m        0.5817  0.0001  1.6062\n",
      "     26            \u001b[36m0.9417\u001b[0m                     \u001b[32m0.9423\u001b[0m        \u001b[35m0.3099\u001b[0m            0.7221                     0.7189        0.5899  0.0001  1.6030\n",
      "     27            \u001b[36m0.9439\u001b[0m                     \u001b[32m0.9449\u001b[0m        \u001b[35m0.2785\u001b[0m            0.7308                     0.7289        0.5910  0.0001  1.6053\n",
      "     28            0.9439                     0.9443        0.2932            0.7294                     0.7257        0.6007  0.0001  1.6062\n",
      "     29            0.9406                     0.9430        0.3012            0.7265                     0.7270        0.5895  0.0000  1.4102\n",
      "     30            \u001b[36m0.9457\u001b[0m                     \u001b[32m0.9477\u001b[0m        0.2869            0.7294                     0.7290        0.5882  0.0000  1.4119\n",
      "     31            0.9435                     0.9456        \u001b[35m0.2773\u001b[0m            0.7265                     0.7261        0.5902  0.0000  1.4157\n",
      "     32            \u001b[36m0.9468\u001b[0m                     \u001b[32m0.9486\u001b[0m        0.2900            0.7279                     0.7268        0.5913  0.0000  1.6023\n",
      "     33            0.9457                     0.9475        0.2777            0.7236                     0.7229        0.5910  0.0000  1.4307\n",
      "     34            0.9442                     0.9462        \u001b[35m0.2708\u001b[0m            0.7250                     0.7245        0.5909  0.0000  1.4916\n",
      "     35            0.9421                     0.9441        0.2799            0.7265                     0.7261        0.5898  0.0000  1.6046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7430\u001b[0m                     \u001b[32m0.6703\u001b[0m        \u001b[35m1.2802\u001b[0m            \u001b[31m0.7216\u001b[0m                     \u001b[94m0.6377\u001b[0m        \u001b[36m0.7772\u001b[0m  0.0006  3.8165\n",
      "      2            \u001b[36m0.7654\u001b[0m                     \u001b[32m0.7059\u001b[0m        \u001b[35m0.9571\u001b[0m            \u001b[31m0.7223\u001b[0m                     \u001b[94m0.6396\u001b[0m        \u001b[36m0.7202\u001b[0m  0.0006  3.5352\n",
      "      3            0.7502                     \u001b[32m0.7171\u001b[0m        \u001b[35m0.8457\u001b[0m            0.7056                     \u001b[94m0.6485\u001b[0m        \u001b[36m0.6911\u001b[0m  0.0006  3.5368\n",
      "      4            \u001b[36m0.8005\u001b[0m                     0.7078        \u001b[35m0.7529\u001b[0m            \u001b[31m0.7628\u001b[0m                     \u001b[94m0.6496\u001b[0m        0.7289  0.0006  3.5285\n",
      "      5            0.7636                     \u001b[32m0.7381\u001b[0m        \u001b[35m0.6880\u001b[0m            0.7110                     \u001b[94m0.6590\u001b[0m        \u001b[36m0.6882\u001b[0m  0.0006  3.1646\n",
      "      6            0.7276                     \u001b[32m0.7794\u001b[0m        0.6969            0.6731                     \u001b[94m0.7003\u001b[0m        \u001b[36m0.6160\u001b[0m  0.0006  3.3910\n",
      "      7            0.7998                     \u001b[32m0.7799\u001b[0m        \u001b[35m0.6110\u001b[0m            0.7389                     0.6760        0.6581  0.0006  3.5311\n",
      "      8            \u001b[36m0.8060\u001b[0m                     0.7313        \u001b[35m0.5933\u001b[0m            0.7522                     0.6373        0.7588  0.0006  3.6390\n",
      "      9            0.7719                     \u001b[32m0.8112\u001b[0m        \u001b[35m0.5796\u001b[0m            0.6983                     0.6952        \u001b[36m0.6048\u001b[0m  0.0005  3.5336\n",
      "     10            \u001b[36m0.8547\u001b[0m                     0.8044        0.5904            \u001b[31m0.7914\u001b[0m                     0.6772        0.6655  0.0005  3.5725\n",
      "     11            0.8164                     \u001b[32m0.8214\u001b[0m        \u001b[35m0.5206\u001b[0m            0.7395                     0.6983        0.6125  0.0005  3.5368\n",
      "     12            0.8286                     \u001b[32m0.8361\u001b[0m        \u001b[35m0.5003\u001b[0m            0.7429                     0.6901        0.6138  0.0005  3.5887\n",
      "     13            0.8238                     \u001b[32m0.8489\u001b[0m        \u001b[35m0.4749\u001b[0m            0.7468                     \u001b[94m0.7159\u001b[0m        \u001b[36m0.6048\u001b[0m  0.0005  3.6180\n",
      "     14            0.8533                     0.8482        \u001b[35m0.4519\u001b[0m            0.7754                     0.7158        0.6370  0.0004  3.5690\n",
      "     15            0.8140                     \u001b[32m0.8536\u001b[0m        0.4521            0.7229                     0.7072        0.6069  0.0004  3.5994\n",
      "     16            \u001b[36m0.8560\u001b[0m                     \u001b[32m0.8696\u001b[0m        0.4643            0.7495                     0.7029        0.6124  0.0004  3.5702\n",
      "     17            \u001b[36m0.8849\u001b[0m                     0.8660        \u001b[35m0.4201\u001b[0m            0.7874                     0.7055        0.6386  0.0003  3.5655\n",
      "     18            0.8756                     \u001b[32m0.8819\u001b[0m        \u001b[35m0.3997\u001b[0m            0.7801                     \u001b[94m0.7186\u001b[0m        0.6358  0.0003  3.5819\n",
      "     19            \u001b[36m0.8973\u001b[0m                     \u001b[32m0.8922\u001b[0m        \u001b[35m0.3831\u001b[0m            0.7887                     0.6990        0.6450  0.0003  3.5715\n",
      "     20            0.8915                     0.8898        \u001b[35m0.3656\u001b[0m            0.7880                     0.7132        0.6406  0.0003  3.5641\n",
      "     21            0.8950                     0.8853        \u001b[35m0.3621\u001b[0m            \u001b[31m0.8000\u001b[0m                     \u001b[94m0.7205\u001b[0m        0.6579  0.0002  3.5488\n",
      "     22            0.8902                     \u001b[32m0.9076\u001b[0m        \u001b[35m0.3469\u001b[0m            0.7794                     0.7182        0.6269  0.0002  3.1305\n",
      "     23            0.8945                     \u001b[32m0.9113\u001b[0m        0.3476            0.7867                     \u001b[94m0.7270\u001b[0m        0.6258  0.0002  2.9965\n",
      "     24            0.8887                     \u001b[32m0.9169\u001b[0m        \u001b[35m0.3444\u001b[0m            0.7688                     \u001b[94m0.7322\u001b[0m        0.6168  0.0001  3.0307\n",
      "     25            0.8857                     0.9148        \u001b[35m0.3261\u001b[0m            0.7714                     0.7250        0.6192  0.0001  3.2668\n",
      "     26            \u001b[36m0.9007\u001b[0m                     \u001b[32m0.9250\u001b[0m        \u001b[35m0.3260\u001b[0m            0.7801                     0.7201        0.6314  0.0001  3.3106\n",
      "     27            \u001b[36m0.9103\u001b[0m                     \u001b[32m0.9286\u001b[0m        \u001b[35m0.3128\u001b[0m            0.7940                     0.7212        0.6368  0.0001  3.4041\n",
      "     28            0.9103                     0.9261        \u001b[35m0.3119\u001b[0m            0.7960                     0.7181        0.6510  0.0001  3.4194\n",
      "     29            \u001b[36m0.9110\u001b[0m                     \u001b[32m0.9294\u001b[0m        \u001b[35m0.2980\u001b[0m            0.7874                     0.7084        0.6425  0.0000  3.0237\n",
      "     30            \u001b[36m0.9184\u001b[0m                     \u001b[32m0.9317\u001b[0m        \u001b[35m0.2893\u001b[0m            0.7973                     0.7145        0.6540  0.0000  2.9960\n",
      "     31            0.9166                     \u001b[32m0.9325\u001b[0m        0.2937            0.7914                     0.7196        0.6489  0.0000  3.0321\n",
      "     32            \u001b[36m0.9208\u001b[0m                     \u001b[32m0.9346\u001b[0m        0.2982            0.8000                     0.7190        0.6540  0.0000  3.0289\n",
      "     33            0.9153                     0.9338        0.2918            0.7907                     0.7192        0.6466  0.0000  2.9984\n",
      "     34            \u001b[36m0.9234\u001b[0m                     \u001b[32m0.9348\u001b[0m        0.2935            \u001b[31m0.8007\u001b[0m                     0.7151        0.6575  0.0000  3.0096\n",
      "     35            0.9198                     0.9329        0.2906            0.7967                     0.7156        0.6525  0.0000  2.9863\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7186\u001b[0m                     \u001b[32m0.6719\u001b[0m        \u001b[35m1.2893\u001b[0m            \u001b[31m0.7023\u001b[0m                     \u001b[94m0.6362\u001b[0m        \u001b[36m0.7030\u001b[0m  0.0006  2.9586\n",
      "      2            \u001b[36m0.7772\u001b[0m                     0.6692        \u001b[35m1.0128\u001b[0m            \u001b[31m0.7714\u001b[0m                     \u001b[94m0.6447\u001b[0m        0.7263  0.0006  2.9699\n",
      "      3            0.5412                     \u001b[32m0.6792\u001b[0m        \u001b[35m0.8129\u001b[0m            0.5017                     0.6311        0.7424  0.0006  2.9525\n",
      "      4            0.7186                     \u001b[32m0.7528\u001b[0m        \u001b[35m0.7898\u001b[0m            0.6611                     \u001b[94m0.6769\u001b[0m        \u001b[36m0.6119\u001b[0m  0.0006  2.9516\n",
      "      5            0.7040                     0.7508        \u001b[35m0.7163\u001b[0m            0.6591                     \u001b[94m0.6918\u001b[0m        0.6216  0.0006  2.9332\n",
      "      6            0.7452                     0.6976        \u001b[35m0.6537\u001b[0m            0.7216                     0.6363        0.7438  0.0006  2.9806\n",
      "      7            0.7561                     \u001b[32m0.7913\u001b[0m        0.6636            0.6950                     \u001b[94m0.7049\u001b[0m        \u001b[36m0.5723\u001b[0m  0.0006  2.9510\n",
      "      8            0.6645                     0.7663        \u001b[35m0.5971\u001b[0m            0.5874                     0.6715        0.6322  0.0006  2.9641\n",
      "      9            \u001b[36m0.8098\u001b[0m                     \u001b[32m0.8042\u001b[0m        \u001b[35m0.5417\u001b[0m            0.7568                     \u001b[94m0.7059\u001b[0m        0.5948  0.0005  2.9867\n",
      "     10            0.7480                     \u001b[32m0.8069\u001b[0m        \u001b[35m0.5335\u001b[0m            0.6744                     0.6879        0.6091  0.0005  2.9835\n",
      "     11            \u001b[36m0.8392\u001b[0m                     \u001b[32m0.8327\u001b[0m        \u001b[35m0.5163\u001b[0m            \u001b[31m0.7774\u001b[0m                     \u001b[94m0.7141\u001b[0m        0.5840  0.0005  2.9458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12            0.8003                     \u001b[32m0.8365\u001b[0m        \u001b[35m0.5014\u001b[0m            0.7349                     \u001b[94m0.7174\u001b[0m        0.5835  0.0005  2.9851\n",
      "     13            \u001b[36m0.8761\u001b[0m                     0.8281        \u001b[35m0.4882\u001b[0m            \u001b[31m0.8073\u001b[0m                     0.6986        0.6310  0.0005  3.0756\n",
      "     14            0.8189                     \u001b[32m0.8544\u001b[0m        \u001b[35m0.4571\u001b[0m            0.7382                     \u001b[94m0.7282\u001b[0m        0.5794  0.0004  2.9750\n",
      "     15            0.8565                     \u001b[32m0.8736\u001b[0m        \u001b[35m0.4567\u001b[0m            0.7688                     0.7190        0.5825  0.0004  2.9561\n",
      "     16            0.8661                     0.8692        \u001b[35m0.4345\u001b[0m            0.7960                     \u001b[94m0.7385\u001b[0m        0.5775  0.0004  3.0107\n",
      "     17            \u001b[36m0.8807\u001b[0m                     \u001b[32m0.8931\u001b[0m        \u001b[35m0.4183\u001b[0m            0.7914                     0.7313        0.5937  0.0003  2.9893\n",
      "     18            0.8596                     0.8868        \u001b[35m0.3986\u001b[0m            0.7714                     0.7280        0.5751  0.0003  2.9692\n",
      "     19            0.8671                     0.8811        0.4095            0.7920                     0.7317        0.5928  0.0003  2.9631\n",
      "     20            \u001b[36m0.8882\u001b[0m                     0.8896        \u001b[35m0.3908\u001b[0m            0.8027                     0.7294        0.6105  0.0003  2.9598\n",
      "     21            \u001b[36m0.9022\u001b[0m                     \u001b[32m0.8937\u001b[0m        \u001b[35m0.3685\u001b[0m            0.8066                     0.7158        0.6230  0.0002  2.9322\n",
      "     22            0.9013                     0.8913        0.3744            0.8073                     0.7162        0.6280  0.0002  2.9884\n",
      "     23            0.8850                     \u001b[32m0.9136\u001b[0m        \u001b[35m0.3588\u001b[0m            0.7821                     0.7374        0.5830  0.0002  2.9487\n",
      "     24            0.8877                     \u001b[32m0.9156\u001b[0m        \u001b[35m0.3352\u001b[0m            0.7821                     0.7315        0.5924  0.0001  2.9477\n",
      "     25            0.8927                     \u001b[32m0.9168\u001b[0m        0.3431            0.7854                     0.7321        0.5982  0.0001  2.9721\n",
      "     26            \u001b[36m0.9169\u001b[0m                     \u001b[32m0.9188\u001b[0m        \u001b[35m0.3307\u001b[0m            \u001b[31m0.8106\u001b[0m                     0.7167        0.6267  0.0001  3.0535\n",
      "     27            \u001b[36m0.9203\u001b[0m                     \u001b[32m0.9252\u001b[0m        \u001b[35m0.3258\u001b[0m            \u001b[31m0.8113\u001b[0m                     0.7230        0.6259  0.0001  2.9640\n",
      "     28            0.9027                     \u001b[32m0.9269\u001b[0m        \u001b[35m0.3007\u001b[0m            0.7821                     0.7227        0.6064  0.0001  2.9375\n",
      "     29            0.9015                     \u001b[32m0.9284\u001b[0m        0.3147            0.7894                     0.7345        0.6045  0.0000  2.9565\n",
      "     30            0.9106                     \u001b[32m0.9328\u001b[0m        0.3047            0.7934                     0.7267        0.6135  0.0000  2.9678\n",
      "     31            0.9103                     0.9319        0.3062            0.7927                     0.7277        0.6105  0.0000  2.9442\n",
      "     32            0.9100                     0.9310        \u001b[35m0.2908\u001b[0m            0.7953                     0.7279        0.6140  0.0000  3.1327\n",
      "     33            0.9173                     \u001b[32m0.9332\u001b[0m        \u001b[35m0.2888\u001b[0m            0.8047                     0.7306        0.6219  0.0000  3.0156\n",
      "     34            \u001b[36m0.9219\u001b[0m                     \u001b[32m0.9335\u001b[0m        0.2957            0.8073                     0.7191        0.6320  0.0000  3.0189\n",
      "     35            0.9183                     0.9331        0.2979            0.8047                     0.7262        0.6243  0.0000  2.9581\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5409\u001b[0m                     \u001b[32m0.6384\u001b[0m        \u001b[35m1.3521\u001b[0m            \u001b[31m0.5037\u001b[0m                     \u001b[94m0.6074\u001b[0m        \u001b[36m0.7992\u001b[0m  0.0006  2.9712\n",
      "      2            \u001b[36m0.7570\u001b[0m                     \u001b[32m0.6964\u001b[0m        \u001b[35m0.9222\u001b[0m            \u001b[31m0.7150\u001b[0m                     \u001b[94m0.6308\u001b[0m        \u001b[36m0.7155\u001b[0m  0.0006  3.0085\n",
      "      3            \u001b[36m0.7683\u001b[0m                     \u001b[32m0.7149\u001b[0m        \u001b[35m0.8274\u001b[0m            \u001b[31m0.7262\u001b[0m                     \u001b[94m0.6566\u001b[0m        \u001b[36m0.6604\u001b[0m  0.0006  2.9621\n",
      "      4            0.7641                     \u001b[32m0.7545\u001b[0m        \u001b[35m0.7472\u001b[0m            0.7003                     \u001b[94m0.6730\u001b[0m        \u001b[36m0.6391\u001b[0m  0.0006  2.9793\n",
      "      5            \u001b[36m0.7708\u001b[0m                     \u001b[32m0.7720\u001b[0m        \u001b[35m0.6742\u001b[0m            0.7017                     \u001b[94m0.6782\u001b[0m        \u001b[36m0.6316\u001b[0m  0.0006  2.9531\n",
      "      6            \u001b[36m0.8231\u001b[0m                     0.7249        \u001b[35m0.6482\u001b[0m            \u001b[31m0.7914\u001b[0m                     0.6729        0.7281  0.0006  2.9468\n",
      "      7            0.7349                     \u001b[32m0.7813\u001b[0m        \u001b[35m0.6326\u001b[0m            0.6565                     0.6712        \u001b[36m0.6280\u001b[0m  0.0006  3.1734\n",
      "      8            0.8211                     \u001b[32m0.8001\u001b[0m        \u001b[35m0.5626\u001b[0m            0.7548                     \u001b[94m0.6857\u001b[0m        0.6374  0.0006  3.0481\n",
      "      9            \u001b[36m0.8243\u001b[0m                     \u001b[32m0.8123\u001b[0m        \u001b[35m0.5549\u001b[0m            0.7309                     \u001b[94m0.6931\u001b[0m        \u001b[36m0.6191\u001b[0m  0.0005  2.9882\n",
      "     10            \u001b[36m0.8493\u001b[0m                     \u001b[32m0.8147\u001b[0m        \u001b[35m0.5445\u001b[0m            0.7860                     \u001b[94m0.7032\u001b[0m        \u001b[36m0.6071\u001b[0m  0.0005  2.9802\n",
      "     11            \u001b[36m0.8691\u001b[0m                     \u001b[32m0.8169\u001b[0m        \u001b[35m0.5128\u001b[0m            \u001b[31m0.7920\u001b[0m                     0.6864        0.6615  0.0005  2.9642\n",
      "     12            0.8135                     \u001b[32m0.8298\u001b[0m        \u001b[35m0.5099\u001b[0m            0.7389                     \u001b[94m0.7038\u001b[0m        \u001b[36m0.6034\u001b[0m  0.0005  3.2166\n",
      "     13            \u001b[36m0.8744\u001b[0m                     \u001b[32m0.8534\u001b[0m        \u001b[35m0.4832\u001b[0m            0.7827                     \u001b[94m0.7041\u001b[0m        0.6234  0.0005  3.1241\n",
      "     14            0.8560                     \u001b[32m0.8674\u001b[0m        \u001b[35m0.4469\u001b[0m            0.7561                     \u001b[94m0.7114\u001b[0m        \u001b[36m0.5929\u001b[0m  0.0004  2.9912\n",
      "     15            0.8724                     \u001b[32m0.8727\u001b[0m        \u001b[35m0.4354\u001b[0m            0.7688                     \u001b[94m0.7161\u001b[0m        0.6082  0.0004  2.9960\n",
      "     16            \u001b[36m0.8824\u001b[0m                     \u001b[32m0.8754\u001b[0m        \u001b[35m0.4006\u001b[0m            0.7694                     0.6931        0.6388  0.0004  3.0417\n",
      "     17            0.8776                     \u001b[32m0.8857\u001b[0m        0.4119            0.7674                     0.7036        0.6136  0.0003  3.0054\n",
      "     18            \u001b[36m0.8940\u001b[0m                     \u001b[32m0.9037\u001b[0m        \u001b[35m0.3828\u001b[0m            0.7794                     \u001b[94m0.7167\u001b[0m        0.6193  0.0003  2.9581\n",
      "     19            \u001b[36m0.8988\u001b[0m                     \u001b[32m0.9074\u001b[0m        \u001b[35m0.3727\u001b[0m            0.7801                     0.7098        0.6173  0.0003  3.0166\n",
      "     20            \u001b[36m0.9128\u001b[0m                     0.9023        \u001b[35m0.3636\u001b[0m            \u001b[31m0.7987\u001b[0m                     0.7007        0.6523  0.0003  2.9556\n",
      "     21            0.9070                     \u001b[32m0.9167\u001b[0m        \u001b[35m0.3591\u001b[0m            0.7867                     \u001b[94m0.7168\u001b[0m        0.6227  0.0002  3.2720\n",
      "     22            0.9065                     \u001b[32m0.9215\u001b[0m        \u001b[35m0.3336\u001b[0m            0.7894                     \u001b[94m0.7184\u001b[0m        0.6134  0.0002  3.0738\n",
      "     23            0.9070                     \u001b[32m0.9233\u001b[0m        \u001b[35m0.3306\u001b[0m            0.7754                     0.6997        0.6352  0.0002  3.0456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24            \u001b[36m0.9145\u001b[0m                     \u001b[32m0.9271\u001b[0m        \u001b[35m0.3098\u001b[0m            0.7787                     0.6973        0.6428  0.0001  2.9297\n",
      "     25            \u001b[36m0.9274\u001b[0m                     \u001b[32m0.9295\u001b[0m        0.3200            0.7947                     0.6983        0.6477  0.0001  2.9261\n",
      "     26            0.9168                     \u001b[32m0.9296\u001b[0m        \u001b[35m0.3031\u001b[0m            0.7880                     0.7103        0.6309  0.0001  3.0425\n",
      "     27            0.9163                     \u001b[32m0.9363\u001b[0m        \u001b[35m0.2914\u001b[0m            0.7708                     0.7056        0.6411  0.0001  2.9657\n",
      "     28            \u001b[36m0.9352\u001b[0m                     \u001b[32m0.9401\u001b[0m        \u001b[35m0.2836\u001b[0m            0.7987                     0.7022        0.6576  0.0001  2.9621\n",
      "     29            0.9176                     \u001b[32m0.9404\u001b[0m        0.2870            0.7781                     0.7115        0.6358  0.0000  2.9613\n",
      "     30            0.9145                     0.9403        0.2865            0.7767                     0.7151        0.6263  0.0000  2.9824\n",
      "     31            0.9287                     \u001b[32m0.9417\u001b[0m        0.2845            0.7894                     0.7067        0.6468  0.0000  2.9706\n",
      "     32            0.9181                     \u001b[32m0.9418\u001b[0m        \u001b[35m0.2699\u001b[0m            0.7794                     0.7167        0.6305  0.0000  2.9579\n",
      "     33            0.9282                     \u001b[32m0.9428\u001b[0m        0.2771            0.7907                     0.7119        0.6455  0.0000  3.0259\n",
      "     34            0.9251                     \u001b[32m0.9435\u001b[0m        0.2716            0.7867                     0.7110        0.6387  0.0000  2.9619\n",
      "     35            0.9259                     0.9432        0.2751            0.7867                     0.7095        0.6412  0.0000  2.9444\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7284\u001b[0m                     \u001b[32m0.6695\u001b[0m        \u001b[35m1.3586\u001b[0m            \u001b[31m0.6997\u001b[0m                     \u001b[94m0.6229\u001b[0m        \u001b[36m0.7642\u001b[0m  0.0006  2.9488\n",
      "      2            0.4473                     0.6116        \u001b[35m0.9803\u001b[0m            0.4199                     0.5697        0.9594  0.0006  2.9520\n",
      "      3            \u001b[36m0.7968\u001b[0m                     \u001b[32m0.7188\u001b[0m        \u001b[35m0.8630\u001b[0m            \u001b[31m0.7648\u001b[0m                     \u001b[94m0.6523\u001b[0m        \u001b[36m0.6731\u001b[0m  0.0006  2.9478\n",
      "      4            0.7714                     \u001b[32m0.7366\u001b[0m        \u001b[35m0.7744\u001b[0m            0.7229                     \u001b[94m0.6634\u001b[0m        \u001b[36m0.6650\u001b[0m  0.0006  3.0143\n",
      "      5            0.7301                     \u001b[32m0.7575\u001b[0m        \u001b[35m0.7288\u001b[0m            0.6904                     \u001b[94m0.6918\u001b[0m        \u001b[36m0.6198\u001b[0m  0.0006  3.0758\n",
      "      6            0.7965                     \u001b[32m0.7683\u001b[0m        \u001b[35m0.6462\u001b[0m            0.7382                     0.6888        0.6462  0.0006  3.0412\n",
      "      7            \u001b[36m0.8113\u001b[0m                     0.7630        \u001b[35m0.6336\u001b[0m            0.7535                     0.6820        0.6732  0.0006  3.1220\n",
      "      8            0.7346                     \u001b[32m0.7921\u001b[0m        \u001b[35m0.6002\u001b[0m            0.6631                     0.6884        0.6235  0.0006  3.2406\n",
      "      9            \u001b[36m0.8651\u001b[0m                     0.7757        \u001b[35m0.5690\u001b[0m            \u001b[31m0.8106\u001b[0m                     0.6860        0.6623  0.0005  3.0309\n",
      "     10            0.8003                     \u001b[32m0.8156\u001b[0m        \u001b[35m0.5569\u001b[0m            0.7349                     \u001b[94m0.7043\u001b[0m        \u001b[36m0.5842\u001b[0m  0.0005  3.2978\n",
      "     11            0.7917                     0.8042        \u001b[35m0.5180\u001b[0m            0.7003                     0.6789        0.6737  0.0005  3.3150\n",
      "     12            0.8226                     \u001b[32m0.8372\u001b[0m        \u001b[35m0.5079\u001b[0m            0.7289                     0.6846        0.6061  0.0005  3.1186\n",
      "     13            0.8249                     \u001b[32m0.8375\u001b[0m        0.5299            0.7395                     0.6954        0.6012  0.0005  3.0788\n",
      "     14            0.8468                     \u001b[32m0.8395\u001b[0m        \u001b[35m0.4918\u001b[0m            0.7628                     0.6920        0.6353  0.0004  3.2521\n",
      "     15            0.8301                     \u001b[32m0.8579\u001b[0m        \u001b[35m0.4470\u001b[0m            0.7342                     \u001b[94m0.7068\u001b[0m        0.6057  0.0004  3.3389\n",
      "     16            0.8560                     \u001b[32m0.8769\u001b[0m        \u001b[35m0.4433\u001b[0m            0.7542                     0.7014        0.5961  0.0004  3.1604\n",
      "     17            0.8610                     0.8631        \u001b[35m0.4150\u001b[0m            0.7854                     \u001b[94m0.7218\u001b[0m        0.6365  0.0003  2.9497\n",
      "     18            \u001b[36m0.8668\u001b[0m                     \u001b[32m0.8835\u001b[0m        0.4154            0.7708                     0.7129        0.6156  0.0003  2.9391\n",
      "     19            \u001b[36m0.8779\u001b[0m                     \u001b[32m0.8844\u001b[0m        \u001b[35m0.3961\u001b[0m            0.7708                     0.6954        0.6270  0.0003  3.1155\n",
      "     20            \u001b[36m0.8842\u001b[0m                     \u001b[32m0.8893\u001b[0m        \u001b[35m0.3943\u001b[0m            0.7907                     0.7192        0.6155  0.0003  3.0064\n",
      "     21            \u001b[36m0.8844\u001b[0m                     0.8847        \u001b[35m0.3563\u001b[0m            0.7900                     0.7159        0.6616  0.0002  2.9631\n",
      "     22            \u001b[36m0.8970\u001b[0m                     \u001b[32m0.8953\u001b[0m        0.3781            0.8013                     \u001b[94m0.7242\u001b[0m        0.6247  0.0002  2.9611\n",
      "     23            0.8816                     \u001b[32m0.9060\u001b[0m        \u001b[35m0.3551\u001b[0m            0.7714                     0.7104        0.6157  0.0002  3.1132\n",
      "     24            0.8910                     \u001b[32m0.9129\u001b[0m        \u001b[35m0.3514\u001b[0m            0.7821                     0.7110        0.6199  0.0001  3.0376\n",
      "     25            \u001b[36m0.9043\u001b[0m                     \u001b[32m0.9158\u001b[0m        \u001b[35m0.3390\u001b[0m            0.7887                     0.7078        0.6249  0.0001  2.9292\n",
      "     26            0.9027                     \u001b[32m0.9192\u001b[0m        0.3397            0.7907                     0.7192        0.6167  0.0001  2.9292\n",
      "     27            0.9028                     \u001b[32m0.9197\u001b[0m        \u001b[35m0.3179\u001b[0m            0.7920                     0.7215        0.6262  0.0001  2.9372\n",
      "     28            \u001b[36m0.9060\u001b[0m                     \u001b[32m0.9201\u001b[0m        \u001b[35m0.3166\u001b[0m            0.7920                     0.7040        0.6503  0.0001  2.9343\n",
      "     29            0.9035                     \u001b[32m0.9230\u001b[0m        \u001b[35m0.3164\u001b[0m            0.7980                     0.7237        0.6349  0.0000  2.9352\n",
      "     30            \u001b[36m0.9153\u001b[0m                     \u001b[32m0.9265\u001b[0m        \u001b[35m0.3003\u001b[0m            0.8007                     0.7092        0.6420  0.0000  2.9329\n",
      "     31            0.9146                     \u001b[32m0.9276\u001b[0m        0.3078            0.7993                     0.7099        0.6420  0.0000  2.9372\n",
      "     32            \u001b[36m0.9163\u001b[0m                     0.9260        0.3098            0.8027                     0.7075        0.6509  0.0000  2.9274\n",
      "     33            0.9043                     0.9268        \u001b[35m0.2979\u001b[0m            0.7920                     0.7200        0.6317  0.0000  2.9232\n",
      "     34            0.9113                     \u001b[32m0.9296\u001b[0m        0.3006            0.7973                     0.7174        0.6386  0.0000  2.9344\n",
      "     35            0.9000                     0.9260        0.3037            0.7860                     0.7164        0.6281  0.0000  2.9322\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6625\u001b[0m                     \u001b[32m0.6539\u001b[0m        \u001b[35m1.2796\u001b[0m            \u001b[31m0.6618\u001b[0m                     \u001b[94m0.6203\u001b[0m        \u001b[36m0.7990\u001b[0m  0.0006  2.9242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            \u001b[36m0.6774\u001b[0m                     \u001b[32m0.7072\u001b[0m        \u001b[35m0.9592\u001b[0m            0.6478                     \u001b[94m0.6513\u001b[0m        \u001b[36m0.6500\u001b[0m  0.0006  2.9302\n",
      "      3            \u001b[36m0.7193\u001b[0m                     \u001b[32m0.7210\u001b[0m        \u001b[35m0.8530\u001b[0m            \u001b[31m0.6857\u001b[0m                     \u001b[94m0.6641\u001b[0m        \u001b[36m0.6276\u001b[0m  0.0006  2.9195\n",
      "      4            \u001b[36m0.7430\u001b[0m                     \u001b[32m0.7530\u001b[0m        \u001b[35m0.7410\u001b[0m            \u001b[31m0.7136\u001b[0m                     \u001b[94m0.6884\u001b[0m        \u001b[36m0.5980\u001b[0m  0.0006  2.9322\n",
      "      5            \u001b[36m0.7942\u001b[0m                     \u001b[32m0.7717\u001b[0m        \u001b[35m0.7014\u001b[0m            \u001b[31m0.7342\u001b[0m                     0.6702        0.6165  0.0006  2.9161\n",
      "      6            0.7930                     \u001b[32m0.7742\u001b[0m        \u001b[35m0.6481\u001b[0m            \u001b[31m0.7468\u001b[0m                     0.6838        \u001b[36m0.5902\u001b[0m  0.0006  2.9255\n",
      "      7            0.7794                     \u001b[32m0.7905\u001b[0m        \u001b[35m0.6208\u001b[0m            0.7296                     \u001b[94m0.6996\u001b[0m        \u001b[36m0.5586\u001b[0m  0.0006  2.9242\n",
      "      8            0.7643                     0.7864        \u001b[35m0.6124\u001b[0m            0.7176                     0.6952        0.5968  0.0006  2.9240\n",
      "      9            \u001b[36m0.8189\u001b[0m                     \u001b[32m0.7995\u001b[0m        \u001b[35m0.5529\u001b[0m            \u001b[31m0.7575\u001b[0m                     0.6961        0.6158  0.0005  2.9242\n",
      "     10            \u001b[36m0.8596\u001b[0m                     \u001b[32m0.8257\u001b[0m        \u001b[35m0.5346\u001b[0m            \u001b[31m0.7894\u001b[0m                     0.6994        0.5937  0.0005  2.9194\n",
      "     11            0.8312                     \u001b[32m0.8399\u001b[0m        \u001b[35m0.5037\u001b[0m            0.7595                     \u001b[94m0.7221\u001b[0m        0.5667  0.0005  2.9198\n",
      "     12            0.8362                     0.8327        \u001b[35m0.4782\u001b[0m            0.7741                     0.7077        0.5963  0.0005  2.9252\n",
      "     13            0.8576                     0.8377        \u001b[35m0.4680\u001b[0m            \u001b[31m0.8020\u001b[0m                     0.7159        0.6034  0.0005  2.9257\n",
      "     14            0.8470                     \u001b[32m0.8620\u001b[0m        0.4684            0.7701                     0.7213        0.5671  0.0004  2.9272\n",
      "     15            \u001b[36m0.8605\u001b[0m                     0.8460        \u001b[35m0.4337\u001b[0m            0.7847                     0.6893        0.6339  0.0004  2.9272\n",
      "     16            0.8375                     0.8577        0.4436            0.7654                     0.7141        0.6059  0.0004  2.9282\n",
      "     17            \u001b[36m0.8782\u001b[0m                     \u001b[32m0.8681\u001b[0m        \u001b[35m0.4301\u001b[0m            0.8020                     0.7202        0.6117  0.0003  2.9225\n",
      "     18            \u001b[36m0.8791\u001b[0m                     \u001b[32m0.8851\u001b[0m        \u001b[35m0.3970\u001b[0m            0.7960                     0.7151        0.6047  0.0003  2.9242\n",
      "     19            0.8703                     \u001b[32m0.8988\u001b[0m        \u001b[35m0.3896\u001b[0m            0.7814                     \u001b[94m0.7267\u001b[0m        0.5897  0.0003  2.9272\n",
      "     20            \u001b[36m0.8922\u001b[0m                     \u001b[32m0.9008\u001b[0m        \u001b[35m0.3718\u001b[0m            0.8000                     0.7263        0.6030  0.0003  2.9297\n",
      "     21            \u001b[36m0.8955\u001b[0m                     \u001b[32m0.9119\u001b[0m        \u001b[35m0.3602\u001b[0m            0.7973                     \u001b[94m0.7306\u001b[0m        0.5822  0.0002  2.9209\n",
      "     22            0.8894                     0.9056        \u001b[35m0.3464\u001b[0m            0.7967                     0.7272        0.5940  0.0002  2.9212\n",
      "     23            \u001b[36m0.8978\u001b[0m                     \u001b[32m0.9203\u001b[0m        0.3497            0.7900                     0.7261        0.5985  0.0002  2.9280\n",
      "     24            \u001b[36m0.9248\u001b[0m                     0.9067        \u001b[35m0.3254\u001b[0m            \u001b[31m0.8266\u001b[0m                     0.7089        0.6468  0.0001  2.9342\n",
      "     25            0.8465                     0.9048        0.3414            0.7455                     \u001b[94m0.7356\u001b[0m        0.5675  0.0001  2.9220\n",
      "     26            0.9047                     \u001b[32m0.9215\u001b[0m        \u001b[35m0.3162\u001b[0m            0.7980                     0.7222        0.6164  0.0001  2.9332\n",
      "     27            0.9136                     \u001b[32m0.9317\u001b[0m        \u001b[35m0.3066\u001b[0m            0.7967                     0.7199        0.6106  0.0001  2.9322\n",
      "     28            0.9196                     \u001b[32m0.9328\u001b[0m        0.3068            0.8073                     0.7249        0.6161  0.0001  2.9304\n",
      "     29            0.9173                     \u001b[32m0.9354\u001b[0m        \u001b[35m0.3055\u001b[0m            0.8007                     0.7238        0.6097  0.0000  2.9222\n",
      "     30            0.9241                     \u001b[32m0.9363\u001b[0m        \u001b[35m0.2968\u001b[0m            0.8113                     0.7215        0.6219  0.0000  2.9242\n",
      "     31            0.9184                     \u001b[32m0.9369\u001b[0m        \u001b[35m0.2803\u001b[0m            0.8020                     0.7232        0.6098  0.0000  2.9387\n",
      "     32            0.9234                     \u001b[32m0.9373\u001b[0m        0.2915            0.8080                     0.7239        0.6172  0.0000  2.9309\n",
      "     33            0.9201                     \u001b[32m0.9386\u001b[0m        0.2982            0.8027                     0.7265        0.6103  0.0000  2.9302\n",
      "     34            \u001b[36m0.9261\u001b[0m                     0.9368        0.2950            0.8113                     0.7244        0.6230  0.0000  2.9257\n",
      "     35            0.9261                     0.9378        \u001b[35m0.2800\u001b[0m            0.8106                     0.7255        0.6220  0.0000  2.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5699\u001b[0m                     \u001b[32m0.5714\u001b[0m        \u001b[35m1.3695\u001b[0m            \u001b[31m0.5422\u001b[0m                     \u001b[94m0.5438\u001b[0m        \u001b[36m0.8777\u001b[0m  0.0006  2.3873\n",
      "      2            \u001b[36m0.6262\u001b[0m                     \u001b[32m0.6254\u001b[0m        \u001b[35m1.0004\u001b[0m            \u001b[31m0.5645\u001b[0m                     \u001b[94m0.5638\u001b[0m        \u001b[36m0.7361\u001b[0m  0.0006  2.0072\n",
      "      3            \u001b[36m0.6786\u001b[0m                     \u001b[32m0.6788\u001b[0m        \u001b[35m0.8728\u001b[0m            \u001b[31m0.6081\u001b[0m                     \u001b[94m0.6085\u001b[0m        \u001b[36m0.6644\u001b[0m  0.0006  2.0007\n",
      "      4            \u001b[36m0.6964\u001b[0m                     \u001b[32m0.6967\u001b[0m        \u001b[35m0.8246\u001b[0m            \u001b[31m0.6334\u001b[0m                     \u001b[94m0.6339\u001b[0m        0.6670  0.0006  2.0009\n",
      "      5            \u001b[36m0.7459\u001b[0m                     \u001b[32m0.7462\u001b[0m        \u001b[35m0.7129\u001b[0m            \u001b[31m0.6547\u001b[0m                     \u001b[94m0.6551\u001b[0m        \u001b[36m0.6423\u001b[0m  0.0006  2.0008\n",
      "      6            0.7388                     0.7396        \u001b[35m0.6584\u001b[0m            \u001b[31m0.6615\u001b[0m                     \u001b[94m0.6625\u001b[0m        \u001b[36m0.6257\u001b[0m  0.0006  1.9988\n",
      "      7            \u001b[36m0.7777\u001b[0m                     \u001b[32m0.7777\u001b[0m        \u001b[35m0.6506\u001b[0m            \u001b[31m0.6751\u001b[0m                     \u001b[94m0.6753\u001b[0m        \u001b[36m0.6022\u001b[0m  0.0006  1.9997\n",
      "      8            \u001b[36m0.7998\u001b[0m                     \u001b[32m0.7998\u001b[0m        \u001b[35m0.6059\u001b[0m            \u001b[31m0.7061\u001b[0m                     \u001b[94m0.7062\u001b[0m        \u001b[36m0.5664\u001b[0m  0.0006  2.0002\n",
      "      9            0.7932                     0.7934        \u001b[35m0.5675\u001b[0m            0.6857                     0.6861        0.5822  0.0005  1.9959\n",
      "     10            0.7833                     0.7825        \u001b[35m0.5330\u001b[0m            0.6809                     0.6799        0.6054  0.0005  2.0018\n",
      "     11            \u001b[36m0.8153\u001b[0m                     \u001b[32m0.8157\u001b[0m        \u001b[35m0.5222\u001b[0m            \u001b[31m0.7110\u001b[0m                     \u001b[94m0.7115\u001b[0m        0.5723  0.0005  2.0007\n",
      "     12            \u001b[36m0.8345\u001b[0m                     \u001b[32m0.8348\u001b[0m        \u001b[35m0.5008\u001b[0m            0.6974                     0.6979        0.5749  0.0005  2.0095\n",
      "     13            \u001b[36m0.8427\u001b[0m                     \u001b[32m0.8428\u001b[0m        \u001b[35m0.4811\u001b[0m            \u001b[31m0.7139\u001b[0m                     \u001b[94m0.7142\u001b[0m        0.5756  0.0005  1.9997\n",
      "     14            \u001b[36m0.8575\u001b[0m                     \u001b[32m0.8575\u001b[0m        \u001b[35m0.4576\u001b[0m            0.7119                     0.7120        \u001b[36m0.5636\u001b[0m  0.0004  2.0021\n",
      "     15            \u001b[36m0.8704\u001b[0m                     \u001b[32m0.8703\u001b[0m        \u001b[35m0.4424\u001b[0m            \u001b[31m0.7207\u001b[0m                     \u001b[94m0.7208\u001b[0m        0.5640  0.0004  2.0034\n",
      "     16            0.8636                     0.8634        \u001b[35m0.4369\u001b[0m            0.7197                     0.7194        0.5718  0.0004  2.0026\n",
      "     17            0.8689                     0.8687        \u001b[35m0.4246\u001b[0m            0.7168                     0.7165        0.5762  0.0003  1.9992\n",
      "     18            \u001b[36m0.8779\u001b[0m                     \u001b[32m0.8778\u001b[0m        0.4270            \u001b[31m0.7304\u001b[0m                     \u001b[94m0.7303\u001b[0m        \u001b[36m0.5603\u001b[0m  0.0003  2.0086\n",
      "     19            \u001b[36m0.8837\u001b[0m                     \u001b[32m0.8837\u001b[0m        \u001b[35m0.4079\u001b[0m            0.7187                     0.7186        0.5687  0.0003  1.9957\n",
      "     20            0.8769                     0.8769        \u001b[35m0.3912\u001b[0m            0.7158                     0.7157        0.5888  0.0003  2.0087\n",
      "     21            \u001b[36m0.8917\u001b[0m                     \u001b[32m0.8918\u001b[0m        \u001b[35m0.3864\u001b[0m            0.7197                     0.7197        0.5778  0.0002  2.0026\n",
      "     22            \u001b[36m0.8995\u001b[0m                     \u001b[32m0.8995\u001b[0m        \u001b[35m0.3790\u001b[0m            0.7139                     0.7137        0.5724  0.0002  1.9967\n",
      "     23            \u001b[36m0.9095\u001b[0m                     \u001b[32m0.9096\u001b[0m        \u001b[35m0.3607\u001b[0m            0.7187                     0.7188        0.5821  0.0002  1.9982\n",
      "     24            0.9092                     0.9093        0.3630            0.7255                     0.7256        0.5770  0.0001  2.0018\n",
      "     25            \u001b[36m0.9187\u001b[0m                     \u001b[32m0.9188\u001b[0m        \u001b[35m0.3512\u001b[0m            0.7177                     0.7178        0.5877  0.0001  2.0066\n",
      "     26            0.9153                     0.9152        \u001b[35m0.3445\u001b[0m            0.7177                     0.7176        0.5891  0.0001  1.9977\n",
      "     27            0.9172                     0.9174        \u001b[35m0.3359\u001b[0m            0.7197                     0.7198        0.5901  0.0001  1.9997\n",
      "     28            \u001b[36m0.9226\u001b[0m                     \u001b[32m0.9227\u001b[0m        \u001b[35m0.3244\u001b[0m            0.7197                     0.7197        0.5900  0.0001  1.9987\n",
      "     29            0.9218                     0.9219        0.3310            0.7236                     0.7236        0.5906  0.0000  1.9992\n",
      "     30            \u001b[36m0.9240\u001b[0m                     \u001b[32m0.9241\u001b[0m        \u001b[35m0.3165\u001b[0m            0.7216                     0.7216        0.5871  0.0000  2.0031\n",
      "     31            0.9231                     0.9231        \u001b[35m0.3146\u001b[0m            0.7187                     0.7188        0.5911  0.0000  1.9968\n",
      "     32            0.9240                     \u001b[32m0.9241\u001b[0m        0.3194            0.7187                     0.7187        0.5898  0.0000  2.0054\n",
      "     33            \u001b[36m0.9262\u001b[0m                     \u001b[32m0.9262\u001b[0m        0.3195            0.7177                     0.7177        0.5895  0.0000  2.0038\n",
      "     34            0.9257                     0.9257        \u001b[35m0.3101\u001b[0m            0.7187                     0.7186        0.5901  0.0000  2.0016\n",
      "     35            0.9260                     0.9260        0.3119            0.7197                     0.7196        0.5894  0.0000  2.0016\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5728\u001b[0m                     \u001b[32m0.5738\u001b[0m        \u001b[35m1.3592\u001b[0m            \u001b[31m0.5597\u001b[0m                     \u001b[94m0.5607\u001b[0m        \u001b[36m0.7858\u001b[0m  0.0006  2.0010\n",
      "      2            \u001b[36m0.5908\u001b[0m                     \u001b[32m0.5890\u001b[0m        \u001b[35m1.0469\u001b[0m            \u001b[31m0.5635\u001b[0m                     \u001b[94m0.5620\u001b[0m        \u001b[36m0.7788\u001b[0m  0.0006  1.9987\n",
      "      3            \u001b[36m0.6660\u001b[0m                     \u001b[32m0.6657\u001b[0m        \u001b[35m0.9049\u001b[0m            \u001b[31m0.6052\u001b[0m                     \u001b[94m0.6052\u001b[0m        \u001b[36m0.6689\u001b[0m  0.0006  1.9937\n",
      "      4            \u001b[36m0.6951\u001b[0m                     \u001b[32m0.6946\u001b[0m        \u001b[35m0.7996\u001b[0m            \u001b[31m0.6275\u001b[0m                     \u001b[94m0.6273\u001b[0m        \u001b[36m0.6595\u001b[0m  0.0006  1.9986\n",
      "      5            \u001b[36m0.7476\u001b[0m                     \u001b[32m0.7475\u001b[0m        \u001b[35m0.7427\u001b[0m            \u001b[31m0.6469\u001b[0m                     \u001b[94m0.6471\u001b[0m        \u001b[36m0.6268\u001b[0m  0.0006  2.0025\n",
      "      6            \u001b[36m0.7600\u001b[0m                     \u001b[32m0.7596\u001b[0m        \u001b[35m0.6826\u001b[0m            \u001b[31m0.6586\u001b[0m                     \u001b[94m0.6584\u001b[0m        \u001b[36m0.6225\u001b[0m  0.0006  1.9964\n",
      "      7            \u001b[36m0.7784\u001b[0m                     \u001b[32m0.7785\u001b[0m        \u001b[35m0.6312\u001b[0m            0.6528                     0.6531        \u001b[36m0.6129\u001b[0m  0.0006  1.9952\n",
      "      8            \u001b[36m0.7862\u001b[0m                     \u001b[32m0.7864\u001b[0m        \u001b[35m0.6117\u001b[0m            \u001b[31m0.6760\u001b[0m                     \u001b[94m0.6764\u001b[0m        \u001b[36m0.6090\u001b[0m  0.0006  1.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      9            \u001b[36m0.8104\u001b[0m                     \u001b[32m0.8103\u001b[0m        \u001b[35m0.5666\u001b[0m            \u001b[31m0.6857\u001b[0m                     \u001b[94m0.6856\u001b[0m        \u001b[36m0.5843\u001b[0m  0.0005  1.9967\n",
      "     10            0.7990                     0.7990        \u001b[35m0.5555\u001b[0m            0.6848                     0.6848        0.5938  0.0005  1.9957\n",
      "     11            \u001b[36m0.8262\u001b[0m                     \u001b[32m0.8260\u001b[0m        \u001b[35m0.5321\u001b[0m            \u001b[31m0.6896\u001b[0m                     \u001b[94m0.6896\u001b[0m        \u001b[36m0.5836\u001b[0m  0.0005  2.0046\n",
      "     12            \u001b[36m0.8320\u001b[0m                     \u001b[32m0.8320\u001b[0m        \u001b[35m0.5018\u001b[0m            \u001b[31m0.7110\u001b[0m                     \u001b[94m0.7111\u001b[0m        \u001b[36m0.5814\u001b[0m  0.0005  1.9993\n",
      "     13            0.8299                     0.8299        0.5031            0.7042                     0.7043        0.5908  0.0005  1.9988\n",
      "     14            \u001b[36m0.8391\u001b[0m                     \u001b[32m0.8394\u001b[0m        \u001b[35m0.4644\u001b[0m            0.7071                     0.7075        0.5914  0.0004  2.0026\n",
      "     15            \u001b[36m0.8464\u001b[0m                     \u001b[32m0.8466\u001b[0m        \u001b[35m0.4568\u001b[0m            0.6974                     0.6978        0.5980  0.0004  2.0012\n",
      "     16            \u001b[36m0.8519\u001b[0m                     \u001b[32m0.8523\u001b[0m        \u001b[35m0.4532\u001b[0m            \u001b[31m0.7158\u001b[0m                     \u001b[94m0.7163\u001b[0m        0.5865  0.0004  1.9983\n",
      "     17            \u001b[36m0.8602\u001b[0m                     \u001b[32m0.8602\u001b[0m        \u001b[35m0.4326\u001b[0m            \u001b[31m0.7187\u001b[0m                     \u001b[94m0.7189\u001b[0m        0.5829  0.0003  1.9942\n",
      "     18            \u001b[36m0.8682\u001b[0m                     \u001b[32m0.8682\u001b[0m        \u001b[35m0.4204\u001b[0m            0.7119                     0.7121        0.5854  0.0003  2.0026\n",
      "     19            0.8680                     \u001b[32m0.8682\u001b[0m        \u001b[35m0.4168\u001b[0m            0.7148                     0.7153        0.5968  0.0003  1.9977\n",
      "     20            \u001b[36m0.8687\u001b[0m                     \u001b[32m0.8685\u001b[0m        \u001b[35m0.4019\u001b[0m            0.7013                     0.7012        0.6034  0.0003  1.9967\n",
      "     21            \u001b[36m0.8971\u001b[0m                     \u001b[32m0.8971\u001b[0m        \u001b[35m0.3985\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7265\u001b[0m        \u001b[36m0.5799\u001b[0m  0.0002  2.0016\n",
      "     22            0.8956                     0.8958        \u001b[35m0.3782\u001b[0m            0.7177                     0.7181        0.5892  0.0002  2.0055\n",
      "     23            \u001b[36m0.9034\u001b[0m                     \u001b[32m0.9035\u001b[0m        \u001b[35m0.3749\u001b[0m            0.7177                     0.7180        0.5904  0.0002  1.9997\n",
      "     24            \u001b[36m0.9100\u001b[0m                     \u001b[32m0.9100\u001b[0m        0.3757            0.7207                     0.7207        0.5877  0.0001  1.9987\n",
      "     25            0.9090                     0.9091        \u001b[35m0.3611\u001b[0m            0.7255                     0.7258        0.5867  0.0001  2.0046\n",
      "     26            \u001b[36m0.9107\u001b[0m                     \u001b[32m0.9107\u001b[0m        \u001b[35m0.3532\u001b[0m            0.7158                     0.7160        0.5893  0.0001  1.9965\n",
      "     27            \u001b[36m0.9153\u001b[0m                     \u001b[32m0.9153\u001b[0m        \u001b[35m0.3476\u001b[0m            0.7187                     0.7188        0.5826  0.0001  2.0036\n",
      "     28            \u001b[36m0.9172\u001b[0m                     \u001b[32m0.9171\u001b[0m        \u001b[35m0.3330\u001b[0m            0.7187                     0.7186        0.5916  0.0001  2.0026\n",
      "     29            \u001b[36m0.9204\u001b[0m                     \u001b[32m0.9204\u001b[0m        \u001b[35m0.3297\u001b[0m            0.7226                     0.7227        0.5884  0.0000  1.9972\n",
      "     30            \u001b[36m0.9221\u001b[0m                     \u001b[32m0.9221\u001b[0m        0.3328            0.7187                     0.7188        0.5866  0.0000  2.0106\n",
      "     31            \u001b[36m0.9223\u001b[0m                     \u001b[32m0.9223\u001b[0m        0.3362            0.7265                     0.7265        0.5872  0.0000  2.0028\n",
      "     32            \u001b[36m0.9226\u001b[0m                     \u001b[32m0.9226\u001b[0m        \u001b[35m0.3241\u001b[0m            0.7187                     0.7188        0.5874  0.0000  2.0026\n",
      "     33            0.9218                     0.9219        0.3369            0.7255                     0.7256        0.5874  0.0000  1.9985\n",
      "     34            0.9211                     0.9211        \u001b[35m0.3225\u001b[0m            0.7226                     0.7227        0.5874  0.0000  2.0031\n",
      "     35            0.9218                     0.9219        0.3258            0.7245                     0.7246        0.5875  0.0000  2.0036\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5697\u001b[0m                     \u001b[32m0.5709\u001b[0m        \u001b[35m1.3719\u001b[0m            \u001b[31m0.5529\u001b[0m                     \u001b[94m0.5542\u001b[0m        \u001b[36m0.7859\u001b[0m  0.0006  1.9982\n",
      "      2            \u001b[36m0.5981\u001b[0m                     \u001b[32m0.5990\u001b[0m        \u001b[35m1.0245\u001b[0m            \u001b[31m0.5616\u001b[0m                     \u001b[94m0.5625\u001b[0m        \u001b[36m0.7490\u001b[0m  0.0006  2.0023\n",
      "      3            \u001b[36m0.6655\u001b[0m                     \u001b[32m0.6649\u001b[0m        \u001b[35m0.8916\u001b[0m            \u001b[31m0.5926\u001b[0m                     \u001b[94m0.5919\u001b[0m        \u001b[36m0.6869\u001b[0m  0.0006  2.0002\n",
      "      4            \u001b[36m0.6682\u001b[0m                     \u001b[32m0.6672\u001b[0m        \u001b[35m0.7933\u001b[0m            \u001b[31m0.6014\u001b[0m                     \u001b[94m0.6002\u001b[0m        \u001b[36m0.6728\u001b[0m  0.0006  1.9987\n",
      "      5            \u001b[36m0.7117\u001b[0m                     \u001b[32m0.7119\u001b[0m        \u001b[35m0.7518\u001b[0m            \u001b[31m0.6353\u001b[0m                     \u001b[94m0.6357\u001b[0m        \u001b[36m0.6412\u001b[0m  0.0006  2.0086\n",
      "      6            \u001b[36m0.7223\u001b[0m                     \u001b[32m0.7227\u001b[0m        \u001b[35m0.7065\u001b[0m            \u001b[31m0.6867\u001b[0m                     \u001b[94m0.6871\u001b[0m        \u001b[36m0.6075\u001b[0m  0.0006  2.0012\n",
      "      7            \u001b[36m0.7578\u001b[0m                     \u001b[32m0.7581\u001b[0m        \u001b[35m0.6564\u001b[0m            0.6770                     0.6775        0.6124  0.0006  1.9977\n",
      "      8            \u001b[36m0.7760\u001b[0m                     \u001b[32m0.7757\u001b[0m        \u001b[35m0.6207\u001b[0m            \u001b[31m0.7022\u001b[0m                     \u001b[94m0.7021\u001b[0m        \u001b[36m0.5917\u001b[0m  0.0006  2.0024\n",
      "      9            0.7740                     0.7734        \u001b[35m0.5936\u001b[0m            0.6964                     0.6958        \u001b[36m0.5831\u001b[0m  0.0005  1.9957\n",
      "     10            \u001b[36m0.7937\u001b[0m                     \u001b[32m0.7933\u001b[0m        \u001b[35m0.5821\u001b[0m            \u001b[31m0.7187\u001b[0m                     \u001b[94m0.7183\u001b[0m        \u001b[36m0.5601\u001b[0m  0.0005  1.9977\n",
      "     11            \u001b[36m0.8015\u001b[0m                     \u001b[32m0.8010\u001b[0m        \u001b[35m0.5512\u001b[0m            0.7100                     0.7095        0.5637  0.0005  2.0013\n",
      "     12            \u001b[36m0.8269\u001b[0m                     \u001b[32m0.8271\u001b[0m        \u001b[35m0.5247\u001b[0m            \u001b[31m0.7381\u001b[0m                     \u001b[94m0.7384\u001b[0m        \u001b[36m0.5399\u001b[0m  0.0005  2.0087\n",
      "     13            0.8238                     0.8236        \u001b[35m0.5192\u001b[0m            0.7313                     0.7312        0.5571  0.0005  2.0036\n",
      "     14            \u001b[36m0.8439\u001b[0m                     \u001b[32m0.8441\u001b[0m        \u001b[35m0.4803\u001b[0m            0.7304                     0.7307        \u001b[36m0.5394\u001b[0m  0.0004  1.9997\n",
      "     15            \u001b[36m0.8490\u001b[0m                     \u001b[32m0.8489\u001b[0m        \u001b[35m0.4703\u001b[0m            \u001b[31m0.7401\u001b[0m                     \u001b[94m0.7399\u001b[0m        \u001b[36m0.5383\u001b[0m  0.0004  1.9992\n",
      "     16            \u001b[36m0.8570\u001b[0m                     \u001b[32m0.8574\u001b[0m        \u001b[35m0.4585\u001b[0m            \u001b[31m0.7449\u001b[0m                     \u001b[94m0.7453\u001b[0m        0.5387  0.0004  1.9987\n",
      "     17            \u001b[36m0.8723\u001b[0m                     \u001b[32m0.8723\u001b[0m        \u001b[35m0.4481\u001b[0m            0.7439                     0.7439        \u001b[36m0.5314\u001b[0m  0.0003  2.0045\n",
      "     18            \u001b[36m0.8743\u001b[0m                     \u001b[32m0.8743\u001b[0m        \u001b[35m0.4347\u001b[0m            \u001b[31m0.7595\u001b[0m                     \u001b[94m0.7595\u001b[0m        \u001b[36m0.5296\u001b[0m  0.0003  1.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     19            0.8731                     0.8729        \u001b[35m0.4126\u001b[0m            0.7391                     0.7389        0.5332  0.0003  2.0053\n",
      "     20            \u001b[36m0.8789\u001b[0m                     \u001b[32m0.8792\u001b[0m        0.4222            0.7488                     0.7493        \u001b[36m0.5276\u001b[0m  0.0003  1.9976\n",
      "     21            \u001b[36m0.8886\u001b[0m                     \u001b[32m0.8884\u001b[0m        \u001b[35m0.4023\u001b[0m            0.7498                     0.7495        \u001b[36m0.5178\u001b[0m  0.0002  1.9997\n",
      "     22            0.8879                     0.8880        \u001b[35m0.3957\u001b[0m            \u001b[31m0.7604\u001b[0m                     \u001b[94m0.7607\u001b[0m        0.5325  0.0002  1.9977\n",
      "     23            0.8867                     0.8869        \u001b[35m0.3834\u001b[0m            0.7498                     0.7502        0.5333  0.0002  2.0066\n",
      "     24            \u001b[36m0.9027\u001b[0m                     \u001b[32m0.9025\u001b[0m        \u001b[35m0.3583\u001b[0m            0.7595                     0.7593        0.5231  0.0001  1.9957\n",
      "     25            \u001b[36m0.9039\u001b[0m                     \u001b[32m0.9040\u001b[0m        0.3584            0.7536                     0.7538        0.5310  0.0001  1.9957\n",
      "     26            \u001b[36m0.9109\u001b[0m                     \u001b[32m0.9110\u001b[0m        0.3698            0.7604                     0.7606        0.5271  0.0001  2.0036\n",
      "     27            0.9083                     0.9084        \u001b[35m0.3379\u001b[0m            0.7556                     0.7557        0.5248  0.0001  1.9967\n",
      "     28            \u001b[36m0.9184\u001b[0m                     \u001b[32m0.9184\u001b[0m        0.3568            0.7585                     0.7585        0.5252  0.0001  1.9968\n",
      "     29            0.9180                     0.9180        \u001b[35m0.3369\u001b[0m            0.7595                     0.7597        0.5229  0.0000  2.0012\n",
      "     30            \u001b[36m0.9187\u001b[0m                     \u001b[32m0.9187\u001b[0m        \u001b[35m0.3332\u001b[0m            0.7595                     0.7595        0.5230  0.0000  1.9997\n",
      "     31            \u001b[36m0.9189\u001b[0m                     \u001b[32m0.9190\u001b[0m        \u001b[35m0.3285\u001b[0m            0.7556                     0.7557        0.5236  0.0000  2.0007\n",
      "     32            \u001b[36m0.9223\u001b[0m                     \u001b[32m0.9224\u001b[0m        0.3378            \u001b[31m0.7614\u001b[0m                     \u001b[94m0.7615\u001b[0m        0.5237  0.0000  2.0076\n",
      "     33            \u001b[36m0.9240\u001b[0m                     \u001b[32m0.9241\u001b[0m        0.3305            0.7614                     0.7615        0.5233  0.0000  2.0083\n",
      "     34            0.9235                     0.9236        0.3378            0.7604                     0.7606        0.5236  0.0000  2.0007\n",
      "     35            0.9240                     \u001b[32m0.9241\u001b[0m        0.3287            0.7604                     0.7606        0.5235  0.0000  2.0067\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5612\u001b[0m                     \u001b[32m0.5630\u001b[0m        \u001b[35m1.3163\u001b[0m            \u001b[31m0.5364\u001b[0m                     \u001b[94m0.5382\u001b[0m        \u001b[36m0.8942\u001b[0m  0.0006  1.9982\n",
      "      2            \u001b[36m0.6063\u001b[0m                     \u001b[32m0.6076\u001b[0m        \u001b[35m0.9892\u001b[0m            \u001b[31m0.5849\u001b[0m                     \u001b[94m0.5862\u001b[0m        \u001b[36m0.7833\u001b[0m  0.0006  1.9977\n",
      "      3            \u001b[36m0.6318\u001b[0m                     \u001b[32m0.6306\u001b[0m        \u001b[35m0.8513\u001b[0m            \u001b[31m0.6159\u001b[0m                     \u001b[94m0.6148\u001b[0m        \u001b[36m0.7058\u001b[0m  0.0006  1.9990\n",
      "      4            \u001b[36m0.6738\u001b[0m                     \u001b[32m0.6746\u001b[0m        \u001b[35m0.8000\u001b[0m            \u001b[31m0.6217\u001b[0m                     \u001b[94m0.6227\u001b[0m        \u001b[36m0.6972\u001b[0m  0.0006  1.9997\n",
      "      5            \u001b[36m0.7444\u001b[0m                     \u001b[32m0.7446\u001b[0m        \u001b[35m0.7262\u001b[0m            \u001b[31m0.6867\u001b[0m                     \u001b[94m0.6870\u001b[0m        \u001b[36m0.6019\u001b[0m  0.0006  2.0039\n",
      "      6            \u001b[36m0.7500\u001b[0m                     \u001b[32m0.7497\u001b[0m        \u001b[35m0.6831\u001b[0m            \u001b[31m0.6877\u001b[0m                     \u001b[94m0.6874\u001b[0m        \u001b[36m0.5946\u001b[0m  0.0006  1.9967\n",
      "      7            \u001b[36m0.7745\u001b[0m                     \u001b[32m0.7747\u001b[0m        \u001b[35m0.6451\u001b[0m            \u001b[31m0.7013\u001b[0m                     \u001b[94m0.7016\u001b[0m        \u001b[36m0.5812\u001b[0m  0.0006  1.9987\n",
      "      8            0.7633                     0.7627        \u001b[35m0.5937\u001b[0m            \u001b[31m0.7110\u001b[0m                     \u001b[94m0.7103\u001b[0m        \u001b[36m0.5674\u001b[0m  0.0006  1.9942\n",
      "      9            \u001b[36m0.7881\u001b[0m                     \u001b[32m0.7883\u001b[0m        \u001b[35m0.5753\u001b[0m            \u001b[31m0.7139\u001b[0m                     \u001b[94m0.7141\u001b[0m        0.5793  0.0005  2.0026\n",
      "     10            \u001b[36m0.7993\u001b[0m                     \u001b[32m0.7989\u001b[0m        \u001b[35m0.5555\u001b[0m            0.7129                     0.7124        0.5754  0.0005  2.0026\n",
      "     11            \u001b[36m0.8209\u001b[0m                     \u001b[32m0.8210\u001b[0m        \u001b[35m0.5311\u001b[0m            \u001b[31m0.7352\u001b[0m                     \u001b[94m0.7353\u001b[0m        \u001b[36m0.5455\u001b[0m  0.0005  1.9967\n",
      "     12            0.8000                     0.8005        \u001b[35m0.5110\u001b[0m            0.7042                     0.7048        0.5889  0.0005  2.0067\n",
      "     13            \u001b[36m0.8335\u001b[0m                     \u001b[32m0.8337\u001b[0m        \u001b[35m0.4810\u001b[0m            \u001b[31m0.7439\u001b[0m                     \u001b[94m0.7443\u001b[0m        0.5533  0.0005  2.0016\n",
      "     14            \u001b[36m0.8466\u001b[0m                     \u001b[32m0.8466\u001b[0m        0.4950            0.7362                     0.7363        \u001b[36m0.5371\u001b[0m  0.0004  1.9957\n",
      "     15            \u001b[36m0.8556\u001b[0m                     \u001b[32m0.8558\u001b[0m        \u001b[35m0.4669\u001b[0m            0.7313                     0.7316        0.5463  0.0004  2.0002\n",
      "     16            \u001b[36m0.8573\u001b[0m                     \u001b[32m0.8574\u001b[0m        \u001b[35m0.4584\u001b[0m            0.7401                     0.7403        0.5570  0.0004  2.0066\n",
      "     17            \u001b[36m0.8595\u001b[0m                     \u001b[32m0.8598\u001b[0m        \u001b[35m0.4547\u001b[0m            0.7342                     0.7348        0.5600  0.0003  1.9977\n",
      "     18            \u001b[36m0.8738\u001b[0m                     \u001b[32m0.8737\u001b[0m        \u001b[35m0.4310\u001b[0m            \u001b[31m0.7478\u001b[0m                     \u001b[94m0.7476\u001b[0m        0.5390  0.0003  2.0016\n",
      "     19            \u001b[36m0.8840\u001b[0m                     \u001b[32m0.8840\u001b[0m        \u001b[35m0.4301\u001b[0m            \u001b[31m0.7507\u001b[0m                     \u001b[94m0.7507\u001b[0m        0.5487  0.0003  2.0016\n",
      "     20            0.8830                     0.8828        \u001b[35m0.4012\u001b[0m            0.7468                     0.7465        0.5446  0.0003  2.0016\n",
      "     21            \u001b[36m0.8978\u001b[0m                     \u001b[32m0.8978\u001b[0m        \u001b[35m0.3956\u001b[0m            \u001b[31m0.7556\u001b[0m                     \u001b[94m0.7556\u001b[0m        0.5472  0.0002  2.0034\n",
      "     22            0.8915                     0.8913        \u001b[35m0.3830\u001b[0m            0.7507                     0.7505        0.5456  0.0002  1.9987\n",
      "     23            \u001b[36m0.9032\u001b[0m                     \u001b[32m0.9031\u001b[0m        \u001b[35m0.3799\u001b[0m            0.7362                     0.7362        0.5541  0.0002  1.9967\n",
      "     24            0.8985                     0.8984        \u001b[35m0.3658\u001b[0m            0.7430                     0.7428        0.5590  0.0001  1.9982\n",
      "     25            \u001b[36m0.9080\u001b[0m                     \u001b[32m0.9080\u001b[0m        \u001b[35m0.3641\u001b[0m            0.7468                     0.7469        0.5539  0.0001  2.0026\n",
      "     26            \u001b[36m0.9107\u001b[0m                     \u001b[32m0.9107\u001b[0m        \u001b[35m0.3627\u001b[0m            0.7420                     0.7421        0.5493  0.0001  2.0061\n",
      "     27            \u001b[36m0.9180\u001b[0m                     \u001b[32m0.9180\u001b[0m        \u001b[35m0.3557\u001b[0m            0.7468                     0.7469        0.5483  0.0001  2.0100\n",
      "     28            \u001b[36m0.9226\u001b[0m                     \u001b[32m0.9225\u001b[0m        \u001b[35m0.3481\u001b[0m            0.7468                     0.7469        0.5541  0.0001  2.0026\n",
      "     29            0.9180                     0.9179        \u001b[35m0.3387\u001b[0m            0.7507                     0.7507        0.5531  0.0000  1.9977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     30            0.9211                     0.9211        \u001b[35m0.3304\u001b[0m            0.7439                     0.7441        0.5521  0.0000  2.0045\n",
      "     31            \u001b[36m0.9235\u001b[0m                     \u001b[32m0.9235\u001b[0m        \u001b[35m0.3237\u001b[0m            0.7498                     0.7498        0.5518  0.0000  1.9997\n",
      "     32            \u001b[36m0.9238\u001b[0m                     \u001b[32m0.9238\u001b[0m        0.3258            0.7401                     0.7402        0.5536  0.0000  2.0046\n",
      "     33            0.9214                     0.9214        0.3265            0.7459                     0.7460        0.5526  0.0000  2.0155\n",
      "     34            0.9228                     0.9228        0.3275            0.7459                     0.7459        0.5524  0.0000  2.0041\n",
      "     35            \u001b[36m0.9245\u001b[0m                     \u001b[32m0.9245\u001b[0m        0.3246            0.7478                     0.7478        0.5526  0.0000  2.0059\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5867\u001b[0m                     \u001b[32m0.5877\u001b[0m        \u001b[35m1.3295\u001b[0m            \u001b[31m0.5645\u001b[0m                     \u001b[94m0.5657\u001b[0m        \u001b[36m0.7849\u001b[0m  0.0006  2.0000\n",
      "      2            \u001b[36m0.6221\u001b[0m                     \u001b[32m0.6225\u001b[0m        \u001b[35m1.0170\u001b[0m            \u001b[31m0.5829\u001b[0m                     \u001b[94m0.5834\u001b[0m        \u001b[36m0.7395\u001b[0m  0.0006  1.9957\n",
      "      3            \u001b[36m0.6621\u001b[0m                     \u001b[32m0.6613\u001b[0m        \u001b[35m0.8996\u001b[0m            \u001b[31m0.6227\u001b[0m                     \u001b[94m0.6220\u001b[0m        \u001b[36m0.6883\u001b[0m  0.0006  1.9987\n",
      "      4            \u001b[36m0.7087\u001b[0m                     \u001b[32m0.7088\u001b[0m        \u001b[35m0.7956\u001b[0m            \u001b[31m0.6314\u001b[0m                     \u001b[94m0.6316\u001b[0m        \u001b[36m0.6631\u001b[0m  0.0006  2.0007\n",
      "      5            \u001b[36m0.7277\u001b[0m                     \u001b[32m0.7281\u001b[0m        \u001b[35m0.7314\u001b[0m            0.6198                     0.6203        \u001b[36m0.6622\u001b[0m  0.0006  1.9939\n",
      "      6            \u001b[36m0.7449\u001b[0m                     \u001b[32m0.7450\u001b[0m        \u001b[35m0.6854\u001b[0m            \u001b[31m0.6625\u001b[0m                     \u001b[94m0.6627\u001b[0m        \u001b[36m0.6376\u001b[0m  0.0006  2.0026\n",
      "      7            \u001b[36m0.7483\u001b[0m                     \u001b[32m0.7476\u001b[0m        \u001b[35m0.6446\u001b[0m            \u001b[31m0.6731\u001b[0m                     \u001b[94m0.6723\u001b[0m        \u001b[36m0.6275\u001b[0m  0.0006  2.0014\n",
      "      8            \u001b[36m0.7515\u001b[0m                     \u001b[32m0.7507\u001b[0m        \u001b[35m0.6046\u001b[0m            \u001b[31m0.6780\u001b[0m                     \u001b[94m0.6772\u001b[0m        0.6342  0.0006  2.0002\n",
      "      9            \u001b[36m0.7813\u001b[0m                     \u001b[32m0.7809\u001b[0m        \u001b[35m0.5763\u001b[0m            \u001b[31m0.6964\u001b[0m                     \u001b[94m0.6961\u001b[0m        \u001b[36m0.5985\u001b[0m  0.0005  2.0016\n",
      "     10            \u001b[36m0.8109\u001b[0m                     \u001b[32m0.8107\u001b[0m        \u001b[35m0.5532\u001b[0m            \u001b[31m0.7119\u001b[0m                     \u001b[94m0.7118\u001b[0m        \u001b[36m0.5887\u001b[0m  0.0005  2.0007\n",
      "     11            0.7925                     0.7930        \u001b[35m0.5267\u001b[0m            0.6819                     0.6825        0.6338  0.0005  2.0036\n",
      "     12            0.8075                     0.8072        \u001b[35m0.5131\u001b[0m            0.6935                     0.6930        0.5986  0.0005  2.0060\n",
      "     13            \u001b[36m0.8459\u001b[0m                     \u001b[32m0.8458\u001b[0m        \u001b[35m0.4954\u001b[0m            0.7110                     0.7110        \u001b[36m0.5846\u001b[0m  0.0005  2.0058\n",
      "     14            \u001b[36m0.8563\u001b[0m                     \u001b[32m0.8561\u001b[0m        \u001b[35m0.4820\u001b[0m            0.7100                     0.7097        0.5851  0.0004  1.9977\n",
      "     15            \u001b[36m0.8629\u001b[0m                     \u001b[32m0.8628\u001b[0m        \u001b[35m0.4520\u001b[0m            \u001b[31m0.7148\u001b[0m                     \u001b[94m0.7148\u001b[0m        \u001b[36m0.5741\u001b[0m  0.0004  2.0066\n",
      "     16            0.8546                     0.8550        \u001b[35m0.4518\u001b[0m            0.6984                     0.6989        0.5914  0.0004  1.9987\n",
      "     17            \u001b[36m0.8740\u001b[0m                     \u001b[32m0.8740\u001b[0m        \u001b[35m0.4351\u001b[0m            \u001b[31m0.7207\u001b[0m                     \u001b[94m0.7206\u001b[0m        \u001b[36m0.5721\u001b[0m  0.0003  1.9987\n",
      "     18            \u001b[36m0.8854\u001b[0m                     \u001b[32m0.8855\u001b[0m        \u001b[35m0.4177\u001b[0m            0.7207                     \u001b[94m0.7208\u001b[0m        \u001b[36m0.5651\u001b[0m  0.0003  2.0076\n",
      "     19            0.8808                     0.8810        \u001b[35m0.4041\u001b[0m            0.7158                     0.7160        0.5726  0.0003  2.0046\n",
      "     20            \u001b[36m0.8886\u001b[0m                     \u001b[32m0.8883\u001b[0m        \u001b[35m0.3980\u001b[0m            0.7148                     0.7145        0.5774  0.0003  2.0016\n",
      "     21            \u001b[36m0.8913\u001b[0m                     \u001b[32m0.8914\u001b[0m        \u001b[35m0.3828\u001b[0m            \u001b[31m0.7245\u001b[0m                     \u001b[94m0.7246\u001b[0m        \u001b[36m0.5639\u001b[0m  0.0002  2.0027\n",
      "     22            \u001b[36m0.9056\u001b[0m                     \u001b[32m0.9056\u001b[0m        \u001b[35m0.3810\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7265\u001b[0m        \u001b[36m0.5562\u001b[0m  0.0002  2.0006\n",
      "     23            0.9046                     0.9046        \u001b[35m0.3665\u001b[0m            0.7226                     0.7227        0.5707  0.0002  1.9989\n",
      "     24            \u001b[36m0.9080\u001b[0m                     \u001b[32m0.9081\u001b[0m        \u001b[35m0.3532\u001b[0m            0.7255                     0.7256        0.5634  0.0001  2.0016\n",
      "     25            \u001b[36m0.9165\u001b[0m                     \u001b[32m0.9165\u001b[0m        0.3676            0.7216                     0.7217        0.5699  0.0001  2.0007\n",
      "     26            0.9146                     0.9144        \u001b[35m0.3496\u001b[0m            0.7207                     0.7205        0.5705  0.0001  1.9970\n",
      "     27            \u001b[36m0.9170\u001b[0m                     \u001b[32m0.9170\u001b[0m        \u001b[35m0.3451\u001b[0m            \u001b[31m0.7342\u001b[0m                     \u001b[94m0.7342\u001b[0m        0.5630  0.0001  2.0056\n",
      "     28            \u001b[36m0.9175\u001b[0m                     \u001b[32m0.9174\u001b[0m        \u001b[35m0.3336\u001b[0m            0.7187                     0.7187        0.5616  0.0001  2.0074\n",
      "     29            \u001b[36m0.9184\u001b[0m                     \u001b[32m0.9184\u001b[0m        \u001b[35m0.3285\u001b[0m            0.7313                     0.7313        0.5616  0.0000  2.0046\n",
      "     30            \u001b[36m0.9223\u001b[0m                     \u001b[32m0.9223\u001b[0m        \u001b[35m0.3223\u001b[0m            0.7313                     0.7314        0.5611  0.0000  2.0092\n",
      "     31            \u001b[36m0.9240\u001b[0m                     \u001b[32m0.9240\u001b[0m        \u001b[35m0.3219\u001b[0m            0.7304                     0.7304        0.5617  0.0000  2.0066\n",
      "     32            0.9228                     0.9228        0.3241            0.7284                     0.7285        0.5634  0.0000  2.0063\n",
      "     33            0.9221                     0.9221        0.3232            0.7274                     0.7275        0.5628  0.0000  2.0007\n",
      "     34            0.9218                     0.9218        \u001b[35m0.3213\u001b[0m            0.7294                     0.7294        0.5631  0.0000  2.0024\n",
      "     35            0.9221                     0.9221        \u001b[35m0.3096\u001b[0m            0.7284                     0.7284        0.5630  0.0000  2.0026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6292\u001b[0m                     \u001b[32m0.6471\u001b[0m        \u001b[35m1.2816\u001b[0m            \u001b[31m0.6264\u001b[0m                     \u001b[94m0.6441\u001b[0m        \u001b[36m0.7206\u001b[0m  0.0006  1.7720\n",
      "      2            \u001b[36m0.6566\u001b[0m                     \u001b[32m0.6737\u001b[0m        \u001b[35m1.0243\u001b[0m            \u001b[31m0.6312\u001b[0m                     \u001b[94m0.6458\u001b[0m        \u001b[36m0.7161\u001b[0m  0.0006  1.2148\n",
      "      3            \u001b[36m0.7199\u001b[0m                     \u001b[32m0.7313\u001b[0m        \u001b[35m0.8213\u001b[0m            \u001b[31m0.6473\u001b[0m                     \u001b[94m0.6567\u001b[0m        \u001b[36m0.6558\u001b[0m  0.0006  1.2057\n",
      "      4            \u001b[36m0.7602\u001b[0m                     \u001b[32m0.7587\u001b[0m        \u001b[35m0.7632\u001b[0m            \u001b[31m0.6828\u001b[0m                     \u001b[94m0.6814\u001b[0m        \u001b[36m0.6399\u001b[0m  0.0006  1.2032\n",
      "      5            \u001b[36m0.7868\u001b[0m                     \u001b[32m0.7856\u001b[0m        \u001b[35m0.6823\u001b[0m            0.6779                     0.6758        \u001b[36m0.6324\u001b[0m  0.0006  1.2018\n",
      "      6            0.7445                     0.7580        \u001b[35m0.6493\u001b[0m            0.6667                     0.6771        0.6872  0.0006  1.2028\n",
      "      7            \u001b[36m0.8037\u001b[0m                     \u001b[32m0.7993\u001b[0m        \u001b[35m0.5990\u001b[0m            \u001b[31m0.6924\u001b[0m                     \u001b[94m0.6843\u001b[0m        0.6627  0.0006  1.2018\n",
      "      8            \u001b[36m0.8150\u001b[0m                     \u001b[32m0.8155\u001b[0m        \u001b[35m0.5842\u001b[0m            0.6876                     \u001b[94m0.6846\u001b[0m        \u001b[36m0.6301\u001b[0m  0.0006  1.2078\n",
      "      9            \u001b[36m0.8416\u001b[0m                     \u001b[32m0.8414\u001b[0m        \u001b[35m0.5392\u001b[0m            0.6876                     0.6844        0.6422  0.0005  1.2058\n",
      "     10            0.8323                     0.8398        \u001b[35m0.5176\u001b[0m            0.6860                     \u001b[94m0.6924\u001b[0m        0.6358  0.0005  1.2012\n",
      "     11            \u001b[36m0.8581\u001b[0m                     \u001b[32m0.8570\u001b[0m        \u001b[35m0.4995\u001b[0m            \u001b[31m0.7021\u001b[0m                     \u001b[94m0.6967\u001b[0m        0.6520  0.0005  1.2038\n",
      "     12            \u001b[36m0.8658\u001b[0m                     \u001b[32m0.8627\u001b[0m        \u001b[35m0.4744\u001b[0m            0.6892                     0.6814        0.6663  0.0005  1.1983\n",
      "     13            0.8384                     0.8498        \u001b[35m0.4637\u001b[0m            0.6812                     0.6898        0.6742  0.0005  1.2116\n",
      "     14            \u001b[36m0.8795\u001b[0m                     \u001b[32m0.8829\u001b[0m        \u001b[35m0.4395\u001b[0m            0.6908                     0.6918        0.6520  0.0004  1.2048\n",
      "     15            0.8654                     0.8725        \u001b[35m0.4081\u001b[0m            0.6763                     0.6812        0.6740  0.0004  1.2058\n",
      "     16            \u001b[36m0.9004\u001b[0m                     \u001b[32m0.8987\u001b[0m        \u001b[35m0.4062\u001b[0m            0.6812                     0.6758        0.6915  0.0004  1.2088\n",
      "     17            0.8940                     0.8986        \u001b[35m0.3887\u001b[0m            0.6779                     0.6809        0.6658  0.0003  1.2048\n",
      "     18            \u001b[36m0.9025\u001b[0m                     \u001b[32m0.9058\u001b[0m        \u001b[35m0.3699\u001b[0m            0.6763                     0.6770        0.6885  0.0003  1.1998\n",
      "     19            \u001b[36m0.9146\u001b[0m                     \u001b[32m0.9171\u001b[0m        \u001b[35m0.3545\u001b[0m            0.6763                     0.6758        0.6762  0.0003  1.2063\n",
      "     20            0.9141                     \u001b[32m0.9183\u001b[0m        \u001b[35m0.3391\u001b[0m            0.6779                     0.6788        0.6800  0.0003  1.2048\n",
      "     21            \u001b[36m0.9258\u001b[0m                     \u001b[32m0.9303\u001b[0m        \u001b[35m0.3338\u001b[0m            0.6731                     0.6764        0.6802  0.0002  1.2108\n",
      "     22            \u001b[36m0.9391\u001b[0m                     \u001b[32m0.9399\u001b[0m        \u001b[35m0.3239\u001b[0m            0.6747                     0.6711        0.7035  0.0002  1.2058\n",
      "     23            0.9299                     0.9335        \u001b[35m0.3039\u001b[0m            0.6747                     0.6764        0.6980  0.0002  1.2018\n",
      "     24            \u001b[36m0.9484\u001b[0m                     \u001b[32m0.9505\u001b[0m        0.3129            0.6731                     0.6717        0.6872  0.0001  1.2078\n",
      "     25            0.9480                     0.9477        \u001b[35m0.2929\u001b[0m            0.6731                     0.6675        0.7024  0.0001  1.2043\n",
      "     26            \u001b[36m0.9508\u001b[0m                     \u001b[32m0.9521\u001b[0m        \u001b[35m0.2823\u001b[0m            0.6763                     0.6728        0.6980  0.0001  1.2038\n",
      "     27            \u001b[36m0.9553\u001b[0m                     \u001b[32m0.9564\u001b[0m        \u001b[35m0.2778\u001b[0m            0.6812                     0.6785        0.7012  0.0001  1.2108\n",
      "     28            \u001b[36m0.9601\u001b[0m                     \u001b[32m0.9612\u001b[0m        0.2821            0.6683                     0.6652        0.7069  0.0001  1.2091\n",
      "     29            0.9569                     0.9584        \u001b[35m0.2521\u001b[0m            0.6763                     0.6734        0.7142  0.0000  1.2068\n",
      "     30            0.9589                     0.9608        0.2728            0.6731                     0.6714        0.7073  0.0000  1.2028\n",
      "     31            0.9585                     0.9607        0.2624            0.6747                     0.6728        0.7074  0.0000  1.2098\n",
      "     32            \u001b[36m0.9605\u001b[0m                     \u001b[32m0.9616\u001b[0m        0.2684            0.6779                     0.6743        0.7102  0.0000  1.2056\n",
      "     33            0.9605                     \u001b[32m0.9624\u001b[0m        0.2779            0.6795                     0.6773        0.7083  0.0000  1.2038\n",
      "     34            \u001b[36m0.9609\u001b[0m                     \u001b[32m0.9628\u001b[0m        0.2613            0.6795                     0.6773        0.7081  0.0000  1.2088\n",
      "     35            0.9589                     0.9603        0.2652            0.6795                     0.6767        0.7101  0.0000  1.2098\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6747\u001b[0m                     \u001b[32m0.6740\u001b[0m        \u001b[35m1.2342\u001b[0m            \u001b[31m0.6570\u001b[0m                     \u001b[94m0.6572\u001b[0m        \u001b[36m0.6652\u001b[0m  0.0006  1.2048\n",
      "      2            \u001b[36m0.7170\u001b[0m                     \u001b[32m0.7245\u001b[0m        \u001b[35m0.9644\u001b[0m            0.6554                     \u001b[94m0.6623\u001b[0m        \u001b[36m0.6484\u001b[0m  0.0006  1.2028\n",
      "      3            \u001b[36m0.7412\u001b[0m                     \u001b[32m0.7466\u001b[0m        \u001b[35m0.8529\u001b[0m            0.6441                     0.6502        \u001b[36m0.6455\u001b[0m  0.0006  1.2003\n",
      "      4            0.7102                     0.7279        \u001b[35m0.7645\u001b[0m            0.6361                     0.6544        0.7171  0.0006  1.2028\n",
      "      5            \u001b[36m0.7650\u001b[0m                     \u001b[32m0.7767\u001b[0m        \u001b[35m0.6965\u001b[0m            0.6554                     \u001b[94m0.6677\u001b[0m        0.6480  0.0006  1.2038\n",
      "      6            \u001b[36m0.7819\u001b[0m                     0.7753        \u001b[35m0.6068\u001b[0m            \u001b[31m0.6651\u001b[0m                     0.6592        0.6577  0.0006  1.2068\n",
      "      7            \u001b[36m0.8077\u001b[0m                     \u001b[32m0.8085\u001b[0m        \u001b[35m0.6008\u001b[0m            \u001b[31m0.6715\u001b[0m                     \u001b[94m0.6702\u001b[0m        \u001b[36m0.6125\u001b[0m  0.0006  1.2098\n",
      "      8            0.8077                     \u001b[32m0.8151\u001b[0m        \u001b[35m0.5803\u001b[0m            0.6667                     \u001b[94m0.6723\u001b[0m        0.6132  0.0006  1.2008\n",
      "      9            \u001b[36m0.8420\u001b[0m                     \u001b[32m0.8454\u001b[0m        \u001b[35m0.5610\u001b[0m            0.6715                     \u001b[94m0.6735\u001b[0m        0.6154  0.0005  1.2078\n",
      "     10            0.8384                     0.8447        \u001b[35m0.5057\u001b[0m            \u001b[31m0.6731\u001b[0m                     \u001b[94m0.6815\u001b[0m        0.6292  0.0005  1.2028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            0.8388                     0.8298        \u001b[35m0.4877\u001b[0m            0.6586                     0.6456        0.6920  0.0005  1.2055\n",
      "     12            \u001b[36m0.8658\u001b[0m                     \u001b[32m0.8690\u001b[0m        \u001b[35m0.4713\u001b[0m            \u001b[31m0.6779\u001b[0m                     0.6788        0.6444  0.0005  1.2078\n",
      "     13            \u001b[36m0.8807\u001b[0m                     \u001b[32m0.8826\u001b[0m        \u001b[35m0.4578\u001b[0m            0.6763                     0.6767        0.6323  0.0005  1.2060\n",
      "     14            \u001b[36m0.8888\u001b[0m                     \u001b[32m0.8875\u001b[0m        \u001b[35m0.4270\u001b[0m            0.6618                     0.6602        0.6919  0.0004  1.2058\n",
      "     15            \u001b[36m0.8912\u001b[0m                     \u001b[32m0.8908\u001b[0m        0.4284            \u001b[31m0.6876\u001b[0m                     \u001b[94m0.6861\u001b[0m        0.6410  0.0004  1.2098\n",
      "     16            \u001b[36m0.8956\u001b[0m                     \u001b[32m0.8986\u001b[0m        \u001b[35m0.3890\u001b[0m            0.6747                     0.6779        0.6643  0.0004  1.2028\n",
      "     17            \u001b[36m0.9170\u001b[0m                     \u001b[32m0.9184\u001b[0m        \u001b[35m0.3680\u001b[0m            0.6731                     0.6747        0.6645  0.0003  1.2088\n",
      "     18            \u001b[36m0.9186\u001b[0m                     \u001b[32m0.9201\u001b[0m        \u001b[35m0.3494\u001b[0m            0.6602                     0.6605        0.6744  0.0003  1.2103\n",
      "     19            \u001b[36m0.9287\u001b[0m                     \u001b[32m0.9309\u001b[0m        \u001b[35m0.3427\u001b[0m            0.6522                     0.6525        0.6748  0.0003  1.2023\n",
      "     20            \u001b[36m0.9291\u001b[0m                     \u001b[32m0.9313\u001b[0m        \u001b[35m0.3082\u001b[0m            0.6683                     0.6708        0.6753  0.0003  1.2048\n",
      "     21            \u001b[36m0.9383\u001b[0m                     \u001b[32m0.9386\u001b[0m        \u001b[35m0.3061\u001b[0m            0.6731                     0.6723        0.6525  0.0002  1.2048\n",
      "     22            0.9242                     0.9274        0.3064            0.6763                     0.6818        0.6645  0.0002  1.2080\n",
      "     23            \u001b[36m0.9464\u001b[0m                     \u001b[32m0.9476\u001b[0m        \u001b[35m0.2869\u001b[0m            0.6779                     0.6770        0.6851  0.0002  1.2028\n",
      "     24            0.9440                     0.9447        0.2985            \u001b[31m0.6940\u001b[0m                     \u001b[94m0.6941\u001b[0m        0.6885  0.0001  1.2028\n",
      "     25            0.9315                     0.9357        0.2887            0.6844                     0.6900        0.6783  0.0001  1.2085\n",
      "     26            \u001b[36m0.9528\u001b[0m                     \u001b[32m0.9536\u001b[0m        \u001b[35m0.2774\u001b[0m            0.6844                     0.6847        0.6808  0.0001  1.2028\n",
      "     27            \u001b[36m0.9541\u001b[0m                     \u001b[32m0.9552\u001b[0m        \u001b[35m0.2763\u001b[0m            0.6844                     0.6850        0.6768  0.0001  1.2078\n",
      "     28            \u001b[36m0.9565\u001b[0m                     \u001b[32m0.9574\u001b[0m        \u001b[35m0.2730\u001b[0m            0.6940                     0.6935        0.6784  0.0001  1.2038\n",
      "     29            \u001b[36m0.9597\u001b[0m                     \u001b[32m0.9613\u001b[0m        \u001b[35m0.2664\u001b[0m            0.6892                     0.6909        0.6812  0.0000  1.2048\n",
      "     30            0.9585                     0.9596        \u001b[35m0.2657\u001b[0m            0.6860                     0.6865        0.6783  0.0000  1.2068\n",
      "     31            0.9597                     \u001b[32m0.9615\u001b[0m        \u001b[35m0.2603\u001b[0m            0.6860                     0.6879        0.6804  0.0000  1.2088\n",
      "     32            0.9593                     0.9608        \u001b[35m0.2409\u001b[0m            0.6892                     0.6906        0.6817  0.0000  1.2029\n",
      "     33            \u001b[36m0.9601\u001b[0m                     0.9613        0.2614            0.6828                     0.6829        0.6823  0.0000  1.2078\n",
      "     34            0.9593                     0.9607        0.2554            0.6876                     0.6882        0.6823  0.0000  1.2078\n",
      "     35            0.9589                     0.9603        0.2496            0.6892                     0.6903        0.6820  0.0000  1.2038\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6800\u001b[0m                     \u001b[32m0.6819\u001b[0m        \u001b[35m1.2578\u001b[0m            \u001b[31m0.6087\u001b[0m                     \u001b[94m0.6106\u001b[0m        \u001b[36m0.7488\u001b[0m  0.0006  1.2066\n",
      "      2            0.6763                     \u001b[32m0.6916\u001b[0m        \u001b[35m0.9855\u001b[0m            \u001b[31m0.6441\u001b[0m                     \u001b[94m0.6582\u001b[0m        \u001b[36m0.7113\u001b[0m  0.0006  1.2058\n",
      "      3            \u001b[36m0.7308\u001b[0m                     \u001b[32m0.7349\u001b[0m        \u001b[35m0.8985\u001b[0m            \u001b[31m0.6602\u001b[0m                     \u001b[94m0.6664\u001b[0m        \u001b[36m0.6430\u001b[0m  0.0006  1.2038\n",
      "      4            \u001b[36m0.7360\u001b[0m                     \u001b[32m0.7425\u001b[0m        \u001b[35m0.7551\u001b[0m            \u001b[31m0.6634\u001b[0m                     \u001b[94m0.6679\u001b[0m        \u001b[36m0.6124\u001b[0m  0.0006  1.2073\n",
      "      5            \u001b[36m0.7432\u001b[0m                     \u001b[32m0.7554\u001b[0m        \u001b[35m0.7024\u001b[0m            \u001b[31m0.6715\u001b[0m                     \u001b[94m0.6812\u001b[0m        0.6335  0.0006  1.2088\n",
      "      6            \u001b[36m0.7747\u001b[0m                     \u001b[32m0.7792\u001b[0m        \u001b[35m0.6457\u001b[0m            0.6667                     0.6705        0.6382  0.0006  1.2058\n",
      "      7            \u001b[36m0.8106\u001b[0m                     \u001b[32m0.8081\u001b[0m        \u001b[35m0.6272\u001b[0m            0.6651                     0.6583        0.6508  0.0006  1.2126\n",
      "      8            \u001b[36m0.8279\u001b[0m                     \u001b[32m0.8288\u001b[0m        \u001b[35m0.6115\u001b[0m            \u001b[31m0.6731\u001b[0m                     0.6714        0.6681  0.0006  1.2058\n",
      "      9            \u001b[36m0.8351\u001b[0m                     \u001b[32m0.8350\u001b[0m        \u001b[35m0.5482\u001b[0m            0.6683                     0.6664        0.6448  0.0005  1.2098\n",
      "     10            \u001b[36m0.8412\u001b[0m                     \u001b[32m0.8441\u001b[0m        \u001b[35m0.5088\u001b[0m            \u001b[31m0.6876\u001b[0m                     \u001b[94m0.6873\u001b[0m        0.6407  0.0005  1.2058\n",
      "     11            0.8243                     0.8251        \u001b[35m0.5016\u001b[0m            0.6876                     \u001b[94m0.6879\u001b[0m        0.6904  0.0005  1.2038\n",
      "     12            \u001b[36m0.8480\u001b[0m                     \u001b[32m0.8503\u001b[0m        \u001b[35m0.4808\u001b[0m            \u001b[31m0.7005\u001b[0m                     \u001b[94m0.7012\u001b[0m        0.6600  0.0005  1.2048\n",
      "     13            0.8448                     \u001b[32m0.8516\u001b[0m        \u001b[35m0.4466\u001b[0m            0.6860                     0.6924        0.6309  0.0005  1.2051\n",
      "     14            \u001b[36m0.8815\u001b[0m                     \u001b[32m0.8836\u001b[0m        \u001b[35m0.4218\u001b[0m            0.7005                     \u001b[94m0.7024\u001b[0m        0.6322  0.0004  1.2018\n",
      "     15            \u001b[36m0.8819\u001b[0m                     \u001b[32m0.8859\u001b[0m        \u001b[35m0.4075\u001b[0m            0.6763                     0.6800        0.6491  0.0004  1.2068\n",
      "     16            \u001b[36m0.8968\u001b[0m                     \u001b[32m0.8974\u001b[0m        \u001b[35m0.3917\u001b[0m            0.6795                     0.6773        0.6728  0.0004  1.2013\n",
      "     17            \u001b[36m0.8984\u001b[0m                     0.8960        \u001b[35m0.3769\u001b[0m            0.6795                     0.6746        0.6696  0.0003  1.2088\n",
      "     18            \u001b[36m0.9077\u001b[0m                     \u001b[32m0.9058\u001b[0m        \u001b[35m0.3609\u001b[0m            0.6940                     0.6914        0.6582  0.0003  1.2078\n",
      "     19            \u001b[36m0.9174\u001b[0m                     \u001b[32m0.9202\u001b[0m        \u001b[35m0.3365\u001b[0m            0.7005                     \u001b[94m0.7039\u001b[0m        0.6510  0.0003  1.2023\n",
      "     20            0.9105                     0.9094        0.3557            0.6779                     0.6740        0.6738  0.0003  1.2048\n",
      "     21            \u001b[36m0.9210\u001b[0m                     \u001b[32m0.9238\u001b[0m        0.3431            0.6828                     0.6859        0.6609  0.0002  1.2068\n",
      "     22            0.9210                     \u001b[32m0.9249\u001b[0m        \u001b[35m0.3117\u001b[0m            0.6940                     0.6998        0.6560  0.0002  1.2037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     23            \u001b[36m0.9287\u001b[0m                     \u001b[32m0.9324\u001b[0m        \u001b[35m0.3035\u001b[0m            0.6876                     0.6924        0.6689  0.0002  1.2038\n",
      "     24            0.9279                     0.9312        \u001b[35m0.3002\u001b[0m            0.6892                     0.6933        0.6702  0.0001  1.2088\n",
      "     25            \u001b[36m0.9420\u001b[0m                     \u001b[32m0.9422\u001b[0m        \u001b[35m0.2945\u001b[0m            0.6940                     0.6932        0.6853  0.0001  1.2078\n",
      "     26            \u001b[36m0.9424\u001b[0m                     \u001b[32m0.9443\u001b[0m        \u001b[35m0.2763\u001b[0m            0.6989                     0.7012        0.6737  0.0001  1.2038\n",
      "     27            \u001b[36m0.9476\u001b[0m                     \u001b[32m0.9498\u001b[0m        \u001b[35m0.2633\u001b[0m            0.6973                     0.7004        0.6703  0.0001  1.2078\n",
      "     28            \u001b[36m0.9528\u001b[0m                     \u001b[32m0.9536\u001b[0m        \u001b[35m0.2531\u001b[0m            0.6989                     0.7003        0.6737  0.0001  1.2047\n",
      "     29            \u001b[36m0.9597\u001b[0m                     \u001b[32m0.9605\u001b[0m        0.2752            \u001b[31m0.7053\u001b[0m                     \u001b[94m0.7053\u001b[0m        0.6690  0.0000  1.2028\n",
      "     30            0.9565                     0.9578        0.2554            0.7021                     0.7030        0.6769  0.0000  1.2048\n",
      "     31            0.9577                     0.9591        0.2641            0.7021                     0.7027        0.6759  0.0000  1.2087\n",
      "     32            0.9565                     0.9580        0.2546            0.7005                     0.7021        0.6774  0.0000  1.2064\n",
      "     33            0.9577                     0.9587        0.2706            0.7037                     0.7042        0.6766  0.0000  1.2128\n",
      "     34            0.9561                     0.9574        0.2684            0.6989                     0.6997        0.6762  0.0000  1.2058\n",
      "     35            0.9561                     0.9573        0.2581            0.6973                     0.6983        0.6767  0.0000  1.2038\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6550\u001b[0m                     \u001b[32m0.6549\u001b[0m        \u001b[35m1.3090\u001b[0m            \u001b[31m0.6119\u001b[0m                     \u001b[94m0.6091\u001b[0m        \u001b[36m0.7612\u001b[0m  0.0006  1.2026\n",
      "      2            \u001b[36m0.6961\u001b[0m                     \u001b[32m0.7096\u001b[0m        \u001b[35m0.9581\u001b[0m            \u001b[31m0.6232\u001b[0m                     \u001b[94m0.6334\u001b[0m        \u001b[36m0.7089\u001b[0m  0.0006  1.2038\n",
      "      3            \u001b[36m0.7046\u001b[0m                     0.7053        \u001b[35m0.8720\u001b[0m            0.6071                     0.6058        0.7451  0.0006  1.2078\n",
      "      4            \u001b[36m0.7465\u001b[0m                     \u001b[32m0.7411\u001b[0m        \u001b[35m0.7730\u001b[0m            \u001b[31m0.6457\u001b[0m                     \u001b[94m0.6377\u001b[0m        \u001b[36m0.6772\u001b[0m  0.0006  1.2098\n",
      "      5            \u001b[36m0.7630\u001b[0m                     \u001b[32m0.7708\u001b[0m        \u001b[35m0.7003\u001b[0m            0.6361                     \u001b[94m0.6443\u001b[0m        \u001b[36m0.6543\u001b[0m  0.0006  1.2028\n",
      "      6            \u001b[36m0.7767\u001b[0m                     0.7702        \u001b[35m0.6364\u001b[0m            0.6441                     0.6368        0.6587  0.0006  1.1998\n",
      "      7            \u001b[36m0.7912\u001b[0m                     \u001b[32m0.7992\u001b[0m        \u001b[35m0.6203\u001b[0m            \u001b[31m0.6667\u001b[0m                     \u001b[94m0.6741\u001b[0m        \u001b[36m0.6501\u001b[0m  0.0006  1.2068\n",
      "      8            \u001b[36m0.8089\u001b[0m                     \u001b[32m0.8108\u001b[0m        \u001b[35m0.5634\u001b[0m            0.6634                     0.6637        \u001b[36m0.6258\u001b[0m  0.0006  1.2058\n",
      "      9            \u001b[36m0.8158\u001b[0m                     \u001b[32m0.8144\u001b[0m        \u001b[35m0.5540\u001b[0m            0.6634                     0.6628        \u001b[36m0.6172\u001b[0m  0.0005  1.2068\n",
      "     10            \u001b[36m0.8307\u001b[0m                     \u001b[32m0.8363\u001b[0m        \u001b[35m0.5089\u001b[0m            0.6457                     0.6502        0.6505  0.0005  2.2799\n",
      "     11            0.8271                     0.8338        \u001b[35m0.4990\u001b[0m            \u001b[31m0.6795\u001b[0m                     \u001b[94m0.6859\u001b[0m        0.6396  0.0005  1.1948\n",
      "     12            \u001b[36m0.8323\u001b[0m                     \u001b[32m0.8417\u001b[0m        \u001b[35m0.4767\u001b[0m            0.6683                     0.6783        0.6391  0.0005  1.2383\n",
      "     13            \u001b[36m0.8597\u001b[0m                     \u001b[32m0.8561\u001b[0m        \u001b[35m0.4506\u001b[0m            0.6699                     0.6648        0.6531  0.0005  1.2198\n",
      "     14            \u001b[36m0.8654\u001b[0m                     \u001b[32m0.8698\u001b[0m        \u001b[35m0.4479\u001b[0m            0.6763                     0.6812        \u001b[36m0.6058\u001b[0m  0.0004  1.2028\n",
      "     15            \u001b[36m0.8662\u001b[0m                     \u001b[32m0.8726\u001b[0m        \u001b[35m0.4343\u001b[0m            \u001b[31m0.6876\u001b[0m                     \u001b[94m0.6936\u001b[0m        0.6177  0.0004  1.1953\n",
      "     16            \u001b[36m0.8908\u001b[0m                     \u001b[32m0.8947\u001b[0m        \u001b[35m0.4110\u001b[0m            0.6795                     0.6841        0.6204  0.0004  1.1948\n",
      "     17            \u001b[36m0.8916\u001b[0m                     \u001b[32m0.8954\u001b[0m        \u001b[35m0.3935\u001b[0m            \u001b[31m0.7005\u001b[0m                     \u001b[94m0.7063\u001b[0m        \u001b[36m0.6057\u001b[0m  0.0003  1.1953\n",
      "     18            \u001b[36m0.9178\u001b[0m                     \u001b[32m0.9164\u001b[0m        \u001b[35m0.3772\u001b[0m            0.6683                     0.6649        0.6191  0.0003  1.1964\n",
      "     19            \u001b[36m0.9186\u001b[0m                     \u001b[32m0.9180\u001b[0m        0.3794            0.6795                     0.6779        0.6366  0.0003  1.1946\n",
      "     20            \u001b[36m0.9210\u001b[0m                     \u001b[32m0.9217\u001b[0m        \u001b[35m0.3506\u001b[0m            0.6892                     0.6891        0.6196  0.0003  1.1938\n",
      "     21            \u001b[36m0.9303\u001b[0m                     \u001b[32m0.9310\u001b[0m        \u001b[35m0.3390\u001b[0m            0.6747                     0.6726        \u001b[36m0.6052\u001b[0m  0.0002  1.1948\n",
      "     22            0.9258                     0.9287        \u001b[35m0.3227\u001b[0m            0.6876                     0.6903        0.6155  0.0002  1.1910\n",
      "     23            \u001b[36m0.9416\u001b[0m                     \u001b[32m0.9426\u001b[0m        \u001b[35m0.3055\u001b[0m            0.6957                     0.6962        0.6210  0.0002  1.2058\n",
      "     24            \u001b[36m0.9472\u001b[0m                     \u001b[32m0.9472\u001b[0m        \u001b[35m0.3036\u001b[0m            0.6908                     0.6897        0.6285  0.0001  1.1958\n",
      "     25            \u001b[36m0.9496\u001b[0m                     \u001b[32m0.9494\u001b[0m        \u001b[35m0.3029\u001b[0m            0.6908                     0.6882        0.6200  0.0001  1.1918\n",
      "     26            0.9412                     0.9440        \u001b[35m0.2854\u001b[0m            \u001b[31m0.7021\u001b[0m                     0.7051        0.6239  0.0001  1.1988\n",
      "     27            \u001b[36m0.9561\u001b[0m                     \u001b[32m0.9562\u001b[0m        \u001b[35m0.2743\u001b[0m            0.6989                     0.6980        0.6332  0.0001  1.1958\n",
      "     28            0.9545                     0.9550        \u001b[35m0.2726\u001b[0m            0.7021                     0.7018        0.6268  0.0001  1.1938\n",
      "     29            0.9496                     0.9510        0.2798            0.7021                     0.7027        0.6269  0.0000  1.2028\n",
      "     30            \u001b[36m0.9581\u001b[0m                     \u001b[32m0.9586\u001b[0m        \u001b[35m0.2631\u001b[0m            0.7021                     0.7021        0.6274  0.0000  1.1928\n",
      "     31            0.9549                     0.9559        0.2736            0.7005                     0.7006        0.6296  0.0000  1.1990\n",
      "     32            \u001b[36m0.9589\u001b[0m                     \u001b[32m0.9592\u001b[0m        \u001b[35m0.2479\u001b[0m            0.6957                     0.6944        0.6327  0.0000  1.1908\n",
      "     33            0.9549                     0.9557        0.2634            0.6989                     0.6994        0.6315  0.0000  1.1958\n",
      "     34            0.9589                     \u001b[32m0.9593\u001b[0m        0.2617            0.6957                     0.6944        0.6323  0.0000  1.1918\n",
      "     35            0.9541                     0.9549        0.2520            0.6989                     0.6997        0.6314  0.0000  1.2058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6626\u001b[0m                     \u001b[32m0.6769\u001b[0m        \u001b[35m1.2251\u001b[0m            \u001b[31m0.6345\u001b[0m                     \u001b[94m0.6476\u001b[0m        \u001b[36m0.7871\u001b[0m  0.0006  1.1918\n",
      "      2            \u001b[36m0.7066\u001b[0m                     \u001b[32m0.7040\u001b[0m        \u001b[35m0.9790\u001b[0m            \u001b[31m0.6425\u001b[0m                     0.6428        \u001b[36m0.6837\u001b[0m  0.0006  1.1964\n",
      "      3            \u001b[36m0.7199\u001b[0m                     \u001b[32m0.7281\u001b[0m        \u001b[35m0.8532\u001b[0m            0.6425                     \u001b[94m0.6493\u001b[0m        0.6839  0.0006  1.1953\n",
      "      4            \u001b[36m0.7469\u001b[0m                     \u001b[32m0.7507\u001b[0m        \u001b[35m0.7628\u001b[0m            \u001b[31m0.6892\u001b[0m                     \u001b[94m0.6906\u001b[0m        \u001b[36m0.6306\u001b[0m  0.0006  1.1962\n",
      "      5            \u001b[36m0.7582\u001b[0m                     \u001b[32m0.7520\u001b[0m        \u001b[35m0.6991\u001b[0m            0.6795                     0.6716        \u001b[36m0.6174\u001b[0m  0.0006  1.1908\n",
      "      6            \u001b[36m0.7703\u001b[0m                     \u001b[32m0.7669\u001b[0m        \u001b[35m0.6518\u001b[0m            0.6779                     0.6698        0.6208  0.0006  1.1978\n",
      "      7            \u001b[36m0.8033\u001b[0m                     \u001b[32m0.8033\u001b[0m        \u001b[35m0.6414\u001b[0m            0.6876                     0.6849        \u001b[36m0.5954\u001b[0m  0.0006  1.1988\n",
      "      8            \u001b[36m0.8106\u001b[0m                     \u001b[32m0.8190\u001b[0m        \u001b[35m0.5523\u001b[0m            0.6828                     \u001b[94m0.6907\u001b[0m        0.6327  0.0006  1.1938\n",
      "      9            \u001b[36m0.8263\u001b[0m                     \u001b[32m0.8304\u001b[0m        0.5668            0.6506                     0.6546        0.6562  0.0005  1.1988\n",
      "     10            \u001b[36m0.8372\u001b[0m                     \u001b[32m0.8368\u001b[0m        \u001b[35m0.5195\u001b[0m            0.6892                     0.6855        0.6138  0.0005  1.1964\n",
      "     11            \u001b[36m0.8493\u001b[0m                     \u001b[32m0.8516\u001b[0m        \u001b[35m0.4939\u001b[0m            0.6828                     0.6823        0.6159  0.0005  1.1938\n",
      "     12            \u001b[36m0.8577\u001b[0m                     \u001b[32m0.8561\u001b[0m        \u001b[35m0.4856\u001b[0m            0.6731                     0.6663        0.6495  0.0005  1.1968\n",
      "     13            \u001b[36m0.8763\u001b[0m                     \u001b[32m0.8770\u001b[0m        \u001b[35m0.4633\u001b[0m            \u001b[31m0.7069\u001b[0m                     \u001b[94m0.7050\u001b[0m        0.6057  0.0005  1.1990\n",
      "     14            \u001b[36m0.8879\u001b[0m                     \u001b[32m0.8847\u001b[0m        \u001b[35m0.4380\u001b[0m            0.7037                     0.6982        0.6127  0.0004  1.1938\n",
      "     15            0.8650                     0.8710        \u001b[35m0.4264\u001b[0m            0.6699                     0.6765        0.6826  0.0004  1.2018\n",
      "     16            0.8811                     \u001b[32m0.8867\u001b[0m        \u001b[35m0.4185\u001b[0m            0.6844                     0.6889        0.6357  0.0004  1.1968\n",
      "     17            0.8694                     0.8770        \u001b[35m0.3744\u001b[0m            0.6795                     0.6865        0.6633  0.0003  1.1933\n",
      "     18            \u001b[36m0.8964\u001b[0m                     \u001b[32m0.8985\u001b[0m        \u001b[35m0.3702\u001b[0m            0.6844                     0.6847        0.6467  0.0003  1.1948\n",
      "     19            \u001b[36m0.9170\u001b[0m                     \u001b[32m0.9187\u001b[0m        \u001b[35m0.3598\u001b[0m            0.7021                     0.7018        0.6357  0.0003  1.2008\n",
      "     20            \u001b[36m0.9218\u001b[0m                     \u001b[32m0.9238\u001b[0m        0.3599            0.7037                     0.7039        0.6155  0.0003  1.1948\n",
      "     21            \u001b[36m0.9254\u001b[0m                     \u001b[32m0.9266\u001b[0m        \u001b[35m0.3428\u001b[0m            0.6812                     0.6787        0.6476  0.0002  1.1978\n",
      "     22            \u001b[36m0.9363\u001b[0m                     \u001b[32m0.9367\u001b[0m        \u001b[35m0.3104\u001b[0m            0.7037                     0.7003        0.6243  0.0002  1.1957\n",
      "     23            \u001b[36m0.9456\u001b[0m                     \u001b[32m0.9458\u001b[0m        \u001b[35m0.2997\u001b[0m            0.6940                     0.6905        0.6361  0.0002  1.1938\n",
      "     24            0.9399                     0.9412        0.3076            0.7053                     0.7036        0.6424  0.0001  1.2038\n",
      "     25            \u001b[36m0.9492\u001b[0m                     \u001b[32m0.9495\u001b[0m        0.3002            0.7005                     0.6973        0.6284  0.0001  1.1958\n",
      "     26            0.9488                     \u001b[32m0.9495\u001b[0m        \u001b[35m0.2950\u001b[0m            0.7037                     0.7012        0.6343  0.0001  1.1968\n",
      "     27            \u001b[36m0.9504\u001b[0m                     \u001b[32m0.9511\u001b[0m        \u001b[35m0.2824\u001b[0m            0.6989                     0.6965        0.6433  0.0001  1.1948\n",
      "     28            \u001b[36m0.9561\u001b[0m                     \u001b[32m0.9566\u001b[0m        \u001b[35m0.2746\u001b[0m            \u001b[31m0.7118\u001b[0m                     \u001b[94m0.7095\u001b[0m        0.6354  0.0001  1.1981\n",
      "     29            0.9528                     0.9538        0.2865            0.7101                     0.7077        0.6357  0.0000  1.1908\n",
      "     30            \u001b[36m0.9577\u001b[0m                     \u001b[32m0.9586\u001b[0m        \u001b[35m0.2682\u001b[0m            0.7053                     0.7027        0.6329  0.0000  1.1978\n",
      "     31            0.9573                     \u001b[32m0.9586\u001b[0m        \u001b[35m0.2659\u001b[0m            0.7069                     0.7047        0.6344  0.0000  1.2078\n",
      "     32            0.9569                     0.9581        \u001b[35m0.2585\u001b[0m            0.7069                     0.7053        0.6376  0.0000  1.1978\n",
      "     33            0.9561                     0.9575        0.2717            0.7069                     0.7053        0.6388  0.0000  1.1948\n",
      "     34            0.9569                     0.9582        0.2617            0.7085                     0.7068        0.6390  0.0000  1.1978\n",
      "     35            0.9557                     0.9572        0.2707            0.7053                     0.7039        0.6384  0.0000  1.2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6004\u001b[0m                     \u001b[32m0.6641\u001b[0m        \u001b[35m1.2124\u001b[0m            \u001b[31m0.5995\u001b[0m                     \u001b[94m0.6369\u001b[0m        \u001b[36m0.7265\u001b[0m  0.0006  3.2152\n",
      "      2            \u001b[36m0.6448\u001b[0m                     \u001b[32m0.7066\u001b[0m        \u001b[35m0.9169\u001b[0m            \u001b[31m0.6259\u001b[0m                     \u001b[94m0.6479\u001b[0m        \u001b[36m0.6938\u001b[0m  0.0006  2.6679\n",
      "      3            \u001b[36m0.6824\u001b[0m                     \u001b[32m0.7304\u001b[0m        \u001b[35m0.7879\u001b[0m            \u001b[31m0.6553\u001b[0m                     \u001b[94m0.6558\u001b[0m        \u001b[36m0.6680\u001b[0m  0.0006  2.6649\n",
      "      4            \u001b[36m0.7610\u001b[0m                     \u001b[32m0.7357\u001b[0m        \u001b[35m0.7158\u001b[0m            \u001b[31m0.7366\u001b[0m                     \u001b[94m0.6804\u001b[0m        \u001b[36m0.6452\u001b[0m  0.0006  2.6745\n",
      "      5            \u001b[36m0.7826\u001b[0m                     \u001b[32m0.7735\u001b[0m        \u001b[35m0.6937\u001b[0m            \u001b[31m0.7591\u001b[0m                     \u001b[94m0.7024\u001b[0m        \u001b[36m0.6160\u001b[0m  0.0006  2.6831\n",
      "      6            0.6888                     0.7649        \u001b[35m0.6524\u001b[0m            0.6344                     0.6498        0.6747  0.0006  2.6579\n",
      "      7            \u001b[36m0.8298\u001b[0m                     \u001b[32m0.7823\u001b[0m        \u001b[35m0.6027\u001b[0m            \u001b[31m0.7878\u001b[0m                     0.6898        0.6475  0.0006  2.6608\n",
      "      8            0.8186                     \u001b[32m0.8219\u001b[0m        \u001b[35m0.5889\u001b[0m            0.7730                     \u001b[94m0.7059\u001b[0m        0.6210  0.0006  2.6200\n",
      "      9            \u001b[36m0.8471\u001b[0m                     \u001b[32m0.8276\u001b[0m        \u001b[35m0.5305\u001b[0m            \u001b[31m0.7940\u001b[0m                     0.7003        0.6527  0.0005  2.6288\n",
      "     10            \u001b[36m0.8711\u001b[0m                     \u001b[32m0.8493\u001b[0m        \u001b[35m0.5013\u001b[0m            \u001b[31m0.8002\u001b[0m                     0.6923        0.6535  0.0005  2.6419\n",
      "     11            0.8244                     0.8368        \u001b[35m0.4894\u001b[0m            0.7560                     0.6955        0.6263  0.0005  2.6559\n",
      "     12            0.8234                     \u001b[32m0.8504\u001b[0m        \u001b[35m0.4520\u001b[0m            0.7599                     \u001b[94m0.7163\u001b[0m        \u001b[36m0.6114\u001b[0m  0.0005  2.6354\n",
      "     13            0.8481                     \u001b[32m0.8751\u001b[0m        \u001b[35m0.4463\u001b[0m            0.7591                     0.7008        0.6241  0.0005  2.6627\n",
      "     14            0.8145                     0.8575        \u001b[35m0.4173\u001b[0m            0.7289                     0.6857        0.6635  0.0004  2.6649\n",
      "     15            0.8498                     \u001b[32m0.8832\u001b[0m        \u001b[35m0.4130\u001b[0m            0.7560                     0.7005        0.6459  0.0004  2.6469\n",
      "     16            \u001b[36m0.8950\u001b[0m                     0.8714        \u001b[35m0.3871\u001b[0m            \u001b[31m0.8079\u001b[0m                     0.6853        0.7129  0.0004  2.6202\n",
      "     17            0.8727                     \u001b[32m0.8972\u001b[0m        \u001b[35m0.3784\u001b[0m            0.7839                     0.7075        0.6556  0.0003  2.6375\n",
      "     18            0.8281                     0.8801        \u001b[35m0.3718\u001b[0m            0.7320                     0.6976        0.6309  0.0003  2.6230\n",
      "     19            0.8849                     \u001b[32m0.9151\u001b[0m        \u001b[35m0.3538\u001b[0m            0.7684                     0.6847        0.6609  0.0003  2.6350\n",
      "     20            \u001b[36m0.9124\u001b[0m                     \u001b[32m0.9256\u001b[0m        \u001b[35m0.3466\u001b[0m            0.7994                     0.6935        0.6746  0.0003  2.6380\n",
      "     21            \u001b[36m0.9145\u001b[0m                     \u001b[32m0.9315\u001b[0m        \u001b[35m0.3255\u001b[0m            0.7940                     0.6936        0.6988  0.0002  2.6245\n",
      "     22            0.9130                     \u001b[32m0.9343\u001b[0m        \u001b[35m0.3127\u001b[0m            0.7947                     0.6974        0.6735  0.0002  2.6439\n",
      "     23            \u001b[36m0.9165\u001b[0m                     \u001b[32m0.9352\u001b[0m        0.3147            0.7924                     0.6910        0.6845  0.0002  2.6190\n",
      "     24            0.9141                     \u001b[32m0.9367\u001b[0m        \u001b[35m0.3120\u001b[0m            0.7909                     0.6934        0.6825  0.0001  2.6174\n",
      "     25            \u001b[36m0.9297\u001b[0m                     \u001b[32m0.9370\u001b[0m        \u001b[35m0.2851\u001b[0m            0.8064                     0.6794        0.7313  0.0001  2.6216\n",
      "     26            \u001b[36m0.9314\u001b[0m                     \u001b[32m0.9456\u001b[0m        \u001b[35m0.2834\u001b[0m            0.8056                     0.6923        0.6989  0.0001  2.6220\n",
      "     27            0.9231                     0.9447        \u001b[35m0.2772\u001b[0m            0.7971                     0.6938        0.6863  0.0001  2.6310\n",
      "     28            0.9297                     \u001b[32m0.9474\u001b[0m        \u001b[35m0.2701\u001b[0m            0.8017                     0.6832        0.7096  0.0001  2.6674\n",
      "     29            0.9271                     \u001b[32m0.9476\u001b[0m        0.2705            0.7986                     0.6947        0.6948  0.0000  2.6422\n",
      "     30            \u001b[36m0.9368\u001b[0m                     \u001b[32m0.9522\u001b[0m        \u001b[35m0.2584\u001b[0m            0.8040                     0.6880        0.7092  0.0000  2.6609\n",
      "     31            \u001b[36m0.9370\u001b[0m                     \u001b[32m0.9528\u001b[0m        \u001b[35m0.2528\u001b[0m            0.7994                     0.6818        0.7123  0.0000  2.6328\n",
      "     32            0.9349                     0.9523        0.2590            0.8017                     0.6866        0.7098  0.0000  2.6235\n",
      "     33            0.9347                     0.9518        0.2578            0.8025                     0.6887        0.7105  0.0000  2.6320\n",
      "     34            \u001b[36m0.9399\u001b[0m                     \u001b[32m0.9550\u001b[0m        0.2577            0.8040                     0.6813        0.7197  0.0000  2.6419\n",
      "     35            0.9388                     0.9543        0.2561            0.8025                     0.6804        0.7176  0.0000  2.6300\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7529\u001b[0m                     \u001b[32m0.6541\u001b[0m        \u001b[35m1.1576\u001b[0m            \u001b[31m0.7273\u001b[0m                     \u001b[94m0.6228\u001b[0m        \u001b[36m0.8037\u001b[0m  0.0006  2.5516\n",
      "      2            \u001b[36m0.7797\u001b[0m                     \u001b[32m0.6930\u001b[0m        \u001b[35m0.9028\u001b[0m            \u001b[31m0.7552\u001b[0m                     \u001b[94m0.6566\u001b[0m        \u001b[36m0.7423\u001b[0m  0.0006  2.5168\n",
      "      3            0.7384                     \u001b[32m0.7361\u001b[0m        \u001b[35m0.7755\u001b[0m            0.6909                     \u001b[94m0.6675\u001b[0m        \u001b[36m0.6649\u001b[0m  0.0006  2.5184\n",
      "      4            0.7163                     \u001b[32m0.7515\u001b[0m        \u001b[35m0.7444\u001b[0m            0.6623                     \u001b[94m0.6852\u001b[0m        \u001b[36m0.6561\u001b[0m  0.0006  2.5186\n",
      "      5            0.7000                     \u001b[32m0.7588\u001b[0m        \u001b[35m0.6477\u001b[0m            0.6460                     0.6669        \u001b[36m0.6418\u001b[0m  0.0006  2.5183\n",
      "      6            \u001b[36m0.8368\u001b[0m                     \u001b[32m0.7920\u001b[0m        0.6499            \u001b[31m0.7715\u001b[0m                     0.6799        0.6460  0.0006  2.6177\n",
      "      7            0.8141                     \u001b[32m0.8058\u001b[0m        \u001b[35m0.5778\u001b[0m            0.7459                     \u001b[94m0.6961\u001b[0m        \u001b[36m0.6318\u001b[0m  0.0006  2.5262\n",
      "      8            0.7919                     \u001b[32m0.8190\u001b[0m        \u001b[35m0.5751\u001b[0m            0.7119                     \u001b[94m0.6987\u001b[0m        \u001b[36m0.6256\u001b[0m  0.0006  2.5562\n",
      "      9            \u001b[36m0.8465\u001b[0m                     \u001b[32m0.8297\u001b[0m        \u001b[35m0.5282\u001b[0m            0.7645                     0.6857        0.6461  0.0005  2.5394\n",
      "     10            0.8328                     \u001b[32m0.8397\u001b[0m        \u001b[35m0.5077\u001b[0m            0.7537                     \u001b[94m0.7041\u001b[0m        \u001b[36m0.6187\u001b[0m  0.0005  2.5380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            0.7758                     0.8326        \u001b[35m0.4825\u001b[0m            0.6948                     0.6950        0.6303  0.0005  2.5382\n",
      "     12            \u001b[36m0.8548\u001b[0m                     \u001b[32m0.8603\u001b[0m        \u001b[35m0.4689\u001b[0m            0.7521                     0.6898        0.6259  0.0005  2.5478\n",
      "     13            0.8459                     \u001b[32m0.8679\u001b[0m        \u001b[35m0.4499\u001b[0m            0.7490                     0.7013        0.6315  0.0005  2.5423\n",
      "     14            0.8469                     \u001b[32m0.8714\u001b[0m        \u001b[35m0.4307\u001b[0m            0.7444                     \u001b[94m0.7068\u001b[0m        0.6494  0.0004  2.5435\n",
      "     15            \u001b[36m0.8564\u001b[0m                     \u001b[32m0.8868\u001b[0m        \u001b[35m0.4164\u001b[0m            0.7467                     0.6999        0.6323  0.0004  2.5571\n",
      "     16            \u001b[36m0.8990\u001b[0m                     0.8856        \u001b[35m0.4038\u001b[0m            \u001b[31m0.7924\u001b[0m                     0.6926        0.6744  0.0004  2.5395\n",
      "     17            0.8917                     \u001b[32m0.9050\u001b[0m        \u001b[35m0.3967\u001b[0m            0.7792                     0.7047        0.6390  0.0003  2.5543\n",
      "     18            0.8853                     \u001b[32m0.9095\u001b[0m        \u001b[35m0.3723\u001b[0m            0.7645                     0.7007        0.6526  0.0003  2.5372\n",
      "     19            \u001b[36m0.9033\u001b[0m                     0.9071        \u001b[35m0.3508\u001b[0m            \u001b[31m0.7940\u001b[0m                     \u001b[94m0.7120\u001b[0m        0.6562  0.0003  2.5387\n",
      "     20            0.8895                     \u001b[32m0.9171\u001b[0m        \u001b[35m0.3442\u001b[0m            0.7583                     0.7020        0.6371  0.0003  2.5472\n",
      "     21            0.8990                     0.9145        \u001b[35m0.3298\u001b[0m            0.7893                     \u001b[94m0.7142\u001b[0m        0.6540  0.0002  2.5411\n",
      "     22            \u001b[36m0.9037\u001b[0m                     \u001b[32m0.9253\u001b[0m        \u001b[35m0.3148\u001b[0m            0.7761                     \u001b[94m0.7145\u001b[0m        0.6405  0.0002  2.5402\n",
      "     23            \u001b[36m0.9217\u001b[0m                     \u001b[32m0.9325\u001b[0m        \u001b[35m0.3120\u001b[0m            \u001b[31m0.7947\u001b[0m                     0.7074        0.6745  0.0002  2.5301\n",
      "     24            \u001b[36m0.9267\u001b[0m                     \u001b[32m0.9327\u001b[0m        \u001b[35m0.3064\u001b[0m            0.7932                     0.6981        0.6901  0.0001  2.5522\n",
      "     25            0.9223                     \u001b[32m0.9346\u001b[0m        \u001b[35m0.3020\u001b[0m            0.7885                     0.7070        0.6888  0.0001  2.5368\n",
      "     26            0.9190                     \u001b[32m0.9430\u001b[0m        \u001b[35m0.2919\u001b[0m            0.7777                     0.7004        0.6582  0.0001  2.5457\n",
      "     27            0.9267                     \u001b[32m0.9444\u001b[0m        \u001b[35m0.2760\u001b[0m            0.7854                     0.7018        0.6729  0.0001  2.5367\n",
      "     28            \u001b[36m0.9326\u001b[0m                     \u001b[32m0.9446\u001b[0m        \u001b[35m0.2741\u001b[0m            0.7924                     0.6993        0.6811  0.0001  2.5422\n",
      "     29            0.9279                     \u001b[32m0.9468\u001b[0m        \u001b[35m0.2666\u001b[0m            0.7800                     0.6985        0.6707  0.0000  2.5352\n",
      "     30            \u001b[36m0.9384\u001b[0m                     \u001b[32m0.9507\u001b[0m        0.2701            \u001b[31m0.7978\u001b[0m                     0.7043        0.6950  0.0000  2.5557\n",
      "     31            0.9380                     \u001b[32m0.9534\u001b[0m        \u001b[35m0.2656\u001b[0m            0.7940                     0.7003        0.6836  0.0000  2.5280\n",
      "     32            \u001b[36m0.9409\u001b[0m                     \u001b[32m0.9547\u001b[0m        \u001b[35m0.2623\u001b[0m            \u001b[31m0.7994\u001b[0m                     0.7019        0.6895  0.0000  2.6429\n",
      "     33            0.9401                     0.9534        \u001b[35m0.2513\u001b[0m            0.7978                     0.7026        0.6882  0.0000  2.5421\n",
      "     34            0.9393                     0.9546        0.2529            0.7947                     0.7024        0.6848  0.0000  2.5631\n",
      "     35            0.9388                     0.9530        0.2614            0.7955                     0.7029        0.6850  0.0000  2.5496\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5897\u001b[0m                     \u001b[32m0.6442\u001b[0m        \u001b[35m1.2438\u001b[0m            \u001b[31m0.6104\u001b[0m                     \u001b[94m0.6552\u001b[0m        \u001b[36m0.7398\u001b[0m  0.0006  2.5300\n",
      "      2            0.5411                     \u001b[32m0.6668\u001b[0m        \u001b[35m0.9583\u001b[0m            0.5321                     0.6476        \u001b[36m0.7395\u001b[0m  0.0006  2.5661\n",
      "      3            \u001b[36m0.7236\u001b[0m                     \u001b[32m0.7028\u001b[0m        \u001b[35m0.8366\u001b[0m            \u001b[31m0.7002\u001b[0m                     \u001b[94m0.6816\u001b[0m        \u001b[36m0.6901\u001b[0m  0.0006  2.5472\n",
      "      4            \u001b[36m0.7769\u001b[0m                     \u001b[32m0.7425\u001b[0m        \u001b[35m0.7543\u001b[0m            \u001b[31m0.7576\u001b[0m                     \u001b[94m0.7098\u001b[0m        \u001b[36m0.6077\u001b[0m  0.0006  2.5476\n",
      "      5            0.7262                     \u001b[32m0.7722\u001b[0m        \u001b[35m0.6964\u001b[0m            0.6607                     0.6876        \u001b[36m0.6008\u001b[0m  0.0006  2.5779\n",
      "      6            0.7368                     \u001b[32m0.7728\u001b[0m        \u001b[35m0.6316\u001b[0m            0.7033                     \u001b[94m0.7186\u001b[0m        \u001b[36m0.5791\u001b[0m  0.0006  2.5555\n",
      "      7            \u001b[36m0.8023\u001b[0m                     \u001b[32m0.7835\u001b[0m        \u001b[35m0.6196\u001b[0m            \u001b[31m0.7591\u001b[0m                     \u001b[94m0.7242\u001b[0m        \u001b[36m0.5752\u001b[0m  0.0006  2.5338\n",
      "      8            \u001b[36m0.8047\u001b[0m                     \u001b[32m0.8121\u001b[0m        \u001b[35m0.5881\u001b[0m            0.7521                     \u001b[94m0.7383\u001b[0m        \u001b[36m0.5612\u001b[0m  0.0006  2.5529\n",
      "      9            \u001b[36m0.8508\u001b[0m                     \u001b[32m0.8311\u001b[0m        \u001b[35m0.5329\u001b[0m            \u001b[31m0.7738\u001b[0m                     0.7198        0.5959  0.0005  2.5589\n",
      "     10            0.7930                     0.8226        \u001b[35m0.5122\u001b[0m            0.7397                     0.7341        0.5653  0.0005  2.6061\n",
      "     11            0.8450                     \u001b[32m0.8434\u001b[0m        \u001b[35m0.4978\u001b[0m            \u001b[31m0.7800\u001b[0m                     \u001b[94m0.7386\u001b[0m        0.5652  0.0005  2.6271\n",
      "     12            0.8399                     \u001b[32m0.8579\u001b[0m        \u001b[35m0.4721\u001b[0m            0.7637                     0.7371        \u001b[36m0.5450\u001b[0m  0.0005  2.6218\n",
      "     13            \u001b[36m0.8746\u001b[0m                     0.8531        \u001b[35m0.4512\u001b[0m            \u001b[31m0.8071\u001b[0m                     \u001b[94m0.7434\u001b[0m        0.5751  0.0005  2.6100\n",
      "     14            0.8498                     \u001b[32m0.8619\u001b[0m        \u001b[35m0.4308\u001b[0m            0.7599                     0.7263        0.5855  0.0004  2.6340\n",
      "     15            \u001b[36m0.8874\u001b[0m                     \u001b[32m0.8702\u001b[0m        \u001b[35m0.4264\u001b[0m            0.7932                     0.7316        0.5923  0.0004  2.6350\n",
      "     16            0.8864                     \u001b[32m0.8964\u001b[0m        \u001b[35m0.3946\u001b[0m            0.7862                     0.7390        0.5470  0.0004  2.6359\n",
      "     17            \u001b[36m0.9031\u001b[0m                     0.8877        0.3958            0.7909                     0.7118        0.6051  0.0003  2.6449\n",
      "     18            0.8669                     0.8895        \u001b[35m0.3818\u001b[0m            0.7831                     \u001b[94m0.7438\u001b[0m        0.5632  0.0003  2.6160\n",
      "     19            0.8781                     \u001b[32m0.8988\u001b[0m        \u001b[35m0.3714\u001b[0m            0.7831                     \u001b[94m0.7455\u001b[0m        0.5599  0.0003  2.6392\n",
      "     20            0.9027                     \u001b[32m0.9193\u001b[0m        \u001b[35m0.3497\u001b[0m            0.7839                     0.7293        0.5719  0.0003  2.6062\n",
      "     21            \u001b[36m0.9076\u001b[0m                     0.9151        \u001b[35m0.3405\u001b[0m            0.7986                     0.7366        0.5725  0.0002  2.6110\n",
      "     22            0.8983                     \u001b[32m0.9241\u001b[0m        \u001b[35m0.3301\u001b[0m            0.7847                     \u001b[94m0.7515\u001b[0m        0.5534  0.0002  2.6110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     23            0.9070                     \u001b[32m0.9273\u001b[0m        \u001b[35m0.3189\u001b[0m            0.7885                     0.7438        0.5872  0.0002  2.6043\n",
      "     24            \u001b[36m0.9172\u001b[0m                     \u001b[32m0.9323\u001b[0m        \u001b[35m0.3070\u001b[0m            0.7947                     0.7275        0.5788  0.0001  2.5899\n",
      "     25            \u001b[36m0.9266\u001b[0m                     \u001b[32m0.9389\u001b[0m        \u001b[35m0.2902\u001b[0m            \u001b[31m0.8087\u001b[0m                     0.7494        0.5761  0.0001  2.6230\n",
      "     26            0.9103                     0.9360        0.2924            0.7916                     \u001b[94m0.7524\u001b[0m        0.5789  0.0001  2.6120\n",
      "     27            \u001b[36m0.9271\u001b[0m                     \u001b[32m0.9421\u001b[0m        0.2947            0.7994                     0.7404        0.5852  0.0001  2.5894\n",
      "     28            0.9244                     0.9376        \u001b[35m0.2729\u001b[0m            0.7978                     0.7361        0.5821  0.0001  2.6079\n",
      "     29            \u001b[36m0.9366\u001b[0m                     \u001b[32m0.9500\u001b[0m        0.2829            \u001b[31m0.8095\u001b[0m                     0.7432        0.5941  0.0000  2.6250\n",
      "     30            0.9262                     0.9478        \u001b[35m0.2611\u001b[0m            0.7932                     0.7433        0.5792  0.0000  2.5881\n",
      "     31            0.9318                     \u001b[32m0.9513\u001b[0m        0.2761            0.7971                     0.7423        0.5822  0.0000  2.6036\n",
      "     32            0.9316                     0.9486        0.2790            0.8025                     0.7456        0.5842  0.0000  2.6107\n",
      "     33            0.9314                     0.9502        0.2736            0.7986                     0.7433        0.5837  0.0000  2.5979\n",
      "     34            0.9349                     0.9506        \u001b[35m0.2575\u001b[0m            0.8087                     0.7494        0.5880  0.0000  2.5961\n",
      "     35            0.9345                     0.9512        \u001b[35m0.2535\u001b[0m            0.8079                     0.7489        0.5871  0.0000  2.5842\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7277\u001b[0m                     \u001b[32m0.6697\u001b[0m        \u001b[35m1.2277\u001b[0m            \u001b[31m0.7149\u001b[0m                     \u001b[94m0.6554\u001b[0m        \u001b[36m0.6700\u001b[0m  0.0006  2.5120\n",
      "      2            0.7112                     \u001b[32m0.7103\u001b[0m        \u001b[35m0.9412\u001b[0m            0.6785                     \u001b[94m0.6600\u001b[0m        \u001b[36m0.6263\u001b[0m  0.0006  2.5133\n",
      "      3            \u001b[36m0.7440\u001b[0m                     \u001b[32m0.7416\u001b[0m        \u001b[35m0.8099\u001b[0m            0.7057                     \u001b[94m0.6999\u001b[0m        \u001b[36m0.5880\u001b[0m  0.0006  2.5143\n",
      "      4            0.7202                     0.7350        \u001b[35m0.7361\u001b[0m            0.6816                     0.6886        0.6224  0.0006  2.5055\n",
      "      5            \u001b[36m0.7694\u001b[0m                     \u001b[32m0.7630\u001b[0m        \u001b[35m0.6822\u001b[0m            \u001b[31m0.7250\u001b[0m                     \u001b[94m0.7017\u001b[0m        0.6245  0.0006  2.5071\n",
      "      6            0.7362                     \u001b[32m0.7880\u001b[0m        \u001b[35m0.6314\u001b[0m            0.6685                     0.6973        0.6059  0.0006  2.5123\n",
      "      7            0.6878                     0.7743        \u001b[35m0.6155\u001b[0m            0.6158                     0.6702        0.6251  0.0006  2.5227\n",
      "      8            \u001b[36m0.8504\u001b[0m                     \u001b[32m0.7948\u001b[0m        \u001b[35m0.5588\u001b[0m            \u001b[31m0.7870\u001b[0m                     \u001b[94m0.7111\u001b[0m        0.6158  0.0006  2.5268\n",
      "      9            0.8374                     \u001b[32m0.8237\u001b[0m        \u001b[35m0.5327\u001b[0m            0.7483                     0.6975        0.6051  0.0005  2.5212\n",
      "     10            0.8068                     \u001b[32m0.8453\u001b[0m        \u001b[35m0.4944\u001b[0m            0.7088                     0.7052        0.5886  0.0005  2.5612\n",
      "     11            0.8461                     \u001b[32m0.8567\u001b[0m        0.5087            0.7552                     \u001b[94m0.7151\u001b[0m        0.5903  0.0005  2.5671\n",
      "     12            \u001b[36m0.8773\u001b[0m                     \u001b[32m0.8636\u001b[0m        \u001b[35m0.4691\u001b[0m            \u001b[31m0.7901\u001b[0m                     \u001b[94m0.7180\u001b[0m        0.6327  0.0005  2.5444\n",
      "     13            0.8634                     0.8635        \u001b[35m0.4479\u001b[0m            0.7831                     \u001b[94m0.7288\u001b[0m        0.6320  0.0005  2.5252\n",
      "     14            \u001b[36m0.8779\u001b[0m                     \u001b[32m0.8715\u001b[0m        \u001b[35m0.4313\u001b[0m            0.7816                     0.7111        0.6361  0.0004  2.5582\n",
      "     15            \u001b[36m0.8967\u001b[0m                     0.8704        \u001b[35m0.4123\u001b[0m            0.7901                     0.6979        0.6767  0.0004  2.5412\n",
      "     16            0.8857                     \u001b[32m0.8821\u001b[0m        0.4166            0.7707                     0.7078        0.6476  0.0004  2.5578\n",
      "     17            0.8707                     \u001b[32m0.9044\u001b[0m        \u001b[35m0.3832\u001b[0m            0.7452                     0.7040        0.6473  0.0003  2.6649\n",
      "     18            0.8903                     \u001b[32m0.9067\u001b[0m        \u001b[35m0.3596\u001b[0m            0.7808                     0.7190        0.6494  0.0003  2.6838\n",
      "     19            \u001b[36m0.9062\u001b[0m                     \u001b[32m0.9210\u001b[0m        \u001b[35m0.3451\u001b[0m            0.7808                     0.7190        0.6401  0.0003  2.6748\n",
      "     20            0.9041                     \u001b[32m0.9251\u001b[0m        0.3456            0.7893                     \u001b[94m0.7326\u001b[0m        0.6453  0.0003  2.6710\n",
      "     21            \u001b[36m0.9186\u001b[0m                     \u001b[32m0.9265\u001b[0m        \u001b[35m0.3264\u001b[0m            \u001b[31m0.7940\u001b[0m                     0.7287        0.6676  0.0002  2.6778\n",
      "     22            0.8798                     0.9221        \u001b[35m0.3235\u001b[0m            0.7436                     0.7164        0.6409  0.0002  2.7088\n",
      "     23            0.9153                     \u001b[32m0.9312\u001b[0m        \u001b[35m0.3108\u001b[0m            0.7746                     0.7119        0.6919  0.0002  2.6780\n",
      "     24            \u001b[36m0.9289\u001b[0m                     \u001b[32m0.9461\u001b[0m        \u001b[35m0.3008\u001b[0m            0.7932                     0.7266        0.6664  0.0001  2.6843\n",
      "     25            0.9256                     \u001b[32m0.9462\u001b[0m        \u001b[35m0.2841\u001b[0m            0.7932                     0.7282        0.6835  0.0001  2.6763\n",
      "     26            0.9275                     0.9436        0.2861            \u001b[31m0.7978\u001b[0m                     0.7244        0.6834  0.0001  2.6190\n",
      "     27            \u001b[36m0.9347\u001b[0m                     \u001b[32m0.9543\u001b[0m        \u001b[35m0.2703\u001b[0m            0.7963                     0.7218        0.6882  0.0001  2.5931\n",
      "     28            0.9333                     \u001b[32m0.9543\u001b[0m        0.2812            0.7947                     0.7242        0.6838  0.0001  2.6404\n",
      "     29            \u001b[36m0.9477\u001b[0m                     \u001b[32m0.9580\u001b[0m        \u001b[35m0.2612\u001b[0m            \u001b[31m0.8087\u001b[0m                     0.7226        0.7177  0.0000  2.6024\n",
      "     30            0.9393                     0.9567        0.2641            0.7971                     0.7206        0.6951  0.0000  2.5762\n",
      "     31            0.9345                     0.9550        \u001b[35m0.2575\u001b[0m            0.7940                     0.7220        0.6864  0.0000  2.6096\n",
      "     32            0.9448                     \u001b[32m0.9592\u001b[0m        \u001b[35m0.2531\u001b[0m            0.8025                     0.7205        0.7050  0.0000  2.6034\n",
      "     33            0.9376                     0.9565        \u001b[35m0.2499\u001b[0m            0.7971                     0.7222        0.6921  0.0000  2.6040\n",
      "     34            0.9438                     0.9590        0.2517            0.8025                     0.7222        0.7033  0.0000  2.6150\n",
      "     35            0.9428                     0.9588        0.2520            0.8002                     0.7208        0.7010  0.0000  2.5911\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6543\u001b[0m                     \u001b[32m0.6768\u001b[0m        \u001b[35m1.2423\u001b[0m            \u001b[31m0.6174\u001b[0m                     \u001b[94m0.6126\u001b[0m        \u001b[36m0.7601\u001b[0m  0.0006  2.5574\n",
      "      2            \u001b[36m0.6994\u001b[0m                     \u001b[32m0.7123\u001b[0m        \u001b[35m0.9278\u001b[0m            \u001b[31m0.6762\u001b[0m                     \u001b[94m0.6703\u001b[0m        \u001b[36m0.6618\u001b[0m  0.0006  2.5110\n",
      "      3            0.6857                     \u001b[32m0.7400\u001b[0m        \u001b[35m0.7963\u001b[0m            0.6460                     \u001b[94m0.6719\u001b[0m        \u001b[36m0.6173\u001b[0m  0.0006  2.5193\n",
      "      4            \u001b[36m0.7556\u001b[0m                     \u001b[32m0.7705\u001b[0m        \u001b[35m0.7407\u001b[0m            \u001b[31m0.6971\u001b[0m                     \u001b[94m0.6864\u001b[0m        \u001b[36m0.5995\u001b[0m  0.0006  2.5193\n",
      "      5            0.6928                     0.7653        \u001b[35m0.6534\u001b[0m            0.6344                     0.6782        0.6325  0.0006  2.5148\n",
      "      6            \u001b[36m0.7612\u001b[0m                     \u001b[32m0.7982\u001b[0m        \u001b[35m0.6058\u001b[0m            0.6933                     \u001b[94m0.6957\u001b[0m        \u001b[36m0.5962\u001b[0m  0.0006  2.5261\n",
      "      7            \u001b[36m0.7979\u001b[0m                     \u001b[32m0.8122\u001b[0m        \u001b[35m0.5872\u001b[0m            \u001b[31m0.7250\u001b[0m                     \u001b[94m0.6967\u001b[0m        0.6002  0.0006  2.5262\n",
      "      8            \u001b[36m0.8297\u001b[0m                     \u001b[32m0.8333\u001b[0m        \u001b[35m0.5823\u001b[0m            \u001b[31m0.7421\u001b[0m                     0.6954        \u001b[36m0.5795\u001b[0m  0.0006  2.5318\n",
      "      9            0.7781                     0.8261        \u001b[35m0.5403\u001b[0m            0.6840                     0.6867        0.6043  0.0005  2.5514\n",
      "     10            \u001b[36m0.8324\u001b[0m                     \u001b[32m0.8362\u001b[0m        \u001b[35m0.5100\u001b[0m            \u001b[31m0.7637\u001b[0m                     \u001b[94m0.7002\u001b[0m        0.6142  0.0005  2.5432\n",
      "     11            \u001b[36m0.8610\u001b[0m                     \u001b[32m0.8491\u001b[0m        \u001b[35m0.4829\u001b[0m            \u001b[31m0.7862\u001b[0m                     \u001b[94m0.7073\u001b[0m        0.6121  0.0005  2.5402\n",
      "     12            0.8523                     \u001b[32m0.8622\u001b[0m        \u001b[35m0.4496\u001b[0m            0.7661                     \u001b[94m0.7134\u001b[0m        0.6093  0.0005  2.5831\n",
      "     13            \u001b[36m0.8802\u001b[0m                     \u001b[32m0.8809\u001b[0m        \u001b[35m0.4305\u001b[0m            0.7808                     0.7023        0.6155  0.0005  2.5799\n",
      "     14            \u001b[36m0.8816\u001b[0m                     \u001b[32m0.8888\u001b[0m        0.4387            0.7816                     \u001b[94m0.7278\u001b[0m        0.5889  0.0004  2.5881\n",
      "     15            \u001b[36m0.8928\u001b[0m                     0.8772        \u001b[35m0.4017\u001b[0m            \u001b[31m0.8071\u001b[0m                     0.7133        0.6385  0.0004  2.6039\n",
      "     16            0.8928                     0.8856        \u001b[35m0.3975\u001b[0m            0.7932                     0.7115        0.6421  0.0004  2.6090\n",
      "     17            0.8436                     \u001b[32m0.8916\u001b[0m        \u001b[35m0.3859\u001b[0m            0.7397                     0.7224        0.6043  0.0003  2.5826\n",
      "     18            \u001b[36m0.8942\u001b[0m                     \u001b[32m0.9162\u001b[0m        \u001b[35m0.3674\u001b[0m            0.7792                     0.7248        0.6001  0.0003  2.5851\n",
      "     19            \u001b[36m0.9178\u001b[0m                     0.9147        0.3683            0.8048                     0.6935        0.6555  0.0003  2.5716\n",
      "     20            0.9019                     \u001b[32m0.9234\u001b[0m        \u001b[35m0.3526\u001b[0m            0.7994                     \u001b[94m0.7370\u001b[0m        0.6112  0.0003  2.5701\n",
      "     21            0.9078                     \u001b[32m0.9266\u001b[0m        \u001b[35m0.3468\u001b[0m            0.7870                     0.7127        0.6244  0.0002  2.6030\n",
      "     22            0.9132                     \u001b[32m0.9282\u001b[0m        \u001b[35m0.3083\u001b[0m            0.8033                     0.7210        0.6355  0.0002  2.6100\n",
      "     23            \u001b[36m0.9207\u001b[0m                     \u001b[32m0.9370\u001b[0m        0.3091            0.8033                     0.7176        0.6399  0.0002  2.6198\n",
      "     24            0.9157                     \u001b[32m0.9398\u001b[0m        \u001b[35m0.3034\u001b[0m            0.7955                     0.7196        0.6409  0.0001  2.6110\n",
      "     25            \u001b[36m0.9238\u001b[0m                     \u001b[32m0.9418\u001b[0m        \u001b[35m0.2825\u001b[0m            0.7924                     0.7127        0.6529  0.0001  2.6030\n",
      "     26            \u001b[36m0.9283\u001b[0m                     \u001b[32m0.9466\u001b[0m        0.2832            0.7971                     0.7172        0.6494  0.0001  2.6210\n",
      "     27            \u001b[36m0.9378\u001b[0m                     \u001b[32m0.9495\u001b[0m        0.2829            \u001b[31m0.8079\u001b[0m                     0.7138        0.6686  0.0001  2.6309\n",
      "     28            0.9283                     0.9487        \u001b[35m0.2685\u001b[0m            0.8009                     0.7313        0.6502  0.0001  2.6197\n",
      "     29            0.9329                     \u001b[32m0.9511\u001b[0m        \u001b[35m0.2672\u001b[0m            0.8079                     0.7238        0.6534  0.0000  2.6310\n",
      "     30            0.9353                     \u001b[32m0.9521\u001b[0m        \u001b[35m0.2529\u001b[0m            \u001b[31m0.8087\u001b[0m                     0.7243        0.6590  0.0000  2.6340\n",
      "     31            \u001b[36m0.9428\u001b[0m                     \u001b[32m0.9551\u001b[0m        0.2556            0.8064                     0.7078        0.6728  0.0000  2.6088\n",
      "     32            0.9390                     0.9531        0.2553            0.8064                     0.7112        0.6653  0.0000  2.6190\n",
      "     33            0.9407                     0.9538        0.2581            0.8033                     0.7059        0.6679  0.0000  2.6170\n",
      "     34            0.9390                     0.9540        0.2559            0.8017                     0.7083        0.6620  0.0000  2.6170\n",
      "     35            0.9390                     0.9535        0.2544            0.8033                     0.7093        0.6635  0.0000  2.6118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 1 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n",
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5677\u001b[0m                     \u001b[32m0.5660\u001b[0m        \u001b[35m4.1708\u001b[0m            \u001b[31m0.5506\u001b[0m                     \u001b[94m0.5488\u001b[0m        \u001b[36m1.9132\u001b[0m  0.0100  4.2554\n",
      "      2            0.5296                     0.5276        \u001b[35m1.8318\u001b[0m            0.5151                     0.5133        \u001b[36m1.0045\u001b[0m  0.0100  2.0136\n",
      "      3            0.5484                     0.5476        \u001b[35m1.6334\u001b[0m            \u001b[31m0.5653\u001b[0m                     \u001b[94m0.5645\u001b[0m        1.7478  0.0099  1.9976\n",
      "      4            \u001b[36m0.5856\u001b[0m                     \u001b[32m0.5824\u001b[0m        \u001b[35m1.3474\u001b[0m            \u001b[31m0.5782\u001b[0m                     \u001b[94m0.5752\u001b[0m        1.1491  0.0098  1.9707\n",
      "      5            \u001b[36m0.6416\u001b[0m                     \u001b[32m0.6433\u001b[0m        \u001b[35m0.9285\u001b[0m            \u001b[31m0.6249\u001b[0m                     \u001b[94m0.6269\u001b[0m        \u001b[36m0.8574\u001b[0m  0.0097  1.9827\n",
      "      6            \u001b[36m0.6805\u001b[0m                     \u001b[32m0.6816\u001b[0m        \u001b[35m0.9041\u001b[0m            \u001b[31m0.6802\u001b[0m                     \u001b[94m0.6815\u001b[0m        \u001b[36m0.6691\u001b[0m  0.0095  1.9980\n",
      "      7            \u001b[36m0.6939\u001b[0m                     \u001b[32m0.6949\u001b[0m        \u001b[35m0.7990\u001b[0m            \u001b[31m0.6871\u001b[0m                     \u001b[94m0.6882\u001b[0m        \u001b[36m0.6535\u001b[0m  0.0093  1.9987\n",
      "      8            0.6928                     \u001b[32m0.6949\u001b[0m        \u001b[35m0.6846\u001b[0m            \u001b[31m0.6906\u001b[0m                     \u001b[94m0.6927\u001b[0m        0.6721  0.0090  1.9777\n",
      "      9            \u001b[36m0.7196\u001b[0m                     \u001b[32m0.7186\u001b[0m        \u001b[35m0.6554\u001b[0m            \u001b[31m0.7277\u001b[0m                     \u001b[94m0.7267\u001b[0m        \u001b[36m0.5785\u001b[0m  0.0087  1.9777\n",
      "     10            0.6835                     0.6844        \u001b[35m0.6328\u001b[0m            0.6863                     0.6872        0.7178  0.0084  1.9877\n",
      "     11            \u001b[36m0.7319\u001b[0m                     \u001b[32m0.7307\u001b[0m        0.6392            0.7105                     0.7092        \u001b[36m0.5726\u001b[0m  0.0080  1.9708\n",
      "     12            0.7103                     0.7083        \u001b[35m0.6019\u001b[0m            0.6932                     0.6909        0.5863  0.0076  1.9637\n",
      "     13            \u001b[36m0.7404\u001b[0m                     \u001b[32m0.7410\u001b[0m        0.6173            0.7234                     0.7242        0.6203  0.0072  1.9648\n",
      "     14            \u001b[36m0.7626\u001b[0m                     \u001b[32m0.7631\u001b[0m        \u001b[35m0.5903\u001b[0m            \u001b[31m0.7511\u001b[0m                     \u001b[94m0.7515\u001b[0m        \u001b[36m0.5266\u001b[0m  0.0068  1.9588\n",
      "     15            \u001b[36m0.7633\u001b[0m                     \u001b[32m0.7632\u001b[0m        \u001b[35m0.5393\u001b[0m            \u001b[31m0.7675\u001b[0m                     \u001b[94m0.7674\u001b[0m        \u001b[36m0.5200\u001b[0m  0.0064  1.9765\n",
      "     16            \u001b[36m0.7711\u001b[0m                     \u001b[32m0.7719\u001b[0m        0.5439            0.7623                     0.7632        \u001b[36m0.5106\u001b[0m  0.0059  1.9697\n",
      "     17            0.7436                     0.7423        0.5403            0.7459                     0.7448        0.5581  0.0055  1.9653\n",
      "     18            0.7434                     0.7447        \u001b[35m0.5187\u001b[0m            0.7433                     0.7446        0.5389  0.0050  1.9691\n",
      "     19            \u001b[36m0.7825\u001b[0m                     \u001b[32m0.7834\u001b[0m        0.5202            0.7666                     \u001b[94m0.7677\u001b[0m        \u001b[36m0.5040\u001b[0m  0.0045  1.9747\n",
      "     20            0.7711                     0.7703        0.5312            0.7615                     0.7607        0.5136  0.0041  1.9619\n",
      "     21            \u001b[36m0.7942\u001b[0m                     \u001b[32m0.7950\u001b[0m        \u001b[35m0.4967\u001b[0m            0.7623                     0.7632        \u001b[36m0.4945\u001b[0m  0.0036  1.9767\n",
      "     22            \u001b[36m0.8042\u001b[0m                     \u001b[32m0.8045\u001b[0m        \u001b[35m0.4833\u001b[0m            0.7615                     0.7619        \u001b[36m0.4871\u001b[0m  0.0032  1.9677\n",
      "     23            \u001b[36m0.8054\u001b[0m                     \u001b[32m0.8061\u001b[0m        0.4885            \u001b[31m0.7744\u001b[0m                     \u001b[94m0.7750\u001b[0m        \u001b[36m0.4788\u001b[0m  0.0028  1.9968\n",
      "     24            0.8052                     0.8060        \u001b[35m0.4700\u001b[0m            0.7710                     0.7718        \u001b[36m0.4758\u001b[0m  0.0024  1.9935\n",
      "     25            \u001b[36m0.8115\u001b[0m                     \u001b[32m0.8120\u001b[0m        \u001b[35m0.4610\u001b[0m            \u001b[31m0.7839\u001b[0m                     \u001b[94m0.7845\u001b[0m        0.4766  0.0020  1.9807\n",
      "     26            \u001b[36m0.8206\u001b[0m                     \u001b[32m0.8207\u001b[0m        \u001b[35m0.4504\u001b[0m            \u001b[31m0.7891\u001b[0m                     \u001b[94m0.7890\u001b[0m        \u001b[36m0.4659\u001b[0m  0.0016  1.9737\n",
      "     27            0.8167                     0.8173        \u001b[35m0.4495\u001b[0m            0.7796                     0.7802        0.4678  0.0013  1.9789\n",
      "     28            0.8098                     0.8107        \u001b[35m0.4417\u001b[0m            0.7675                     0.7684        0.4831  0.0010  1.9787\n",
      "     29            0.7985                     0.7996        \u001b[35m0.4371\u001b[0m            0.7666                     0.7677        0.4846  0.0007  1.9830\n",
      "     30            0.8139                     0.8146        \u001b[35m0.4364\u001b[0m            0.7692                     0.7699        0.4765  0.0005  1.9893\n",
      "     31            \u001b[36m0.8221\u001b[0m                     \u001b[32m0.8226\u001b[0m        \u001b[35m0.4273\u001b[0m            0.7753                     0.7756        \u001b[36m0.4644\u001b[0m  0.0003  2.0036\n",
      "     32            \u001b[36m0.8236\u001b[0m                     \u001b[32m0.8241\u001b[0m        \u001b[35m0.4199\u001b[0m            0.7753                     0.7757        0.4664  0.0002  1.9897\n",
      "     33            0.8042                     0.8053        \u001b[35m0.4194\u001b[0m            0.7649                     0.7660        0.4834  0.0001  2.0306\n",
      "     34            0.8201                     0.8208        0.4220            0.7770                     0.7776        0.4666  0.0000  2.0070\n",
      "     35            0.8054                     0.8065        \u001b[35m0.4112\u001b[0m            0.7658                     0.7669        0.4833  0.0000  2.0136\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5030\u001b[0m                     \u001b[32m0.5082\u001b[0m        \u001b[35m3.5324\u001b[0m            \u001b[31m0.5039\u001b[0m                     \u001b[94m0.5093\u001b[0m        \u001b[36m2.3565\u001b[0m  0.0100  1.9747\n",
      "      2            \u001b[36m0.5590\u001b[0m                     \u001b[32m0.5550\u001b[0m        \u001b[35m1.5551\u001b[0m            \u001b[31m0.5583\u001b[0m                     \u001b[94m0.5543\u001b[0m        2.7805  0.0100  1.9766\n",
      "      3            \u001b[36m0.5845\u001b[0m                     \u001b[32m0.5813\u001b[0m        \u001b[35m1.5238\u001b[0m            \u001b[31m0.6076\u001b[0m                     \u001b[94m0.6043\u001b[0m        \u001b[36m1.5364\u001b[0m  0.0099  1.9777\n",
      "      4            \u001b[36m0.6879\u001b[0m                     \u001b[32m0.6872\u001b[0m        1.7928            \u001b[31m0.6776\u001b[0m                     \u001b[94m0.6769\u001b[0m        \u001b[36m0.8778\u001b[0m  0.0098  1.9622\n",
      "      5            0.6457                     0.6473        \u001b[35m0.8587\u001b[0m            0.6629                     0.6644        \u001b[36m0.7822\u001b[0m  0.0097  1.9818\n",
      "      6            \u001b[36m0.7108\u001b[0m                     \u001b[32m0.7103\u001b[0m        \u001b[35m0.7147\u001b[0m            \u001b[31m0.7113\u001b[0m                     \u001b[94m0.7109\u001b[0m        \u001b[36m0.5847\u001b[0m  0.0095  1.9797\n",
      "      7            0.6775                     0.6763        0.7936            0.6646                     0.6635        0.7043  0.0093  1.9657\n",
      "      8            0.7000                     0.7002        \u001b[35m0.6836\u001b[0m            0.6949                     0.6954        0.6263  0.0090  1.9787\n",
      "      9            0.6850                     0.6865        \u001b[35m0.6802\u001b[0m            0.6819                     0.6834        0.6604  0.0087  1.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10            \u001b[36m0.7194\u001b[0m                     \u001b[32m0.7197\u001b[0m        \u001b[35m0.6670\u001b[0m            \u001b[31m0.7122\u001b[0m                     \u001b[94m0.7126\u001b[0m        0.5921  0.0084  1.9864\n",
      "     11            \u001b[36m0.7367\u001b[0m                     \u001b[32m0.7372\u001b[0m        \u001b[35m0.6036\u001b[0m            0.7096                     0.7103        \u001b[36m0.5651\u001b[0m  0.0080  1.9662\n",
      "     12            0.7298                     0.7308        0.6819            \u001b[31m0.7217\u001b[0m                     \u001b[94m0.7230\u001b[0m        0.5926  0.0076  1.9802\n",
      "     13            0.7041                     0.7054        0.6245            0.6819                     0.6835        0.7414  0.0072  1.9677\n",
      "     14            0.7302                     0.7311        0.6141            0.6923                     0.6934        0.6225  0.0068  1.9711\n",
      "     15            \u001b[36m0.7613\u001b[0m                     \u001b[32m0.7622\u001b[0m        \u001b[35m0.5709\u001b[0m            \u001b[31m0.7381\u001b[0m                     \u001b[94m0.7393\u001b[0m        \u001b[36m0.5365\u001b[0m  0.0064  1.9757\n",
      "     16            0.7462                     0.7459        \u001b[35m0.5346\u001b[0m            0.7208                     0.7207        0.5684  0.0059  1.9847\n",
      "     17            \u001b[36m0.7663\u001b[0m                     \u001b[32m0.7661\u001b[0m        0.5652            \u001b[31m0.7433\u001b[0m                     \u001b[94m0.7434\u001b[0m        \u001b[36m0.5276\u001b[0m  0.0055  1.9598\n",
      "     18            0.7633                     0.7641        \u001b[35m0.5287\u001b[0m            0.7424                     \u001b[94m0.7437\u001b[0m        0.5305  0.0050  1.9846\n",
      "     19            \u001b[36m0.7678\u001b[0m                     \u001b[32m0.7675\u001b[0m        0.5317            \u001b[31m0.7476\u001b[0m                     \u001b[94m0.7475\u001b[0m        \u001b[36m0.5202\u001b[0m  0.0045  1.9811\n",
      "     20            \u001b[36m0.7739\u001b[0m                     \u001b[32m0.7744\u001b[0m        \u001b[35m0.5194\u001b[0m            \u001b[31m0.7545\u001b[0m                     \u001b[94m0.7552\u001b[0m        \u001b[36m0.5127\u001b[0m  0.0041  1.9894\n",
      "     21            \u001b[36m0.7793\u001b[0m                     \u001b[32m0.7791\u001b[0m        \u001b[35m0.5079\u001b[0m            0.7537                     0.7537        0.5174  0.0036  1.9887\n",
      "     22            \u001b[36m0.7931\u001b[0m                     \u001b[32m0.7928\u001b[0m        \u001b[35m0.4957\u001b[0m            \u001b[31m0.7632\u001b[0m                     \u001b[94m0.7630\u001b[0m        \u001b[36m0.5076\u001b[0m  0.0032  1.9791\n",
      "     23            0.7616                     0.7633        \u001b[35m0.4885\u001b[0m            0.7321                     0.7340        0.5432  0.0028  1.9927\n",
      "     24            \u001b[36m0.7942\u001b[0m                     \u001b[32m0.7949\u001b[0m        \u001b[35m0.4875\u001b[0m            0.7528                     0.7538        \u001b[36m0.5044\u001b[0m  0.0024  1.9857\n",
      "     25            \u001b[36m0.7972\u001b[0m                     \u001b[32m0.7973\u001b[0m        \u001b[35m0.4790\u001b[0m            \u001b[31m0.7666\u001b[0m                     \u001b[94m0.7670\u001b[0m        \u001b[36m0.4904\u001b[0m  0.0020  1.9666\n",
      "     26            \u001b[36m0.8016\u001b[0m                     \u001b[32m0.8019\u001b[0m        \u001b[35m0.4691\u001b[0m            0.7571                     0.7579        0.4962  0.0016  1.9907\n",
      "     27            0.7985                     0.7989        \u001b[35m0.4681\u001b[0m            0.7658                     0.7665        0.4924  0.0013  1.9937\n",
      "     28            \u001b[36m0.8029\u001b[0m                     \u001b[32m0.8035\u001b[0m        \u001b[35m0.4560\u001b[0m            \u001b[31m0.7692\u001b[0m                     \u001b[94m0.7702\u001b[0m        \u001b[36m0.4860\u001b[0m  0.0010  1.9882\n",
      "     29            \u001b[36m0.8102\u001b[0m                     \u001b[32m0.8105\u001b[0m        0.4600            \u001b[31m0.7727\u001b[0m                     \u001b[94m0.7733\u001b[0m        \u001b[36m0.4831\u001b[0m  0.0007  1.9732\n",
      "     30            0.8083                     0.8086        \u001b[35m0.4524\u001b[0m            0.7718                     0.7723        0.4835  0.0005  2.0142\n",
      "     31            \u001b[36m0.8115\u001b[0m                     \u001b[32m0.8121\u001b[0m        0.4527            0.7589                     0.7598        0.4851  0.0003  2.0056\n",
      "     32            0.8113                     0.8115        \u001b[35m0.4445\u001b[0m            \u001b[31m0.7805\u001b[0m                     \u001b[94m0.7809\u001b[0m        \u001b[36m0.4799\u001b[0m  0.0002  1.9857\n",
      "     33            \u001b[36m0.8139\u001b[0m                     \u001b[32m0.8143\u001b[0m        \u001b[35m0.4433\u001b[0m            0.7779                     0.7785        0.4809  0.0001  1.9827\n",
      "     34            0.8100                     0.8106        \u001b[35m0.4421\u001b[0m            0.7606                     0.7615        0.4873  0.0000  2.0382\n",
      "     35            \u001b[36m0.8150\u001b[0m                     \u001b[32m0.8154\u001b[0m        \u001b[35m0.4403\u001b[0m            0.7675                     0.7683        0.4820  0.0000  1.9919\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5661\u001b[0m                     \u001b[32m0.5632\u001b[0m        \u001b[35m4.8875\u001b[0m            \u001b[31m0.5601\u001b[0m                     \u001b[94m0.5572\u001b[0m        \u001b[36m3.5336\u001b[0m  0.0100  2.0061\n",
      "      2            \u001b[36m0.5824\u001b[0m                     \u001b[32m0.5857\u001b[0m        \u001b[35m2.2662\u001b[0m            \u001b[31m0.5748\u001b[0m                     \u001b[94m0.5783\u001b[0m        \u001b[36m1.4126\u001b[0m  0.0100  1.9807\n",
      "      3            \u001b[36m0.6561\u001b[0m                     \u001b[32m0.6553\u001b[0m        \u001b[35m1.3341\u001b[0m            \u001b[31m0.6482\u001b[0m                     \u001b[94m0.6474\u001b[0m        \u001b[36m0.8378\u001b[0m  0.0099  1.9918\n",
      "      4            \u001b[36m0.6580\u001b[0m                     \u001b[32m0.6607\u001b[0m        \u001b[35m0.8288\u001b[0m            \u001b[31m0.6629\u001b[0m                     \u001b[94m0.6659\u001b[0m        \u001b[36m0.6912\u001b[0m  0.0098  2.0007\n",
      "      5            \u001b[36m0.6948\u001b[0m                     \u001b[32m0.6943\u001b[0m        \u001b[35m0.7329\u001b[0m            \u001b[31m0.6880\u001b[0m                     \u001b[94m0.6874\u001b[0m        \u001b[36m0.6139\u001b[0m  0.0097  1.9826\n",
      "      6            \u001b[36m0.7227\u001b[0m                     \u001b[32m0.7230\u001b[0m        0.7415            \u001b[31m0.7096\u001b[0m                     \u001b[94m0.7098\u001b[0m        \u001b[36m0.5848\u001b[0m  0.0095  2.0086\n",
      "      7            0.7019                     0.7019        \u001b[35m0.6852\u001b[0m            0.6750                     0.6750        0.6546  0.0093  1.9952\n",
      "      8            0.7095                     0.7081        \u001b[35m0.6185\u001b[0m            \u001b[31m0.7131\u001b[0m                     \u001b[94m0.7117\u001b[0m        0.5950  0.0090  2.0007\n",
      "      9            0.6814                     0.6835        \u001b[35m0.6075\u001b[0m            0.6750                     0.6772        0.7185  0.0087  1.9917\n",
      "     10            0.7190                     0.7200        \u001b[35m0.6060\u001b[0m            \u001b[31m0.7182\u001b[0m                     \u001b[94m0.7194\u001b[0m        0.6908  0.0084  2.0000\n",
      "     11            \u001b[36m0.7534\u001b[0m                     \u001b[32m0.7535\u001b[0m        0.6315            \u001b[31m0.7355\u001b[0m                     \u001b[94m0.7358\u001b[0m        \u001b[36m0.5332\u001b[0m  0.0080  1.9717\n",
      "     12            0.7391                     0.7386        \u001b[35m0.5527\u001b[0m            0.7338                     0.7332        0.5519  0.0076  1.9727\n",
      "     13            \u001b[36m0.7616\u001b[0m                     \u001b[32m0.7613\u001b[0m        \u001b[35m0.5320\u001b[0m            \u001b[31m0.7519\u001b[0m                     \u001b[94m0.7515\u001b[0m        \u001b[36m0.5282\u001b[0m  0.0072  1.9707\n",
      "     14            \u001b[36m0.7635\u001b[0m                     \u001b[32m0.7630\u001b[0m        \u001b[35m0.5212\u001b[0m            \u001b[31m0.7589\u001b[0m                     \u001b[94m0.7582\u001b[0m        \u001b[36m0.5216\u001b[0m  0.0068  1.9624\n",
      "     15            \u001b[36m0.7693\u001b[0m                     \u001b[32m0.7704\u001b[0m        \u001b[35m0.5040\u001b[0m            0.7468                     0.7479        \u001b[36m0.5197\u001b[0m  0.0064  1.9643\n",
      "     16            \u001b[36m0.7748\u001b[0m                     \u001b[32m0.7743\u001b[0m        0.5086            0.7511                     0.7507        \u001b[36m0.5102\u001b[0m  0.0059  1.9757\n",
      "     17            \u001b[36m0.7765\u001b[0m                     \u001b[32m0.7772\u001b[0m        \u001b[35m0.5029\u001b[0m            0.7545                     0.7553        0.5117  0.0055  1.9797\n",
      "     18            \u001b[36m0.7806\u001b[0m                     \u001b[32m0.7808\u001b[0m        \u001b[35m0.4935\u001b[0m            \u001b[31m0.7692\u001b[0m                     \u001b[94m0.7695\u001b[0m        \u001b[36m0.4995\u001b[0m  0.0050  1.9817\n",
      "     19            \u001b[36m0.7815\u001b[0m                     \u001b[32m0.7813\u001b[0m        \u001b[35m0.4909\u001b[0m            0.7606                     0.7603        0.5028  0.0045  1.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     20            \u001b[36m0.7869\u001b[0m                     \u001b[32m0.7875\u001b[0m        0.4919            0.7589                     0.7595        0.5058  0.0041  1.9697\n",
      "     21            0.7840                     0.7849        \u001b[35m0.4772\u001b[0m            0.7589                     0.7598        0.5022  0.0036  1.9722\n",
      "     22            0.7853                     0.7860        \u001b[35m0.4691\u001b[0m            0.7589                     0.7595        0.5125  0.0032  1.9677\n",
      "     23            \u001b[36m0.7953\u001b[0m                     \u001b[32m0.7959\u001b[0m        0.4718            0.7615                     0.7620        0.5042  0.0028  1.9847\n",
      "     24            \u001b[36m0.8050\u001b[0m                     \u001b[32m0.8051\u001b[0m        \u001b[35m0.4651\u001b[0m            0.7675                     0.7675        \u001b[36m0.4898\u001b[0m  0.0024  1.9748\n",
      "     25            \u001b[36m0.8096\u001b[0m                     \u001b[32m0.8095\u001b[0m        \u001b[35m0.4564\u001b[0m            0.7658                     0.7656        \u001b[36m0.4822\u001b[0m  0.0020  1.9667\n",
      "     26            \u001b[36m0.8115\u001b[0m                     \u001b[32m0.8119\u001b[0m        \u001b[35m0.4520\u001b[0m            0.7684                     0.7688        0.4867  0.0016  1.9776\n",
      "     27            \u001b[36m0.8167\u001b[0m                     \u001b[32m0.8166\u001b[0m        \u001b[35m0.4507\u001b[0m            0.7692                     0.7691        0.4884  0.0013  1.9727\n",
      "     28            0.8080                     0.8087        \u001b[35m0.4465\u001b[0m            \u001b[31m0.7761\u001b[0m                     \u001b[94m0.7766\u001b[0m        \u001b[36m0.4807\u001b[0m  0.0010  1.9777\n",
      "     29            0.8076                     0.8081        \u001b[35m0.4421\u001b[0m            \u001b[31m0.7770\u001b[0m                     \u001b[94m0.7774\u001b[0m        0.4852  0.0007  1.9817\n",
      "     30            0.8072                     0.8077        \u001b[35m0.4409\u001b[0m            \u001b[31m0.7779\u001b[0m                     \u001b[94m0.7783\u001b[0m        0.4854  0.0005  1.9647\n",
      "     31            0.8067                     0.8075        \u001b[35m0.4319\u001b[0m            0.7727                     0.7733        0.4821  0.0003  1.9711\n",
      "     32            0.8160                     0.8165        0.4337            0.7727                     0.7731        \u001b[36m0.4790\u001b[0m  0.0002  1.9717\n",
      "     33            0.8067                     0.8074        0.4338            0.7761                     0.7767        0.4805  0.0001  1.9727\n",
      "     34            0.8130                     0.8135        0.4341            0.7753                     0.7758        0.4805  0.0000  1.9757\n",
      "     35            0.8163                     \u001b[32m0.8166\u001b[0m        0.4329            0.7744                     0.7748        0.4793  0.0000  1.9733\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5082\u001b[0m                     \u001b[32m0.5105\u001b[0m        \u001b[35m4.0446\u001b[0m            \u001b[31m0.4909\u001b[0m                     \u001b[94m0.4932\u001b[0m        \u001b[36m3.2916\u001b[0m  0.0100  1.9770\n",
      "      2            \u001b[36m0.5791\u001b[0m                     \u001b[32m0.5818\u001b[0m        \u001b[35m1.7611\u001b[0m            \u001b[31m0.5782\u001b[0m                     \u001b[94m0.5812\u001b[0m        \u001b[36m1.6601\u001b[0m  0.0100  1.9757\n",
      "      3            \u001b[36m0.6124\u001b[0m                     \u001b[32m0.6131\u001b[0m        \u001b[35m1.6847\u001b[0m            \u001b[31m0.5972\u001b[0m                     \u001b[94m0.5981\u001b[0m        \u001b[36m1.1273\u001b[0m  0.0099  1.9767\n",
      "      4            0.5348                     0.5384        \u001b[35m0.9852\u001b[0m            0.5203                     0.5242        1.4361  0.0098  1.9657\n",
      "      5            \u001b[36m0.6265\u001b[0m                     \u001b[32m0.6243\u001b[0m        1.2422            \u001b[31m0.6050\u001b[0m                     \u001b[94m0.6025\u001b[0m        1.2077  0.0097  1.9757\n",
      "      6            \u001b[36m0.6697\u001b[0m                     \u001b[32m0.6691\u001b[0m        \u001b[35m0.8669\u001b[0m            \u001b[31m0.6448\u001b[0m                     \u001b[94m0.6442\u001b[0m        \u001b[36m0.7621\u001b[0m  0.0095  1.9735\n",
      "      7            0.6675                     0.6670        \u001b[35m0.8342\u001b[0m            \u001b[31m0.6474\u001b[0m                     \u001b[94m0.6468\u001b[0m        0.7626  0.0093  1.9745\n",
      "      8            \u001b[36m0.7175\u001b[0m                     \u001b[32m0.7168\u001b[0m        \u001b[35m0.6791\u001b[0m            \u001b[31m0.6819\u001b[0m                     \u001b[94m0.6810\u001b[0m        \u001b[36m0.6505\u001b[0m  0.0090  1.9697\n",
      "      9            \u001b[36m0.7391\u001b[0m                     \u001b[32m0.7395\u001b[0m        \u001b[35m0.6239\u001b[0m            \u001b[31m0.7139\u001b[0m                     \u001b[94m0.7144\u001b[0m        \u001b[36m0.5884\u001b[0m  0.0087  1.9637\n",
      "     10            \u001b[36m0.7408\u001b[0m                     \u001b[32m0.7407\u001b[0m        0.6850            \u001b[31m0.7217\u001b[0m                     \u001b[94m0.7215\u001b[0m        0.7163  0.0084  1.9803\n",
      "     11            0.7283                     0.7274        0.6990            0.7113                     0.7105        0.6152  0.0080  1.9787\n",
      "     12            0.6719                     0.6693        0.6438            0.6292                     0.6265        0.8247  0.0076  1.9717\n",
      "     13            0.7339                     0.7348        0.6854            0.6889                     0.6899        0.6739  0.0072  1.9707\n",
      "     14            \u001b[36m0.7460\u001b[0m                     \u001b[32m0.7473\u001b[0m        \u001b[35m0.5822\u001b[0m            0.6940                     0.6956        0.6117  0.0068  1.9717\n",
      "     15            \u001b[36m0.7527\u001b[0m                     \u001b[32m0.7523\u001b[0m        \u001b[35m0.5470\u001b[0m            \u001b[31m0.7295\u001b[0m                     \u001b[94m0.7292\u001b[0m        \u001b[36m0.5623\u001b[0m  0.0064  1.9759\n",
      "     16            \u001b[36m0.7672\u001b[0m                     \u001b[32m0.7667\u001b[0m        0.5480            0.7277                     0.7272        \u001b[36m0.5610\u001b[0m  0.0059  1.9696\n",
      "     17            \u001b[36m0.7728\u001b[0m                     \u001b[32m0.7732\u001b[0m        0.5740            0.7243                     0.7249        0.5778  0.0055  1.9739\n",
      "     18            \u001b[36m0.7810\u001b[0m                     \u001b[32m0.7815\u001b[0m        \u001b[35m0.5302\u001b[0m            \u001b[31m0.7416\u001b[0m                     \u001b[94m0.7422\u001b[0m        0.5654  0.0050  1.9897\n",
      "     19            0.7717                     0.7708        \u001b[35m0.5100\u001b[0m            0.7321                     0.7312        0.5762  0.0045  1.9817\n",
      "     20            \u001b[36m0.7972\u001b[0m                     \u001b[32m0.7976\u001b[0m        \u001b[35m0.5072\u001b[0m            \u001b[31m0.7519\u001b[0m                     \u001b[94m0.7525\u001b[0m        0.6013  0.0041  1.9777\n",
      "     21            0.7962                     0.7963        \u001b[35m0.4990\u001b[0m            0.7476                     0.7479        \u001b[36m0.5235\u001b[0m  0.0036  1.9875\n",
      "     22            \u001b[36m0.8059\u001b[0m                     \u001b[32m0.8057\u001b[0m        0.5100            \u001b[31m0.7718\u001b[0m                     \u001b[94m0.7717\u001b[0m        0.5518  0.0032  1.9718\n",
      "     23            0.8005                     0.8009        \u001b[35m0.4808\u001b[0m            0.7554                     0.7560        0.5433  0.0028  1.9767\n",
      "     24            \u001b[36m0.8091\u001b[0m                     \u001b[32m0.8097\u001b[0m        \u001b[35m0.4733\u001b[0m            0.7554                     0.7560        0.5302  0.0024  1.9902\n",
      "     25            \u001b[36m0.8102\u001b[0m                     \u001b[32m0.8108\u001b[0m        \u001b[35m0.4659\u001b[0m            0.7519                     0.7527        0.5493  0.0020  1.9837\n",
      "     26            0.8100                     0.8107        \u001b[35m0.4644\u001b[0m            0.7485                     0.7494        0.5576  0.0016  1.9811\n",
      "     27            \u001b[36m0.8171\u001b[0m                     \u001b[32m0.8174\u001b[0m        \u001b[35m0.4515\u001b[0m            0.7684                     0.7687        0.5436  0.0013  1.9668\n",
      "     28            \u001b[36m0.8225\u001b[0m                     \u001b[32m0.8227\u001b[0m        0.4545            0.7718                     \u001b[94m0.7722\u001b[0m        0.5440  0.0010  1.9787\n",
      "     29            0.8221                     0.8226        \u001b[35m0.4494\u001b[0m            0.7589                     0.7597        0.5403  0.0007  1.9707\n",
      "     30            \u001b[36m0.8243\u001b[0m                     \u001b[32m0.8247\u001b[0m        \u001b[35m0.4421\u001b[0m            0.7658                     0.7663        0.5470  0.0005  1.9817\n",
      "     31            \u001b[36m0.8260\u001b[0m                     \u001b[32m0.8262\u001b[0m        \u001b[35m0.4368\u001b[0m            0.7710                     0.7714        0.5397  0.0003  1.9753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     32            0.8240                     0.8244        \u001b[35m0.4353\u001b[0m            0.7710                     0.7715        0.5409  0.0002  1.9907\n",
      "     33            0.8251                     0.8256        \u001b[35m0.4338\u001b[0m            0.7675                     0.7681        0.5470  0.0001  1.9837\n",
      "     34            0.8253                     0.8258        0.4344            \u001b[31m0.7727\u001b[0m                     \u001b[94m0.7733\u001b[0m        0.5437  0.0000  1.9798\n",
      "     35            0.8230                     0.8234        \u001b[35m0.4319\u001b[0m            0.7692                     0.7698        0.5415  0.0000  1.9687\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5093\u001b[0m                     \u001b[32m0.5128\u001b[0m        \u001b[35m4.2181\u001b[0m            \u001b[31m0.5048\u001b[0m                     \u001b[94m0.5084\u001b[0m        \u001b[36m5.9545\u001b[0m  0.0100  1.9977\n",
      "      2            \u001b[36m0.5597\u001b[0m                     \u001b[32m0.5633\u001b[0m        \u001b[35m2.1126\u001b[0m            \u001b[31m0.5480\u001b[0m                     \u001b[94m0.5518\u001b[0m        \u001b[36m1.2268\u001b[0m  0.0100  1.9890\n",
      "      3            \u001b[36m0.6866\u001b[0m                     \u001b[32m0.6858\u001b[0m        \u001b[35m1.4582\u001b[0m            \u001b[31m0.6655\u001b[0m                     \u001b[94m0.6648\u001b[0m        \u001b[36m0.7891\u001b[0m  0.0099  2.0051\n",
      "      4            0.6574                     0.6578        \u001b[35m1.4046\u001b[0m            0.6327                     0.6332        \u001b[36m0.7569\u001b[0m  0.0098  2.0530\n",
      "      5            0.6035                     0.6024        \u001b[35m1.1553\u001b[0m            0.6292                     0.6281        1.2111  0.0097  2.0906\n",
      "      6            \u001b[36m0.7041\u001b[0m                     \u001b[32m0.7048\u001b[0m        \u001b[35m0.8872\u001b[0m            \u001b[31m0.7035\u001b[0m                     \u001b[94m0.7044\u001b[0m        \u001b[36m0.6765\u001b[0m  0.0095  2.1018\n",
      "      7            \u001b[36m0.7168\u001b[0m                     \u001b[32m0.7173\u001b[0m        \u001b[35m0.7183\u001b[0m            \u001b[31m0.7070\u001b[0m                     \u001b[94m0.7076\u001b[0m        0.6988  0.0093  2.0902\n",
      "      8            0.7019                     0.7036        0.7277            0.6932                     0.6950        \u001b[36m0.6659\u001b[0m  0.0090  2.0914\n",
      "      9            \u001b[36m0.7309\u001b[0m                     \u001b[32m0.7302\u001b[0m        \u001b[35m0.6568\u001b[0m            \u001b[31m0.7286\u001b[0m                     \u001b[94m0.7281\u001b[0m        \u001b[36m0.5737\u001b[0m  0.0087  2.1044\n",
      "     10            \u001b[36m0.7350\u001b[0m                     \u001b[32m0.7359\u001b[0m        \u001b[35m0.5959\u001b[0m            \u001b[31m0.7295\u001b[0m                     \u001b[94m0.7306\u001b[0m        0.5888  0.0084  2.1094\n",
      "     11            \u001b[36m0.7397\u001b[0m                     \u001b[32m0.7389\u001b[0m        \u001b[35m0.5759\u001b[0m            0.7243                     0.7237        \u001b[36m0.5556\u001b[0m  0.0080  2.0879\n",
      "     12            \u001b[36m0.7529\u001b[0m                     \u001b[32m0.7530\u001b[0m        \u001b[35m0.5616\u001b[0m            \u001b[31m0.7347\u001b[0m                     \u001b[94m0.7349\u001b[0m        0.5758  0.0076  2.0881\n",
      "     13            \u001b[36m0.7622\u001b[0m                     \u001b[32m0.7622\u001b[0m        0.6062            0.7347                     0.7347        \u001b[36m0.5528\u001b[0m  0.0072  2.0997\n",
      "     14            \u001b[36m0.7782\u001b[0m                     \u001b[32m0.7786\u001b[0m        \u001b[35m0.5430\u001b[0m            \u001b[31m0.7571\u001b[0m                     \u001b[94m0.7578\u001b[0m        \u001b[36m0.5223\u001b[0m  0.0068  2.0864\n",
      "     15            0.7607                     0.7616        \u001b[35m0.5273\u001b[0m            0.7390                     0.7401        0.5531  0.0064  2.0894\n",
      "     16            0.7778                     0.7785        \u001b[35m0.5231\u001b[0m            0.7571                     \u001b[94m0.7582\u001b[0m        \u001b[36m0.5180\u001b[0m  0.0059  2.0940\n",
      "     17            \u001b[36m0.7819\u001b[0m                     \u001b[32m0.7825\u001b[0m        0.5278            \u001b[31m0.7640\u001b[0m                     \u001b[94m0.7648\u001b[0m        \u001b[36m0.5151\u001b[0m  0.0055  2.1133\n",
      "     18            \u001b[36m0.7901\u001b[0m                     \u001b[32m0.7902\u001b[0m        \u001b[35m0.5024\u001b[0m            0.7640                     0.7643        \u001b[36m0.5050\u001b[0m  0.0050  2.0725\n",
      "     19            \u001b[36m0.7981\u001b[0m                     \u001b[32m0.7987\u001b[0m        \u001b[35m0.4912\u001b[0m            0.7545                     0.7554        \u001b[36m0.5023\u001b[0m  0.0045  2.0519\n",
      "     20            \u001b[36m0.8048\u001b[0m                     \u001b[32m0.8051\u001b[0m        \u001b[35m0.4830\u001b[0m            0.7589                     0.7593        \u001b[36m0.4994\u001b[0m  0.0041  2.0585\n",
      "     21            \u001b[36m0.8098\u001b[0m                     \u001b[32m0.8097\u001b[0m        0.4903            \u001b[31m0.7736\u001b[0m                     \u001b[94m0.7737\u001b[0m        \u001b[36m0.4862\u001b[0m  0.0036  2.0545\n",
      "     22            0.7933                     0.7944        \u001b[35m0.4749\u001b[0m            0.7589                     0.7600        0.5131  0.0032  2.0617\n",
      "     23            \u001b[36m0.8115\u001b[0m                     \u001b[32m0.8120\u001b[0m        \u001b[35m0.4643\u001b[0m            0.7632                     0.7639        0.5002  0.0028  2.0226\n",
      "     24            \u001b[36m0.8141\u001b[0m                     \u001b[32m0.8146\u001b[0m        \u001b[35m0.4637\u001b[0m            0.7606                     0.7613        0.4943  0.0024  2.0196\n",
      "     25            \u001b[36m0.8160\u001b[0m                     \u001b[32m0.8162\u001b[0m        \u001b[35m0.4509\u001b[0m            0.7649                     0.7654        0.4865  0.0020  2.0226\n",
      "     26            0.8156                     0.8159        \u001b[35m0.4472\u001b[0m            0.7675                     0.7681        0.4947  0.0016  2.0166\n",
      "     27            \u001b[36m0.8225\u001b[0m                     \u001b[32m0.8227\u001b[0m        0.4505            0.7640                     0.7645        0.4923  0.0013  2.0192\n",
      "     28            \u001b[36m0.8260\u001b[0m                     \u001b[32m0.8262\u001b[0m        \u001b[35m0.4335\u001b[0m            0.7589                     0.7594        0.4904  0.0010  2.0196\n",
      "     29            0.8083                     0.8091        0.4358            0.7537                     0.7548        0.4940  0.0007  2.0176\n",
      "     30            \u001b[36m0.8275\u001b[0m                     \u001b[32m0.8277\u001b[0m        0.4389            0.7692                     0.7699        \u001b[36m0.4810\u001b[0m  0.0005  2.0166\n",
      "     31            \u001b[36m0.8307\u001b[0m                     \u001b[32m0.8310\u001b[0m        \u001b[35m0.4299\u001b[0m            \u001b[31m0.7761\u001b[0m                     \u001b[94m0.7766\u001b[0m        0.4814  0.0003  2.0225\n",
      "     32            0.8264                     0.8268        \u001b[35m0.4257\u001b[0m            0.7710                     0.7717        \u001b[36m0.4803\u001b[0m  0.0002  2.0282\n",
      "     33            0.8098                     0.8106        0.4284            0.7632                     0.7643        0.4915  0.0001  2.0246\n",
      "     34            0.8268                     0.8273        \u001b[35m0.4207\u001b[0m            0.7701                     0.7709        0.4847  0.0000  2.0196\n",
      "     35            \u001b[36m0.8312\u001b[0m                     \u001b[32m0.8315\u001b[0m        0.4255            0.7727                     0.7733        0.4817  0.0000  2.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6354\u001b[0m                     \u001b[32m0.6261\u001b[0m        \u001b[35m5.0603\u001b[0m            \u001b[31m0.6295\u001b[0m                     \u001b[94m0.6205\u001b[0m        \u001b[36m4.2140\u001b[0m  0.0100  1.8695\n",
      "      2            0.5706                     0.5925        \u001b[35m2.3515\u001b[0m            0.5745                     0.5994        \u001b[36m3.1297\u001b[0m  0.0100  1.1639\n",
      "      3            \u001b[36m0.6694\u001b[0m                     \u001b[32m0.6801\u001b[0m        \u001b[35m1.5466\u001b[0m            \u001b[31m0.7106\u001b[0m                     \u001b[94m0.7207\u001b[0m        \u001b[36m0.8371\u001b[0m  0.0099  1.1639\n",
      "      4            0.6318                     0.6428        \u001b[35m1.1567\u001b[0m            0.6107                     0.6259        2.8981  0.0098  1.1679\n",
      "      5            \u001b[36m0.6818\u001b[0m                     \u001b[32m0.6977\u001b[0m        1.3942            0.6845                     0.7046        \u001b[36m0.7917\u001b[0m  0.0097  1.1649\n",
      "      6            \u001b[36m0.7219\u001b[0m                     \u001b[32m0.7245\u001b[0m        \u001b[35m0.7920\u001b[0m            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7307\u001b[0m        0.8211  0.0095  1.1679\n",
      "      7            0.7216                     0.7172        0.8767            0.7164                     0.7145        \u001b[36m0.7413\u001b[0m  0.0093  1.1649\n",
      "      8            \u001b[36m0.7303\u001b[0m                     \u001b[32m0.7368\u001b[0m        \u001b[35m0.6788\u001b[0m            \u001b[31m0.7337\u001b[0m                     \u001b[94m0.7420\u001b[0m        \u001b[36m0.5891\u001b[0m  0.0090  1.1684\n",
      "      9            0.7035                     0.7162        0.6877            0.7091                     0.7227        0.6207  0.0087  1.1609\n",
      "     10            \u001b[36m0.7317\u001b[0m                     0.7267        0.6805            0.6845                     0.6827        0.6226  0.0084  1.1699\n",
      "     11            \u001b[36m0.7458\u001b[0m                     \u001b[32m0.7409\u001b[0m        \u001b[35m0.5920\u001b[0m            0.7294                     0.7260        \u001b[36m0.5349\u001b[0m  0.0080  1.1654\n",
      "     12            \u001b[36m0.7578\u001b[0m                     \u001b[32m0.7616\u001b[0m        \u001b[35m0.5642\u001b[0m            0.7279                     0.7316        \u001b[36m0.5278\u001b[0m  0.0076  1.1649\n",
      "     13            0.7509                     0.7557        \u001b[35m0.5510\u001b[0m            0.7337                     0.7384        0.5567  0.0072  1.1679\n",
      "     14            \u001b[36m0.7676\u001b[0m                     \u001b[32m0.7673\u001b[0m        0.6514            \u001b[31m0.7540\u001b[0m                     \u001b[94m0.7571\u001b[0m        \u001b[36m0.5261\u001b[0m  0.0068  1.1609\n",
      "     15            0.7531                     0.7479        \u001b[35m0.5119\u001b[0m            0.7366                     0.7335        0.6364  0.0064  1.1659\n",
      "     16            \u001b[36m0.7734\u001b[0m                     \u001b[32m0.7741\u001b[0m        0.5277            0.7525                     0.7546        \u001b[36m0.5157\u001b[0m  0.0059  1.1664\n",
      "     17            0.7679                     \u001b[32m0.7790\u001b[0m        \u001b[35m0.5018\u001b[0m            0.7352                     0.7460        0.5182  0.0055  1.1642\n",
      "     18            0.7668                     0.7724        \u001b[35m0.5011\u001b[0m            0.7337                     0.7405        0.5389  0.0050  1.1659\n",
      "     19            0.7404                     0.7568        0.5051            0.7207                     0.7395        0.5454  0.0045  1.1619\n",
      "     20            \u001b[36m0.7741\u001b[0m                     0.7641        \u001b[35m0.4845\u001b[0m            0.7467                     0.7397        0.5330  0.0041  1.1688\n",
      "     21            0.7741                     \u001b[32m0.7791\u001b[0m        \u001b[35m0.4765\u001b[0m            0.7323                     0.7395        0.5469  0.0036  1.1699\n",
      "     22            \u001b[36m0.7972\u001b[0m                     \u001b[32m0.7979\u001b[0m        0.4802            \u001b[31m0.7569\u001b[0m                     \u001b[94m0.7579\u001b[0m        0.5169  0.0032  1.1699\n",
      "     23            0.7484                     0.7646        0.4785            0.6990                     0.7180        0.5667  0.0028  1.1699\n",
      "     24            0.7632                     0.7766        \u001b[35m0.4751\u001b[0m            0.7265                     0.7417        0.5403  0.0024  1.1629\n",
      "     25            0.7867                     0.7853        \u001b[35m0.4700\u001b[0m            \u001b[31m0.7656\u001b[0m                     \u001b[94m0.7664\u001b[0m        \u001b[36m0.5068\u001b[0m  0.0020  1.1679\n",
      "     26            0.7911                     \u001b[32m0.7984\u001b[0m        \u001b[35m0.4567\u001b[0m            0.7323                     0.7413        0.5126  0.0016  1.1695\n",
      "     27            \u001b[36m0.8027\u001b[0m                     \u001b[32m0.8017\u001b[0m        \u001b[35m0.4469\u001b[0m            0.7612                     0.7615        \u001b[36m0.5029\u001b[0m  0.0013  1.1669\n",
      "     28            0.7954                     0.8007        \u001b[35m0.4469\u001b[0m            0.7381                     0.7438        0.5219  0.0010  1.1680\n",
      "     29            0.8001                     \u001b[32m0.8039\u001b[0m        \u001b[35m0.4395\u001b[0m            0.7467                     0.7508        \u001b[36m0.4998\u001b[0m  0.0007  1.1659\n",
      "     30            \u001b[36m0.8081\u001b[0m                     \u001b[32m0.8089\u001b[0m        \u001b[35m0.4373\u001b[0m            0.7540                     0.7565        \u001b[36m0.4962\u001b[0m  0.0005  1.1621\n",
      "     31            0.8012                     0.8077        \u001b[35m0.4339\u001b[0m            0.7323                     0.7389        0.5073  0.0003  1.1639\n",
      "     32            0.8005                     0.8048        \u001b[35m0.4310\u001b[0m            0.7424                     0.7469        0.4979  0.0002  1.1639\n",
      "     33            0.8020                     0.8066        0.4376            0.7525                     0.7579        0.4968  0.0001  1.1649\n",
      "     34            \u001b[36m0.8103\u001b[0m                     \u001b[32m0.8135\u001b[0m        \u001b[35m0.4307\u001b[0m            0.7540                     0.7571        0.4973  0.0000  1.1609\n",
      "     35            0.8034                     0.8072        0.4381            0.7482                     0.7521        0.4965  0.0000  1.1657\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6220\u001b[0m                     \u001b[32m0.5945\u001b[0m        \u001b[35m4.3786\u001b[0m            \u001b[31m0.5962\u001b[0m                     \u001b[94m0.5680\u001b[0m        \u001b[36m2.0577\u001b[0m  0.0100  1.1689\n",
      "      2            \u001b[36m0.6249\u001b[0m                     \u001b[32m0.6374\u001b[0m        \u001b[35m2.2975\u001b[0m            \u001b[31m0.6382\u001b[0m                     \u001b[94m0.6512\u001b[0m        \u001b[36m1.3900\u001b[0m  0.0100  1.1629\n",
      "      3            \u001b[36m0.7071\u001b[0m                     \u001b[32m0.7113\u001b[0m        \u001b[35m1.3933\u001b[0m            \u001b[31m0.6874\u001b[0m                     \u001b[94m0.6931\u001b[0m        \u001b[36m0.8525\u001b[0m  0.0099  1.1629\n",
      "      4            0.6423                     0.6579        \u001b[35m1.2483\u001b[0m            0.6136                     0.6307        1.3646  0.0098  1.1649\n",
      "      5            0.6720                     0.6732        1.9069            0.6512                     0.6537        1.2565  0.0097  1.1629\n",
      "      6            \u001b[36m0.7136\u001b[0m                     \u001b[32m0.7263\u001b[0m        \u001b[35m0.9749\u001b[0m            0.6802                     \u001b[94m0.6931\u001b[0m        \u001b[36m0.6386\u001b[0m  0.0095  1.1679\n",
      "      7            \u001b[36m0.7187\u001b[0m                     \u001b[32m0.7293\u001b[0m        \u001b[35m0.6704\u001b[0m            0.6657                     0.6764        0.7275  0.0093  1.1679\n",
      "      8            0.6673                     0.6759        0.8522            0.6208                     0.6285        1.0768  0.0090  1.1679\n",
      "      9            0.7085                     0.7236        0.8602            \u001b[31m0.6918\u001b[0m                     \u001b[94m0.7088\u001b[0m        0.6516  0.0087  1.1639\n",
      "     10            \u001b[36m0.7444\u001b[0m                     \u001b[32m0.7440\u001b[0m        0.6961            \u001b[31m0.7120\u001b[0m                     \u001b[94m0.7097\u001b[0m        \u001b[36m0.6216\u001b[0m  0.0084  1.1669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            0.7172                     0.7152        0.6778            0.6541                     0.6530        0.8086  0.0080  1.1649\n",
      "     12            \u001b[36m0.7520\u001b[0m                     \u001b[32m0.7549\u001b[0m        0.7130            0.7120                     \u001b[94m0.7160\u001b[0m        \u001b[36m0.6106\u001b[0m  0.0076  1.1689\n",
      "     13            \u001b[36m0.7686\u001b[0m                     \u001b[32m0.7672\u001b[0m        0.6806            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7256\u001b[0m        \u001b[36m0.5850\u001b[0m  0.0072  1.1639\n",
      "     14            0.7487                     0.7587        \u001b[35m0.5403\u001b[0m            0.7149                     \u001b[94m0.7270\u001b[0m        0.6040  0.0068  1.1659\n",
      "     15            0.7513                     0.7543        0.5696            0.7106                     0.7114        0.6312  0.0064  1.1629\n",
      "     16            0.7610                     \u001b[32m0.7677\u001b[0m        \u001b[35m0.5256\u001b[0m            0.7236                     \u001b[94m0.7313\u001b[0m        \u001b[36m0.5730\u001b[0m  0.0059  1.1649\n",
      "     17            \u001b[36m0.7730\u001b[0m                     \u001b[32m0.7726\u001b[0m        0.5321            0.7178                     0.7179        \u001b[36m0.5559\u001b[0m  0.0055  1.1659\n",
      "     18            0.7448                     0.7565        \u001b[35m0.5242\u001b[0m            0.7120                     0.7262        0.5590  0.0050  1.1669\n",
      "     19            0.7408                     0.7536        0.5258            0.7019                     0.7155        0.5838  0.0045  1.1699\n",
      "     20            0.7708                     0.7688        0.5510            \u001b[31m0.7323\u001b[0m                     0.7275        0.5844  0.0041  1.1645\n",
      "     21            0.7708                     \u001b[32m0.7779\u001b[0m        \u001b[35m0.4876\u001b[0m            0.7279                     \u001b[94m0.7349\u001b[0m        \u001b[36m0.5418\u001b[0m  0.0036  1.1629\n",
      "     22            0.7657                     0.7692        0.4888            0.7279                     0.7298        0.5455  0.0032  1.1659\n",
      "     23            \u001b[36m0.7744\u001b[0m                     0.7713        \u001b[35m0.4868\u001b[0m            0.7279                     0.7235        0.5734  0.0028  1.1629\n",
      "     24            \u001b[36m0.7788\u001b[0m                     \u001b[32m0.7839\u001b[0m        0.4878            0.7250                     0.7302        \u001b[36m0.5196\u001b[0m  0.0024  1.1679\n",
      "     25            \u001b[36m0.7871\u001b[0m                     \u001b[32m0.7924\u001b[0m        \u001b[35m0.4732\u001b[0m            0.7279                     0.7325        0.5248  0.0020  1.1609\n",
      "     26            0.7817                     0.7869        \u001b[35m0.4660\u001b[0m            0.7221                     0.7273        \u001b[36m0.5174\u001b[0m  0.0016  1.1624\n",
      "     27            0.7429                     0.7577        0.4698            0.7062                     0.7225        0.5676  0.0013  1.1669\n",
      "     28            \u001b[36m0.7882\u001b[0m                     \u001b[32m0.7933\u001b[0m        \u001b[35m0.4540\u001b[0m            \u001b[31m0.7352\u001b[0m                     \u001b[94m0.7406\u001b[0m        0.5250  0.0010  1.1672\n",
      "     29            \u001b[36m0.7911\u001b[0m                     \u001b[32m0.7936\u001b[0m        \u001b[35m0.4496\u001b[0m            \u001b[31m0.7381\u001b[0m                     0.7399        \u001b[36m0.5131\u001b[0m  0.0007  1.1692\n",
      "     30            \u001b[36m0.7918\u001b[0m                     \u001b[32m0.7953\u001b[0m        0.4540            \u001b[31m0.7467\u001b[0m                     \u001b[94m0.7502\u001b[0m        \u001b[36m0.5115\u001b[0m  0.0005  1.1619\n",
      "     31            0.7875                     0.7909        0.4498            0.7395                     0.7430        \u001b[36m0.5030\u001b[0m  0.0003  1.1699\n",
      "     32            \u001b[36m0.7969\u001b[0m                     \u001b[32m0.8019\u001b[0m        0.4532            0.7366                     0.7410        0.5123  0.0002  1.1659\n",
      "     33            0.7922                     0.7960        \u001b[35m0.4486\u001b[0m            0.7352                     0.7388        0.5091  0.0001  1.1719\n",
      "     34            0.7951                     0.7998        \u001b[35m0.4440\u001b[0m            0.7410                     0.7459        0.5078  0.0000  1.1641\n",
      "     35            0.7907                     0.7939        0.4523            0.7395                     0.7421        0.5060  0.0000  1.1654\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5862\u001b[0m                     \u001b[32m0.5687\u001b[0m        \u001b[35m4.3296\u001b[0m            \u001b[31m0.5876\u001b[0m                     \u001b[94m0.5704\u001b[0m        \u001b[36m3.5837\u001b[0m  0.0100  1.1659\n",
      "      2            \u001b[36m0.5952\u001b[0m                     \u001b[32m0.5901\u001b[0m        \u001b[35m3.6452\u001b[0m            0.5818                     \u001b[94m0.5766\u001b[0m        3.7189  0.0100  1.1679\n",
      "      3            \u001b[36m0.6166\u001b[0m                     \u001b[32m0.6123\u001b[0m        \u001b[35m2.7517\u001b[0m            \u001b[31m0.5919\u001b[0m                     \u001b[94m0.5851\u001b[0m        \u001b[36m1.5472\u001b[0m  0.0099  1.1647\n",
      "      4            \u001b[36m0.6521\u001b[0m                     \u001b[32m0.6708\u001b[0m        \u001b[35m1.7171\u001b[0m            \u001b[31m0.6744\u001b[0m                     \u001b[94m0.6918\u001b[0m        \u001b[36m0.9913\u001b[0m  0.0098  1.1639\n",
      "      5            \u001b[36m0.6908\u001b[0m                     \u001b[32m0.6918\u001b[0m        \u001b[35m1.0620\u001b[0m            \u001b[31m0.6889\u001b[0m                     0.6866        \u001b[36m0.9887\u001b[0m  0.0097  1.1669\n",
      "      6            0.5996                     0.6108        \u001b[35m0.8464\u001b[0m            0.5687                     0.5795        1.7796  0.0095  1.1640\n",
      "      7            0.5442                     0.5069        1.0966            0.5369                     0.4983        1.9458  0.0093  1.1699\n",
      "      8            0.6741                     0.6833        0.9256            0.6845                     0.6917        \u001b[36m0.8380\u001b[0m  0.0090  1.1659\n",
      "      9            \u001b[36m0.7013\u001b[0m                     0.6903        \u001b[35m0.8370\u001b[0m            \u001b[31m0.7091\u001b[0m                     \u001b[94m0.6986\u001b[0m        0.8520  0.0087  1.1659\n",
      "     10            \u001b[36m0.7274\u001b[0m                     \u001b[32m0.7243\u001b[0m        \u001b[35m0.7205\u001b[0m            \u001b[31m0.7164\u001b[0m                     \u001b[94m0.7139\u001b[0m        \u001b[36m0.6792\u001b[0m  0.0084  1.1729\n",
      "     11            0.7006                     0.7158        \u001b[35m0.7016\u001b[0m            0.6990                     0.7099        0.6922  0.0080  1.1654\n",
      "     12            \u001b[36m0.7397\u001b[0m                     \u001b[32m0.7474\u001b[0m        \u001b[35m0.6156\u001b[0m            \u001b[31m0.7308\u001b[0m                     \u001b[94m0.7379\u001b[0m        \u001b[36m0.5431\u001b[0m  0.0076  1.1668\n",
      "     13            0.7371                     0.7447        0.6200            0.7164                     0.7232        0.5532  0.0072  1.1689\n",
      "     14            \u001b[36m0.7415\u001b[0m                     \u001b[32m0.7476\u001b[0m        0.6483            \u001b[31m0.7352\u001b[0m                     \u001b[94m0.7403\u001b[0m        0.6037  0.0068  1.1661\n",
      "     15            \u001b[36m0.7600\u001b[0m                     \u001b[32m0.7661\u001b[0m        0.6168            0.7352                     \u001b[94m0.7406\u001b[0m        \u001b[36m0.5202\u001b[0m  0.0064  1.1649\n",
      "     16            \u001b[36m0.7621\u001b[0m                     0.7548        \u001b[35m0.5547\u001b[0m            \u001b[31m0.7598\u001b[0m                     \u001b[94m0.7539\u001b[0m        \u001b[36m0.5111\u001b[0m  0.0059  1.1639\n",
      "     17            \u001b[36m0.7690\u001b[0m                     \u001b[32m0.7688\u001b[0m        \u001b[35m0.5287\u001b[0m            0.7453                     0.7453        0.5143  0.0055  1.1629\n",
      "     18            0.7361                     0.7500        0.5373            0.7279                     0.7413        0.5294  0.0050  1.1733\n",
      "     19            0.7542                     0.7682        0.5393            0.7395                     0.7515        0.5129  0.0045  1.1659\n",
      "     20            \u001b[36m0.7773\u001b[0m                     \u001b[32m0.7765\u001b[0m        \u001b[35m0.5190\u001b[0m            \u001b[31m0.7685\u001b[0m                     \u001b[94m0.7687\u001b[0m        \u001b[36m0.4926\u001b[0m  0.0041  1.1649\n",
      "     21            0.7538                     0.7619        \u001b[35m0.5009\u001b[0m            0.7366                     0.7446        0.5271  0.0036  1.1644\n",
      "     22            0.7712                     0.7748        0.5357            0.7656                     \u001b[94m0.7697\u001b[0m        \u001b[36m0.4914\u001b[0m  0.0032  1.1719\n",
      "     23            0.7697                     \u001b[32m0.7770\u001b[0m        \u001b[35m0.4836\u001b[0m            0.7352                     0.7421        0.5161  0.0028  1.1659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24            \u001b[36m0.7810\u001b[0m                     \u001b[32m0.7818\u001b[0m        0.5032            0.7525                     0.7527        0.4951  0.0024  1.1649\n",
      "     25            \u001b[36m0.7828\u001b[0m                     \u001b[32m0.7855\u001b[0m        \u001b[35m0.4775\u001b[0m            0.7366                     0.7401        0.5075  0.0020  1.1679\n",
      "     26            \u001b[36m0.7849\u001b[0m                     0.7836        0.4789            0.7482                     0.7470        \u001b[36m0.4880\u001b[0m  0.0016  1.1719\n",
      "     27            \u001b[36m0.7871\u001b[0m                     \u001b[32m0.7917\u001b[0m        \u001b[35m0.4666\u001b[0m            0.7496                     0.7555        \u001b[36m0.4842\u001b[0m  0.0013  1.1694\n",
      "     28            0.7820                     0.7863        \u001b[35m0.4663\u001b[0m            0.7554                     0.7602        0.4856  0.0010  1.1639\n",
      "     29            0.7864                     \u001b[32m0.7929\u001b[0m        \u001b[35m0.4546\u001b[0m            0.7438                     0.7506        \u001b[36m0.4813\u001b[0m  0.0007  1.1625\n",
      "     30            \u001b[36m0.7911\u001b[0m                     \u001b[32m0.7940\u001b[0m        \u001b[35m0.4531\u001b[0m            0.7482                     0.7518        \u001b[36m0.4795\u001b[0m  0.0005  1.1677\n",
      "     31            0.7904                     0.7908        \u001b[35m0.4520\u001b[0m            0.7583                     0.7592        \u001b[36m0.4793\u001b[0m  0.0003  1.1619\n",
      "     32            0.7896                     0.7918        \u001b[35m0.4487\u001b[0m            0.7540                     0.7574        0.4799  0.0002  1.1669\n",
      "     33            \u001b[36m0.7936\u001b[0m                     \u001b[32m0.7952\u001b[0m        \u001b[35m0.4408\u001b[0m            0.7554                     0.7587        \u001b[36m0.4790\u001b[0m  0.0001  1.1709\n",
      "     34            0.7900                     0.7918        0.4499            0.7554                     0.7587        0.4807  0.0000  1.1619\n",
      "     35            0.7933                     0.7948        0.4467            0.7511                     0.7535        \u001b[36m0.4782\u001b[0m  0.0000  1.1649\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6050\u001b[0m                     \u001b[32m0.5873\u001b[0m        \u001b[35m4.4371\u001b[0m            \u001b[31m0.5933\u001b[0m                     \u001b[94m0.5732\u001b[0m        \u001b[36m2.2882\u001b[0m  0.0100  1.1639\n",
      "      2            \u001b[36m0.6904\u001b[0m                     \u001b[32m0.7001\u001b[0m        \u001b[35m1.3058\u001b[0m            \u001b[31m0.6715\u001b[0m                     \u001b[94m0.6793\u001b[0m        \u001b[36m1.2037\u001b[0m  0.0100  1.1649\n",
      "      3            0.5829                     0.5594        1.6312            0.6035                     0.5812        2.3166  0.0099  1.1740\n",
      "      4            0.6698                     0.6708        1.7746            0.6454                     0.6421        \u001b[36m0.9128\u001b[0m  0.0098  1.1619\n",
      "      5            \u001b[36m0.7219\u001b[0m                     \u001b[32m0.7177\u001b[0m        1.6596            \u001b[31m0.7004\u001b[0m                     \u001b[94m0.6956\u001b[0m        0.9985  0.0097  1.1669\n",
      "      6            0.6814                     0.7001        \u001b[35m1.2333\u001b[0m            0.6758                     0.6952        1.0811  0.0095  1.1659\n",
      "      7            \u001b[36m0.7306\u001b[0m                     \u001b[32m0.7392\u001b[0m        \u001b[35m0.9254\u001b[0m            \u001b[31m0.7135\u001b[0m                     \u001b[94m0.7215\u001b[0m        \u001b[36m0.6659\u001b[0m  0.0093  1.1679\n",
      "      8            \u001b[36m0.7524\u001b[0m                     \u001b[32m0.7547\u001b[0m        \u001b[35m0.7846\u001b[0m            0.7091                     0.7092        \u001b[36m0.6631\u001b[0m  0.0090  1.1684\n",
      "      9            \u001b[36m0.7560\u001b[0m                     \u001b[32m0.7579\u001b[0m        \u001b[35m0.6969\u001b[0m            \u001b[31m0.7337\u001b[0m                     \u001b[94m0.7345\u001b[0m        \u001b[36m0.5526\u001b[0m  0.0087  1.1664\n",
      "     10            0.7201                     0.7389        \u001b[35m0.5847\u001b[0m            0.7120                     0.7295        0.6110  0.0084  1.1619\n",
      "     11            \u001b[36m0.7618\u001b[0m                     \u001b[32m0.7621\u001b[0m        0.6030            0.7337                     0.7324        0.5718  0.0080  1.1713\n",
      "     12            0.7574                     0.7545        \u001b[35m0.5516\u001b[0m            \u001b[31m0.7352\u001b[0m                     0.7310        0.6701  0.0076  1.1731\n",
      "     13            0.7498                     0.7617        0.5567            0.6990                     0.7123        0.5840  0.0072  1.1629\n",
      "     14            \u001b[36m0.7755\u001b[0m                     \u001b[32m0.7784\u001b[0m        \u001b[35m0.5311\u001b[0m            0.7279                     0.7304        \u001b[36m0.5475\u001b[0m  0.0068  1.1679\n",
      "     15            0.7701                     \u001b[32m0.7789\u001b[0m        \u001b[35m0.5075\u001b[0m            0.7221                     0.7315        0.5502  0.0064  1.1629\n",
      "     16            \u001b[36m0.7777\u001b[0m                     \u001b[32m0.7791\u001b[0m        \u001b[35m0.4992\u001b[0m            \u001b[31m0.7395\u001b[0m                     \u001b[94m0.7409\u001b[0m        0.5724  0.0059  1.1639\n",
      "     17            0.7629                     0.7731        0.5195            0.7149                     0.7237        0.5923  0.0055  1.1619\n",
      "     18            0.7723                     0.7725        \u001b[35m0.4951\u001b[0m            0.7294                     0.7287        0.5550  0.0050  1.1639\n",
      "     19            0.7437                     0.7603        \u001b[35m0.4937\u001b[0m            0.7091                     0.7266        0.6493  0.0045  1.1860\n",
      "     20            0.7683                     \u001b[32m0.7800\u001b[0m        \u001b[35m0.4816\u001b[0m            0.7192                     0.7298        0.5541  0.0041  1.1689\n",
      "     21            0.7712                     \u001b[32m0.7816\u001b[0m        \u001b[35m0.4750\u001b[0m            0.7149                     0.7249        \u001b[36m0.5330\u001b[0m  0.0036  1.1683\n",
      "     22            \u001b[36m0.7828\u001b[0m                     0.7805        0.4758            \u001b[31m0.7482\u001b[0m                     \u001b[94m0.7440\u001b[0m        0.5359  0.0032  1.1679\n",
      "     23            \u001b[36m0.7835\u001b[0m                     \u001b[32m0.7875\u001b[0m        \u001b[35m0.4718\u001b[0m            0.7250                     0.7287        0.5417  0.0028  1.1639\n",
      "     24            0.7824                     \u001b[32m0.7887\u001b[0m        \u001b[35m0.4544\u001b[0m            0.7279                     0.7334        \u001b[36m0.5190\u001b[0m  0.0024  1.1739\n",
      "     25            \u001b[36m0.7882\u001b[0m                     \u001b[32m0.7923\u001b[0m        \u001b[35m0.4511\u001b[0m            0.7265                     0.7291        0.5251  0.0020  1.1689\n",
      "     26            0.7853                     \u001b[32m0.7934\u001b[0m        \u001b[35m0.4508\u001b[0m            0.7236                     0.7310        0.5456  0.0016  1.1749\n",
      "     27            \u001b[36m0.7886\u001b[0m                     \u001b[32m0.7966\u001b[0m        \u001b[35m0.4421\u001b[0m            0.7221                     0.7285        0.5484  0.0013  1.1659\n",
      "     28            \u001b[36m0.7965\u001b[0m                     \u001b[32m0.7992\u001b[0m        0.4481            0.7352                     0.7355        0.5314  0.0010  1.1649\n",
      "     29            0.7882                     0.7909        0.4434            0.7250                     0.7260        0.5260  0.0007  1.1619\n",
      "     30            0.7933                     0.7935        \u001b[35m0.4331\u001b[0m            0.7352                     0.7331        0.5366  0.0005  1.1642\n",
      "     31            \u001b[36m0.8041\u001b[0m                     \u001b[32m0.8054\u001b[0m        \u001b[35m0.4328\u001b[0m            0.7308                     0.7301        0.5391  0.0003  1.1659\n",
      "     32            0.7976                     0.7983        0.4371            0.7294                     0.7281        0.5350  0.0002  1.1679\n",
      "     33            0.7954                     0.7962        0.4359            0.7323                     0.7308        0.5327  0.0001  1.1694\n",
      "     34            0.7762                     0.7822        0.4365            0.7207                     0.7263        0.5496  0.0000  1.1679\n",
      "     35            0.7831                     0.7828        \u001b[35m0.4315\u001b[0m            0.7221                     0.7204        0.5324  0.0000  1.1669\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5185\u001b[0m                     \u001b[32m0.5483\u001b[0m        \u001b[35m5.6002\u001b[0m            \u001b[31m0.5152\u001b[0m                     \u001b[94m0.5432\u001b[0m        \u001b[36m5.6289\u001b[0m  0.0100  1.1649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            \u001b[36m0.5692\u001b[0m                     \u001b[32m0.6059\u001b[0m        \u001b[35m2.2843\u001b[0m            \u001b[31m0.5572\u001b[0m                     \u001b[94m0.5960\u001b[0m        \u001b[36m2.4356\u001b[0m  0.0100  1.1649\n",
      "      3            \u001b[36m0.6528\u001b[0m                     \u001b[32m0.6526\u001b[0m        \u001b[35m1.5796\u001b[0m            \u001b[31m0.6368\u001b[0m                     \u001b[94m0.6387\u001b[0m        \u001b[36m1.0819\u001b[0m  0.0099  1.1689\n",
      "      4            0.6086                     0.5976        \u001b[35m1.3491\u001b[0m            0.6049                     0.5951        1.3938  0.0098  1.1639\n",
      "      5            \u001b[36m0.6923\u001b[0m                     \u001b[32m0.7083\u001b[0m        1.4025            \u001b[31m0.6889\u001b[0m                     \u001b[94m0.7067\u001b[0m        \u001b[36m0.8030\u001b[0m  0.0097  1.1639\n",
      "      6            \u001b[36m0.7201\u001b[0m                     \u001b[32m0.7122\u001b[0m        \u001b[35m0.8940\u001b[0m            \u001b[31m0.7091\u001b[0m                     0.7020        \u001b[36m0.7730\u001b[0m  0.0095  1.1679\n",
      "      7            0.7006                     0.6876        0.9035            0.6975                     0.6854        0.8067  0.0093  1.1659\n",
      "      8            \u001b[36m0.7335\u001b[0m                     \u001b[32m0.7357\u001b[0m        \u001b[35m0.7578\u001b[0m            \u001b[31m0.7164\u001b[0m                     \u001b[94m0.7184\u001b[0m        \u001b[36m0.6979\u001b[0m  0.0090  1.1629\n",
      "      9            0.7143                     0.7147        0.7628            \u001b[31m0.7192\u001b[0m                     \u001b[94m0.7199\u001b[0m        \u001b[36m0.6754\u001b[0m  0.0087  1.1679\n",
      "     10            0.6781                     0.6871        \u001b[35m0.6483\u001b[0m            0.6773                     0.6860        0.7557  0.0084  1.1659\n",
      "     11            \u001b[36m0.7440\u001b[0m                     \u001b[32m0.7448\u001b[0m        0.6585            0.7062                     0.7092        \u001b[36m0.6015\u001b[0m  0.0080  1.1599\n",
      "     12            0.7230                     0.7367        \u001b[35m0.5986\u001b[0m            0.7062                     \u001b[94m0.7204\u001b[0m        0.6074  0.0076  1.1719\n",
      "     13            0.7085                     0.7108        0.6128            0.6889                     0.6908        0.9490  0.0072  1.1729\n",
      "     14            0.7020                     0.7163        0.7106            0.6946                     0.7072        0.6885  0.0068  1.1709\n",
      "     15            0.7382                     0.7421        \u001b[35m0.5371\u001b[0m            \u001b[31m0.7424\u001b[0m                     \u001b[94m0.7457\u001b[0m        \u001b[36m0.5685\u001b[0m  0.0064  1.1699\n",
      "     16            0.7364                     0.7433        0.6288            0.7178                     0.7270        0.5955  0.0059  1.1609\n",
      "     17            \u001b[36m0.7632\u001b[0m                     \u001b[32m0.7696\u001b[0m        0.5832            0.7294                     0.7339        \u001b[36m0.5385\u001b[0m  0.0055  1.1619\n",
      "     18            0.7509                     0.7574        0.5621            0.7221                     0.7261        0.5667  0.0050  1.1659\n",
      "     19            \u001b[36m0.7723\u001b[0m                     0.7642        \u001b[35m0.5012\u001b[0m            \u001b[31m0.7554\u001b[0m                     \u001b[94m0.7464\u001b[0m        0.5753  0.0045  1.1649\n",
      "     20            0.7676                     \u001b[32m0.7734\u001b[0m        0.5140            0.7438                     \u001b[94m0.7482\u001b[0m        0.5389  0.0041  1.1649\n",
      "     21            0.7542                     0.7660        \u001b[35m0.4925\u001b[0m            0.7048                     0.7167        0.5599  0.0036  1.1644\n",
      "     22            \u001b[36m0.7831\u001b[0m                     \u001b[32m0.7823\u001b[0m        \u001b[35m0.4813\u001b[0m            0.7294                     0.7269        \u001b[36m0.5350\u001b[0m  0.0032  1.1699\n",
      "     23            0.7730                     \u001b[32m0.7829\u001b[0m        0.4829            0.7265                     0.7372        0.5418  0.0028  1.1659\n",
      "     24            0.7610                     0.7727        \u001b[35m0.4761\u001b[0m            0.7337                     0.7438        0.5444  0.0024  1.1639\n",
      "     25            \u001b[36m0.7864\u001b[0m                     \u001b[32m0.7914\u001b[0m        \u001b[35m0.4656\u001b[0m            0.7323                     0.7356        \u001b[36m0.5288\u001b[0m  0.0020  1.1649\n",
      "     26            0.7618                     0.7732        \u001b[35m0.4622\u001b[0m            0.7207                     0.7299        0.5473  0.0016  1.1609\n",
      "     27            0.7679                     0.7797        \u001b[35m0.4588\u001b[0m            0.7221                     0.7330        0.5379  0.0013  1.1689\n",
      "     28            0.7824                     0.7906        \u001b[35m0.4492\u001b[0m            0.7250                     0.7326        0.5321  0.0010  1.1669\n",
      "     29            0.7781                     0.7868        0.4560            0.7381                     0.7459        \u001b[36m0.5261\u001b[0m  0.0007  1.1708\n",
      "     30            0.7828                     0.7890        0.4499            0.7381                     0.7432        \u001b[36m0.5224\u001b[0m  0.0005  1.1668\n",
      "     31            0.7802                     0.7889        \u001b[35m0.4386\u001b[0m            0.7337                     0.7426        0.5237  0.0003  1.1719\n",
      "     32            \u001b[36m0.7882\u001b[0m                     \u001b[32m0.7955\u001b[0m        \u001b[35m0.4368\u001b[0m            0.7337                     0.7408        0.5243  0.0002  1.1619\n",
      "     33            0.7835                     0.7917        0.4412            0.7294                     0.7366        \u001b[36m0.5217\u001b[0m  0.0001  1.1649\n",
      "     34            0.7864                     0.7930        \u001b[35m0.4358\u001b[0m            0.7323                     0.7389        \u001b[36m0.5215\u001b[0m  0.0000  1.1639\n",
      "     35            0.7878                     0.7947        \u001b[35m0.4310\u001b[0m            0.7294                     0.7351        \u001b[36m0.5179\u001b[0m  0.0000  1.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7394\u001b[0m                     \u001b[32m0.6033\u001b[0m        \u001b[35m3.5782\u001b[0m            \u001b[31m0.7349\u001b[0m                     \u001b[94m0.6020\u001b[0m        \u001b[36m1.7791\u001b[0m  0.0100  3.4526\n",
      "      2            0.5013                     0.6009        \u001b[35m1.8398\u001b[0m            0.4910                     0.5939        3.3464  0.0100  2.7526\n",
      "      3            \u001b[36m0.8256\u001b[0m                     0.5702        1.8890            \u001b[31m0.8292\u001b[0m                     0.5761        \u001b[36m1.2081\u001b[0m  0.0099  2.7502\n",
      "      4            0.6493                     \u001b[32m0.6623\u001b[0m        \u001b[35m1.2394\u001b[0m            0.6458                     \u001b[94m0.6618\u001b[0m        \u001b[36m0.8154\u001b[0m  0.0098  2.7731\n",
      "      5            0.7659                     \u001b[32m0.6703\u001b[0m        \u001b[35m0.7674\u001b[0m            0.7714                     \u001b[94m0.6827\u001b[0m        \u001b[36m0.6260\u001b[0m  0.0097  2.7237\n",
      "      6            0.5824                     \u001b[32m0.6787\u001b[0m        \u001b[35m0.6860\u001b[0m            0.5781                     0.6644        0.7189  0.0095  2.7307\n",
      "      7            0.8226                     0.6664        0.7928            0.8219                     0.6651        0.6830  0.0093  2.7297\n",
      "      8            0.6957                     0.6679        \u001b[35m0.6740\u001b[0m            0.6997                     0.6785        0.6660  0.0090  2.7329\n",
      "      9            0.7126                     \u001b[32m0.7334\u001b[0m        \u001b[35m0.6256\u001b[0m            0.7243                     \u001b[94m0.7387\u001b[0m        \u001b[36m0.5473\u001b[0m  0.0087  2.7337\n",
      "     10            0.7623                     0.6945        \u001b[35m0.5746\u001b[0m            0.7429                     0.6609        0.6092  0.0084  2.7506\n",
      "     11            0.8058                     0.7308        \u001b[35m0.5671\u001b[0m            0.7940                     0.7066        0.5735  0.0080  2.7295\n",
      "     12            0.7806                     \u001b[32m0.7433\u001b[0m        0.5703            0.7681                     0.7157        \u001b[36m0.5466\u001b[0m  0.0076  2.7392\n",
      "     13            0.7116                     0.7408        \u001b[35m0.5509\u001b[0m            0.7070                     0.7341        0.5536  0.0072  2.7367\n",
      "     14            \u001b[36m0.8311\u001b[0m                     0.6964        \u001b[35m0.5483\u001b[0m            \u001b[31m0.8326\u001b[0m                     0.6979        0.6026  0.0068  2.7337\n",
      "     15            0.7817                     \u001b[32m0.7513\u001b[0m        \u001b[35m0.5457\u001b[0m            0.7648                     0.7327        0.5494  0.0064  2.7427\n",
      "     16            0.7201                     0.7493        0.5490            0.7163                     0.7353        0.5492  0.0059  2.7305\n",
      "     17            0.7709                     0.7502        \u001b[35m0.5375\u001b[0m            0.7488                     0.7142        0.5545  0.0055  2.7297\n",
      "     18            0.8174                     0.7408        0.5384            0.7914                     0.7123        0.5664  0.0050  2.7471\n",
      "     19            0.8023                     \u001b[32m0.7536\u001b[0m        \u001b[35m0.5349\u001b[0m            0.7887                     0.7282        0.5560  0.0045  2.7592\n",
      "     20            0.7708                     \u001b[32m0.7538\u001b[0m        \u001b[35m0.5330\u001b[0m            0.7542                     0.7218        0.5514  0.0041  2.7367\n",
      "     21            0.7924                     \u001b[32m0.7541\u001b[0m        0.5376            0.7721                     0.7181        0.5575  0.0036  2.7447\n",
      "     22            0.8028                     \u001b[32m0.7634\u001b[0m        \u001b[35m0.5214\u001b[0m            0.7774                     0.7214        0.5528  0.0032  2.7360\n",
      "     23            0.8053                     0.7451        \u001b[35m0.5134\u001b[0m            0.7834                     0.7089        0.5699  0.0028  2.7408\n",
      "     24            0.7678                     \u001b[32m0.7651\u001b[0m        \u001b[35m0.5120\u001b[0m            0.7488                     0.7274        \u001b[36m0.5401\u001b[0m  0.0024  2.7536\n",
      "     25            0.7960                     0.7603        \u001b[35m0.5115\u001b[0m            0.7807                     0.7278        0.5457  0.0020  2.7706\n",
      "     26            0.7814                     \u001b[32m0.7760\u001b[0m        \u001b[35m0.5082\u001b[0m            0.7581                     0.7345        \u001b[36m0.5355\u001b[0m  0.0016  2.7389\n",
      "     27            0.7937                     0.7688        \u001b[35m0.5050\u001b[0m            0.7701                     0.7272        0.5425  0.0013  2.7328\n",
      "     28            0.8093                     0.7637        \u001b[35m0.4988\u001b[0m            0.7927                     0.7350        0.5440  0.0010  2.7686\n",
      "     29            0.8110                     0.7745        \u001b[35m0.4961\u001b[0m            0.7900                     0.7349        0.5366  0.0007  2.7532\n",
      "     30            0.8121                     \u001b[32m0.7789\u001b[0m        \u001b[35m0.4882\u001b[0m            0.7900                     0.7364        0.5373  0.0005  2.7427\n",
      "     31            0.7944                     \u001b[32m0.7816\u001b[0m        0.4942            0.7688                     0.7380        \u001b[36m0.5321\u001b[0m  0.0003  2.7556\n",
      "     32            0.8174                     0.7682        0.4905            0.7967                     0.7170        0.5418  0.0002  2.7317\n",
      "     33            0.8116                     0.7775        0.4942            0.7940                     0.7359        0.5370  0.0001  2.7696\n",
      "     34            0.8154                     0.7678        \u001b[35m0.4871\u001b[0m            0.7987                     0.7299        0.5420  0.0000  2.7462\n",
      "     35            0.8169                     0.7738        0.4893            0.7993                     0.7362        0.5406  0.0000  2.7407\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5151\u001b[0m                     \u001b[32m0.5251\u001b[0m        \u001b[35m4.0674\u001b[0m            \u001b[31m0.5196\u001b[0m                     \u001b[94m0.5324\u001b[0m        \u001b[36m3.3406\u001b[0m  0.0100  2.6037\n",
      "      2            0.3756                     \u001b[32m0.5654\u001b[0m        \u001b[35m2.0762\u001b[0m            0.3681                     \u001b[94m0.5630\u001b[0m        \u001b[36m3.1974\u001b[0m  0.0100  2.5791\n",
      "      3            \u001b[36m0.8110\u001b[0m                     \u001b[32m0.6209\u001b[0m        \u001b[35m1.4088\u001b[0m            \u001b[31m0.8159\u001b[0m                     \u001b[94m0.6337\u001b[0m        \u001b[36m0.9155\u001b[0m  0.0099  2.5741\n",
      "      4            \u001b[36m0.8194\u001b[0m                     \u001b[32m0.6257\u001b[0m        \u001b[35m0.9130\u001b[0m            \u001b[31m0.8385\u001b[0m                     \u001b[94m0.6533\u001b[0m        0.9193  0.0098  2.5771\n",
      "      5            0.6460                     \u001b[32m0.6837\u001b[0m        \u001b[35m0.7362\u001b[0m            0.6551                     \u001b[94m0.7025\u001b[0m        \u001b[36m0.6141\u001b[0m  0.0097  2.5761\n",
      "      6            0.7591                     \u001b[32m0.7010\u001b[0m        \u001b[35m0.7238\u001b[0m            0.7668                     \u001b[94m0.7178\u001b[0m        \u001b[36m0.5976\u001b[0m  0.0095  2.5701\n",
      "      7            0.7419                     0.6352        \u001b[35m0.7173\u001b[0m            0.7561                     0.6734        0.9229  0.0093  2.5850\n",
      "      8            0.7794                     0.6858        \u001b[35m0.6675\u001b[0m            0.7847                     0.6951        \u001b[36m0.5805\u001b[0m  0.0090  2.5701\n",
      "      9            0.6985                     \u001b[32m0.7270\u001b[0m        \u001b[35m0.5909\u001b[0m            0.6983                     \u001b[94m0.7200\u001b[0m        \u001b[36m0.5495\u001b[0m  0.0087  2.5697\n",
      "     10            0.8125                     0.7060        \u001b[35m0.5672\u001b[0m            0.8226                     \u001b[94m0.7299\u001b[0m        0.5622  0.0084  2.5791\n",
      "     11            0.7885                     0.7210        0.5831            0.7940                     0.7227        0.5662  0.0080  2.5774\n",
      "     12            0.8015                     0.7253        \u001b[35m0.5502\u001b[0m            0.8093                     0.7247        0.5599  0.0076  2.5771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     13            0.7890                     \u001b[32m0.7279\u001b[0m        0.5542            0.7834                     0.7250        0.5502  0.0072  2.5841\n",
      "     14            0.7970                     \u001b[32m0.7306\u001b[0m        0.5532            0.8086                     0.7272        \u001b[36m0.5491\u001b[0m  0.0068  2.5742\n",
      "     15            0.8181                     0.7269        0.5563            0.8252                     \u001b[94m0.7344\u001b[0m        0.5564  0.0064  2.5810\n",
      "     16            0.8013                     \u001b[32m0.7471\u001b[0m        \u001b[35m0.5478\u001b[0m            0.7993                     \u001b[94m0.7376\u001b[0m        \u001b[36m0.5472\u001b[0m  0.0059  2.5851\n",
      "     17            0.7829                     \u001b[32m0.7578\u001b[0m        \u001b[35m0.5398\u001b[0m            0.7748                     \u001b[94m0.7388\u001b[0m        \u001b[36m0.5290\u001b[0m  0.0055  2.5771\n",
      "     18            0.7922                     0.7551        \u001b[35m0.5376\u001b[0m            0.7947                     \u001b[94m0.7538\u001b[0m        0.5305  0.0050  2.5841\n",
      "     19            \u001b[36m0.8236\u001b[0m                     0.7354        \u001b[35m0.5255\u001b[0m            0.8279                     0.7360        0.5460  0.0045  2.5738\n",
      "     20            0.8090                     \u001b[32m0.7583\u001b[0m        \u001b[35m0.5222\u001b[0m            0.8173                     \u001b[94m0.7646\u001b[0m        0.5310  0.0041  2.5831\n",
      "     21            0.8088                     0.7429        \u001b[35m0.5217\u001b[0m            0.8100                     0.7324        0.5419  0.0036  2.5821\n",
      "     22            0.7389                     \u001b[32m0.7622\u001b[0m        0.5224            0.7482                     0.7547        \u001b[36m0.5196\u001b[0m  0.0032  2.5789\n",
      "     23            0.7960                     \u001b[32m0.7633\u001b[0m        \u001b[35m0.5197\u001b[0m            0.7987                     0.7518        0.5238  0.0028  2.5803\n",
      "     24            0.8037                     \u001b[32m0.7701\u001b[0m        \u001b[35m0.5176\u001b[0m            0.8060                     0.7548        0.5217  0.0024  2.5821\n",
      "     25            0.7927                     \u001b[32m0.7718\u001b[0m        \u001b[35m0.5116\u001b[0m            0.7993                     \u001b[94m0.7669\u001b[0m        0.5198  0.0020  2.5900\n",
      "     26            0.8081                     0.7666        \u001b[35m0.5106\u001b[0m            0.8066                     0.7596        0.5267  0.0016  2.5851\n",
      "     27            0.8048                     \u001b[32m0.7734\u001b[0m        \u001b[35m0.4959\u001b[0m            0.8080                     0.7633        0.5214  0.0013  2.5752\n",
      "     28            0.7849                     \u001b[32m0.7792\u001b[0m        0.4989            0.7874                     \u001b[94m0.7669\u001b[0m        0.5212  0.0010  2.5751\n",
      "     29            0.8065                     0.7769        0.4962            0.8153                     \u001b[94m0.7707\u001b[0m        \u001b[36m0.5185\u001b[0m  0.0007  2.5781\n",
      "     30            0.8013                     0.7723        \u001b[35m0.4817\u001b[0m            0.8133                     \u001b[94m0.7710\u001b[0m        0.5198  0.0005  2.6003\n",
      "     31            0.8050                     0.7786        0.4918            0.8093                     0.7656        0.5200  0.0003  2.6140\n",
      "     32            0.7945                     0.7741        0.4929            0.8060                     \u001b[94m0.7724\u001b[0m        0.5203  0.0002  2.5946\n",
      "     33            0.8061                     0.7724        0.4895            0.8126                     0.7676        0.5213  0.0001  2.6060\n",
      "     34            0.7885                     \u001b[32m0.7810\u001b[0m        0.4856            0.7987                     0.7723        0.5187  0.0000  2.6050\n",
      "     35            0.7947                     0.7804        0.4863            0.8080                     \u001b[94m0.7780\u001b[0m        \u001b[36m0.5174\u001b[0m  0.0000  2.6134\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6904\u001b[0m                     \u001b[32m0.5856\u001b[0m        \u001b[35m4.8829\u001b[0m            \u001b[31m0.6784\u001b[0m                     \u001b[94m0.5720\u001b[0m        \u001b[36m2.4744\u001b[0m  0.0100  2.6988\n",
      "      2            \u001b[36m0.6907\u001b[0m                     \u001b[32m0.6612\u001b[0m        \u001b[35m2.1309\u001b[0m            0.6731                     \u001b[94m0.6345\u001b[0m        \u001b[36m0.9621\u001b[0m  0.0100  2.6962\n",
      "      3            0.6729                     0.6577        \u001b[35m1.2609\u001b[0m            0.6485                     \u001b[94m0.6371\u001b[0m        1.3579  0.0099  2.7140\n",
      "      4            \u001b[36m0.7492\u001b[0m                     0.6100        \u001b[35m1.1327\u001b[0m            \u001b[31m0.7276\u001b[0m                     0.5800        1.2284  0.0098  2.6978\n",
      "      5            \u001b[36m0.8168\u001b[0m                     \u001b[32m0.6855\u001b[0m        \u001b[35m0.8322\u001b[0m            \u001b[31m0.7967\u001b[0m                     \u001b[94m0.6629\u001b[0m        \u001b[36m0.7044\u001b[0m  0.0097  2.6988\n",
      "      6            0.7032                     \u001b[32m0.7291\u001b[0m        \u001b[35m0.7788\u001b[0m            0.6837                     \u001b[94m0.7009\u001b[0m        \u001b[36m0.6020\u001b[0m  0.0095  2.7152\n",
      "      7            0.7218                     0.7016        \u001b[35m0.6769\u001b[0m            0.7156                     0.6911        0.7442  0.0093  2.7100\n",
      "      8            0.7518                     \u001b[32m0.7393\u001b[0m        0.6981            0.7216                     \u001b[94m0.7064\u001b[0m        \u001b[36m0.5777\u001b[0m  0.0090  2.7028\n",
      "      9            0.7168                     0.7092        0.7134            0.6870                     0.6766        0.6126  0.0087  2.7217\n",
      "     10            0.6352                     0.6699        \u001b[35m0.6481\u001b[0m            0.6040                     0.6466        0.7251  0.0084  2.7278\n",
      "     11            0.7920                     0.7250        0.6844            0.7581                     0.7023        0.5843  0.0080  2.7201\n",
      "     12            0.8146                     0.7204        \u001b[35m0.5616\u001b[0m            0.7827                     0.6749        0.6139  0.0076  2.6998\n",
      "     13            0.8093                     \u001b[32m0.7428\u001b[0m        0.5775            0.7767                     0.6990        \u001b[36m0.5675\u001b[0m  0.0072  2.7157\n",
      "     14            0.7535                     \u001b[32m0.7539\u001b[0m        \u001b[35m0.5546\u001b[0m            0.7130                     \u001b[94m0.7158\u001b[0m        0.5686  0.0068  2.7173\n",
      "     15            0.7261                     0.7496        0.5811            0.7083                     \u001b[94m0.7173\u001b[0m        \u001b[36m0.5636\u001b[0m  0.0064  2.7240\n",
      "     16            0.8133                     0.7441        0.5676            0.7741                     0.6843        0.5746  0.0059  2.7237\n",
      "     17            0.7834                     \u001b[32m0.7622\u001b[0m        \u001b[35m0.5443\u001b[0m            0.7455                     0.7166        0.5733  0.0055  2.7336\n",
      "     18            0.7586                     0.7277        \u001b[35m0.5422\u001b[0m            0.7169                     0.6729        0.5955  0.0050  2.7200\n",
      "     19            0.8010                     0.7571        \u001b[35m0.5300\u001b[0m            0.7502                     0.6843        0.5792  0.0045  2.7357\n",
      "     20            0.7681                     0.7595        \u001b[35m0.5137\u001b[0m            0.7316                     0.7169        \u001b[36m0.5630\u001b[0m  0.0041  2.7199\n",
      "     21            0.7281                     \u001b[32m0.7644\u001b[0m        0.5277            0.6890                     \u001b[94m0.7348\u001b[0m        \u001b[36m0.5557\u001b[0m  0.0036  2.7402\n",
      "     22            0.7693                     \u001b[32m0.7766\u001b[0m        0.5239            0.7209                     0.7221        0.5630  0.0032  2.7259\n",
      "     23            0.7713                     0.7734        0.5163            0.7355                     \u001b[94m0.7368\u001b[0m        \u001b[36m0.5476\u001b[0m  0.0028  2.7197\n",
      "     24            \u001b[36m0.8204\u001b[0m                     0.7609        \u001b[35m0.5072\u001b[0m            0.7887                     0.7107        0.5661  0.0024  2.7327\n",
      "     25            0.8000                     \u001b[32m0.7774\u001b[0m        \u001b[35m0.5049\u001b[0m            0.7648                     0.7341        0.5554  0.0020  2.7302\n",
      "     26            0.8080                     \u001b[32m0.7782\u001b[0m        \u001b[35m0.5000\u001b[0m            0.7714                     \u001b[94m0.7382\u001b[0m        0.5516  0.0016  2.5737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     27            0.8083                     0.7652        \u001b[35m0.4888\u001b[0m            0.7701                     0.7125        0.5608  0.0013  2.5761\n",
      "     28            0.8164                     \u001b[32m0.7815\u001b[0m        0.4953            0.7787                     0.7324        0.5490  0.0010  2.5761\n",
      "     29            0.8053                     \u001b[32m0.7890\u001b[0m        \u001b[35m0.4852\u001b[0m            0.7661                     0.7350        0.5514  0.0007  2.5761\n",
      "     30            0.8008                     0.7885        \u001b[35m0.4722\u001b[0m            0.7621                     0.7355        0.5558  0.0005  2.5770\n",
      "     31            0.8018                     \u001b[32m0.7957\u001b[0m        0.4790            0.7548                     0.7354        0.5525  0.0003  2.5801\n",
      "     32            0.8096                     0.7928        \u001b[35m0.4682\u001b[0m            0.7648                     0.7298        0.5497  0.0002  2.5821\n",
      "     33            0.8133                     0.7917        0.4717            0.7681                     0.7318        0.5530  0.0001  2.5795\n",
      "     34            0.8146                     0.7903        \u001b[35m0.4642\u001b[0m            0.7714                     0.7323        0.5495  0.0000  2.5813\n",
      "     35            0.8131                     0.7887        0.4703            0.7668                     0.7295        0.5522  0.0000  2.5871\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7944\u001b[0m                     \u001b[32m0.5731\u001b[0m        \u001b[35m4.1682\u001b[0m            \u001b[31m0.7960\u001b[0m                     \u001b[94m0.5778\u001b[0m        \u001b[36m2.7862\u001b[0m  0.0100  2.5757\n",
      "      2            0.6919                     \u001b[32m0.6794\u001b[0m        \u001b[35m1.7989\u001b[0m            0.6585                     \u001b[94m0.6417\u001b[0m        \u001b[36m0.9244\u001b[0m  0.0100  2.5791\n",
      "      3            0.6480                     0.6743        \u001b[35m1.2391\u001b[0m            0.6405                     \u001b[94m0.6644\u001b[0m        1.0679  0.0099  2.5751\n",
      "      4            0.7791                     0.6648        \u001b[35m0.8719\u001b[0m            0.7628                     0.6365        \u001b[36m0.7863\u001b[0m  0.0098  2.5781\n",
      "      5            0.6262                     \u001b[32m0.6809\u001b[0m        0.9170            0.5980                     0.6532        0.8391  0.0097  2.5929\n",
      "      6            0.7532                     0.6450        \u001b[35m0.8385\u001b[0m            0.7635                     0.6573        \u001b[36m0.6456\u001b[0m  0.0095  2.5786\n",
      "      7            0.7159                     \u001b[32m0.6985\u001b[0m        \u001b[35m0.6751\u001b[0m            0.6957                     \u001b[94m0.6746\u001b[0m        0.8478  0.0093  2.5861\n",
      "      8            0.6905                     \u001b[32m0.7152\u001b[0m        \u001b[35m0.6512\u001b[0m            0.6771                     \u001b[94m0.7071\u001b[0m        \u001b[36m0.5832\u001b[0m  0.0090  2.5761\n",
      "      9            0.7510                     \u001b[32m0.7293\u001b[0m        \u001b[35m0.6044\u001b[0m            0.7276                     0.6954        \u001b[36m0.5804\u001b[0m  0.0087  2.5896\n",
      "     10            \u001b[36m0.8111\u001b[0m                     0.6770        \u001b[35m0.5896\u001b[0m            \u001b[31m0.8047\u001b[0m                     0.6634        0.6486  0.0084  2.5791\n",
      "     11            0.7882                     \u001b[32m0.7351\u001b[0m        0.5960            0.7701                     0.6994        \u001b[36m0.5732\u001b[0m  0.0080  2.5853\n",
      "     12            0.7679                     \u001b[32m0.7381\u001b[0m        \u001b[35m0.5657\u001b[0m            0.7462                     \u001b[94m0.7111\u001b[0m        \u001b[36m0.5722\u001b[0m  0.0076  2.5881\n",
      "     13            0.7874                     \u001b[32m0.7408\u001b[0m        \u001b[35m0.5528\u001b[0m            0.7674                     0.7022        0.5909  0.0072  2.6677\n",
      "     14            0.7620                     \u001b[32m0.7554\u001b[0m        \u001b[35m0.5465\u001b[0m            0.7203                     0.7100        \u001b[36m0.5556\u001b[0m  0.0068  2.6909\n",
      "     15            0.7728                     0.7188        \u001b[35m0.5359\u001b[0m            0.7801                     \u001b[94m0.7142\u001b[0m        0.5864  0.0064  2.7233\n",
      "     16            0.7458                     \u001b[32m0.7573\u001b[0m        \u001b[35m0.5350\u001b[0m            0.7243                     \u001b[94m0.7153\u001b[0m        0.5631  0.0059  2.7267\n",
      "     17            \u001b[36m0.8194\u001b[0m                     \u001b[32m0.7680\u001b[0m        \u001b[35m0.5333\u001b[0m            0.7927                     \u001b[94m0.7307\u001b[0m        0.5637  0.0055  2.7224\n",
      "     18            0.7075                     0.7251        \u001b[35m0.5308\u001b[0m            0.6944                     0.6840        0.6141  0.0050  2.7070\n",
      "     19            0.7822                     0.7677        \u001b[35m0.5152\u001b[0m            0.7608                     \u001b[94m0.7361\u001b[0m        \u001b[36m0.5492\u001b[0m  0.0045  2.7367\n",
      "     20            0.7302                     \u001b[32m0.7712\u001b[0m        \u001b[35m0.5146\u001b[0m            0.6990                     0.7219        0.5628  0.0041  2.7327\n",
      "     21            0.7987                     \u001b[32m0.7795\u001b[0m        0.5181            0.7635                     0.7246        0.5536  0.0036  2.7368\n",
      "     22            0.7832                     \u001b[32m0.7855\u001b[0m        \u001b[35m0.5033\u001b[0m            0.7535                     0.7258        \u001b[36m0.5483\u001b[0m  0.0032  2.6657\n",
      "     23            0.8096                     0.7825        \u001b[35m0.5006\u001b[0m            0.7874                     \u001b[94m0.7391\u001b[0m        0.5483  0.0028  2.6719\n",
      "     24            0.8028                     0.7824        \u001b[35m0.4964\u001b[0m            0.7668                     0.7149        0.5574  0.0024  2.7178\n",
      "     25            0.7977                     \u001b[32m0.7928\u001b[0m        \u001b[35m0.4917\u001b[0m            0.7561                     0.7318        0.5535  0.0020  2.6953\n",
      "     26            \u001b[36m0.8291\u001b[0m                     0.7702        \u001b[35m0.4846\u001b[0m            0.7993                     0.7216        0.5673  0.0016  2.6851\n",
      "     27            0.8145                     0.7913        0.4906            0.7701                     0.7198        0.5683  0.0013  2.6629\n",
      "     28            \u001b[36m0.8322\u001b[0m                     0.7824        \u001b[35m0.4816\u001b[0m            0.7894                     0.7155        0.5529  0.0010  2.6399\n",
      "     29            0.8169                     0.7903        \u001b[35m0.4770\u001b[0m            0.7774                     0.7243        \u001b[36m0.5479\u001b[0m  0.0007  2.6569\n",
      "     30            0.8060                     0.7913        \u001b[35m0.4741\u001b[0m            0.7621                     0.7223        0.5508  0.0005  2.6539\n",
      "     31            0.8156                     \u001b[32m0.7946\u001b[0m        \u001b[35m0.4718\u001b[0m            0.7741                     0.7281        0.5536  0.0003  2.6497\n",
      "     32            0.8203                     0.7897        \u001b[35m0.4656\u001b[0m            0.7860                     0.7266        0.5563  0.0002  2.6689\n",
      "     33            0.8113                     0.7894        \u001b[35m0.4655\u001b[0m            0.7781                     0.7247        \u001b[36m0.5470\u001b[0m  0.0001  2.6489\n",
      "     34            0.8178                     0.7904        0.4678            0.7761                     0.7235        0.5528  0.0000  2.6740\n",
      "     35            0.8204                     0.7898        0.4667            0.7827                     0.7261        0.5496  0.0000  2.6589\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7802\u001b[0m                     \u001b[32m0.6307\u001b[0m        \u001b[35m5.0915\u001b[0m            \u001b[31m0.7648\u001b[0m                     \u001b[94m0.6128\u001b[0m        \u001b[36m2.3032\u001b[0m  0.0100  2.6460\n",
      "      2            0.5611                     0.6178        \u001b[35m1.9160\u001b[0m            0.5635                     \u001b[94m0.6307\u001b[0m        \u001b[36m2.2142\u001b[0m  0.0100  2.6517\n",
      "      3            0.5973                     0.6249        \u001b[35m1.6518\u001b[0m            0.5741                     0.6021        \u001b[36m1.5698\u001b[0m  0.0099  2.6509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4            0.6865                     \u001b[32m0.6736\u001b[0m        \u001b[35m1.1693\u001b[0m            0.6738                     \u001b[94m0.6466\u001b[0m        \u001b[36m0.6848\u001b[0m  0.0098  2.6479\n",
      "      5            0.7154                     \u001b[32m0.7176\u001b[0m        \u001b[35m0.7501\u001b[0m            0.7196                     \u001b[94m0.7096\u001b[0m        \u001b[36m0.5843\u001b[0m  0.0097  2.6570\n",
      "      6            0.5350                     0.6422        \u001b[35m0.6751\u001b[0m            0.5302                     0.6251        0.8821  0.0095  2.6560\n",
      "      7            0.6827                     0.6545        0.7512            0.6757                     0.6551        0.8578  0.0093  2.6559\n",
      "      8            0.7390                     0.7015        0.6796            0.7249                     0.6807        0.6540  0.0090  2.6559\n",
      "      9            0.7400                     0.7138        \u001b[35m0.6044\u001b[0m            0.7276                     0.6954        0.5939  0.0087  2.6577\n",
      "     10            0.7316                     \u001b[32m0.7376\u001b[0m        \u001b[35m0.5693\u001b[0m            0.7090                     0.6943        \u001b[36m0.5634\u001b[0m  0.0084  2.6552\n",
      "     11            0.7317                     \u001b[32m0.7578\u001b[0m        0.5703            0.7096                     \u001b[94m0.7123\u001b[0m        \u001b[36m0.5579\u001b[0m  0.0080  2.6524\n",
      "     12            0.7694                     0.7237        0.5919            0.7435                     0.6832        0.5963  0.0076  2.6639\n",
      "     13            0.7593                     0.7128        0.6252            0.7336                     0.6903        0.5949  0.0072  2.6539\n",
      "     14            0.7547                     0.7462        \u001b[35m0.5590\u001b[0m            0.7249                     0.7026        0.5684  0.0068  2.6577\n",
      "     15            \u001b[36m0.8050\u001b[0m                     0.7442        \u001b[35m0.5511\u001b[0m            \u001b[31m0.7794\u001b[0m                     0.7065        0.5694  0.0064  2.6579\n",
      "     16            0.7397                     0.7382        0.5579            0.7110                     0.6985        0.5765  0.0059  2.6699\n",
      "     17            0.7585                     \u001b[32m0.7613\u001b[0m        \u001b[35m0.5423\u001b[0m            0.7395                     \u001b[94m0.7173\u001b[0m        \u001b[36m0.5512\u001b[0m  0.0055  2.6629\n",
      "     18            0.7846                     0.7567        \u001b[35m0.5372\u001b[0m            0.7601                     0.7109        0.5588  0.0050  2.6456\n",
      "     19            0.7414                     0.7534        \u001b[35m0.5297\u001b[0m            0.7183                     0.7117        0.5609  0.0045  2.6489\n",
      "     20            0.7176                     0.7518        \u001b[35m0.5295\u001b[0m            0.7023                     0.7166        0.5633  0.0041  2.6599\n",
      "     21            0.7831                     \u001b[32m0.7634\u001b[0m        \u001b[35m0.5278\u001b[0m            0.7515                     0.7114        0.5656  0.0036  2.6553\n",
      "     22            0.7875                     0.7563        \u001b[35m0.5221\u001b[0m            0.7588                     0.7086        0.5746  0.0032  2.6624\n",
      "     23            0.7841                     0.7633        \u001b[35m0.5191\u001b[0m            0.7502                     0.6916        0.5755  0.0028  2.6758\n",
      "     24            0.7942                     \u001b[32m0.7654\u001b[0m        \u001b[35m0.5188\u001b[0m            0.7688                     0.7073        0.5623  0.0024  2.6561\n",
      "     25            0.7963                     \u001b[32m0.7759\u001b[0m        \u001b[35m0.5127\u001b[0m            0.7575                     0.7107        0.5677  0.0020  2.6499\n",
      "     26            0.8015                     \u001b[32m0.7801\u001b[0m        \u001b[35m0.5096\u001b[0m            0.7628                     0.7081        0.5630  0.0016  2.6659\n",
      "     27            0.7889                     0.7735        \u001b[35m0.5083\u001b[0m            0.7575                     0.7107        0.5579  0.0013  2.6529\n",
      "     28            0.7870                     0.7717        \u001b[35m0.5018\u001b[0m            0.7555                     0.7168        0.5596  0.0010  2.6545\n",
      "     29            0.7902                     0.7755        0.5024            0.7515                     0.7027        0.5625  0.0007  2.6509\n",
      "     30            \u001b[36m0.8125\u001b[0m                     0.7766        0.5022            0.7635                     0.7012        0.5645  0.0005  2.6699\n",
      "     31            0.8015                     \u001b[32m0.7820\u001b[0m        \u001b[35m0.4985\u001b[0m            0.7548                     0.7062        0.5597  0.0003  2.6670\n",
      "     32            0.7967                     0.7812        \u001b[35m0.4925\u001b[0m            0.7548                     0.7105        0.5609  0.0002  2.6674\n",
      "     33            0.8051                     0.7813        \u001b[35m0.4924\u001b[0m            0.7668                     0.7164        0.5617  0.0001  2.6712\n",
      "     34            0.7997                     \u001b[32m0.7830\u001b[0m        0.4926            0.7608                     0.7127        0.5625  0.0000  2.6514\n",
      "     35            0.8085                     0.7785        \u001b[35m0.4904\u001b[0m            0.7721                     0.7152        0.5618  0.0000  2.6469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 1 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5484\u001b[0m                     \u001b[32m0.5473\u001b[0m        \u001b[35m3.6059\u001b[0m            \u001b[31m0.5514\u001b[0m                     \u001b[94m0.5508\u001b[0m        \u001b[36m1.7572\u001b[0m  0.0100  2.1095\n",
      "      2            0.5348                     0.5347        \u001b[35m2.1119\u001b[0m            \u001b[31m0.5583\u001b[0m                     \u001b[94m0.5583\u001b[0m        \u001b[36m1.5123\u001b[0m  0.0100  1.9403\n",
      "      3            \u001b[36m0.5709\u001b[0m                     \u001b[32m0.5738\u001b[0m        2.4353            \u001b[31m0.5687\u001b[0m                     \u001b[94m0.5716\u001b[0m        2.2112  0.0099  1.9558\n",
      "      4            \u001b[36m0.6773\u001b[0m                     \u001b[32m0.6766\u001b[0m        \u001b[35m1.2611\u001b[0m            \u001b[31m0.6863\u001b[0m                     \u001b[94m0.6858\u001b[0m        \u001b[36m0.6323\u001b[0m  0.0098  1.9540\n",
      "      5            0.6736                     0.6732        \u001b[35m0.8345\u001b[0m            0.6698                     0.6698        0.7664  0.0097  1.9582\n",
      "      6            0.6074                     0.6104        1.0469            0.6171                     0.6201        1.1241  0.0095  1.9501\n",
      "      7            \u001b[36m0.6917\u001b[0m                     \u001b[32m0.6922\u001b[0m        \u001b[35m0.7456\u001b[0m            0.6854                     \u001b[94m0.6860\u001b[0m        0.7407  0.0093  1.9449\n",
      "      8            0.6308                     0.6334        \u001b[35m0.6705\u001b[0m            0.6404                     0.6432        1.1887  0.0090  1.9518\n",
      "      9            0.6872                     0.6861        0.7833            0.6603                     0.6592        0.6550  0.0087  1.9498\n",
      "     10            0.6535                     0.6549        \u001b[35m0.6601\u001b[0m            0.6560                     0.6575        0.9097  0.0084  1.9508\n",
      "     11            \u001b[36m0.7181\u001b[0m                     \u001b[32m0.7168\u001b[0m        0.7723            \u001b[31m0.7165\u001b[0m                     \u001b[94m0.7151\u001b[0m        \u001b[36m0.5632\u001b[0m  0.0080  1.9518\n",
      "     12            \u001b[36m0.7544\u001b[0m                     \u001b[32m0.7540\u001b[0m        \u001b[35m0.5995\u001b[0m            \u001b[31m0.7502\u001b[0m                     \u001b[94m0.7498\u001b[0m        \u001b[36m0.5369\u001b[0m  0.0076  1.9581\n",
      "     13            0.7518                     0.7521        0.6328            0.7485                     0.7487        \u001b[36m0.5343\u001b[0m  0.0072  1.9520\n",
      "     14            0.7423                     0.7438        \u001b[35m0.5830\u001b[0m            0.7381                     0.7396        0.5536  0.0068  1.9508\n",
      "     15            \u001b[36m0.7659\u001b[0m                     \u001b[32m0.7660\u001b[0m        \u001b[35m0.5679\u001b[0m            \u001b[31m0.7571\u001b[0m                     \u001b[94m0.7573\u001b[0m        \u001b[36m0.5237\u001b[0m  0.0064  1.9468\n",
      "     16            \u001b[36m0.7711\u001b[0m                     \u001b[32m0.7711\u001b[0m        \u001b[35m0.5586\u001b[0m            \u001b[31m0.7675\u001b[0m                     \u001b[94m0.7674\u001b[0m        \u001b[36m0.5056\u001b[0m  0.0059  1.9535\n",
      "     17            0.7689                     0.7691        \u001b[35m0.5486\u001b[0m            \u001b[31m0.7684\u001b[0m                     \u001b[94m0.7686\u001b[0m        0.5286  0.0055  1.9528\n",
      "     18            0.7531                     0.7525        \u001b[35m0.5209\u001b[0m            0.7511                     0.7504        0.5415  0.0050  1.9518\n",
      "     19            0.7670                     0.7669        0.5603            0.7554                     0.7553        0.5340  0.0045  1.9568\n",
      "     20            0.7704                     0.7700        \u001b[35m0.5173\u001b[0m            \u001b[31m0.7692\u001b[0m                     \u001b[94m0.7688\u001b[0m        0.5137  0.0041  1.9558\n",
      "     21            \u001b[36m0.7942\u001b[0m                     \u001b[32m0.7949\u001b[0m        \u001b[35m0.5057\u001b[0m            \u001b[31m0.7822\u001b[0m                     \u001b[94m0.7830\u001b[0m        \u001b[36m0.4848\u001b[0m  0.0036  1.9518\n",
      "     22            \u001b[36m0.7944\u001b[0m                     \u001b[32m0.7949\u001b[0m        \u001b[35m0.4907\u001b[0m            \u001b[31m0.7848\u001b[0m                     \u001b[94m0.7852\u001b[0m        0.4989  0.0032  1.9498\n",
      "     23            \u001b[36m0.8009\u001b[0m                     \u001b[32m0.8012\u001b[0m        \u001b[35m0.4883\u001b[0m            \u001b[31m0.7917\u001b[0m                     \u001b[94m0.7919\u001b[0m        0.5000  0.0028  1.9650\n",
      "     24            \u001b[36m0.8072\u001b[0m                     \u001b[32m0.8070\u001b[0m        \u001b[35m0.4758\u001b[0m            0.7908                     0.7905        \u001b[36m0.4741\u001b[0m  0.0024  1.9528\n",
      "     25            0.8054                     0.8061        \u001b[35m0.4601\u001b[0m            0.7796                     0.7803        0.4966  0.0020  1.9518\n",
      "     26            \u001b[36m0.8156\u001b[0m                     \u001b[32m0.8153\u001b[0m        0.4635            0.7857                     0.7853        0.4778  0.0016  1.9553\n",
      "     27            0.8106                     0.8112        \u001b[35m0.4561\u001b[0m            0.7900                     0.7907        0.4771  0.0013  1.9558\n",
      "     28            0.8134                     0.8138        \u001b[35m0.4377\u001b[0m            0.7632                     0.7635        0.4837  0.0010  1.9597\n",
      "     29            0.8124                     0.8129        \u001b[35m0.4356\u001b[0m            0.7770                     0.7776        0.4808  0.0007  1.9598\n",
      "     30            \u001b[36m0.8221\u001b[0m                     \u001b[32m0.8222\u001b[0m        0.4365            0.7848                     0.7849        0.4755  0.0005  1.9508\n",
      "     31            0.8210                     0.8214        0.4367            0.7865                     0.7869        0.4745  0.0003  1.9548\n",
      "     32            \u001b[36m0.8234\u001b[0m                     \u001b[32m0.8237\u001b[0m        \u001b[35m0.4269\u001b[0m            0.7891                     0.7895        0.4744  0.0002  1.9684\n",
      "     33            0.8143                     0.8149        \u001b[35m0.4269\u001b[0m            0.7857                     0.7863        0.4760  0.0001  1.9528\n",
      "     34            0.8234                     \u001b[32m0.8237\u001b[0m        \u001b[35m0.4223\u001b[0m            0.7908                     0.7912        \u001b[36m0.4717\u001b[0m  0.0000  1.9488\n",
      "     35            0.8176                     0.8181        0.4227            0.7900                     0.7906        0.4743  0.0000  1.9548\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5266\u001b[0m                     \u001b[32m0.5289\u001b[0m        \u001b[35m3.7596\u001b[0m            \u001b[31m0.4952\u001b[0m                     \u001b[94m0.4979\u001b[0m        \u001b[36m2.5085\u001b[0m  0.0100  1.9548\n",
      "      2            \u001b[36m0.5642\u001b[0m                     \u001b[32m0.5616\u001b[0m        \u001b[35m1.9728\u001b[0m            \u001b[31m0.5756\u001b[0m                     \u001b[94m0.5729\u001b[0m        \u001b[36m1.2099\u001b[0m  0.0100  1.9393\n",
      "      3            \u001b[36m0.6429\u001b[0m                     \u001b[32m0.6415\u001b[0m        \u001b[35m1.5509\u001b[0m            \u001b[31m0.6387\u001b[0m                     \u001b[94m0.6374\u001b[0m        \u001b[36m0.7369\u001b[0m  0.0099  1.9519\n",
      "      4            0.6139                     0.6130        \u001b[35m0.9499\u001b[0m            0.6033                     0.6024        1.0072  0.0098  1.9508\n",
      "      5            0.6319                     0.6346        \u001b[35m0.8538\u001b[0m            0.6361                     \u001b[94m0.6388\u001b[0m        1.0511  0.0097  1.9465\n",
      "      6            \u001b[36m0.6915\u001b[0m                     \u001b[32m0.6924\u001b[0m        0.9223            \u001b[31m0.6793\u001b[0m                     \u001b[94m0.6805\u001b[0m        \u001b[36m0.6671\u001b[0m  0.0095  1.9687\n",
      "      7            \u001b[36m0.7123\u001b[0m                     \u001b[32m0.7132\u001b[0m        \u001b[35m0.7702\u001b[0m            \u001b[31m0.6871\u001b[0m                     \u001b[94m0.6881\u001b[0m        0.7053  0.0093  1.9438\n",
      "      8            0.7015                     0.7020        \u001b[35m0.6918\u001b[0m            \u001b[31m0.7010\u001b[0m                     \u001b[94m0.7015\u001b[0m        \u001b[36m0.6448\u001b[0m  0.0090  1.9518\n",
      "      9            \u001b[36m0.7131\u001b[0m                     \u001b[32m0.7138\u001b[0m        0.6960            \u001b[31m0.7044\u001b[0m                     \u001b[94m0.7052\u001b[0m        \u001b[36m0.5922\u001b[0m  0.0087  1.9499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10            0.7095                     0.7087        \u001b[35m0.6458\u001b[0m            0.6828                     0.6822        0.7478  0.0084  1.9423\n",
      "     11            \u001b[36m0.7466\u001b[0m                     \u001b[32m0.7469\u001b[0m        \u001b[35m0.6050\u001b[0m            \u001b[31m0.7269\u001b[0m                     \u001b[94m0.7272\u001b[0m        \u001b[36m0.5771\u001b[0m  0.0080  1.9526\n",
      "     12            \u001b[36m0.7566\u001b[0m                     \u001b[32m0.7570\u001b[0m        0.6350            \u001b[31m0.7407\u001b[0m                     \u001b[94m0.7413\u001b[0m        \u001b[36m0.5237\u001b[0m  0.0076  1.9407\n",
      "     13            0.6928                     0.6953        \u001b[35m0.5568\u001b[0m            0.6776                     0.6802        0.7245  0.0072  1.9428\n",
      "     14            0.7521                     0.7527        \u001b[35m0.5560\u001b[0m            0.7252                     0.7260        0.5643  0.0068  1.9479\n",
      "     15            0.7555                     0.7559        \u001b[35m0.5461\u001b[0m            0.7252                     0.7257        0.5485  0.0064  1.9548\n",
      "     16            0.7566                     0.7558        \u001b[35m0.5114\u001b[0m            0.7381                     0.7373        0.5430  0.0059  1.9467\n",
      "     17            \u001b[36m0.7570\u001b[0m                     0.7562        0.5335            0.7390                     0.7384        \u001b[36m0.5233\u001b[0m  0.0055  1.9438\n",
      "     18            \u001b[36m0.7951\u001b[0m                     \u001b[32m0.7955\u001b[0m        \u001b[35m0.5026\u001b[0m            \u001b[31m0.7666\u001b[0m                     \u001b[94m0.7672\u001b[0m        \u001b[36m0.4931\u001b[0m  0.0050  1.9488\n",
      "     19            0.7877                     0.7876        \u001b[35m0.4963\u001b[0m            0.7623                     0.7624        0.5012  0.0045  1.9487\n",
      "     20            0.7936                     0.7938        0.4974            \u001b[31m0.7718\u001b[0m                     \u001b[94m0.7721\u001b[0m        \u001b[36m0.4801\u001b[0m  0.0041  1.9428\n",
      "     21            \u001b[36m0.8016\u001b[0m                     \u001b[32m0.8015\u001b[0m        \u001b[35m0.4802\u001b[0m            0.7640                     0.7642        0.4866  0.0036  1.9458\n",
      "     22            0.7994                     0.7992        \u001b[35m0.4748\u001b[0m            0.7632                     0.7631        0.4844  0.0032  1.9538\n",
      "     23            0.7715                     0.7731        \u001b[35m0.4629\u001b[0m            0.7390                     0.7406        0.5264  0.0028  1.9478\n",
      "     24            \u001b[36m0.8026\u001b[0m                     \u001b[32m0.8033\u001b[0m        0.4640            0.7519                     0.7528        0.4936  0.0024  1.9518\n",
      "     25            \u001b[36m0.8109\u001b[0m                     \u001b[32m0.8112\u001b[0m        \u001b[35m0.4538\u001b[0m            0.7718                     \u001b[94m0.7722\u001b[0m        \u001b[36m0.4705\u001b[0m  0.0020  1.9504\n",
      "     26            \u001b[36m0.8160\u001b[0m                     \u001b[32m0.8164\u001b[0m        \u001b[35m0.4469\u001b[0m            \u001b[31m0.7822\u001b[0m                     \u001b[94m0.7827\u001b[0m        \u001b[36m0.4681\u001b[0m  0.0016  1.9558\n",
      "     27            0.8113                     0.8119        \u001b[35m0.4435\u001b[0m            0.7615                     0.7622        0.4748  0.0013  1.9448\n",
      "     28            0.8156                     0.8163        \u001b[35m0.4320\u001b[0m            0.7692                     0.7702        0.4737  0.0010  1.9433\n",
      "     29            \u001b[36m0.8240\u001b[0m                     \u001b[32m0.8244\u001b[0m        \u001b[35m0.4264\u001b[0m            0.7744                     0.7750        \u001b[36m0.4644\u001b[0m  0.0007  1.9488\n",
      "     30            0.8176                     0.8180        0.4273            0.7666                     0.7672        0.4673  0.0005  1.9540\n",
      "     31            0.8173                     0.8180        \u001b[35m0.4200\u001b[0m            0.7632                     0.7639        0.4718  0.0003  1.9528\n",
      "     32            \u001b[36m0.8271\u001b[0m                     \u001b[32m0.8273\u001b[0m        \u001b[35m0.4151\u001b[0m            0.7796                     0.7800        \u001b[36m0.4623\u001b[0m  0.0002  1.9483\n",
      "     33            0.8251                     0.8255        0.4256            0.7744                     0.7750        0.4649  0.0001  1.9458\n",
      "     34            0.8096                     0.8102        \u001b[35m0.4109\u001b[0m            0.7623                     0.7631        0.4721  0.0000  1.9488\n",
      "     35            0.8217                     0.8221        0.4130            0.7718                     0.7724        0.4658  0.0000  1.9478\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5056\u001b[0m                     \u001b[32m0.5031\u001b[0m        \u001b[35m4.1936\u001b[0m            \u001b[31m0.4849\u001b[0m                     \u001b[94m0.4822\u001b[0m        \u001b[36m2.9863\u001b[0m  0.0100  1.9398\n",
      "      2            \u001b[36m0.5465\u001b[0m                     \u001b[32m0.5432\u001b[0m        \u001b[35m1.6895\u001b[0m            \u001b[31m0.5428\u001b[0m                     \u001b[94m0.5393\u001b[0m        \u001b[36m1.6791\u001b[0m  0.0100  1.9488\n",
      "      3            \u001b[36m0.5726\u001b[0m                     \u001b[32m0.5765\u001b[0m        \u001b[35m1.2984\u001b[0m            \u001b[31m0.5756\u001b[0m                     \u001b[94m0.5797\u001b[0m        \u001b[36m1.0965\u001b[0m  0.0099  1.9538\n",
      "      4            \u001b[36m0.6187\u001b[0m                     \u001b[32m0.6212\u001b[0m        \u001b[35m1.0384\u001b[0m            \u001b[31m0.6180\u001b[0m                     \u001b[94m0.6205\u001b[0m        \u001b[36m0.7627\u001b[0m  0.0098  1.9418\n",
      "      5            \u001b[36m0.6291\u001b[0m                     \u001b[32m0.6286\u001b[0m        \u001b[35m0.8963\u001b[0m            0.6085                     0.6078        0.9777  0.0097  1.9471\n",
      "      6            0.6224                     0.6201        \u001b[35m0.8615\u001b[0m            0.6093                     0.6070        0.9262  0.0095  1.9478\n",
      "      7            \u001b[36m0.6526\u001b[0m                     \u001b[32m0.6514\u001b[0m        \u001b[35m0.7757\u001b[0m            \u001b[31m0.6275\u001b[0m                     \u001b[94m0.6263\u001b[0m        1.0255  0.0093  1.9468\n",
      "      8            \u001b[36m0.6889\u001b[0m                     \u001b[32m0.6881\u001b[0m        \u001b[35m0.6976\u001b[0m            \u001b[31m0.6724\u001b[0m                     \u001b[94m0.6720\u001b[0m        \u001b[36m0.6930\u001b[0m  0.0090  1.9478\n",
      "      9            0.6669                     0.6691        \u001b[35m0.6513\u001b[0m            0.6655                     0.6680        0.7751  0.0087  1.9544\n",
      "     10            \u001b[36m0.6943\u001b[0m                     \u001b[32m0.6935\u001b[0m        0.7051            \u001b[31m0.6750\u001b[0m                     \u001b[94m0.6744\u001b[0m        0.7161  0.0084  1.9478\n",
      "     11            \u001b[36m0.7216\u001b[0m                     \u001b[32m0.7199\u001b[0m        \u001b[35m0.6388\u001b[0m            \u001b[31m0.7027\u001b[0m                     \u001b[94m0.7011\u001b[0m        \u001b[36m0.6210\u001b[0m  0.0080  1.9448\n",
      "     12            \u001b[36m0.7309\u001b[0m                     \u001b[32m0.7306\u001b[0m        \u001b[35m0.6138\u001b[0m            \u001b[31m0.7398\u001b[0m                     \u001b[94m0.7396\u001b[0m        \u001b[36m0.6022\u001b[0m  0.0076  1.9508\n",
      "     13            \u001b[36m0.7378\u001b[0m                     \u001b[32m0.7365\u001b[0m        \u001b[35m0.6060\u001b[0m            0.7001                     0.6989        0.6068  0.0072  1.9558\n",
      "     14            \u001b[36m0.7689\u001b[0m                     \u001b[32m0.7686\u001b[0m        \u001b[35m0.5399\u001b[0m            \u001b[31m0.7416\u001b[0m                     \u001b[94m0.7414\u001b[0m        \u001b[36m0.5428\u001b[0m  0.0068  1.9481\n",
      "     15            \u001b[36m0.7806\u001b[0m                     \u001b[32m0.7810\u001b[0m        0.5455            \u001b[31m0.7545\u001b[0m                     \u001b[94m0.7549\u001b[0m        0.5469  0.0064  1.9488\n",
      "     16            \u001b[36m0.7832\u001b[0m                     \u001b[32m0.7834\u001b[0m        0.5910            0.7312                     0.7315        0.6009  0.0059  1.9482\n",
      "     17            \u001b[36m0.7858\u001b[0m                     \u001b[32m0.7864\u001b[0m        \u001b[35m0.5248\u001b[0m            0.7502                     0.7510        \u001b[36m0.5204\u001b[0m  0.0055  1.9548\n",
      "     18            \u001b[36m0.7923\u001b[0m                     \u001b[32m0.7919\u001b[0m        \u001b[35m0.5158\u001b[0m            \u001b[31m0.7571\u001b[0m                     \u001b[94m0.7569\u001b[0m        \u001b[36m0.5171\u001b[0m  0.0050  1.9458\n",
      "     19            0.7920                     0.7913        \u001b[35m0.4962\u001b[0m            0.7476                     0.7469        0.5722  0.0045  1.9505\n",
      "     20            0.7760                     0.7759        0.4969            0.7321                     0.7319        0.5792  0.0041  1.9518\n",
      "     21            \u001b[36m0.8009\u001b[0m                     \u001b[32m0.8017\u001b[0m        \u001b[35m0.4856\u001b[0m            0.7494                     0.7502        0.5570  0.0036  1.9573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22            \u001b[36m0.8063\u001b[0m                     \u001b[32m0.8064\u001b[0m        \u001b[35m0.4720\u001b[0m            0.7442                     0.7440        0.5950  0.0032  1.9538\n",
      "     23            0.7990                     0.7997        \u001b[35m0.4710\u001b[0m            \u001b[31m0.7597\u001b[0m                     \u001b[94m0.7606\u001b[0m        0.5992  0.0028  1.9467\n",
      "     24            \u001b[36m0.8150\u001b[0m                     \u001b[32m0.8154\u001b[0m        \u001b[35m0.4441\u001b[0m            0.7545                     0.7550        0.5994  0.0024  1.9508\n",
      "     25            \u001b[36m0.8210\u001b[0m                     \u001b[32m0.8211\u001b[0m        0.4518            0.7571                     0.7570        0.5982  0.0020  1.9528\n",
      "     26            \u001b[36m0.8275\u001b[0m                     \u001b[32m0.8276\u001b[0m        0.4497            0.7597                     0.7598        0.6103  0.0016  1.9458\n",
      "     27            0.8253                     0.8250        \u001b[35m0.4357\u001b[0m            \u001b[31m0.7640\u001b[0m                     \u001b[94m0.7634\u001b[0m        0.5881  0.0013  1.9480\n",
      "     28            0.8180                     0.8186        \u001b[35m0.4311\u001b[0m            0.7615                     0.7622        0.5795  0.0010  1.9508\n",
      "     29            0.8180                     0.8187        \u001b[35m0.4250\u001b[0m            0.7537                     0.7545        0.5933  0.0007  1.9578\n",
      "     30            0.8256                     0.8259        \u001b[35m0.4229\u001b[0m            \u001b[31m0.7701\u001b[0m                     \u001b[94m0.7704\u001b[0m        0.5826  0.0005  1.9540\n",
      "     31            0.8128                     0.8136        \u001b[35m0.4131\u001b[0m            0.7649                     0.7657        0.5910  0.0003  1.9511\n",
      "     32            \u001b[36m0.8374\u001b[0m                     \u001b[32m0.8376\u001b[0m        \u001b[35m0.4040\u001b[0m            \u001b[31m0.7710\u001b[0m                     \u001b[94m0.7710\u001b[0m        0.6044  0.0002  1.9501\n",
      "     33            0.8201                     0.8208        0.4074            0.7649                     0.7656        0.5822  0.0001  1.9548\n",
      "     34            0.8344                     0.8347        \u001b[35m0.4010\u001b[0m            0.7658                     0.7661        0.6101  0.0000  1.9500\n",
      "     35            \u001b[36m0.8390\u001b[0m                     \u001b[32m0.8390\u001b[0m        \u001b[35m0.3968\u001b[0m            \u001b[31m0.7736\u001b[0m                     \u001b[94m0.7736\u001b[0m        0.6089  0.0000  1.9443\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5004\u001b[0m                     \u001b[32m0.5056\u001b[0m        \u001b[35m3.5864\u001b[0m            \u001b[31m0.4970\u001b[0m                     \u001b[94m0.5024\u001b[0m        \u001b[36m2.8610\u001b[0m  0.0100  1.9448\n",
      "      2            \u001b[36m0.6120\u001b[0m                     \u001b[32m0.6130\u001b[0m        \u001b[35m1.4783\u001b[0m            \u001b[31m0.6067\u001b[0m                     \u001b[94m0.6078\u001b[0m        \u001b[36m1.0738\u001b[0m  0.0100  1.9520\n",
      "      3            \u001b[36m0.6258\u001b[0m                     \u001b[32m0.6283\u001b[0m        1.5425            0.6067                     \u001b[94m0.6095\u001b[0m        1.0877  0.0099  1.9458\n",
      "      4            \u001b[36m0.6727\u001b[0m                     \u001b[32m0.6714\u001b[0m        \u001b[35m0.9313\u001b[0m            \u001b[31m0.6508\u001b[0m                     \u001b[94m0.6495\u001b[0m        1.2508  0.0098  1.9508\n",
      "      5            0.6619                     0.6602        \u001b[35m0.9266\u001b[0m            0.6318                     0.6299        \u001b[36m0.8870\u001b[0m  0.0097  1.9528\n",
      "      6            0.6714                     0.6709        \u001b[35m0.8214\u001b[0m            0.6335                     0.6332        0.9351  0.0095  1.9448\n",
      "      7            \u001b[36m0.7036\u001b[0m                     \u001b[32m0.7042\u001b[0m        \u001b[35m0.8045\u001b[0m            \u001b[31m0.6742\u001b[0m                     \u001b[94m0.6747\u001b[0m        \u001b[36m0.6770\u001b[0m  0.0093  1.9532\n",
      "      8            \u001b[36m0.7495\u001b[0m                     \u001b[32m0.7504\u001b[0m        \u001b[35m0.6662\u001b[0m            \u001b[31m0.7122\u001b[0m                     \u001b[94m0.7132\u001b[0m        \u001b[36m0.5759\u001b[0m  0.0090  1.9466\n",
      "      9            0.7302                     0.7318        \u001b[35m0.5946\u001b[0m            0.6828                     0.6846        0.6562  0.0087  1.9524\n",
      "     10            \u001b[36m0.7512\u001b[0m                     \u001b[32m0.7519\u001b[0m        0.6290            0.7035                     0.7045        0.6739  0.0084  1.9448\n",
      "     11            0.7391                     0.7396        0.6206            0.7087                     0.7093        0.6478  0.0080  1.9528\n",
      "     12            0.7311                     0.7300        \u001b[35m0.5627\u001b[0m            0.6837                     0.6825        0.6984  0.0076  1.9478\n",
      "     13            \u001b[36m0.7683\u001b[0m                     \u001b[32m0.7691\u001b[0m        0.5897            \u001b[31m0.7312\u001b[0m                     \u001b[94m0.7320\u001b[0m        0.6160  0.0072  1.9520\n",
      "     14            0.7255                     0.7276        \u001b[35m0.5184\u001b[0m            0.6906                     0.6930        0.7157  0.0068  1.9538\n",
      "     15            \u001b[36m0.7765\u001b[0m                     \u001b[32m0.7768\u001b[0m        \u001b[35m0.4995\u001b[0m            \u001b[31m0.7424\u001b[0m                     \u001b[94m0.7429\u001b[0m        0.6102  0.0064  1.9568\n",
      "     16            \u001b[36m0.7936\u001b[0m                     \u001b[32m0.7932\u001b[0m        0.4996            \u001b[31m0.7571\u001b[0m                     \u001b[94m0.7569\u001b[0m        0.6231  0.0059  1.9504\n",
      "     17            0.7815                     0.7816        0.5262            0.7424                     0.7428        0.5910  0.0055  1.9453\n",
      "     18            0.7931                     \u001b[32m0.7938\u001b[0m        \u001b[35m0.4886\u001b[0m            0.7424                     0.7433        \u001b[36m0.5730\u001b[0m  0.0050  1.9521\n",
      "     19            \u001b[36m0.7985\u001b[0m                     \u001b[32m0.7986\u001b[0m        \u001b[35m0.4783\u001b[0m            0.7485                     0.7486        0.5958  0.0045  1.9539\n",
      "     20            \u001b[36m0.8104\u001b[0m                     \u001b[32m0.8106\u001b[0m        \u001b[35m0.4673\u001b[0m            0.7545                     0.7548        0.6239  0.0041  1.9498\n",
      "     21            0.8076                     0.8080        0.4707            0.7468                     0.7472        0.6158  0.0036  1.9518\n",
      "     22            \u001b[36m0.8106\u001b[0m                     \u001b[32m0.8109\u001b[0m        0.4712            \u001b[31m0.7597\u001b[0m                     \u001b[94m0.7602\u001b[0m        0.5902  0.0032  1.9428\n",
      "     23            \u001b[36m0.8124\u001b[0m                     \u001b[32m0.8130\u001b[0m        \u001b[35m0.4564\u001b[0m            0.7580                     0.7587        0.6123  0.0028  1.9536\n",
      "     24            0.8111                     0.8117        \u001b[35m0.4490\u001b[0m            0.7528                     0.7535        0.5856  0.0024  1.9478\n",
      "     25            \u001b[36m0.8163\u001b[0m                     \u001b[32m0.8171\u001b[0m        \u001b[35m0.4397\u001b[0m            0.7545                     0.7554        0.6188  0.0020  1.9504\n",
      "     26            \u001b[36m0.8199\u001b[0m                     \u001b[32m0.8207\u001b[0m        \u001b[35m0.4364\u001b[0m            0.7511                     0.7519        0.5989  0.0016  1.9504\n",
      "     27            \u001b[36m0.8277\u001b[0m                     \u001b[32m0.8280\u001b[0m        \u001b[35m0.4244\u001b[0m            \u001b[31m0.7727\u001b[0m                     \u001b[94m0.7732\u001b[0m        0.5903  0.0013  1.9475\n",
      "     28            0.8221                     0.8227        \u001b[35m0.4227\u001b[0m            0.7623                     0.7631        0.5946  0.0010  1.9508\n",
      "     29            \u001b[36m0.8303\u001b[0m                     \u001b[32m0.8309\u001b[0m        \u001b[35m0.4219\u001b[0m            0.7684                     0.7690        0.5989  0.0007  1.9521\n",
      "     30            0.8163                     0.8173        \u001b[35m0.4140\u001b[0m            0.7450                     0.7462        0.6463  0.0005  1.9597\n",
      "     31            \u001b[36m0.8320\u001b[0m                     \u001b[32m0.8325\u001b[0m        \u001b[35m0.4091\u001b[0m            0.7666                     0.7672        0.5920  0.0003  1.9548\n",
      "     32            0.8312                     0.8317        \u001b[35m0.4036\u001b[0m            0.7640                     0.7647        0.6000  0.0002  1.9593\n",
      "     33            0.8288                     0.8294        0.4062            0.7649                     0.7656        0.6031  0.0001  1.9488\n",
      "     34            0.8275                     0.8282        0.4099            0.7606                     0.7614        0.6034  0.0000  1.9505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35            0.8299                     0.8305        0.4037            0.7632                     0.7639        0.5990  0.0000  1.9867\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6200\u001b[0m                     \u001b[32m0.6184\u001b[0m        \u001b[35m4.4000\u001b[0m            \u001b[31m0.6007\u001b[0m                     \u001b[94m0.5993\u001b[0m        \u001b[36m2.1190\u001b[0m  0.0100  1.9508\n",
      "      2            0.5465                     0.5504        \u001b[35m1.9644\u001b[0m            0.5445                     0.5485        \u001b[36m1.6785\u001b[0m  0.0100  1.9478\n",
      "      3            0.5793                     0.5756        \u001b[35m1.1986\u001b[0m            0.5886                     0.5849        \u001b[36m1.3078\u001b[0m  0.0099  1.9448\n",
      "      4            \u001b[36m0.6706\u001b[0m                     \u001b[32m0.6724\u001b[0m        1.2514            \u001b[31m0.6448\u001b[0m                     \u001b[94m0.6468\u001b[0m        \u001b[36m0.7234\u001b[0m  0.0098  1.9539\n",
      "      5            \u001b[36m0.6744\u001b[0m                     \u001b[32m0.6752\u001b[0m        \u001b[35m0.9002\u001b[0m            \u001b[31m0.6811\u001b[0m                     \u001b[94m0.6818\u001b[0m        0.7998  0.0097  1.9541\n",
      "      6            \u001b[36m0.7021\u001b[0m                     \u001b[32m0.7029\u001b[0m        \u001b[35m0.8673\u001b[0m            \u001b[31m0.6845\u001b[0m                     \u001b[94m0.6857\u001b[0m        \u001b[36m0.6838\u001b[0m  0.0095  1.9517\n",
      "      7            0.6552                     0.6566        0.8893            0.6396                     0.6412        0.9258  0.0093  1.9498\n",
      "      8            \u001b[36m0.7038\u001b[0m                     \u001b[32m0.7054\u001b[0m        \u001b[35m0.7971\u001b[0m            \u001b[31m0.6966\u001b[0m                     \u001b[94m0.6983\u001b[0m        \u001b[36m0.6229\u001b[0m  0.0090  1.9448\n",
      "      9            \u001b[36m0.7151\u001b[0m                     \u001b[32m0.7163\u001b[0m        \u001b[35m0.6916\u001b[0m            \u001b[31m0.7139\u001b[0m                     \u001b[94m0.7153\u001b[0m        \u001b[36m0.6022\u001b[0m  0.0087  1.9494\n",
      "     10            \u001b[36m0.7460\u001b[0m                     \u001b[32m0.7470\u001b[0m        \u001b[35m0.5933\u001b[0m            \u001b[31m0.7191\u001b[0m                     \u001b[94m0.7204\u001b[0m        \u001b[36m0.5650\u001b[0m  0.0084  1.9498\n",
      "     11            0.7289                     0.7279        0.6151            0.6906                     0.6896        0.5982  0.0080  1.9492\n",
      "     12            \u001b[36m0.7585\u001b[0m                     \u001b[32m0.7586\u001b[0m        \u001b[35m0.5755\u001b[0m            \u001b[31m0.7442\u001b[0m                     \u001b[94m0.7444\u001b[0m        \u001b[36m0.5264\u001b[0m  0.0076  1.9548\n",
      "     13            \u001b[36m0.7637\u001b[0m                     \u001b[32m0.7643\u001b[0m        \u001b[35m0.5519\u001b[0m            \u001b[31m0.7494\u001b[0m                     \u001b[94m0.7500\u001b[0m        0.5311  0.0072  1.9498\n",
      "     14            0.7603                     0.7606        \u001b[35m0.5404\u001b[0m            0.7424                     0.7429        0.5549  0.0068  1.9553\n",
      "     15            0.7631                     0.7632        \u001b[35m0.5285\u001b[0m            0.7398                     0.7401        0.5511  0.0064  1.9508\n",
      "     16            \u001b[36m0.7804\u001b[0m                     \u001b[32m0.7803\u001b[0m        0.5320            0.7390                     0.7390        \u001b[36m0.5262\u001b[0m  0.0059  1.9497\n",
      "     17            0.7763                     0.7768        \u001b[35m0.5241\u001b[0m            0.7442                     0.7449        \u001b[36m0.5253\u001b[0m  0.0055  1.9468\n",
      "     18            \u001b[36m0.7879\u001b[0m                     \u001b[32m0.7884\u001b[0m        \u001b[35m0.5071\u001b[0m            0.7476                     0.7482        \u001b[36m0.5219\u001b[0m  0.0050  1.9598\n",
      "     19            0.7769                     0.7780        \u001b[35m0.4924\u001b[0m            \u001b[31m0.7597\u001b[0m                     \u001b[94m0.7610\u001b[0m        0.5346  0.0045  1.9490\n",
      "     20            \u001b[36m0.7944\u001b[0m                     \u001b[32m0.7948\u001b[0m        \u001b[35m0.4849\u001b[0m            \u001b[31m0.7606\u001b[0m                     \u001b[94m0.7612\u001b[0m        \u001b[36m0.5100\u001b[0m  0.0041  1.9507\n",
      "     21            \u001b[36m0.8018\u001b[0m                     \u001b[32m0.8022\u001b[0m        \u001b[35m0.4823\u001b[0m            \u001b[31m0.7831\u001b[0m                     \u001b[94m0.7837\u001b[0m        \u001b[36m0.4981\u001b[0m  0.0036  1.9488\n",
      "     22            0.7951                     0.7960        \u001b[35m0.4746\u001b[0m            0.7597                     0.7609        0.5235  0.0032  1.9558\n",
      "     23            \u001b[36m0.8104\u001b[0m                     \u001b[32m0.8109\u001b[0m        \u001b[35m0.4722\u001b[0m            0.7640                     0.7647        0.5078  0.0028  1.9554\n",
      "     24            0.8100                     0.8107        \u001b[35m0.4582\u001b[0m            0.7580                     0.7589        0.5139  0.0024  1.9508\n",
      "     25            0.8033                     0.8042        \u001b[35m0.4546\u001b[0m            0.7692                     0.7702        0.5039  0.0020  1.9494\n",
      "     26            0.8085                     0.8091        \u001b[35m0.4433\u001b[0m            0.7727                     0.7735        0.5083  0.0016  1.9637\n",
      "     27            \u001b[36m0.8197\u001b[0m                     \u001b[32m0.8200\u001b[0m        \u001b[35m0.4428\u001b[0m            0.7615                     0.7619        \u001b[36m0.4970\u001b[0m  0.0013  1.9538\n",
      "     28            \u001b[36m0.8201\u001b[0m                     \u001b[32m0.8204\u001b[0m        \u001b[35m0.4345\u001b[0m            0.7692                     0.7696        0.4994  0.0010  1.9493\n",
      "     29            0.8026                     0.8037        0.4396            0.7675                     0.7687        0.5029  0.0007  1.9557\n",
      "     30            \u001b[36m0.8214\u001b[0m                     \u001b[32m0.8219\u001b[0m        \u001b[35m0.4251\u001b[0m            0.7718                     0.7725        \u001b[36m0.4912\u001b[0m  0.0005  1.9558\n",
      "     31            \u001b[36m0.8275\u001b[0m                     \u001b[32m0.8279\u001b[0m        \u001b[35m0.4240\u001b[0m            0.7718                     0.7725        0.4934  0.0003  1.9553\n",
      "     32            0.8180                     0.8187        \u001b[35m0.4173\u001b[0m            0.7718                     0.7728        0.4960  0.0002  1.9478\n",
      "     33            0.7951                     0.7963        0.4249            0.7658                     0.7672        0.5094  0.0001  1.9566\n",
      "     34            0.8160                     0.8168        0.4261            0.7718                     0.7728        0.4966  0.0000  1.9553\n",
      "     35            0.8266                     0.8271        0.4178            0.7718                     0.7725        0.4927  0.0000  1.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6535\u001b[0m                     \u001b[32m0.6408\u001b[0m        \u001b[35m4.1171\u001b[0m            \u001b[31m0.6512\u001b[0m                     \u001b[94m0.6404\u001b[0m        \u001b[36m4.1776\u001b[0m  0.0100  1.1898\n",
      "      2            0.6531                     \u001b[32m0.6743\u001b[0m        \u001b[35m3.3718\u001b[0m            \u001b[31m0.6527\u001b[0m                     \u001b[94m0.6745\u001b[0m        \u001b[36m1.5654\u001b[0m  0.0100  1.1694\n",
      "      3            \u001b[36m0.6655\u001b[0m                     \u001b[32m0.6805\u001b[0m        \u001b[35m1.7903\u001b[0m            \u001b[31m0.6744\u001b[0m                     \u001b[94m0.6894\u001b[0m        1.7685  0.0099  1.1639\n",
      "      4            \u001b[36m0.6741\u001b[0m                     0.6766        \u001b[35m1.4213\u001b[0m            0.6657                     0.6701        \u001b[36m0.9543\u001b[0m  0.0098  1.1649\n",
      "      5            \u001b[36m0.6933\u001b[0m                     \u001b[32m0.6970\u001b[0m        \u001b[35m1.0163\u001b[0m            \u001b[31m0.7019\u001b[0m                     \u001b[94m0.7095\u001b[0m        \u001b[36m0.7133\u001b[0m  0.0097  1.1739\n",
      "      6            0.6890                     \u001b[32m0.6983\u001b[0m        \u001b[35m0.7430\u001b[0m            0.6831                     0.6928        \u001b[36m0.6835\u001b[0m  0.0095  1.1649\n",
      "      7            \u001b[36m0.7426\u001b[0m                     \u001b[32m0.7376\u001b[0m        \u001b[35m0.7096\u001b[0m            \u001b[31m0.7294\u001b[0m                     \u001b[94m0.7269\u001b[0m        \u001b[36m0.5837\u001b[0m  0.0093  1.1639\n",
      "      8            0.6941                     0.7130        \u001b[35m0.6754\u001b[0m            0.7019                     0.7221        0.6551  0.0090  1.1644\n",
      "      9            0.7209                     0.7297        0.7490            0.7294                     \u001b[94m0.7405\u001b[0m        0.5980  0.0087  1.1676\n",
      "     10            0.7169                     0.7261        \u001b[35m0.6446\u001b[0m            0.6990                     0.7120        0.6133  0.0084  1.1689\n",
      "     11            0.7346                     \u001b[32m0.7487\u001b[0m        \u001b[35m0.5919\u001b[0m            0.7178                     0.7324        \u001b[36m0.5675\u001b[0m  0.0080  1.1634\n",
      "     12            \u001b[36m0.7437\u001b[0m                     0.7352        \u001b[35m0.5879\u001b[0m            0.7279                     0.7211        0.6078  0.0076  1.1679\n",
      "     13            0.7205                     0.7315        \u001b[35m0.5869\u001b[0m            0.6961                     0.7091        0.5774  0.0072  1.1699\n",
      "     14            0.7295                     0.7377        0.6818            0.6990                     0.7108        0.6096  0.0068  1.1672\n",
      "     15            0.7375                     0.7355        \u001b[35m0.5589\u001b[0m            0.7149                     0.7144        0.6487  0.0064  1.1642\n",
      "     16            \u001b[36m0.7495\u001b[0m                     \u001b[32m0.7588\u001b[0m        0.5606            0.7033                     0.7138        0.5707  0.0059  1.1669\n",
      "     17            0.7209                     0.7390        \u001b[35m0.5370\u001b[0m            0.7033                     0.7235        0.5985  0.0055  1.1689\n",
      "     18            0.7476                     0.7574        0.5808            0.7192                     0.7313        \u001b[36m0.5636\u001b[0m  0.0050  1.1635\n",
      "     19            0.7379                     0.7520        \u001b[35m0.5117\u001b[0m            0.7120                     0.7271        0.5700  0.0045  1.1659\n",
      "     20            \u001b[36m0.7784\u001b[0m                     \u001b[32m0.7772\u001b[0m        \u001b[35m0.4875\u001b[0m            \u001b[31m0.7366\u001b[0m                     0.7380        \u001b[36m0.5349\u001b[0m  0.0041  1.1669\n",
      "     21            0.7393                     0.7506        \u001b[35m0.4845\u001b[0m            0.7149                     0.7285        0.6108  0.0036  1.1709\n",
      "     22            0.7770                     \u001b[32m0.7819\u001b[0m        0.4871            0.7352                     \u001b[94m0.7433\u001b[0m        \u001b[36m0.5337\u001b[0m  0.0032  1.1709\n",
      "     23            0.7415                     0.7563        \u001b[35m0.4807\u001b[0m            0.7033                     0.7208        0.5952  0.0028  1.1609\n",
      "     24            0.7469                     0.7595        \u001b[35m0.4766\u001b[0m            0.7250                     0.7401        0.5727  0.0024  1.1684\n",
      "     25            0.7715                     0.7718        0.4924            \u001b[31m0.7496\u001b[0m                     \u001b[94m0.7531\u001b[0m        0.5556  0.0020  1.1739\n",
      "     26            0.7686                     0.7764        \u001b[35m0.4681\u001b[0m            0.7438                     \u001b[94m0.7539\u001b[0m        \u001b[36m0.5310\u001b[0m  0.0016  1.1649\n",
      "     27            \u001b[36m0.7824\u001b[0m                     \u001b[32m0.7846\u001b[0m        \u001b[35m0.4510\u001b[0m            0.7381                     0.7423        0.5341  0.0013  1.1658\n",
      "     28            0.7744                     0.7844        0.4729            0.7323                     0.7440        0.5367  0.0010  1.1689\n",
      "     29            0.7726                     0.7816        \u001b[35m0.4491\u001b[0m            0.7438                     \u001b[94m0.7542\u001b[0m        \u001b[36m0.5237\u001b[0m  0.0007  1.1694\n",
      "     30            0.7795                     \u001b[32m0.7890\u001b[0m        \u001b[35m0.4473\u001b[0m            0.7381                     0.7492        \u001b[36m0.5232\u001b[0m  0.0005  1.1649\n",
      "     31            0.7810                     \u001b[32m0.7904\u001b[0m        \u001b[35m0.4431\u001b[0m            0.7323                     0.7428        0.5356  0.0003  1.1699\n",
      "     32            0.7697                     0.7815        \u001b[35m0.4378\u001b[0m            0.7352                     0.7475        0.5374  0.0002  1.1669\n",
      "     33            0.7741                     0.7852        0.4476            0.7294                     0.7417        0.5313  0.0001  1.1609\n",
      "     34            \u001b[36m0.7842\u001b[0m                     \u001b[32m0.7924\u001b[0m        0.4443            0.7381                     0.7480        0.5245  0.0000  1.1689\n",
      "     35            \u001b[36m0.7853\u001b[0m                     \u001b[32m0.7936\u001b[0m        0.4392            0.7381                     0.7474        \u001b[36m0.5229\u001b[0m  0.0000  1.1624\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5228\u001b[0m                     \u001b[32m0.5612\u001b[0m        \u001b[35m4.9892\u001b[0m            \u001b[31m0.5166\u001b[0m                     \u001b[94m0.5596\u001b[0m        \u001b[36m2.9240\u001b[0m  0.0100  1.1624\n",
      "      2            \u001b[36m0.5941\u001b[0m                     \u001b[32m0.6199\u001b[0m        \u001b[35m1.7674\u001b[0m            \u001b[31m0.5803\u001b[0m                     \u001b[94m0.6068\u001b[0m        \u001b[36m2.0199\u001b[0m  0.0100  1.1649\n",
      "      3            0.5844                     0.6161        \u001b[35m1.4484\u001b[0m            0.5803                     \u001b[94m0.6134\u001b[0m        \u001b[36m1.6908\u001b[0m  0.0099  1.1669\n",
      "      4            \u001b[36m0.6169\u001b[0m                     \u001b[32m0.6414\u001b[0m        1.9215            \u001b[31m0.5962\u001b[0m                     \u001b[94m0.6236\u001b[0m        1.7722  0.0098  1.1609\n",
      "      5            \u001b[36m0.6930\u001b[0m                     \u001b[32m0.6986\u001b[0m        \u001b[35m1.3303\u001b[0m            \u001b[31m0.6628\u001b[0m                     \u001b[94m0.6687\u001b[0m        \u001b[36m1.1338\u001b[0m  0.0097  1.1629\n",
      "      6            \u001b[36m0.7107\u001b[0m                     \u001b[32m0.7140\u001b[0m        \u001b[35m0.9869\u001b[0m            \u001b[31m0.6860\u001b[0m                     \u001b[94m0.6918\u001b[0m        \u001b[36m0.7725\u001b[0m  0.0095  1.1629\n",
      "      7            0.7035                     \u001b[32m0.7169\u001b[0m        \u001b[35m0.7302\u001b[0m            0.6570                     0.6730        0.8835  0.0093  1.1649\n",
      "      8            0.6752                     0.6744        0.7939            0.6252                     0.6216        1.0136  0.0090  1.1639\n",
      "      9            0.6586                     0.6770        \u001b[35m0.6809\u001b[0m            0.6411                     0.6610        0.7858  0.0087  1.1648\n",
      "     10            \u001b[36m0.7397\u001b[0m                     \u001b[32m0.7420\u001b[0m        0.7043            \u001b[31m0.7048\u001b[0m                     \u001b[94m0.7061\u001b[0m        \u001b[36m0.6749\u001b[0m  0.0084  1.1669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            0.7118                     0.7292        0.7647            0.6729                     0.6896        0.6765  0.0080  1.1629\n",
      "     12            0.7332                     \u001b[32m0.7436\u001b[0m        0.6822            0.6975                     \u001b[94m0.7080\u001b[0m        \u001b[36m0.6551\u001b[0m  0.0076  1.1629\n",
      "     13            \u001b[36m0.7556\u001b[0m                     \u001b[32m0.7559\u001b[0m        0.7079            \u001b[31m0.7294\u001b[0m                     \u001b[94m0.7327\u001b[0m        \u001b[36m0.6548\u001b[0m  0.0072  1.1669\n",
      "     14            0.7295                     0.7422        \u001b[35m0.5263\u001b[0m            0.6831                     0.6967        0.7426  0.0068  1.1629\n",
      "     15            \u001b[36m0.7654\u001b[0m                     \u001b[32m0.7726\u001b[0m        0.5830            0.7178                     0.7273        \u001b[36m0.5957\u001b[0m  0.0064  1.1668\n",
      "     16            0.7437                     0.7545        \u001b[35m0.5205\u001b[0m            0.6990                     0.7108        0.6628  0.0059  1.1669\n",
      "     17            0.7419                     0.7446        0.6014            0.6961                     0.6986        0.6384  0.0055  1.1609\n",
      "     18            0.7524                     0.7588        0.6076            0.7135                     0.7200        \u001b[36m0.5278\u001b[0m  0.0050  1.1651\n",
      "     19            0.7397                     0.7513        0.5566            0.6975                     0.7098        0.5729  0.0045  1.1649\n",
      "     20            \u001b[36m0.7762\u001b[0m                     0.7674        0.5611            0.7091                     0.6986        0.5760  0.0041  1.1619\n",
      "     21            0.7683                     0.7722        \u001b[35m0.5027\u001b[0m            0.7178                     0.7216        0.5570  0.0036  1.1669\n",
      "     22            0.7665                     0.7677        \u001b[35m0.4931\u001b[0m            0.7120                     0.7121        0.5450  0.0032  1.1699\n",
      "     23            \u001b[36m0.7849\u001b[0m                     \u001b[32m0.7803\u001b[0m        \u001b[35m0.4813\u001b[0m            0.7250                     0.7200        0.5536  0.0028  1.1669\n",
      "     24            0.7810                     \u001b[32m0.7818\u001b[0m        \u001b[35m0.4697\u001b[0m            0.7250                     0.7263        \u001b[36m0.5228\u001b[0m  0.0024  1.1716\n",
      "     25            \u001b[36m0.7857\u001b[0m                     \u001b[32m0.7890\u001b[0m        0.4749            0.7279                     0.7316        0.5334  0.0020  1.1619\n",
      "     26            0.7806                     0.7837        \u001b[35m0.4658\u001b[0m            0.7250                     0.7281        0.5292  0.0016  1.1639\n",
      "     27            0.7806                     0.7866        \u001b[35m0.4645\u001b[0m            0.7178                     0.7246        0.5242  0.0013  1.1683\n",
      "     28            0.7835                     0.7875        \u001b[35m0.4619\u001b[0m            0.7265                     0.7300        0.5304  0.0010  1.1639\n",
      "     29            \u001b[36m0.7860\u001b[0m                     0.7881        \u001b[35m0.4496\u001b[0m            \u001b[31m0.7381\u001b[0m                     \u001b[94m0.7399\u001b[0m        \u001b[36m0.5153\u001b[0m  0.0007  1.1689\n",
      "     30            \u001b[36m0.7958\u001b[0m                     \u001b[32m0.7974\u001b[0m        0.4512            0.7337                     0.7360        0.5255  0.0005  1.1660\n",
      "     31            0.7904                     0.7916        \u001b[35m0.4421\u001b[0m            0.7366                     0.7380        0.5272  0.0003  1.1705\n",
      "     32            0.7915                     0.7946        0.4487            0.7265                     0.7300        0.5238  0.0002  1.1621\n",
      "     33            0.7904                     0.7926        0.4504            0.7366                     0.7392        0.5235  0.0001  1.1701\n",
      "     34            0.7907                     0.7943        0.4443            0.7279                     0.7319        0.5192  0.0000  1.1769\n",
      "     35            0.7904                     0.7923        0.4486            \u001b[31m0.7438\u001b[0m                     \u001b[94m0.7458\u001b[0m        0.5198  0.0000  1.1699\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5322\u001b[0m                     \u001b[32m0.5434\u001b[0m        \u001b[35m5.0811\u001b[0m            \u001b[31m0.5485\u001b[0m                     \u001b[94m0.5626\u001b[0m        \u001b[36m4.6494\u001b[0m  0.0100  1.1694\n",
      "      2            \u001b[36m0.6640\u001b[0m                     \u001b[32m0.6752\u001b[0m        \u001b[35m3.3339\u001b[0m            \u001b[31m0.6541\u001b[0m                     \u001b[94m0.6644\u001b[0m        \u001b[36m1.6944\u001b[0m  0.0100  1.1709\n",
      "      3            0.6517                     0.6744        \u001b[35m1.4333\u001b[0m            0.6469                     \u001b[94m0.6672\u001b[0m        \u001b[36m1.0598\u001b[0m  0.0099  1.1779\n",
      "      4            \u001b[36m0.7205\u001b[0m                     \u001b[32m0.7278\u001b[0m        1.9760            \u001b[31m0.7178\u001b[0m                     \u001b[94m0.7219\u001b[0m        \u001b[36m0.9837\u001b[0m  0.0098  1.1629\n",
      "      5            0.6839                     0.6934        \u001b[35m1.0156\u001b[0m            0.7033                     0.7105        \u001b[36m0.7669\u001b[0m  0.0097  1.1589\n",
      "      6            0.6314                     0.6510        \u001b[35m0.8555\u001b[0m            0.6194                     0.6356        1.6146  0.0095  1.1599\n",
      "      7            0.6883                     0.7049        0.8660            0.6773                     0.6914        \u001b[36m0.6924\u001b[0m  0.0093  1.1749\n",
      "      8            0.6897                     0.6907        \u001b[35m0.6824\u001b[0m            0.6874                     0.6889        0.8166  0.0090  1.1689\n",
      "      9            \u001b[36m0.7212\u001b[0m                     0.7218        0.7892            \u001b[31m0.7352\u001b[0m                     \u001b[94m0.7355\u001b[0m        \u001b[36m0.6409\u001b[0m  0.0087  1.1699\n",
      "     10            0.6948                     0.7098        0.7129            0.6874                     0.6994        0.6821  0.0084  1.1679\n",
      "     11            \u001b[36m0.7400\u001b[0m                     \u001b[32m0.7379\u001b[0m        0.7653            0.7250                     0.7215        0.6639  0.0080  1.1629\n",
      "     12            0.7198                     0.7229        \u001b[35m0.6200\u001b[0m            0.7106                     0.7120        \u001b[36m0.6336\u001b[0m  0.0076  1.1649\n",
      "     13            0.7194                     0.7337        \u001b[35m0.6179\u001b[0m            0.7077                     0.7235        \u001b[36m0.5600\u001b[0m  0.0072  1.1769\n",
      "     14            0.7212                     0.7333        \u001b[35m0.5981\u001b[0m            0.7236                     0.7343        0.6258  0.0068  1.1649\n",
      "     15            \u001b[36m0.7462\u001b[0m                     \u001b[32m0.7561\u001b[0m        \u001b[35m0.5970\u001b[0m            0.7279                     \u001b[94m0.7377\u001b[0m        \u001b[36m0.5334\u001b[0m  0.0064  1.1716\n",
      "     16            \u001b[36m0.7585\u001b[0m                     \u001b[32m0.7631\u001b[0m        \u001b[35m0.5277\u001b[0m            \u001b[31m0.7540\u001b[0m                     \u001b[94m0.7601\u001b[0m        \u001b[36m0.4971\u001b[0m  0.0059  1.1659\n",
      "     17            \u001b[36m0.7705\u001b[0m                     \u001b[32m0.7669\u001b[0m        \u001b[35m0.5179\u001b[0m            0.7540                     0.7514        0.5159  0.0055  1.1699\n",
      "     18            0.6995                     0.7137        \u001b[35m0.5085\u001b[0m            0.6889                     0.7013        0.5883  0.0050  1.1659\n",
      "     19            0.7654                     \u001b[32m0.7762\u001b[0m        0.5091            \u001b[31m0.7554\u001b[0m                     \u001b[94m0.7653\u001b[0m        0.5128  0.0045  1.1679\n",
      "     20            \u001b[36m0.7770\u001b[0m                     \u001b[32m0.7787\u001b[0m        \u001b[35m0.4933\u001b[0m            \u001b[31m0.7699\u001b[0m                     \u001b[94m0.7718\u001b[0m        \u001b[36m0.4955\u001b[0m  0.0041  1.1696\n",
      "     21            0.7448                     0.7580        \u001b[35m0.4870\u001b[0m            0.7207                     0.7344        0.5470  0.0036  1.1629\n",
      "     22            \u001b[36m0.7802\u001b[0m                     \u001b[32m0.7846\u001b[0m        0.5107            0.7699                     \u001b[94m0.7754\u001b[0m        0.5040  0.0032  1.1659\n",
      "     23            0.7737                     0.7813        \u001b[35m0.4689\u001b[0m            0.7540                     0.7619        0.5113  0.0028  1.1619\n",
      "     24            \u001b[36m0.7839\u001b[0m                     \u001b[32m0.7882\u001b[0m        0.4852            \u001b[31m0.7728\u001b[0m                     \u001b[94m0.7768\u001b[0m        0.4958  0.0024  1.1719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25            \u001b[36m0.7893\u001b[0m                     \u001b[32m0.7926\u001b[0m        \u001b[35m0.4662\u001b[0m            0.7569                     0.7612        0.4992  0.0020  1.1709\n",
      "     26            \u001b[36m0.7940\u001b[0m                     \u001b[32m0.7939\u001b[0m        \u001b[35m0.4630\u001b[0m            0.7699                     0.7712        \u001b[36m0.4916\u001b[0m  0.0016  1.1689\n",
      "     27            0.7726                     0.7821        \u001b[35m0.4560\u001b[0m            0.7453                     0.7540        0.5089  0.0013  1.1659\n",
      "     28            0.7911                     \u001b[32m0.7963\u001b[0m        0.4593            0.7713                     0.7767        \u001b[36m0.4842\u001b[0m  0.0010  1.1619\n",
      "     29            0.7755                     0.7864        \u001b[35m0.4554\u001b[0m            0.7554                     0.7656        0.4987  0.0007  1.1659\n",
      "     30            0.7929                     \u001b[32m0.7977\u001b[0m        \u001b[35m0.4412\u001b[0m            0.7670                     0.7731        0.4847  0.0005  1.1634\n",
      "     31            0.7893                     0.7961        0.4437            0.7656                     0.7730        0.4945  0.0003  1.1689\n",
      "     32            0.7824                     0.7912        \u001b[35m0.4398\u001b[0m            0.7670                     0.7755        0.4988  0.0002  1.1679\n",
      "     33            0.7940                     \u001b[32m0.8002\u001b[0m        \u001b[35m0.4359\u001b[0m            0.7656                     0.7724        0.4890  0.0001  1.1729\n",
      "     34            0.7882                     0.7949        \u001b[35m0.4356\u001b[0m            0.7627                     0.7694        0.4923  0.0000  1.1671\n",
      "     35            0.7940                     0.7980        \u001b[35m0.4297\u001b[0m            0.7670                     0.7725        \u001b[36m0.4834\u001b[0m  0.0000  1.1649\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6687\u001b[0m                     \u001b[32m0.6510\u001b[0m        \u001b[35m3.9642\u001b[0m            \u001b[31m0.6541\u001b[0m                     \u001b[94m0.6362\u001b[0m        \u001b[36m2.2664\u001b[0m  0.0100  1.1625\n",
      "      2            0.6336                     \u001b[32m0.6599\u001b[0m        \u001b[35m1.7932\u001b[0m            0.6310                     \u001b[94m0.6563\u001b[0m        2.4300  0.0100  1.1629\n",
      "      3            0.6303                     0.5979        2.2581            0.6093                     0.5735        2.3539  0.0099  1.1619\n",
      "      4            0.6130                     0.6314        \u001b[35m1.4124\u001b[0m            0.6208                     0.6375        2.5672  0.0098  1.1609\n",
      "      5            \u001b[36m0.7393\u001b[0m                     \u001b[32m0.7362\u001b[0m        \u001b[35m1.1231\u001b[0m            \u001b[31m0.7221\u001b[0m                     \u001b[94m0.7177\u001b[0m        \u001b[36m0.7565\u001b[0m  0.0097  1.1629\n",
      "      6            0.7104                     0.7095        \u001b[35m0.9754\u001b[0m            0.6715                     0.6693        \u001b[36m0.7473\u001b[0m  0.0095  1.1719\n",
      "      7            0.6897                     0.7058        1.5130            0.6715                     0.6877        0.8929  0.0093  1.1726\n",
      "      8            0.7104                     0.7194        \u001b[35m0.7387\u001b[0m            0.6787                     0.6879        \u001b[36m0.6944\u001b[0m  0.0090  1.1599\n",
      "      9            \u001b[36m0.7498\u001b[0m                     \u001b[32m0.7579\u001b[0m        \u001b[35m0.6583\u001b[0m            0.7048                     0.7124        \u001b[36m0.5612\u001b[0m  0.0087  1.1609\n",
      "     10            0.7295                     0.7446        \u001b[35m0.5802\u001b[0m            0.7192                     \u001b[94m0.7322\u001b[0m        0.5754  0.0084  1.1664\n",
      "     11            0.7426                     0.7428        0.5922            0.7048                     0.7007        0.6461  0.0080  1.1639\n",
      "     12            \u001b[36m0.7524\u001b[0m                     0.7405        \u001b[35m0.5516\u001b[0m            0.7221                     0.7069        0.6462  0.0076  1.1659\n",
      "     13            0.7386                     0.7537        \u001b[35m0.5294\u001b[0m            0.6961                     0.7124        \u001b[36m0.5596\u001b[0m  0.0072  1.1679\n",
      "     14            \u001b[36m0.7839\u001b[0m                     \u001b[32m0.7784\u001b[0m        \u001b[35m0.4955\u001b[0m            \u001b[31m0.7525\u001b[0m                     \u001b[94m0.7455\u001b[0m        \u001b[36m0.5456\u001b[0m  0.0068  1.1656\n",
      "     15            0.7723                     0.7727        0.4981            0.7091                     0.7065        0.5563  0.0064  1.1680\n",
      "     16            \u001b[36m0.7849\u001b[0m                     \u001b[32m0.7841\u001b[0m        0.5108            0.7221                     0.7198        \u001b[36m0.5414\u001b[0m  0.0059  1.1644\n",
      "     17            0.7697                     0.7788        \u001b[35m0.4937\u001b[0m            0.7192                     0.7274        \u001b[36m0.5363\u001b[0m  0.0055  1.1640\n",
      "     18            0.7846                     0.7839        \u001b[35m0.4869\u001b[0m            0.7381                     0.7348        \u001b[36m0.5361\u001b[0m  0.0050  1.1649\n",
      "     19            0.7781                     \u001b[32m0.7865\u001b[0m        \u001b[35m0.4635\u001b[0m            0.7308                     0.7358        \u001b[36m0.5308\u001b[0m  0.0045  1.1639\n",
      "     20            \u001b[36m0.7915\u001b[0m                     \u001b[32m0.7956\u001b[0m        0.4747            0.7366                     0.7377        0.5456  0.0041  1.1742\n",
      "     21            0.7639                     0.7779        \u001b[35m0.4590\u001b[0m            0.7062                     0.7192        0.5349  0.0036  1.1669\n",
      "     22            0.7853                     0.7919        \u001b[35m0.4543\u001b[0m            0.7308                     0.7361        0.5352  0.0032  1.1649\n",
      "     23            0.7799                     0.7889        \u001b[35m0.4511\u001b[0m            0.7323                     0.7407        \u001b[36m0.5201\u001b[0m  0.0028  1.1649\n",
      "     24            0.7810                     0.7920        \u001b[35m0.4428\u001b[0m            0.7236                     0.7325        0.5225  0.0024  1.1649\n",
      "     25            0.7907                     \u001b[32m0.7986\u001b[0m        \u001b[35m0.4425\u001b[0m            0.7308                     0.7370        0.5227  0.0020  1.1729\n",
      "     26            0.7915                     0.7954        \u001b[35m0.4320\u001b[0m            0.7323                     0.7350        0.5369  0.0016  1.1637\n",
      "     27            0.7907                     \u001b[32m0.7993\u001b[0m        \u001b[35m0.4279\u001b[0m            0.7279                     0.7343        0.5344  0.0013  1.1639\n",
      "     28            \u001b[36m0.8012\u001b[0m                     \u001b[32m0.8075\u001b[0m        0.4288            0.7279                     0.7319        0.5259  0.0010  1.1632\n",
      "     29            0.7980                     0.8051        0.4281            0.7279                     0.7334        0.5305  0.0007  1.1624\n",
      "     30            0.7994                     0.8051        \u001b[35m0.4180\u001b[0m            0.7381                     0.7426        0.5315  0.0005  1.1648\n",
      "     31            \u001b[36m0.8085\u001b[0m                     \u001b[32m0.8139\u001b[0m        0.4202            0.7366                     0.7407        0.5311  0.0003  1.1670\n",
      "     32            0.8012                     0.8078        \u001b[35m0.4147\u001b[0m            0.7352                     0.7406        0.5282  0.0002  1.1645\n",
      "     33            0.8045                     0.8094        0.4198            0.7395                     0.7427        0.5297  0.0001  1.1649\n",
      "     34            0.7545                     0.7664        \u001b[35m0.4077\u001b[0m            0.6845                     0.6956        0.5722  0.0000  1.1662\n",
      "     35            0.7976                     0.8041        0.4136            0.7337                     0.7381        0.5255  0.0000  1.1619\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5818\u001b[0m                     \u001b[32m0.5650\u001b[0m        \u001b[35m5.0601\u001b[0m            \u001b[31m0.5528\u001b[0m                     \u001b[94m0.5347\u001b[0m        \u001b[36m3.1476\u001b[0m  0.0100  1.1624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            0.5507                     \u001b[32m0.5877\u001b[0m        \u001b[35m2.6342\u001b[0m            0.5340                     \u001b[94m0.5708\u001b[0m        4.5424  0.0100  1.1635\n",
      "      3            \u001b[36m0.6484\u001b[0m                     \u001b[32m0.6651\u001b[0m        \u001b[35m1.7350\u001b[0m            \u001b[31m0.6281\u001b[0m                     \u001b[94m0.6453\u001b[0m        \u001b[36m0.9960\u001b[0m  0.0099  1.1629\n",
      "      4            \u001b[36m0.6622\u001b[0m                     0.6356        1.7840            \u001b[31m0.6425\u001b[0m                     0.6148        1.1811  0.0098  1.1639\n",
      "      5            \u001b[36m0.6629\u001b[0m                     \u001b[32m0.6813\u001b[0m        \u001b[35m0.8864\u001b[0m            0.6295                     \u001b[94m0.6490\u001b[0m        \u001b[36m0.8822\u001b[0m  0.0097  1.1669\n",
      "      6            \u001b[36m0.7064\u001b[0m                     \u001b[32m0.7120\u001b[0m        0.9038            \u001b[31m0.6845\u001b[0m                     \u001b[94m0.6905\u001b[0m        0.8952  0.0095  1.1729\n",
      "      7            0.7060                     0.7087        \u001b[35m0.8663\u001b[0m            \u001b[31m0.7019\u001b[0m                     \u001b[94m0.7035\u001b[0m        \u001b[36m0.7716\u001b[0m  0.0093  1.1704\n",
      "      8            \u001b[36m0.7078\u001b[0m                     0.7095        0.9524            0.6946                     0.6951        0.7954  0.0090  1.1624\n",
      "      9            \u001b[36m0.7201\u001b[0m                     \u001b[32m0.7286\u001b[0m        \u001b[35m0.7181\u001b[0m            0.6946                     \u001b[94m0.7036\u001b[0m        \u001b[36m0.6878\u001b[0m  0.0087  1.1619\n",
      "     10            0.7136                     0.7191        \u001b[35m0.6071\u001b[0m            \u001b[31m0.7062\u001b[0m                     \u001b[94m0.7123\u001b[0m        \u001b[36m0.6243\u001b[0m  0.0084  1.1680\n",
      "     11            0.7078                     0.7267        0.6361            0.6758                     0.6946        0.6377  0.0080  1.1649\n",
      "     12            \u001b[36m0.7429\u001b[0m                     \u001b[32m0.7492\u001b[0m        0.6809            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7318\u001b[0m        \u001b[36m0.5743\u001b[0m  0.0076  1.1679\n",
      "     13            \u001b[36m0.7560\u001b[0m                     \u001b[32m0.7589\u001b[0m        \u001b[35m0.6066\u001b[0m            \u001b[31m0.7294\u001b[0m                     0.7318        \u001b[36m0.5536\u001b[0m  0.0072  1.1659\n",
      "     14            0.7252                     0.7367        \u001b[35m0.5756\u001b[0m            0.7033                     0.7153        0.6073  0.0068  1.1699\n",
      "     15            \u001b[36m0.7636\u001b[0m                     \u001b[32m0.7630\u001b[0m        \u001b[35m0.5235\u001b[0m            0.7207                     0.7182        0.5615  0.0064  1.1667\n",
      "     16            0.7600                     \u001b[32m0.7651\u001b[0m        0.5267            0.7178                     0.7213        \u001b[36m0.5525\u001b[0m  0.0059  1.1669\n",
      "     17            0.7516                     \u001b[32m0.7658\u001b[0m        \u001b[35m0.5159\u001b[0m            0.7164                     0.7299        0.5538  0.0055  1.1684\n",
      "     18            0.7328                     0.7438        \u001b[35m0.5156\u001b[0m            0.7019                     0.7125        0.6174  0.0050  1.1669\n",
      "     19            \u001b[36m0.7853\u001b[0m                     \u001b[32m0.7870\u001b[0m        0.5162            \u001b[31m0.7337\u001b[0m                     \u001b[94m0.7345\u001b[0m        \u001b[36m0.5444\u001b[0m  0.0045  1.1730\n",
      "     20            0.7701                     0.7801        0.5235            0.7323                     \u001b[94m0.7407\u001b[0m        \u001b[36m0.5305\u001b[0m  0.0041  1.1679\n",
      "     21            0.7654                     0.7792        \u001b[35m0.4734\u001b[0m            0.6990                     0.7120        0.5474  0.0036  1.1639\n",
      "     22            0.7781                     0.7819        0.4863            0.6961                     0.6992        0.5567  0.0032  1.1669\n",
      "     23            0.7773                     0.7863        0.4942            0.7164                     0.7247        \u001b[36m0.5298\u001b[0m  0.0028  1.1709\n",
      "     24            0.7625                     0.7764        \u001b[35m0.4703\u001b[0m            0.7221                     0.7348        0.5406  0.0024  1.1719\n",
      "     25            \u001b[36m0.7875\u001b[0m                     \u001b[32m0.7954\u001b[0m        \u001b[35m0.4669\u001b[0m            0.7279                     0.7346        0.5330  0.0020  1.1664\n",
      "     26            0.7542                     0.7706        \u001b[35m0.4614\u001b[0m            0.6918                     0.7081        0.5621  0.0016  1.1649\n",
      "     27            0.7592                     0.7756        \u001b[35m0.4549\u001b[0m            0.6990                     0.7156        0.5557  0.0013  1.1659\n",
      "     28            0.7810                     0.7924        \u001b[35m0.4459\u001b[0m            0.7091                     0.7188        0.5434  0.0010  1.1630\n",
      "     29            0.7784                     0.7897        0.4480            0.7149                     0.7246        0.5357  0.0007  1.1699\n",
      "     30            0.7867                     \u001b[32m0.7969\u001b[0m        \u001b[35m0.4375\u001b[0m            0.7149                     0.7231        0.5316  0.0005  1.1654\n",
      "     31            0.7759                     0.7882        0.4381            0.7120                     0.7223        0.5358  0.0003  1.1639\n",
      "     32            0.7799                     0.7924        0.4375            0.7135                     0.7251        0.5435  0.0002  1.1689\n",
      "     33            0.7737                     0.7866        \u001b[35m0.4307\u001b[0m            0.6990                     0.7105        0.5400  0.0001  1.1659\n",
      "     34            \u001b[36m0.7900\u001b[0m                     \u001b[32m0.8004\u001b[0m        \u001b[35m0.4282\u001b[0m            0.7178                     0.7258        0.5319  0.0000  1.1694\n",
      "     35            0.7839                     0.7950        0.4286            0.7192                     0.7292        0.5319  0.0000  1.1649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6400\u001b[0m                     \u001b[32m0.5758\u001b[0m        \u001b[35m4.6201\u001b[0m            \u001b[31m0.6578\u001b[0m                     \u001b[94m0.5931\u001b[0m        \u001b[36m3.9431\u001b[0m  0.0100  2.9062\n",
      "      2            0.5731                     0.5260        \u001b[35m1.9192\u001b[0m            0.5668                     0.5055        \u001b[36m2.9807\u001b[0m  0.0100  2.6180\n",
      "      3            0.5673                     0.5528        \u001b[35m1.1819\u001b[0m            0.5608                     0.5370        \u001b[36m2.8847\u001b[0m  0.0099  2.6150\n",
      "      4            \u001b[36m0.7648\u001b[0m                     \u001b[32m0.7062\u001b[0m        \u001b[35m1.1752\u001b[0m            \u001b[31m0.7608\u001b[0m                     \u001b[94m0.6996\u001b[0m        \u001b[36m0.5890\u001b[0m  0.0098  2.6081\n",
      "      5            0.6957                     0.6602        \u001b[35m0.6220\u001b[0m            0.6850                     0.6564        0.6894  0.0097  2.6070\n",
      "      6            0.7339                     \u001b[32m0.7160\u001b[0m        0.6601            0.7362                     \u001b[94m0.7168\u001b[0m        \u001b[36m0.5604\u001b[0m  0.0095  2.6080\n",
      "      7            \u001b[36m0.7982\u001b[0m                     0.7145        \u001b[35m0.5834\u001b[0m            \u001b[31m0.7887\u001b[0m                     0.6990        0.5706  0.0093  2.6090\n",
      "      8            0.7593                     \u001b[32m0.7395\u001b[0m        \u001b[35m0.5789\u001b[0m            0.7528                     \u001b[94m0.7239\u001b[0m        0.5628  0.0090  2.6490\n",
      "      9            0.7809                     0.7303        \u001b[35m0.5644\u001b[0m            0.7794                     \u001b[94m0.7255\u001b[0m        \u001b[36m0.5443\u001b[0m  0.0087  2.6325\n",
      "     10            \u001b[36m0.8096\u001b[0m                     0.7240        \u001b[35m0.5479\u001b[0m            \u001b[31m0.7993\u001b[0m                     0.7157        0.5508  0.0084  2.6190\n",
      "     11            \u001b[36m0.8141\u001b[0m                     0.7260        0.5586            0.7967                     0.7082        0.5510  0.0080  2.6360\n",
      "     12            0.7752                     \u001b[32m0.7488\u001b[0m        0.5613            0.7615                     \u001b[94m0.7307\u001b[0m        \u001b[36m0.5315\u001b[0m  0.0076  2.6166\n",
      "     13            0.7468                     \u001b[32m0.7542\u001b[0m        \u001b[35m0.5449\u001b[0m            0.7369                     \u001b[94m0.7362\u001b[0m        \u001b[36m0.5303\u001b[0m  0.0072  2.6291\n",
      "     14            \u001b[36m0.8364\u001b[0m                     0.7179        0.5518            \u001b[31m0.8186\u001b[0m                     0.6953        0.5667  0.0068  2.6160\n",
      "     15            0.7734                     \u001b[32m0.7546\u001b[0m        0.5450            0.7595                     \u001b[94m0.7397\u001b[0m        \u001b[36m0.5291\u001b[0m  0.0064  2.6360\n",
      "     16            0.7123                     0.7529        \u001b[35m0.5389\u001b[0m            0.7017                     0.7352        \u001b[36m0.5271\u001b[0m  0.0059  2.6353\n",
      "     17            0.7543                     \u001b[32m0.7609\u001b[0m        \u001b[35m0.5373\u001b[0m            0.7395                     \u001b[94m0.7451\u001b[0m        0.5300  0.0055  2.6399\n",
      "     18            0.8130                     0.7542        0.5411            0.7953                     0.7337        0.5346  0.0050  2.6350\n",
      "     19            0.7630                     \u001b[32m0.7669\u001b[0m        \u001b[35m0.5245\u001b[0m            0.7502                     0.7428        \u001b[36m0.5250\u001b[0m  0.0045  2.6335\n",
      "     20            0.7525                     \u001b[32m0.7715\u001b[0m        0.5281            0.7375                     \u001b[94m0.7483\u001b[0m        \u001b[36m0.5164\u001b[0m  0.0041  2.6277\n",
      "     21            0.7917                     0.7672        \u001b[35m0.5188\u001b[0m            0.7748                     0.7373        0.5311  0.0036  2.6399\n",
      "     22            0.7997                     \u001b[32m0.7812\u001b[0m        \u001b[35m0.5133\u001b[0m            0.7807                     0.7438        0.5222  0.0032  2.6391\n",
      "     23            0.8035                     0.7682        \u001b[35m0.5077\u001b[0m            0.7807                     0.7380        0.5276  0.0028  2.6369\n",
      "     24            0.7601                     0.7758        \u001b[35m0.5056\u001b[0m            0.7522                     \u001b[94m0.7542\u001b[0m        0.5187  0.0024  2.6360\n",
      "     25            0.7635                     0.7786        \u001b[35m0.5003\u001b[0m            0.7488                     \u001b[94m0.7566\u001b[0m        \u001b[36m0.5163\u001b[0m  0.0020  2.6385\n",
      "     26            0.7771                     \u001b[32m0.7854\u001b[0m        \u001b[35m0.4960\u001b[0m            0.7635                     0.7553        \u001b[36m0.5141\u001b[0m  0.0016  2.6325\n",
      "     27            0.8040                     \u001b[32m0.7860\u001b[0m        0.4967            0.7827                     0.7480        0.5148  0.0013  2.6399\n",
      "     28            0.7953                     0.7786        \u001b[35m0.4905\u001b[0m            0.7734                     0.7394        0.5157  0.0010  2.6360\n",
      "     29            0.7862                     \u001b[32m0.7880\u001b[0m        \u001b[35m0.4811\u001b[0m            0.7728                     \u001b[94m0.7624\u001b[0m        \u001b[36m0.5091\u001b[0m  0.0007  2.6379\n",
      "     30            0.8080                     \u001b[32m0.7892\u001b[0m        \u001b[35m0.4774\u001b[0m            0.7860                     0.7500        0.5125  0.0005  2.6405\n",
      "     31            0.7905                     \u001b[32m0.7899\u001b[0m        0.4783            0.7721                     0.7561        0.5101  0.0003  2.6310\n",
      "     32            0.8015                     0.7867        0.4797            0.7801                     0.7493        0.5121  0.0002  2.6360\n",
      "     33            0.7963                     0.7887        \u001b[35m0.4741\u001b[0m            0.7748                     0.7548        0.5108  0.0001  2.6419\n",
      "     34            0.7997                     0.7841        \u001b[35m0.4700\u001b[0m            0.7767                     0.7458        0.5125  0.0000  2.6352\n",
      "     35            0.7953                     0.7874        0.4780            0.7741                     0.7486        0.5107  0.0000  2.6344\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.8125\u001b[0m                     \u001b[32m0.5490\u001b[0m        \u001b[35m4.1604\u001b[0m            \u001b[31m0.8047\u001b[0m                     \u001b[94m0.5304\u001b[0m        \u001b[36m3.6219\u001b[0m  0.0100  2.5560\n",
      "      2            0.4488                     \u001b[32m0.6055\u001b[0m        \u001b[35m1.9091\u001b[0m            0.4478                     \u001b[94m0.6056\u001b[0m        \u001b[36m2.2120\u001b[0m  0.0100  2.5408\n",
      "      3            0.6548                     \u001b[32m0.6123\u001b[0m        \u001b[35m1.0405\u001b[0m            0.6664                     \u001b[94m0.6246\u001b[0m        \u001b[36m1.0093\u001b[0m  0.0099  2.5542\n",
      "      4            0.6591                     \u001b[32m0.6489\u001b[0m        1.0521            0.6585                     \u001b[94m0.6607\u001b[0m        1.0098  0.0098  2.5561\n",
      "      5            0.6365                     \u001b[32m0.6846\u001b[0m        \u001b[35m0.7660\u001b[0m            0.6432                     \u001b[94m0.7040\u001b[0m        \u001b[36m0.5828\u001b[0m  0.0097  2.5502\n",
      "      6            0.7495                     0.6413        \u001b[35m0.7067\u001b[0m            0.7754                     0.6573        0.8820  0.0095  2.5382\n",
      "      7            0.7688                     0.6454        0.7230            0.7894                     0.6746        0.7752  0.0093  2.5482\n",
      "      8            0.7379                     0.6621        \u001b[35m0.6534\u001b[0m            0.7455                     0.6610        0.6470  0.0090  2.5572\n",
      "      9            0.7772                     \u001b[32m0.7325\u001b[0m        0.6649            0.7867                     \u001b[94m0.7299\u001b[0m        \u001b[36m0.5497\u001b[0m  0.0087  2.5365\n",
      "     10            0.7934                     0.6556        \u001b[35m0.5710\u001b[0m            \u001b[31m0.8093\u001b[0m                     0.6750        0.5972  0.0084  2.5572\n",
      "     11            0.7993                     0.7166        0.6324            \u001b[31m0.8106\u001b[0m                     0.7270        0.5609  0.0080  2.5464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12            0.7962                     0.7301        \u001b[35m0.5573\u001b[0m            0.8013                     \u001b[94m0.7301\u001b[0m        \u001b[36m0.5491\u001b[0m  0.0076  2.5652\n",
      "     13            0.7460                     \u001b[32m0.7329\u001b[0m        \u001b[35m0.5515\u001b[0m            0.7449                     \u001b[94m0.7337\u001b[0m        \u001b[36m0.5334\u001b[0m  0.0072  2.5552\n",
      "     14            0.7998                     \u001b[32m0.7392\u001b[0m        \u001b[35m0.5493\u001b[0m            0.8060                     \u001b[94m0.7358\u001b[0m        0.5392  0.0068  2.5589\n",
      "     15            \u001b[36m0.8307\u001b[0m                     0.7108        \u001b[35m0.5448\u001b[0m            \u001b[31m0.8399\u001b[0m                     0.7214        0.5773  0.0064  2.5409\n",
      "     16            0.8113                     \u001b[32m0.7426\u001b[0m        0.5484            0.8100                     \u001b[94m0.7412\u001b[0m        0.5389  0.0059  2.5452\n",
      "     17            0.7837                     \u001b[32m0.7609\u001b[0m        \u001b[35m0.5414\u001b[0m            0.7814                     \u001b[94m0.7589\u001b[0m        \u001b[36m0.5261\u001b[0m  0.0055  2.5616\n",
      "     18            0.8005                     0.7554        \u001b[35m0.5328\u001b[0m            0.7987                     0.7562        \u001b[36m0.5251\u001b[0m  0.0050  2.5619\n",
      "     19            0.8048                     0.7390        \u001b[35m0.5236\u001b[0m            0.8126                     0.7369        0.5370  0.0045  2.5631\n",
      "     20            0.8171                     0.7465        \u001b[35m0.5236\u001b[0m            0.8199                     0.7487        0.5409  0.0041  2.5538\n",
      "     21            0.8179                     0.7331        \u001b[35m0.5168\u001b[0m            0.8259                     0.7290        0.5568  0.0036  2.6070\n",
      "     22            0.7847                     \u001b[32m0.7622\u001b[0m        0.5212            0.7834                     0.7572        \u001b[36m0.5229\u001b[0m  0.0032  2.5706\n",
      "     23            0.8106                     \u001b[32m0.7663\u001b[0m        0.5188            0.8153                     \u001b[94m0.7693\u001b[0m        \u001b[36m0.5209\u001b[0m  0.0028  2.5761\n",
      "     24            0.8181                     0.7580        \u001b[35m0.5150\u001b[0m            0.8159                     0.7550        0.5329  0.0024  2.5495\n",
      "     25            0.7914                     \u001b[32m0.7732\u001b[0m        \u001b[35m0.5133\u001b[0m            0.7894                     0.7608        \u001b[36m0.5165\u001b[0m  0.0020  2.5462\n",
      "     26            0.7935                     0.7716        \u001b[35m0.5052\u001b[0m            0.7880                     0.7644        \u001b[36m0.5151\u001b[0m  0.0016  2.5502\n",
      "     27            0.8071                     0.7653        \u001b[35m0.5016\u001b[0m            0.8073                     0.7600        0.5206  0.0013  2.5495\n",
      "     28            0.8013                     \u001b[32m0.7760\u001b[0m        \u001b[35m0.4938\u001b[0m            0.7914                     0.7591        0.5211  0.0010  2.5482\n",
      "     29            0.8113                     0.7718        \u001b[35m0.4930\u001b[0m            0.8113                     0.7624        0.5211  0.0007  2.5522\n",
      "     30            0.8184                     0.7696        \u001b[35m0.4891\u001b[0m            0.8186                     0.7669        0.5218  0.0005  2.5472\n",
      "     31            0.8156                     0.7712        0.4935            0.8133                     0.7637        0.5212  0.0003  2.5399\n",
      "     32            0.8071                     0.7748        0.4921            0.8033                     0.7620        0.5189  0.0002  2.5456\n",
      "     33            0.8206                     0.7665        0.4956            0.8173                     0.7617        0.5244  0.0001  2.5582\n",
      "     34            0.8015                     \u001b[32m0.7768\u001b[0m        0.4899            0.7960                     0.7605        0.5215  0.0000  2.5621\n",
      "     35            0.8143                     0.7729        \u001b[35m0.4847\u001b[0m            0.8126                     0.7676        0.5216  0.0000  2.5572\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7311\u001b[0m                     \u001b[32m0.5939\u001b[0m        \u001b[35m4.1827\u001b[0m            \u001b[31m0.7322\u001b[0m                     \u001b[94m0.5989\u001b[0m        \u001b[36m4.4806\u001b[0m  0.0100  2.5651\n",
      "      2            0.6738                     \u001b[32m0.6157\u001b[0m        \u001b[35m2.2351\u001b[0m            0.6625                     0.5944        \u001b[36m1.7573\u001b[0m  0.0100  2.5392\n",
      "      3            \u001b[36m0.7640\u001b[0m                     \u001b[32m0.6721\u001b[0m        \u001b[35m1.2070\u001b[0m            \u001b[31m0.7542\u001b[0m                     \u001b[94m0.6531\u001b[0m        \u001b[36m1.0380\u001b[0m  0.0099  2.5432\n",
      "      4            0.7231                     0.6318        \u001b[35m1.0513\u001b[0m            0.7090                     0.6169        1.0411  0.0098  2.5289\n",
      "      5            0.7223                     \u001b[32m0.6990\u001b[0m        \u001b[35m0.7930\u001b[0m            0.6930                     \u001b[94m0.6861\u001b[0m        \u001b[36m0.6314\u001b[0m  0.0097  2.5458\n",
      "      6            0.7008                     \u001b[32m0.7050\u001b[0m        \u001b[35m0.7212\u001b[0m            0.6731                     0.6725        0.6560  0.0095  2.5485\n",
      "      7            \u001b[36m0.7864\u001b[0m                     \u001b[32m0.7128\u001b[0m        \u001b[35m0.6621\u001b[0m            \u001b[31m0.7721\u001b[0m                     \u001b[94m0.6962\u001b[0m        0.6492  0.0093  2.5421\n",
      "      8            0.7646                     \u001b[32m0.7409\u001b[0m        \u001b[35m0.6319\u001b[0m            0.7449                     \u001b[94m0.7206\u001b[0m        \u001b[36m0.5618\u001b[0m  0.0090  2.5433\n",
      "      9            \u001b[36m0.7949\u001b[0m                     0.7011        0.6324            0.7701                     0.6760        0.6340  0.0087  2.5400\n",
      "     10            0.7040                     0.7102        \u001b[35m0.5943\u001b[0m            0.6704                     0.6797        0.6030  0.0084  2.5402\n",
      "     11            0.7498                     \u001b[32m0.7418\u001b[0m        0.6258            0.7183                     \u001b[94m0.7234\u001b[0m        0.5653  0.0080  2.5442\n",
      "     12            \u001b[36m0.8105\u001b[0m                     0.7362        \u001b[35m0.5482\u001b[0m            \u001b[31m0.7754\u001b[0m                     0.7070        0.5650  0.0076  2.5492\n",
      "     13            0.7967                     \u001b[32m0.7468\u001b[0m        0.5517            0.7608                     0.7083        0.5666  0.0072  2.5413\n",
      "     14            0.7548                     0.7452        \u001b[35m0.5410\u001b[0m            0.7249                     0.7201        \u001b[36m0.5615\u001b[0m  0.0068  2.5424\n",
      "     15            0.7570                     \u001b[32m0.7640\u001b[0m        \u001b[35m0.5367\u001b[0m            0.7229                     0.7233        \u001b[36m0.5573\u001b[0m  0.0064  2.5509\n",
      "     16            0.8086                     0.7541        0.5388            0.7708                     0.7100        0.5646  0.0059  2.5562\n",
      "     17            \u001b[36m0.8252\u001b[0m                     0.7638        \u001b[35m0.5296\u001b[0m            \u001b[31m0.7880\u001b[0m                     0.7161        \u001b[36m0.5539\u001b[0m  0.0055  2.5611\n",
      "     18            0.8002                     0.7504        0.5315            0.7502                     0.6858        0.5824  0.0050  2.5472\n",
      "     19            0.7980                     0.7634        \u001b[35m0.5173\u001b[0m            0.7575                     0.7165        0.5557  0.0045  2.5631\n",
      "     20            0.7905                     \u001b[32m0.7789\u001b[0m        \u001b[35m0.5102\u001b[0m            0.7395                     0.7217        \u001b[36m0.5457\u001b[0m  0.0041  2.5614\n",
      "     21            0.7274                     0.7618        0.5126            0.6890                     \u001b[94m0.7290\u001b[0m        0.5693  0.0036  2.5517\n",
      "     22            0.7694                     \u001b[32m0.7808\u001b[0m        0.5122            0.7209                     0.7250        \u001b[36m0.5453\u001b[0m  0.0032  2.5492\n",
      "     23            0.7839                     0.7804        \u001b[35m0.5063\u001b[0m            0.7389                     \u001b[94m0.7359\u001b[0m        \u001b[36m0.5420\u001b[0m  0.0028  2.5532\n",
      "     24            \u001b[36m0.8311\u001b[0m                     0.7798        \u001b[35m0.4938\u001b[0m            0.7854                     0.7262        0.5529  0.0024  2.5531\n",
      "     25            \u001b[36m0.8342\u001b[0m                     \u001b[32m0.7880\u001b[0m        0.4946            \u001b[31m0.7900\u001b[0m                     0.7349        0.5442  0.0020  2.5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     26            0.8128                     \u001b[32m0.7961\u001b[0m        \u001b[35m0.4877\u001b[0m            0.7661                     \u001b[94m0.7481\u001b[0m        \u001b[36m0.5360\u001b[0m  0.0016  2.5602\n",
      "     27            \u001b[36m0.8402\u001b[0m                     0.7803        \u001b[35m0.4777\u001b[0m            \u001b[31m0.7907\u001b[0m                     0.7178        0.5527  0.0013  2.5482\n",
      "     28            0.8201                     0.7893        0.4791            0.7774                     0.7360        0.5422  0.0010  2.5573\n",
      "     29            0.8301                     0.7931        \u001b[35m0.4710\u001b[0m            0.7754                     0.7275        0.5488  0.0007  2.5562\n",
      "     30            0.8179                     \u001b[32m0.7989\u001b[0m        \u001b[35m0.4675\u001b[0m            0.7628                     0.7315        0.5454  0.0005  2.5462\n",
      "     31            0.8243                     0.7987        \u001b[35m0.4651\u001b[0m            0.7694                     0.7311        0.5440  0.0003  2.5442\n",
      "     32            0.8316                     0.7984        \u001b[35m0.4630\u001b[0m            0.7807                     0.7292        0.5449  0.0002  2.5472\n",
      "     33            0.8321                     0.7947        \u001b[35m0.4583\u001b[0m            0.7867                     0.7402        0.5473  0.0001  2.5621\n",
      "     34            0.8329                     \u001b[32m0.7992\u001b[0m        \u001b[35m0.4565\u001b[0m            0.7761                     0.7352        0.5409  0.0000  2.5594\n",
      "     35            0.8357                     0.7980        0.4614            0.7860                     0.7354        0.5467  0.0000  2.5507\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.8088\u001b[0m                     \u001b[32m0.5757\u001b[0m        \u001b[35m4.2694\u001b[0m            \u001b[31m0.8047\u001b[0m                     \u001b[94m0.5816\u001b[0m        \u001b[36m6.0769\u001b[0m  0.0100  2.5548\n",
      "      2            0.5804                     \u001b[32m0.5769\u001b[0m        \u001b[35m2.6523\u001b[0m            0.5561                     0.5678        \u001b[36m1.6685\u001b[0m  0.0100  2.5544\n",
      "      3            0.6794                     \u001b[32m0.6858\u001b[0m        \u001b[35m1.1669\u001b[0m            0.6611                     \u001b[94m0.6623\u001b[0m        \u001b[36m0.7502\u001b[0m  0.0099  2.5631\n",
      "      4            0.8060                     \u001b[32m0.6918\u001b[0m        \u001b[35m0.7517\u001b[0m            0.7920                     \u001b[94m0.6762\u001b[0m        \u001b[36m0.6596\u001b[0m  0.0098  2.5482\n",
      "      5            0.6495                     0.6807        0.7833            0.6385                     0.6661        0.7395  0.0097  2.5525\n",
      "      6            0.7751                     0.6276        \u001b[35m0.7401\u001b[0m            0.7907                     0.6359        0.6655  0.0095  2.5515\n",
      "      7            0.7507                     \u001b[32m0.7097\u001b[0m        \u001b[35m0.6512\u001b[0m            0.7183                     0.6649        0.6746  0.0093  2.5532\n",
      "      8            0.6786                     0.7002        \u001b[35m0.6257\u001b[0m            0.6651                     \u001b[94m0.6823\u001b[0m        \u001b[36m0.6241\u001b[0m  0.0090  2.5691\n",
      "      9            0.7194                     \u001b[32m0.7390\u001b[0m        \u001b[35m0.6031\u001b[0m            0.6924                     \u001b[94m0.7018\u001b[0m        \u001b[36m0.5898\u001b[0m  0.0087  2.5587\n",
      "     10            0.8022                     0.7001        \u001b[35m0.5850\u001b[0m            0.7920                     0.6893        0.6015  0.0084  2.5454\n",
      "     11            \u001b[36m0.8234\u001b[0m                     0.7276        \u001b[35m0.5755\u001b[0m            0.8020                     \u001b[94m0.7042\u001b[0m        \u001b[36m0.5736\u001b[0m  0.0080  2.5685\n",
      "     12            0.7600                     \u001b[32m0.7443\u001b[0m        \u001b[35m0.5630\u001b[0m            0.7302                     \u001b[94m0.7146\u001b[0m        \u001b[36m0.5612\u001b[0m  0.0076  2.5469\n",
      "     13            0.8061                     \u001b[32m0.7467\u001b[0m        \u001b[35m0.5427\u001b[0m            0.7807                     \u001b[94m0.7205\u001b[0m        0.5712  0.0072  2.5552\n",
      "     14            0.7558                     \u001b[32m0.7597\u001b[0m        \u001b[35m0.5413\u001b[0m            0.6977                     0.6962        \u001b[36m0.5586\u001b[0m  0.0068  2.5649\n",
      "     15            0.7528                     0.7450        \u001b[35m0.5308\u001b[0m            0.7355                     0.7105        0.5682  0.0064  2.5482\n",
      "     16            0.7392                     \u001b[32m0.7635\u001b[0m        0.5405            0.7003                     0.7139        \u001b[36m0.5504\u001b[0m  0.0059  2.5627\n",
      "     17            0.8123                     \u001b[32m0.7644\u001b[0m        0.5322            0.7841                     \u001b[94m0.7283\u001b[0m        0.5592  0.0055  2.5623\n",
      "     18            0.7596                     0.7532        \u001b[35m0.5232\u001b[0m            0.7342                     0.7126        0.5642  0.0050  2.5661\n",
      "     19            0.7963                     \u001b[32m0.7744\u001b[0m        \u001b[35m0.5163\u001b[0m            0.7475                     0.7090        0.5510  0.0045  2.5562\n",
      "     20            0.6937                     0.7552        \u001b[35m0.5163\u001b[0m            0.6598                     0.7039        0.5745  0.0041  2.5572\n",
      "     21            0.7849                     0.7741        \u001b[35m0.5095\u001b[0m            0.7369                     0.7099        0.5600  0.0036  2.5560\n",
      "     22            0.7407                     0.7677        \u001b[35m0.5030\u001b[0m            0.7056                     0.7128        0.5549  0.0032  2.5572\n",
      "     23            0.7894                     \u001b[32m0.7815\u001b[0m        \u001b[35m0.4959\u001b[0m            0.7502                     0.7282        0.5540  0.0028  2.5641\n",
      "     24            0.7960                     \u001b[32m0.7848\u001b[0m        0.4977            0.7581                     0.7213        0.5580  0.0024  2.5731\n",
      "     25            0.7977                     0.7829        \u001b[35m0.4882\u001b[0m            0.7581                     \u001b[94m0.7360\u001b[0m        0.5523  0.0020  2.5551\n",
      "     26            0.8136                     \u001b[32m0.7868\u001b[0m        \u001b[35m0.4862\u001b[0m            0.7728                     0.7200        \u001b[36m0.5482\u001b[0m  0.0016  2.5701\n",
      "     27            0.8068                     0.7852        \u001b[35m0.4802\u001b[0m            0.7548                     0.7120        0.5622  0.0013  2.5569\n",
      "     28            0.8121                     \u001b[32m0.7928\u001b[0m        \u001b[35m0.4761\u001b[0m            0.7834                     \u001b[94m0.7484\u001b[0m        0.5523  0.0010  2.5483\n",
      "     29            0.7982                     0.7913        \u001b[35m0.4729\u001b[0m            0.7555                     0.7329        0.5517  0.0007  2.5631\n",
      "     30            0.7698                     0.7886        \u001b[35m0.4686\u001b[0m            0.7269                     0.7286        0.5510  0.0005  2.5621\n",
      "     31            0.7995                     \u001b[32m0.7950\u001b[0m        \u001b[35m0.4655\u001b[0m            0.7595                     0.7368        0.5495  0.0003  2.5644\n",
      "     32            0.7949                     \u001b[32m0.7951\u001b[0m        \u001b[35m0.4637\u001b[0m            0.7542                     0.7350        0.5489  0.0002  2.5502\n",
      "     33            0.7952                     0.7939        \u001b[35m0.4591\u001b[0m            0.7575                     0.7385        \u001b[36m0.5460\u001b[0m  0.0001  2.5521\n",
      "     34            0.7904                     0.7928        0.4674            0.7548                     0.7412        0.5489  0.0000  2.5641\n",
      "     35            0.7995                     \u001b[32m0.7965\u001b[0m        0.4627            0.7621                     0.7457        0.5480  0.0000  2.5549\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6963\u001b[0m                     \u001b[32m0.6083\u001b[0m        \u001b[35m4.3175\u001b[0m            \u001b[31m0.6957\u001b[0m                     \u001b[94m0.6278\u001b[0m        \u001b[36m3.8150\u001b[0m  0.0100  2.5554\n",
      "      2            0.5636                     \u001b[32m0.6344\u001b[0m        \u001b[35m2.0838\u001b[0m            0.5748                     \u001b[94m0.6302\u001b[0m        \u001b[36m2.0887\u001b[0m  0.0100  2.5583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3            0.6664                     0.6190        \u001b[35m1.6145\u001b[0m            0.6777                     0.6300        \u001b[36m1.6843\u001b[0m  0.0099  2.5452\n",
      "      4            0.6473                     \u001b[32m0.6560\u001b[0m        \u001b[35m1.1486\u001b[0m            0.6532                     \u001b[94m0.6516\u001b[0m        \u001b[36m0.7790\u001b[0m  0.0098  2.5652\n",
      "      5            \u001b[36m0.7404\u001b[0m                     \u001b[32m0.6910\u001b[0m        \u001b[35m0.9134\u001b[0m            \u001b[31m0.7329\u001b[0m                     \u001b[94m0.6694\u001b[0m        \u001b[36m0.6547\u001b[0m  0.0097  2.5652\n",
      "      6            0.6397                     0.6484        \u001b[35m0.6326\u001b[0m            0.6432                     0.6543        0.7778  0.0095  2.5647\n",
      "      7            0.7294                     \u001b[32m0.6931\u001b[0m        0.6610            0.7282                     \u001b[94m0.6915\u001b[0m        0.7397  0.0093  2.5465\n",
      "      8            \u001b[36m0.7447\u001b[0m                     \u001b[32m0.7379\u001b[0m        \u001b[35m0.6260\u001b[0m            0.7209                     \u001b[94m0.7075\u001b[0m        \u001b[36m0.5807\u001b[0m  0.0090  2.5691\n",
      "      9            0.7412                     0.7252        \u001b[35m0.5845\u001b[0m            0.7316                     0.7052        \u001b[36m0.5762\u001b[0m  0.0087  2.5661\n",
      "     10            0.7173                     \u001b[32m0.7443\u001b[0m        \u001b[35m0.5516\u001b[0m            0.7043                     \u001b[94m0.7105\u001b[0m        \u001b[36m0.5552\u001b[0m  0.0084  2.5550\n",
      "     11            0.7282                     \u001b[32m0.7524\u001b[0m        \u001b[35m0.5482\u001b[0m            0.7209                     \u001b[94m0.7250\u001b[0m        \u001b[36m0.5545\u001b[0m  0.0080  2.5492\n",
      "     12            \u001b[36m0.7568\u001b[0m                     \u001b[32m0.7537\u001b[0m        0.5571            \u001b[31m0.7395\u001b[0m                     0.7232        0.5613  0.0076  2.5587\n",
      "     13            \u001b[36m0.7754\u001b[0m                     0.7339        0.5950            \u001b[31m0.7588\u001b[0m                     0.7042        0.5715  0.0072  2.5602\n",
      "     14            0.7605                     0.7519        \u001b[35m0.5439\u001b[0m            0.7422                     0.7160        0.5661  0.0068  2.5582\n",
      "     15            \u001b[36m0.8256\u001b[0m                     0.7443        \u001b[35m0.5361\u001b[0m            \u001b[31m0.7960\u001b[0m                     0.7020        0.5639  0.0064  2.5502\n",
      "     16            0.7646                     \u001b[32m0.7599\u001b[0m        0.5402            0.7375                     0.7176        0.5556  0.0059  2.5602\n",
      "     17            0.7591                     \u001b[32m0.7624\u001b[0m        \u001b[35m0.5288\u001b[0m            0.7329                     0.7221        \u001b[36m0.5432\u001b[0m  0.0055  2.5703\n",
      "     18            0.8103                     \u001b[32m0.7639\u001b[0m        \u001b[35m0.5177\u001b[0m            0.7821                     0.7110        0.5463  0.0050  2.5528\n",
      "     19            0.7749                     \u001b[32m0.7676\u001b[0m        \u001b[35m0.5169\u001b[0m            0.7515                     0.7246        0.5468  0.0045  2.5542\n",
      "     20            0.7148                     0.7596        \u001b[35m0.5096\u001b[0m            0.6877                     \u001b[94m0.7253\u001b[0m        0.5544  0.0041  2.5477\n",
      "     21            0.8115                     \u001b[32m0.7774\u001b[0m        0.5137            0.7807                     \u001b[94m0.7278\u001b[0m        0.5436  0.0036  2.5661\n",
      "     22            0.8070                     0.7751        \u001b[35m0.5034\u001b[0m            0.7728                     0.7229        0.5568  0.0032  2.5532\n",
      "     23            0.8179                     0.7773        \u001b[35m0.4952\u001b[0m            0.7887                     0.7224        0.5499  0.0028  2.5572\n",
      "     24            0.8091                     0.7767        0.4977            0.7860                     0.7252        0.5516  0.0024  2.5703\n",
      "     25            0.8206                     \u001b[32m0.7863\u001b[0m        \u001b[35m0.4909\u001b[0m            0.7841                     0.7225        0.5521  0.0020  2.5510\n",
      "     26            \u001b[36m0.8286\u001b[0m                     \u001b[32m0.7915\u001b[0m        \u001b[35m0.4856\u001b[0m            0.7907                     0.7251        0.5446  0.0016  2.5512\n",
      "     27            0.8239                     0.7883        \u001b[35m0.4828\u001b[0m            0.7814                     0.7194        \u001b[36m0.5424\u001b[0m  0.0013  2.5520\n",
      "     28            0.8118                     \u001b[32m0.7919\u001b[0m        \u001b[35m0.4783\u001b[0m            0.7761                     \u001b[94m0.7323\u001b[0m        0.5429  0.0010  2.5664\n",
      "     29            0.8133                     \u001b[32m0.7935\u001b[0m        \u001b[35m0.4745\u001b[0m            0.7754                     \u001b[94m0.7333\u001b[0m        0.5426  0.0007  2.5552\n",
      "     30            0.8286                     \u001b[32m0.7977\u001b[0m        \u001b[35m0.4699\u001b[0m            0.7827                     0.7231        0.5489  0.0005  2.5552\n",
      "     31            0.8224                     \u001b[32m0.8009\u001b[0m        0.4731            0.7748                     0.7271        0.5441  0.0003  2.5592\n",
      "     32            0.8203                     0.7989        \u001b[35m0.4610\u001b[0m            0.7728                     0.7273        0.5448  0.0002  2.5575\n",
      "     33            0.8269                     0.7974        0.4614            0.7801                     0.7215        0.5448  0.0001  2.5552\n",
      "     34            0.8238                     0.8003        \u001b[35m0.4597\u001b[0m            0.7787                     0.7295        0.5480  0.0000  2.5592\n",
      "     35            0.8261                     0.7998        0.4641            0.7787                     0.7236        0.5449  0.0000  2.5651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 0 0 ... 0 0 0] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5762\u001b[0m                     \u001b[32m0.5770\u001b[0m        \u001b[35m4.0680\u001b[0m            \u001b[31m0.5645\u001b[0m                     \u001b[94m0.5655\u001b[0m        \u001b[36m1.2058\u001b[0m  0.0100  2.4948\n",
      "      2            \u001b[36m0.6107\u001b[0m                     \u001b[32m0.6121\u001b[0m        \u001b[35m1.4256\u001b[0m            \u001b[31m0.5994\u001b[0m                     \u001b[94m0.6009\u001b[0m        1.4090  0.0100  1.7513\n",
      "      3            \u001b[36m0.6277\u001b[0m                     \u001b[32m0.6292\u001b[0m        \u001b[35m1.1706\u001b[0m            \u001b[31m0.6033\u001b[0m                     \u001b[94m0.6049\u001b[0m        1.5280  0.0099  1.7361\n",
      "      4            \u001b[36m0.6442\u001b[0m                     \u001b[32m0.6437\u001b[0m        1.2166            0.5994                     0.5990        \u001b[36m0.9984\u001b[0m  0.0098  1.7399\n",
      "      5            \u001b[36m0.6633\u001b[0m                     \u001b[32m0.6628\u001b[0m        \u001b[35m1.0286\u001b[0m            \u001b[31m0.6596\u001b[0m                     \u001b[94m0.6590\u001b[0m        \u001b[36m0.9623\u001b[0m  0.0097  1.7406\n",
      "      6            \u001b[36m0.6750\u001b[0m                     \u001b[32m0.6739\u001b[0m        \u001b[35m0.7280\u001b[0m            \u001b[31m0.6654\u001b[0m                     \u001b[94m0.6643\u001b[0m        \u001b[36m0.7151\u001b[0m  0.0095  1.7413\n",
      "      7            \u001b[36m0.7299\u001b[0m                     \u001b[32m0.7307\u001b[0m        0.7696            \u001b[31m0.7013\u001b[0m                     \u001b[94m0.7022\u001b[0m        \u001b[36m0.6356\u001b[0m  0.0093  1.7388\n",
      "      8            0.7252                     0.7262        0.7516            0.6741                     0.6750        0.6594  0.0090  1.7344\n",
      "      9            0.7056                     0.7052        \u001b[35m0.6781\u001b[0m            0.6663                     0.6661        0.8066  0.0087  1.7413\n",
      "     10            \u001b[36m0.7546\u001b[0m                     \u001b[32m0.7552\u001b[0m        \u001b[35m0.6259\u001b[0m            \u001b[31m0.7187\u001b[0m                     \u001b[94m0.7194\u001b[0m        \u001b[36m0.5997\u001b[0m  0.0084  1.7344\n",
      "     11            0.6978                     0.6989        \u001b[35m0.5924\u001b[0m            0.6731                     0.6744        0.7841  0.0080  1.7354\n",
      "     12            0.7255                     0.7255        0.7386            0.6906                     0.6908        0.7586  0.0076  1.7354\n",
      "     13            0.7432                     0.7440        0.6342            0.6838                     0.6846        0.7082  0.0072  1.7349\n",
      "     14            \u001b[36m0.7602\u001b[0m                     \u001b[32m0.7599\u001b[0m        0.6102            0.7139                     0.7135        \u001b[36m0.5952\u001b[0m  0.0068  1.7364\n",
      "     15            \u001b[36m0.7687\u001b[0m                     \u001b[32m0.7690\u001b[0m        \u001b[35m0.5318\u001b[0m            0.7110                     0.7113        \u001b[36m0.5884\u001b[0m  0.0064  1.7395\n",
      "     16            0.7522                     0.7515        \u001b[35m0.5313\u001b[0m            0.7139                     0.7133        0.6329  0.0059  1.7493\n",
      "     17            \u001b[36m0.7857\u001b[0m                     \u001b[32m0.7856\u001b[0m        \u001b[35m0.5167\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7262\u001b[0m        \u001b[36m0.5621\u001b[0m  0.0055  1.7389\n",
      "     18            \u001b[36m0.8066\u001b[0m                     \u001b[32m0.8066\u001b[0m        \u001b[35m0.5041\u001b[0m            \u001b[31m0.7391\u001b[0m                     \u001b[94m0.7390\u001b[0m        \u001b[36m0.5243\u001b[0m  0.0050  1.7334\n",
      "     19            0.7893                     0.7899        0.5055            0.7207                     0.7212        0.5541  0.0045  1.7354\n",
      "     20            \u001b[36m0.8083\u001b[0m                     \u001b[32m0.8086\u001b[0m        \u001b[35m0.4841\u001b[0m            0.7274                     0.7276        0.5365  0.0041  1.7354\n",
      "     21            0.7694                     0.7702        \u001b[35m0.4749\u001b[0m            0.7187                     0.7195        0.6435  0.0036  1.7384\n",
      "     22            \u001b[36m0.8085\u001b[0m                     0.8086        0.4893            \u001b[31m0.7459\u001b[0m                     \u001b[94m0.7459\u001b[0m        0.5387  0.0032  1.7384\n",
      "     23            0.8007                     0.8009        \u001b[35m0.4569\u001b[0m            0.7362                     0.7364        0.5560  0.0028  1.7325\n",
      "     24            \u001b[36m0.8143\u001b[0m                     \u001b[32m0.8142\u001b[0m        0.4694            0.7449                     0.7447        0.5545  0.0024  1.7443\n",
      "     25            \u001b[36m0.8265\u001b[0m                     \u001b[32m0.8267\u001b[0m        \u001b[35m0.4432\u001b[0m            \u001b[31m0.7478\u001b[0m                     \u001b[94m0.7479\u001b[0m        0.5260  0.0020  1.7423\n",
      "     26            \u001b[36m0.8299\u001b[0m                     \u001b[32m0.8301\u001b[0m        \u001b[35m0.4362\u001b[0m            \u001b[31m0.7488\u001b[0m                     \u001b[94m0.7490\u001b[0m        0.5252  0.0016  1.7403\n",
      "     27            \u001b[36m0.8330\u001b[0m                     \u001b[32m0.8332\u001b[0m        0.4378            \u001b[31m0.7498\u001b[0m                     \u001b[94m0.7498\u001b[0m        \u001b[36m0.5155\u001b[0m  0.0013  1.7399\n",
      "     28            0.8320                     0.8324        \u001b[35m0.4356\u001b[0m            0.7420                     0.7423        0.5164  0.0010  1.7344\n",
      "     29            \u001b[36m0.8371\u001b[0m                     \u001b[32m0.8373\u001b[0m        \u001b[35m0.4255\u001b[0m            0.7468                     0.7469        0.5160  0.0007  1.7385\n",
      "     30            \u001b[36m0.8391\u001b[0m                     \u001b[32m0.8392\u001b[0m        \u001b[35m0.4213\u001b[0m            0.7488                     0.7488        \u001b[36m0.5124\u001b[0m  0.0005  1.7398\n",
      "     31            \u001b[36m0.8396\u001b[0m                     \u001b[32m0.8397\u001b[0m        \u001b[35m0.4089\u001b[0m            0.7478                     0.7479        \u001b[36m0.5097\u001b[0m  0.0003  1.7392\n",
      "     32            \u001b[36m0.8403\u001b[0m                     \u001b[32m0.8405\u001b[0m        \u001b[35m0.4053\u001b[0m            0.7498                     \u001b[94m0.7499\u001b[0m        \u001b[36m0.5094\u001b[0m  0.0002  1.7314\n",
      "     33            0.8398                     0.8401        0.4081            0.7498                     \u001b[94m0.7499\u001b[0m        0.5105  0.0001  1.7413\n",
      "     34            \u001b[36m0.8427\u001b[0m                     \u001b[32m0.8429\u001b[0m        0.4065            0.7498                     \u001b[94m0.7499\u001b[0m        0.5114  0.0000  1.7499\n",
      "     35            0.8391                     0.8393        \u001b[35m0.4046\u001b[0m            0.7468                     0.7470        0.5098  0.0000  1.7419\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5451\u001b[0m                     \u001b[32m0.5428\u001b[0m        \u001b[35m3.4301\u001b[0m            \u001b[31m0.5412\u001b[0m                     \u001b[94m0.5387\u001b[0m        \u001b[36m5.5341\u001b[0m  0.0100  1.7321\n",
      "      2            \u001b[36m0.6347\u001b[0m                     \u001b[32m0.6350\u001b[0m        \u001b[35m1.5580\u001b[0m            \u001b[31m0.6246\u001b[0m                     \u001b[94m0.6249\u001b[0m        \u001b[36m1.0384\u001b[0m  0.0100  1.7364\n",
      "      3            0.6289                     0.6284        \u001b[35m0.9856\u001b[0m            0.6091                     0.6086        1.3004  0.0099  1.7403\n",
      "      4            \u001b[36m0.6670\u001b[0m                     \u001b[32m0.6661\u001b[0m        \u001b[35m0.8280\u001b[0m            \u001b[31m0.6382\u001b[0m                     \u001b[94m0.6372\u001b[0m        \u001b[36m0.7842\u001b[0m  0.0098  1.7437\n",
      "      5            \u001b[36m0.6672\u001b[0m                     \u001b[32m0.6672\u001b[0m        0.8438            0.6314                     0.6313        0.8370  0.0097  1.7306\n",
      "      6            \u001b[36m0.7114\u001b[0m                     \u001b[32m0.7115\u001b[0m        \u001b[35m0.7939\u001b[0m            \u001b[31m0.6857\u001b[0m                     \u001b[94m0.6858\u001b[0m        \u001b[36m0.6223\u001b[0m  0.0095  1.7392\n",
      "      7            0.6803                     0.6798        \u001b[35m0.7464\u001b[0m            0.6382                     0.6376        0.8009  0.0093  1.7403\n",
      "      8            \u001b[36m0.7252\u001b[0m                     \u001b[32m0.7253\u001b[0m        \u001b[35m0.7200\u001b[0m            \u001b[31m0.6964\u001b[0m                     \u001b[94m0.6964\u001b[0m        \u001b[36m0.5962\u001b[0m  0.0090  1.7334\n",
      "      9            0.7228                     0.7229        \u001b[35m0.6422\u001b[0m            0.6702                     0.6702        0.6728  0.0087  1.7403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     10            0.7129                     0.7129        0.6739            0.6809                     0.6807        0.6143  0.0084  1.7337\n",
      "     11            \u001b[36m0.7405\u001b[0m                     \u001b[32m0.7405\u001b[0m        \u001b[35m0.5997\u001b[0m            0.6887                     0.6885        \u001b[36m0.5733\u001b[0m  0.0080  1.7423\n",
      "     12            0.7238                     0.7245        \u001b[35m0.5614\u001b[0m            0.6896                     0.6902        0.6741  0.0076  1.7442\n",
      "     13            \u001b[36m0.7476\u001b[0m                     \u001b[32m0.7482\u001b[0m        \u001b[35m0.5595\u001b[0m            \u001b[31m0.7265\u001b[0m                     \u001b[94m0.7269\u001b[0m        \u001b[36m0.5574\u001b[0m  0.0072  1.7413\n",
      "     14            \u001b[36m0.7573\u001b[0m                     \u001b[32m0.7576\u001b[0m        0.5613            \u001b[31m0.7381\u001b[0m                     \u001b[94m0.7384\u001b[0m        \u001b[36m0.5392\u001b[0m  0.0068  1.7374\n",
      "     15            \u001b[36m0.7653\u001b[0m                     \u001b[32m0.7650\u001b[0m        \u001b[35m0.5427\u001b[0m            0.7207                     0.7202        0.5535  0.0064  1.7369\n",
      "     16            \u001b[36m0.7689\u001b[0m                     \u001b[32m0.7697\u001b[0m        \u001b[35m0.5303\u001b[0m            0.7255                     0.7262        0.5559  0.0059  1.7479\n",
      "     17            \u001b[36m0.7811\u001b[0m                     \u001b[32m0.7815\u001b[0m        \u001b[35m0.5060\u001b[0m            \u001b[31m0.7391\u001b[0m                     \u001b[94m0.7392\u001b[0m        \u001b[36m0.5147\u001b[0m  0.0055  1.7354\n",
      "     18            \u001b[36m0.7857\u001b[0m                     \u001b[32m0.7861\u001b[0m        \u001b[35m0.5044\u001b[0m            \u001b[31m0.7459\u001b[0m                     \u001b[94m0.7462\u001b[0m        0.5290  0.0050  1.7483\n",
      "     19            \u001b[36m0.7859\u001b[0m                     0.7860        \u001b[35m0.4906\u001b[0m            0.7352                     0.7352        0.5325  0.0045  1.7354\n",
      "     20            \u001b[36m0.7876\u001b[0m                     \u001b[32m0.7880\u001b[0m        \u001b[35m0.4748\u001b[0m            \u001b[31m0.7662\u001b[0m                     \u001b[94m0.7665\u001b[0m        \u001b[36m0.5123\u001b[0m  0.0041  1.7463\n",
      "     21            \u001b[36m0.7920\u001b[0m                     \u001b[32m0.7925\u001b[0m        \u001b[35m0.4699\u001b[0m            0.7391                     0.7395        0.5301  0.0036  1.7364\n",
      "     22            0.7845                     0.7852        0.4712            0.7391                     0.7398        0.5228  0.0032  1.7388\n",
      "     23            \u001b[36m0.8085\u001b[0m                     \u001b[32m0.8086\u001b[0m        \u001b[35m0.4652\u001b[0m            0.7527                     0.7526        \u001b[36m0.5051\u001b[0m  0.0028  1.7444\n",
      "     24            0.8061                     0.8062        \u001b[35m0.4558\u001b[0m            0.7391                     0.7390        0.5200  0.0024  1.7338\n",
      "     25            \u001b[36m0.8124\u001b[0m                     \u001b[32m0.8122\u001b[0m        \u001b[35m0.4535\u001b[0m            0.7498                     0.7495        0.5132  0.0020  1.7378\n",
      "     26            0.8087                     0.8090        \u001b[35m0.4441\u001b[0m            0.7536                     0.7538        \u001b[36m0.5024\u001b[0m  0.0016  1.7403\n",
      "     27            \u001b[36m0.8163\u001b[0m                     \u001b[32m0.8164\u001b[0m        \u001b[35m0.4422\u001b[0m            0.7507                     0.7508        0.5037  0.0013  1.7374\n",
      "     28            0.8141                     0.8139        \u001b[35m0.4368\u001b[0m            0.7498                     0.7494        0.5149  0.0010  1.7357\n",
      "     29            \u001b[36m0.8197\u001b[0m                     \u001b[32m0.8200\u001b[0m        \u001b[35m0.4339\u001b[0m            0.7595                     0.7597        \u001b[36m0.4991\u001b[0m  0.0007  1.7354\n",
      "     30            0.8197                     0.8199        \u001b[35m0.4218\u001b[0m            0.7546                     0.7547        \u001b[36m0.4980\u001b[0m  0.0005  1.7413\n",
      "     31            \u001b[36m0.8226\u001b[0m                     \u001b[32m0.8228\u001b[0m        0.4219            0.7662                     0.7664        0.5002  0.0003  1.7483\n",
      "     32            \u001b[36m0.8231\u001b[0m                     \u001b[32m0.8233\u001b[0m        \u001b[35m0.4127\u001b[0m            0.7595                     0.7596        0.4996  0.0002  1.7354\n",
      "     33            \u001b[36m0.8243\u001b[0m                     \u001b[32m0.8245\u001b[0m        0.4158            0.7556                     0.7557        0.5008  0.0001  1.7463\n",
      "     34            \u001b[36m0.8250\u001b[0m                     \u001b[32m0.8252\u001b[0m        0.4151            0.7546                     0.7547        0.5000  0.0000  1.7412\n",
      "     35            0.8248                     0.8250        0.4164            0.7575                     0.7577        0.5005  0.0000  1.7413\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5566\u001b[0m                     \u001b[32m0.5550\u001b[0m        \u001b[35m5.1527\u001b[0m            \u001b[31m0.5664\u001b[0m                     \u001b[94m0.5648\u001b[0m        \u001b[36m3.8337\u001b[0m  0.0100  1.7364\n",
      "      2            \u001b[36m0.6282\u001b[0m                     \u001b[32m0.6272\u001b[0m        \u001b[35m3.3887\u001b[0m            \u001b[31m0.6178\u001b[0m                     \u001b[94m0.6168\u001b[0m        \u001b[36m1.3308\u001b[0m  0.0100  1.7403\n",
      "      3            \u001b[36m0.6333\u001b[0m                     \u001b[32m0.6319\u001b[0m        \u001b[35m0.9613\u001b[0m            0.6159                     0.6147        \u001b[36m0.7317\u001b[0m  0.0099  1.7603\n",
      "      4            0.6328                     0.6310        \u001b[35m0.9350\u001b[0m            \u001b[31m0.6217\u001b[0m                     \u001b[94m0.6201\u001b[0m        0.9081  0.0098  1.7374\n",
      "      5            \u001b[36m0.7012\u001b[0m                     \u001b[32m0.7020\u001b[0m        \u001b[35m0.8028\u001b[0m            \u001b[31m0.6819\u001b[0m                     \u001b[94m0.6827\u001b[0m        \u001b[36m0.6937\u001b[0m  0.0097  1.7384\n",
      "      6            \u001b[36m0.7124\u001b[0m                     \u001b[32m0.7122\u001b[0m        \u001b[35m0.7534\u001b[0m            \u001b[31m0.6877\u001b[0m                     \u001b[94m0.6877\u001b[0m        \u001b[36m0.6275\u001b[0m  0.0095  1.7349\n",
      "      7            0.6862                     0.6864        \u001b[35m0.6489\u001b[0m            \u001b[31m0.6896\u001b[0m                     \u001b[94m0.6896\u001b[0m        0.6673  0.0093  1.7354\n",
      "      8            0.6816                     0.6823        0.6747            0.6528                     0.6536        0.9290  0.0090  1.7345\n",
      "      9            0.6755                     0.6762        0.6811            0.6557                     0.6562        0.8081  0.0087  1.7384\n",
      "     10            \u001b[36m0.7551\u001b[0m                     \u001b[32m0.7554\u001b[0m        \u001b[35m0.6028\u001b[0m            \u001b[31m0.7362\u001b[0m                     \u001b[94m0.7367\u001b[0m        \u001b[36m0.5434\u001b[0m  0.0084  1.7423\n",
      "     11            \u001b[36m0.7740\u001b[0m                     \u001b[32m0.7741\u001b[0m        \u001b[35m0.5560\u001b[0m            \u001b[31m0.7536\u001b[0m                     \u001b[94m0.7538\u001b[0m        \u001b[36m0.5276\u001b[0m  0.0080  1.7374\n",
      "     12            0.6898                     0.6913        \u001b[35m0.5469\u001b[0m            0.6450                     0.6467        0.8978  0.0076  1.7346\n",
      "     13            0.7393                     0.7389        0.5955            0.7216                     0.7213        0.6114  0.0072  1.7456\n",
      "     14            \u001b[36m0.7774\u001b[0m                     \u001b[32m0.7773\u001b[0m        0.5638            0.7391                     0.7391        0.5542  0.0068  1.7364\n",
      "     15            0.7631                     0.7631        0.6038            0.7226                     0.7228        0.6081  0.0064  1.7393\n",
      "     16            0.7585                     0.7586        \u001b[35m0.5387\u001b[0m            0.7294                     0.7295        0.5703  0.0059  1.7453\n",
      "     17            \u001b[36m0.7864\u001b[0m                     \u001b[32m0.7868\u001b[0m        \u001b[35m0.5184\u001b[0m            0.7371                     0.7377        0.5547  0.0055  1.7387\n",
      "     18            \u001b[36m0.7976\u001b[0m                     \u001b[32m0.7975\u001b[0m        \u001b[35m0.5057\u001b[0m            0.7333                     0.7332        0.5367  0.0050  1.7379\n",
      "     19            0.7937                     0.7943        \u001b[35m0.4918\u001b[0m            0.7255                     0.7263        0.5337  0.0045  1.7380\n",
      "     20            0.7862                     0.7867        \u001b[35m0.4893\u001b[0m            0.7294                     0.7302        0.5596  0.0041  1.7433\n",
      "     21            \u001b[36m0.8100\u001b[0m                     \u001b[32m0.8102\u001b[0m        \u001b[35m0.4710\u001b[0m            0.7478                     0.7481        \u001b[36m0.5259\u001b[0m  0.0036  1.7433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22            0.8027                     0.8032        0.4968            \u001b[31m0.7565\u001b[0m                     \u001b[94m0.7572\u001b[0m        \u001b[36m0.5164\u001b[0m  0.0032  1.7364\n",
      "     23            0.8070                     0.8070        \u001b[35m0.4707\u001b[0m            0.7391                     0.7391        0.5432  0.0028  1.7374\n",
      "     24            \u001b[36m0.8175\u001b[0m                     \u001b[32m0.8176\u001b[0m        \u001b[35m0.4611\u001b[0m            \u001b[31m0.7614\u001b[0m                     \u001b[94m0.7615\u001b[0m        \u001b[36m0.4952\u001b[0m  0.0024  1.7358\n",
      "     25            0.8143                     0.8145        \u001b[35m0.4569\u001b[0m            \u001b[31m0.7653\u001b[0m                     \u001b[94m0.7655\u001b[0m        0.4985  0.0020  1.7443\n",
      "     26            \u001b[36m0.8260\u001b[0m                     \u001b[32m0.8261\u001b[0m        \u001b[35m0.4456\u001b[0m            \u001b[31m0.7682\u001b[0m                     \u001b[94m0.7683\u001b[0m        \u001b[36m0.4904\u001b[0m  0.0016  1.7463\n",
      "     27            0.8192                     0.8197        \u001b[35m0.4364\u001b[0m            \u001b[31m0.7692\u001b[0m                     \u001b[94m0.7697\u001b[0m        0.4982  0.0013  1.7453\n",
      "     28            0.8201                     0.8201        \u001b[35m0.4331\u001b[0m            0.7672                     0.7672        \u001b[36m0.4896\u001b[0m  0.0010  1.7493\n",
      "     29            \u001b[36m0.8303\u001b[0m                     \u001b[32m0.8305\u001b[0m        \u001b[35m0.4246\u001b[0m            0.7653                     0.7655        \u001b[36m0.4849\u001b[0m  0.0007  1.7334\n",
      "     30            \u001b[36m0.8313\u001b[0m                     \u001b[32m0.8317\u001b[0m        0.4259            0.7633                     0.7638        0.4975  0.0005  1.7469\n",
      "     31            0.8308                     0.8312        \u001b[35m0.4199\u001b[0m            0.7643                     0.7648        0.4967  0.0003  1.7423\n",
      "     32            \u001b[36m0.8330\u001b[0m                     \u001b[32m0.8332\u001b[0m        \u001b[35m0.4159\u001b[0m            0.7672                     0.7674        \u001b[36m0.4836\u001b[0m  0.0002  1.7377\n",
      "     33            \u001b[36m0.8350\u001b[0m                     \u001b[32m0.8352\u001b[0m        0.4176            0.7682                     0.7684        0.4867  0.0001  1.7473\n",
      "     34            0.8342                     0.8344        \u001b[35m0.4103\u001b[0m            0.7672                     0.7674        \u001b[36m0.4828\u001b[0m  0.0000  1.7503\n",
      "     35            0.8342                     0.8344        0.4120            0.7672                     0.7674        0.4856  0.0000  1.7423\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5301\u001b[0m                     \u001b[32m0.5280\u001b[0m        \u001b[35m4.8041\u001b[0m            \u001b[31m0.5102\u001b[0m                     \u001b[94m0.5081\u001b[0m        \u001b[36m1.2318\u001b[0m  0.0100  1.7367\n",
      "      2            \u001b[36m0.5718\u001b[0m                     \u001b[32m0.5740\u001b[0m        \u001b[35m1.7703\u001b[0m            \u001b[31m0.5538\u001b[0m                     \u001b[94m0.5560\u001b[0m        2.3887  0.0100  1.7449\n",
      "      3            \u001b[36m0.5908\u001b[0m                     \u001b[32m0.5891\u001b[0m        \u001b[35m1.2792\u001b[0m            \u001b[31m0.5917\u001b[0m                     \u001b[94m0.5900\u001b[0m        \u001b[36m0.8075\u001b[0m  0.0099  1.7344\n",
      "      4            \u001b[36m0.6488\u001b[0m                     \u001b[32m0.6491\u001b[0m        \u001b[35m1.2152\u001b[0m            \u001b[31m0.6489\u001b[0m                     \u001b[94m0.6494\u001b[0m        0.8591  0.0098  1.7453\n",
      "      5            \u001b[36m0.6859\u001b[0m                     \u001b[32m0.6860\u001b[0m        \u001b[35m0.8990\u001b[0m            \u001b[31m0.6780\u001b[0m                     \u001b[94m0.6781\u001b[0m        \u001b[36m0.6607\u001b[0m  0.0097  1.7423\n",
      "      6            0.6383                     0.6368        0.9101            0.6324                     0.6308        0.8876  0.0095  1.7419\n",
      "      7            0.6612                     0.6614        \u001b[35m0.8060\u001b[0m            0.6566                     0.6570        0.8903  0.0093  1.7380\n",
      "      8            \u001b[36m0.6939\u001b[0m                     \u001b[32m0.6938\u001b[0m        \u001b[35m0.7235\u001b[0m            \u001b[31m0.6867\u001b[0m                     \u001b[94m0.6865\u001b[0m        0.7297  0.0090  1.7483\n",
      "      9            \u001b[36m0.7357\u001b[0m                     \u001b[32m0.7366\u001b[0m        \u001b[35m0.6575\u001b[0m            \u001b[31m0.7139\u001b[0m                     \u001b[94m0.7148\u001b[0m        \u001b[36m0.6146\u001b[0m  0.0087  1.7354\n",
      "     10            \u001b[36m0.7498\u001b[0m                     \u001b[32m0.7500\u001b[0m        \u001b[35m0.6025\u001b[0m            \u001b[31m0.7168\u001b[0m                     \u001b[94m0.7170\u001b[0m        \u001b[36m0.5778\u001b[0m  0.0084  1.7364\n",
      "     11            \u001b[36m0.7621\u001b[0m                     \u001b[32m0.7628\u001b[0m        \u001b[35m0.5949\u001b[0m            \u001b[31m0.7216\u001b[0m                     \u001b[94m0.7223\u001b[0m        \u001b[36m0.5567\u001b[0m  0.0080  1.7468\n",
      "     12            0.7316                     0.7326        \u001b[35m0.5516\u001b[0m            0.6887                     0.6896        0.6301  0.0076  1.7403\n",
      "     13            0.7199                     0.7192        0.6442            0.7013                     0.7005        0.6293  0.0072  1.7340\n",
      "     14            \u001b[36m0.7677\u001b[0m                     \u001b[32m0.7680\u001b[0m        0.5777            \u001b[31m0.7304\u001b[0m                     \u001b[94m0.7305\u001b[0m        0.5572  0.0068  1.7453\n",
      "     15            0.7643                     0.7642        0.5550            \u001b[31m0.7517\u001b[0m                     \u001b[94m0.7514\u001b[0m        \u001b[36m0.5426\u001b[0m  0.0064  1.7393\n",
      "     16            \u001b[36m0.7765\u001b[0m                     \u001b[32m0.7771\u001b[0m        \u001b[35m0.5286\u001b[0m            0.7352                     0.7357        \u001b[36m0.5356\u001b[0m  0.0059  1.7476\n",
      "     17            \u001b[36m0.7837\u001b[0m                     \u001b[32m0.7843\u001b[0m        \u001b[35m0.5132\u001b[0m            \u001b[31m0.7672\u001b[0m                     \u001b[94m0.7677\u001b[0m        \u001b[36m0.5165\u001b[0m  0.0055  1.7410\n",
      "     18            0.7726                     0.7732        \u001b[35m0.5065\u001b[0m            0.7410                     0.7416        0.5340  0.0050  1.7583\n",
      "     19            0.7701                     0.7710        0.5094            0.7381                     0.7389        0.5799  0.0045  1.7381\n",
      "     20            \u001b[36m0.8000\u001b[0m                     \u001b[32m0.8000\u001b[0m        \u001b[35m0.4886\u001b[0m            0.7585                     0.7584        0.5197  0.0041  1.7429\n",
      "     21            0.7876                     0.7884        \u001b[35m0.4830\u001b[0m            0.7459                     0.7466        0.5447  0.0036  1.7364\n",
      "     22            0.7721                     0.7729        \u001b[35m0.4808\u001b[0m            0.7439                     0.7448        0.5390  0.0032  1.7419\n",
      "     23            \u001b[36m0.8078\u001b[0m                     \u001b[32m0.8079\u001b[0m        \u001b[35m0.4658\u001b[0m            0.7575                     0.7577        \u001b[36m0.5039\u001b[0m  0.0028  1.7475\n",
      "     24            \u001b[36m0.8100\u001b[0m                     \u001b[32m0.8103\u001b[0m        0.4732            0.7662                     0.7666        \u001b[36m0.4959\u001b[0m  0.0024  1.7399\n",
      "     25            \u001b[36m0.8141\u001b[0m                     \u001b[32m0.8141\u001b[0m        \u001b[35m0.4510\u001b[0m            0.7662                     0.7662        0.4964  0.0020  1.7416\n",
      "     26            \u001b[36m0.8218\u001b[0m                     \u001b[32m0.8221\u001b[0m        \u001b[35m0.4349\u001b[0m            0.7527                     0.7529        0.4990  0.0016  1.7439\n",
      "     27            0.8155                     0.8162        0.4409            0.7498                     0.7503        0.4988  0.0013  1.7399\n",
      "     28            0.8182                     0.8187        \u001b[35m0.4290\u001b[0m            0.7585                     0.7590        \u001b[36m0.4906\u001b[0m  0.0010  1.7413\n",
      "     29            0.8204                     0.8208        0.4301            \u001b[31m0.7730\u001b[0m                     \u001b[94m0.7734\u001b[0m        \u001b[36m0.4890\u001b[0m  0.0007  1.7379\n",
      "     30            \u001b[36m0.8228\u001b[0m                     \u001b[32m0.8232\u001b[0m        \u001b[35m0.4268\u001b[0m            0.7701                     0.7705        0.4894  0.0005  1.7392\n",
      "     31            0.8211                     0.8217        \u001b[35m0.4169\u001b[0m            0.7653                     0.7658        0.4962  0.0003  1.7427\n",
      "     32            \u001b[36m0.8233\u001b[0m                     \u001b[32m0.8238\u001b[0m        0.4193            0.7662                     0.7667        0.4952  0.0002  1.7463\n",
      "     33            \u001b[36m0.8289\u001b[0m                     \u001b[32m0.8293\u001b[0m        0.4205            0.7692                     0.7695        0.4906  0.0001  1.7393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     34            0.8252                     0.8257        0.4208            0.7653                     0.7657        0.4903  0.0000  1.7483\n",
      "     35            0.8286                     0.8291        0.4180            0.7653                     0.7657        0.4912  0.0000  1.7473\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5922\u001b[0m                     \u001b[32m0.5934\u001b[0m        \u001b[35m3.4696\u001b[0m            \u001b[31m0.5694\u001b[0m                     \u001b[94m0.5704\u001b[0m        \u001b[36m1.6494\u001b[0m  0.0100  1.7383\n",
      "      2            \u001b[36m0.6466\u001b[0m                     \u001b[32m0.6459\u001b[0m        \u001b[35m1.4881\u001b[0m            \u001b[31m0.6654\u001b[0m                     \u001b[94m0.6649\u001b[0m        \u001b[36m0.7855\u001b[0m  0.0100  1.7374\n",
      "      3            0.6461                     \u001b[32m0.6464\u001b[0m        \u001b[35m1.2435\u001b[0m            0.6479                     0.6482        1.2599  0.0099  1.7384\n",
      "      4            \u001b[36m0.7041\u001b[0m                     \u001b[32m0.7042\u001b[0m        \u001b[35m0.9651\u001b[0m            \u001b[31m0.7022\u001b[0m                     \u001b[94m0.7024\u001b[0m        \u001b[36m0.6376\u001b[0m  0.0098  1.7374\n",
      "      5            0.7039                     0.7040        \u001b[35m0.8422\u001b[0m            \u001b[31m0.7168\u001b[0m                     \u001b[94m0.7171\u001b[0m        0.7579  0.0097  1.7419\n",
      "      6            \u001b[36m0.7231\u001b[0m                     \u001b[32m0.7228\u001b[0m        \u001b[35m0.7637\u001b[0m            \u001b[31m0.7236\u001b[0m                     \u001b[94m0.7233\u001b[0m        \u001b[36m0.6165\u001b[0m  0.0095  1.7374\n",
      "      7            0.7032                     0.7029        \u001b[35m0.7283\u001b[0m            0.7110                     0.7107        0.6905  0.0093  1.7415\n",
      "      8            0.6837                     0.6826        0.7862            0.6848                     0.6838        0.6238  0.0090  1.7463\n",
      "      9            0.7158                     0.7151        \u001b[35m0.7028\u001b[0m            0.7197                     0.7191        0.6769  0.0087  1.7411\n",
      "     10            0.7201                     0.7194        \u001b[35m0.6257\u001b[0m            0.7168                     0.7162        0.6436  0.0084  1.7513\n",
      "     11            \u001b[36m0.7400\u001b[0m                     \u001b[32m0.7398\u001b[0m        \u001b[35m0.5798\u001b[0m            \u001b[31m0.7323\u001b[0m                     \u001b[94m0.7322\u001b[0m        \u001b[36m0.6122\u001b[0m  0.0080  1.7491\n",
      "     12            \u001b[36m0.7655\u001b[0m                     \u001b[32m0.7659\u001b[0m        \u001b[35m0.5555\u001b[0m            \u001b[31m0.7391\u001b[0m                     \u001b[94m0.7395\u001b[0m        \u001b[36m0.5653\u001b[0m  0.0076  1.7344\n",
      "     13            \u001b[36m0.7675\u001b[0m                     \u001b[32m0.7676\u001b[0m        0.5719            0.7391                     0.7392        0.5892  0.0072  1.7450\n",
      "     14            0.7655                     0.7660        \u001b[35m0.5495\u001b[0m            \u001b[31m0.7468\u001b[0m                     \u001b[94m0.7473\u001b[0m        \u001b[36m0.5586\u001b[0m  0.0068  1.7374\n",
      "     15            \u001b[36m0.7769\u001b[0m                     \u001b[32m0.7771\u001b[0m        0.5529            \u001b[31m0.7546\u001b[0m                     \u001b[94m0.7549\u001b[0m        \u001b[36m0.5433\u001b[0m  0.0064  1.7413\n",
      "     16            0.7541                     0.7536        \u001b[35m0.5199\u001b[0m            0.7468                     0.7466        0.5898  0.0059  1.7413\n",
      "     17            \u001b[36m0.7879\u001b[0m                     \u001b[32m0.7883\u001b[0m        \u001b[35m0.5060\u001b[0m            \u001b[31m0.7643\u001b[0m                     \u001b[94m0.7647\u001b[0m        \u001b[36m0.5132\u001b[0m  0.0055  1.7369\n",
      "     18            0.7653                     0.7661        \u001b[35m0.5026\u001b[0m            0.7381                     0.7389        0.5818  0.0050  1.7324\n",
      "     19            0.7847                     0.7854        0.5280            0.7614                     0.7621        \u001b[36m0.5097\u001b[0m  0.0045  1.7403\n",
      "     20            \u001b[36m0.8036\u001b[0m                     \u001b[32m0.8038\u001b[0m        \u001b[35m0.4983\u001b[0m            0.7624                     0.7627        0.5128  0.0041  1.7403\n",
      "     21            \u001b[36m0.8061\u001b[0m                     \u001b[32m0.8061\u001b[0m        \u001b[35m0.4720\u001b[0m            \u001b[31m0.7701\u001b[0m                     \u001b[94m0.7703\u001b[0m        \u001b[36m0.5000\u001b[0m  0.0036  1.7543\n",
      "     22            \u001b[36m0.8073\u001b[0m                     \u001b[32m0.8077\u001b[0m        0.4785            0.7662                     0.7667        0.5118  0.0032  1.7453\n",
      "     23            \u001b[36m0.8102\u001b[0m                     \u001b[32m0.8099\u001b[0m        0.4833            0.7682                     0.7680        0.5005  0.0028  1.7409\n",
      "     24            \u001b[36m0.8121\u001b[0m                     \u001b[32m0.8127\u001b[0m        \u001b[35m0.4552\u001b[0m            \u001b[31m0.7759\u001b[0m                     \u001b[94m0.7765\u001b[0m        \u001b[36m0.4960\u001b[0m  0.0024  1.7483\n",
      "     25            \u001b[36m0.8194\u001b[0m                     \u001b[32m0.8194\u001b[0m        \u001b[35m0.4488\u001b[0m            0.7682                     0.7683        0.5056  0.0020  1.7411\n",
      "     26            \u001b[36m0.8218\u001b[0m                     \u001b[32m0.8223\u001b[0m        0.4496            \u001b[31m0.7769\u001b[0m                     \u001b[94m0.7774\u001b[0m        \u001b[36m0.4820\u001b[0m  0.0016  1.7423\n",
      "     27            \u001b[36m0.8265\u001b[0m                     \u001b[32m0.8268\u001b[0m        \u001b[35m0.4443\u001b[0m            0.7759                     0.7764        0.4828  0.0013  1.7409\n",
      "     28            \u001b[36m0.8316\u001b[0m                     \u001b[32m0.8318\u001b[0m        \u001b[35m0.4259\u001b[0m            \u001b[31m0.7837\u001b[0m                     \u001b[94m0.7840\u001b[0m        \u001b[36m0.4808\u001b[0m  0.0010  1.7413\n",
      "     29            0.8303                     0.8305        0.4259            0.7798                     0.7801        \u001b[36m0.4767\u001b[0m  0.0007  1.7498\n",
      "     30            0.8303                     0.8307        \u001b[35m0.4149\u001b[0m            \u001b[31m0.7847\u001b[0m                     \u001b[94m0.7851\u001b[0m        0.4841  0.0005  1.7364\n",
      "     31            0.8274                     0.8279        0.4214            0.7789                     0.7794        0.4858  0.0003  1.7418\n",
      "     32            0.8311                     0.8314        \u001b[35m0.4073\u001b[0m            \u001b[31m0.7876\u001b[0m                     \u001b[94m0.7880\u001b[0m        0.4802  0.0002  1.7463\n",
      "     33            \u001b[36m0.8374\u001b[0m                     \u001b[32m0.8377\u001b[0m        0.4114            0.7866                     0.7870        0.4778  0.0001  1.7459\n",
      "     34            0.8371                     0.8374        \u001b[35m0.4061\u001b[0m            0.7866                     0.7870        0.4785  0.0000  1.7364\n",
      "     35            0.8362                     0.8365        0.4103            0.7876                     0.7880        0.4800  0.0000  1.7446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[1 0 0 ... 0 0 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6602\u001b[0m                     \u001b[32m0.6543\u001b[0m        \u001b[35m4.6626\u001b[0m            \u001b[31m0.6409\u001b[0m                     \u001b[94m0.6332\u001b[0m        \u001b[36m3.7991\u001b[0m  0.0100  2.2796\n",
      "      2            \u001b[36m0.6933\u001b[0m                     \u001b[32m0.6921\u001b[0m        \u001b[35m1.8580\u001b[0m            \u001b[31m0.6908\u001b[0m                     \u001b[94m0.6906\u001b[0m        \u001b[36m1.5936\u001b[0m  0.0100  1.0472\n",
      "      3            0.6651                     0.6847        \u001b[35m0.9986\u001b[0m            0.6651                     0.6825        \u001b[36m1.4664\u001b[0m  0.0099  1.0492\n",
      "      4            0.6417                     0.6137        1.3209            0.6312                     0.6062        \u001b[36m1.2342\u001b[0m  0.0098  1.0472\n",
      "      5            0.6804                     \u001b[32m0.6991\u001b[0m        \u001b[35m0.8996\u001b[0m            0.6538                     0.6722        \u001b[36m0.9716\u001b[0m  0.0097  1.0472\n",
      "      6            0.6780                     0.6893        \u001b[35m0.6879\u001b[0m            0.6473                     0.6546        1.0331  0.0095  1.0582\n",
      "      7            \u001b[36m0.7046\u001b[0m                     \u001b[32m0.7066\u001b[0m        0.7328            \u001b[31m0.6957\u001b[0m                     \u001b[94m0.6971\u001b[0m        \u001b[36m0.8005\u001b[0m  0.0093  1.0494\n",
      "      8            0.6453                     0.6361        0.9306            0.6232                     0.6122        1.0916  0.0090  1.0501\n",
      "      9            \u001b[36m0.7340\u001b[0m                     \u001b[32m0.7343\u001b[0m        0.8056            \u001b[31m0.7230\u001b[0m                     \u001b[94m0.7213\u001b[0m        \u001b[36m0.6527\u001b[0m  0.0087  1.0485\n",
      "     10            \u001b[36m0.7380\u001b[0m                     \u001b[32m0.7450\u001b[0m        \u001b[35m0.6668\u001b[0m            0.7069                     0.7095        0.6612  0.0084  1.0467\n",
      "     11            0.7223                     0.7322        0.6706            0.7118                     0.7193        0.6934  0.0080  1.0455\n",
      "     12            \u001b[36m0.7388\u001b[0m                     0.7417        \u001b[35m0.6000\u001b[0m            0.7150                     0.7127        \u001b[36m0.6433\u001b[0m  0.0076  1.0472\n",
      "     13            0.7364                     0.7408        0.6183            0.7005                     0.7018        0.7159  0.0072  1.0472\n",
      "     14            \u001b[36m0.7521\u001b[0m                     \u001b[32m0.7530\u001b[0m        \u001b[35m0.5853\u001b[0m            0.7069                     0.7068        \u001b[36m0.6063\u001b[0m  0.0068  1.0467\n",
      "     15            0.7517                     \u001b[32m0.7559\u001b[0m        \u001b[35m0.5696\u001b[0m            \u001b[31m0.7262\u001b[0m                     \u001b[94m0.7263\u001b[0m        0.6149  0.0064  1.0492\n",
      "     16            0.7509                     \u001b[32m0.7568\u001b[0m        \u001b[35m0.5430\u001b[0m            0.7085                     0.7101        0.6215  0.0059  1.0582\n",
      "     17            0.6848                     0.7088        0.5707            0.6795                     0.6987        0.6544  0.0055  1.0523\n",
      "     18            \u001b[36m0.7735\u001b[0m                     \u001b[32m0.7764\u001b[0m        \u001b[35m0.5305\u001b[0m            \u001b[31m0.7343\u001b[0m                     \u001b[94m0.7328\u001b[0m        \u001b[36m0.5531\u001b[0m  0.0050  1.0462\n",
      "     19            0.7678                     0.7658        \u001b[35m0.5024\u001b[0m            0.7246                     0.7204        0.6164  0.0045  1.0512\n",
      "     20            0.7622                     0.7516        \u001b[35m0.4941\u001b[0m            \u001b[31m0.7391\u001b[0m                     0.7286        0.5772  0.0041  1.0492\n",
      "     21            \u001b[36m0.7747\u001b[0m                     0.7728        \u001b[35m0.4876\u001b[0m            0.7246                     0.7221        \u001b[36m0.5447\u001b[0m  0.0036  1.0469\n",
      "     22            \u001b[36m0.7791\u001b[0m                     \u001b[32m0.7802\u001b[0m        0.4924            0.7214                     0.7198        0.5452  0.0032  1.0482\n",
      "     23            \u001b[36m0.7799\u001b[0m                     0.7787        \u001b[35m0.4852\u001b[0m            0.7327                     0.7280        0.5665  0.0028  1.0472\n",
      "     24            \u001b[36m0.7900\u001b[0m                     \u001b[32m0.7896\u001b[0m        \u001b[35m0.4708\u001b[0m            0.7311                     0.7292        \u001b[36m0.5406\u001b[0m  0.0024  1.0442\n",
      "     25            0.7755                     0.7855        \u001b[35m0.4600\u001b[0m            0.7134                     0.7202        0.5427  0.0020  1.0502\n",
      "     26            0.7896                     \u001b[32m0.7903\u001b[0m        \u001b[35m0.4557\u001b[0m            0.7327                     0.7301        \u001b[36m0.5344\u001b[0m  0.0016  1.0472\n",
      "     27            \u001b[36m0.7960\u001b[0m                     \u001b[32m0.7959\u001b[0m        0.4584            0.7343                     0.7304        0.5447  0.0013  1.0522\n",
      "     28            0.7896                     \u001b[32m0.7967\u001b[0m        \u001b[35m0.4485\u001b[0m            0.7230                     0.7266        0.5346  0.0010  1.0437\n",
      "     29            0.7920                     0.7930        0.4514            0.7295                     0.7275        0.5357  0.0007  1.0562\n",
      "     30            0.7928                     0.7962        \u001b[35m0.4372\u001b[0m            0.7327                     \u001b[94m0.7331\u001b[0m        \u001b[36m0.5276\u001b[0m  0.0005  1.0557\n",
      "     31            \u001b[36m0.7985\u001b[0m                     \u001b[32m0.8009\u001b[0m        \u001b[35m0.4339\u001b[0m            0.7343                     \u001b[94m0.7337\u001b[0m        0.5299  0.0003  1.0469\n",
      "     32            \u001b[36m0.7997\u001b[0m                     \u001b[32m0.8020\u001b[0m        0.4350            0.7311                     0.7307        0.5277  0.0002  1.0552\n",
      "     33            \u001b[36m0.8005\u001b[0m                     \u001b[32m0.8027\u001b[0m        \u001b[35m0.4315\u001b[0m            0.7343                     \u001b[94m0.7340\u001b[0m        0.5276  0.0001  1.0453\n",
      "     34            0.7997                     0.8025        \u001b[35m0.4280\u001b[0m            0.7311                     0.7310        \u001b[36m0.5260\u001b[0m  0.0000  1.0502\n",
      "     35            \u001b[36m0.8013\u001b[0m                     \u001b[32m0.8038\u001b[0m        0.4322            0.7343                     0.7340        0.5279  0.0000  1.0482\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6364\u001b[0m                     \u001b[32m0.6143\u001b[0m        \u001b[35m4.0164\u001b[0m            \u001b[31m0.6216\u001b[0m                     \u001b[94m0.5982\u001b[0m        \u001b[36m2.3583\u001b[0m  0.0100  1.0462\n",
      "      2            0.5478                     0.5826        \u001b[35m2.0123\u001b[0m            0.5330                     0.5672        2.6706  0.0100  1.0452\n",
      "      3            0.5796                     0.5655        \u001b[35m1.6169\u001b[0m            0.5910                     0.5783        2.9470  0.0099  1.0462\n",
      "      4            \u001b[36m0.6659\u001b[0m                     \u001b[32m0.6815\u001b[0m        \u001b[35m1.5674\u001b[0m            0.6151                     \u001b[94m0.6302\u001b[0m        \u001b[36m1.2792\u001b[0m  0.0098  1.0422\n",
      "      5            \u001b[36m0.7179\u001b[0m                     \u001b[32m0.7092\u001b[0m        \u001b[35m1.2002\u001b[0m            \u001b[31m0.6699\u001b[0m                     \u001b[94m0.6589\u001b[0m        \u001b[36m1.0585\u001b[0m  0.0097  1.0462\n",
      "      6            0.7166                     \u001b[32m0.7122\u001b[0m        \u001b[35m0.7937\u001b[0m            \u001b[31m0.6715\u001b[0m                     \u001b[94m0.6669\u001b[0m        1.2280  0.0095  1.0490\n",
      "      7            0.7146                     \u001b[32m0.7211\u001b[0m        0.9592            0.6715                     \u001b[94m0.6762\u001b[0m        \u001b[36m1.0041\u001b[0m  0.0093  1.0452\n",
      "      8            0.6546                     0.6783        0.9174            0.6264                     0.6507        1.2225  0.0090  1.0467\n",
      "      9            \u001b[36m0.7509\u001b[0m                     \u001b[32m0.7562\u001b[0m        \u001b[35m0.7274\u001b[0m            \u001b[31m0.6828\u001b[0m                     \u001b[94m0.6871\u001b[0m        \u001b[36m0.6499\u001b[0m  0.0087  1.0512\n",
      "     10            0.7457                     0.7539        \u001b[35m0.5586\u001b[0m            0.6795                     \u001b[94m0.6871\u001b[0m        \u001b[36m0.6167\u001b[0m  0.0084  1.0582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11            0.7493                     0.7532        0.5854            \u001b[31m0.6892\u001b[0m                     \u001b[94m0.6915\u001b[0m        0.6224  0.0080  1.0542\n",
      "     12            \u001b[36m0.7586\u001b[0m                     \u001b[32m0.7610\u001b[0m        0.6169            0.6779                     0.6791        0.7264  0.0076  1.0473\n",
      "     13            0.7465                     0.7525        0.5936            \u001b[31m0.7230\u001b[0m                     \u001b[94m0.7284\u001b[0m        0.6176  0.0072  1.0512\n",
      "     14            \u001b[36m0.7646\u001b[0m                     \u001b[32m0.7654\u001b[0m        \u001b[35m0.5476\u001b[0m            0.6892                     0.6882        0.6175  0.0068  1.0452\n",
      "     15            0.7598                     0.7637        \u001b[35m0.5140\u001b[0m            0.6924                     0.6944        0.6291  0.0064  1.0452\n",
      "     16            \u001b[36m0.7727\u001b[0m                     \u001b[32m0.7797\u001b[0m        0.5373            0.7005                     0.7063        \u001b[36m0.5939\u001b[0m  0.0059  1.0487\n",
      "     17            0.7618                     0.7585        0.5262            0.6892                     0.6855        0.6556  0.0055  1.0482\n",
      "     18            \u001b[36m0.7783\u001b[0m                     \u001b[32m0.7808\u001b[0m        \u001b[35m0.4859\u001b[0m            0.7021                     0.7018        0.6037  0.0050  1.0502\n",
      "     19            0.7694                     0.7655        0.5048            0.7053                     0.6997        0.6207  0.0045  1.0462\n",
      "     20            0.7775                     0.7750        0.5007            0.6924                     0.6912        0.6255  0.0041  1.0482\n",
      "     21            \u001b[36m0.7888\u001b[0m                     \u001b[32m0.7894\u001b[0m        0.4940            0.6892                     0.6903        0.6054  0.0036  1.0572\n",
      "     22            \u001b[36m0.7940\u001b[0m                     0.7891        \u001b[35m0.4656\u001b[0m            0.7118                     0.7053        0.6058  0.0032  1.0532\n",
      "     23            0.7912                     \u001b[32m0.7918\u001b[0m        \u001b[35m0.4620\u001b[0m            0.6973                     0.6968        \u001b[36m0.5877\u001b[0m  0.0028  1.0602\n",
      "     24            \u001b[36m0.8073\u001b[0m                     \u001b[32m0.8091\u001b[0m        \u001b[35m0.4430\u001b[0m            0.7005                     0.7012        0.5883  0.0024  1.0552\n",
      "     25            \u001b[36m0.8081\u001b[0m                     \u001b[32m0.8102\u001b[0m        0.4432            0.7021                     0.7048        0.5973  0.0020  1.0542\n",
      "     26            \u001b[36m0.8106\u001b[0m                     0.8079        \u001b[35m0.4344\u001b[0m            0.6908                     0.6885        0.6081  0.0016  1.0482\n",
      "     27            0.8089                     0.8057        \u001b[35m0.4247\u001b[0m            0.7085                     0.7053        0.5891  0.0013  1.0462\n",
      "     28            \u001b[36m0.8162\u001b[0m                     \u001b[32m0.8188\u001b[0m        \u001b[35m0.4174\u001b[0m            0.7037                     0.7042        0.5917  0.0010  1.0452\n",
      "     29            \u001b[36m0.8206\u001b[0m                     \u001b[32m0.8216\u001b[0m        0.4211            0.7037                     0.7024        0.5906  0.0007  1.0467\n",
      "     30            0.8162                     0.8129        \u001b[35m0.4096\u001b[0m            0.7021                     0.6982        0.5984  0.0005  1.0442\n",
      "     31            0.8138                     0.8099        0.4123            0.7005                     0.6967        0.6105  0.0003  1.0512\n",
      "     32            \u001b[36m0.8218\u001b[0m                     0.8207        \u001b[35m0.4064\u001b[0m            0.7053                     0.7027        0.5943  0.0002  1.0514\n",
      "     33            0.8206                     0.8183        0.4099            0.7037                     0.7006        0.6018  0.0001  1.0532\n",
      "     34            0.8182                     0.8157        \u001b[35m0.4033\u001b[0m            0.7037                     0.7006        0.6054  0.0000  1.0442\n",
      "     35            0.8198                     0.8174        \u001b[35m0.4025\u001b[0m            0.7037                     0.7006        0.5923  0.0000  1.0466\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6397\u001b[0m                     \u001b[32m0.6359\u001b[0m        \u001b[35m5.3646\u001b[0m            \u001b[31m0.6055\u001b[0m                     \u001b[94m0.6020\u001b[0m        \u001b[36m6.5835\u001b[0m  0.0100  1.0492\n",
      "      2            0.5256                     0.5013        \u001b[35m3.0981\u001b[0m            0.5362                     0.5111        \u001b[36m3.5633\u001b[0m  0.0100  1.0445\n",
      "      3            \u001b[36m0.6925\u001b[0m                     \u001b[32m0.6932\u001b[0m        \u001b[35m1.7390\u001b[0m            \u001b[31m0.6554\u001b[0m                     \u001b[94m0.6525\u001b[0m        \u001b[36m1.2529\u001b[0m  0.0099  1.0512\n",
      "      4            0.6106                     0.6028        1.7958            0.6006                     0.5898        1.3446  0.0098  1.0542\n",
      "      5            0.6804                     0.6827        \u001b[35m1.1398\u001b[0m            \u001b[31m0.6957\u001b[0m                     \u001b[94m0.6944\u001b[0m        \u001b[36m1.0580\u001b[0m  0.0097  1.0472\n",
      "      6            \u001b[36m0.7207\u001b[0m                     \u001b[32m0.7177\u001b[0m        1.3801            \u001b[31m0.7053\u001b[0m                     \u001b[94m0.6997\u001b[0m        \u001b[36m0.8754\u001b[0m  0.0095  1.0422\n",
      "      7            0.5316                     0.5660        \u001b[35m1.1147\u001b[0m            0.5266                     0.5607        1.5245  0.0093  1.0492\n",
      "      8            0.6981                     0.6998        \u001b[35m1.0064\u001b[0m            0.6570                     0.6566        \u001b[36m0.7671\u001b[0m  0.0090  1.0502\n",
      "      9            \u001b[36m0.7308\u001b[0m                     \u001b[32m0.7242\u001b[0m        \u001b[35m0.6543\u001b[0m            0.6924                     0.6852        \u001b[36m0.6196\u001b[0m  0.0087  1.0462\n",
      "     10            0.7195                     \u001b[32m0.7321\u001b[0m        \u001b[35m0.5780\u001b[0m            0.6908                     \u001b[94m0.7016\u001b[0m        0.6365  0.0084  1.0523\n",
      "     11            0.6896                     0.7101        0.6644            0.6860                     \u001b[94m0.7046\u001b[0m        0.7238  0.0080  1.0532\n",
      "     12            \u001b[36m0.7497\u001b[0m                     \u001b[32m0.7485\u001b[0m        0.6888            0.7037                     0.7030        \u001b[36m0.6183\u001b[0m  0.0076  1.0532\n",
      "     13            0.7320                     0.7400        0.6073            0.6973                     0.7015        0.6706  0.0072  1.0522\n",
      "     14            0.7477                     0.7402        \u001b[35m0.5739\u001b[0m            0.6876                     0.6790        0.6227  0.0068  1.0472\n",
      "     15            \u001b[36m0.7525\u001b[0m                     \u001b[32m0.7615\u001b[0m        \u001b[35m0.5403\u001b[0m            0.7053                     \u001b[94m0.7113\u001b[0m        \u001b[36m0.5837\u001b[0m  0.0064  1.0532\n",
      "     16            0.7461                     0.7583        0.5486            0.7037                     \u001b[94m0.7122\u001b[0m        0.5947  0.0059  1.0572\n",
      "     17            0.7170                     0.7337        0.5538            0.6924                     0.7061        0.6541  0.0055  1.0451\n",
      "     18            0.7416                     0.7551        0.5442            0.6989                     0.7096        0.5889  0.0050  1.0480\n",
      "     19            \u001b[36m0.7719\u001b[0m                     \u001b[32m0.7776\u001b[0m        \u001b[35m0.5186\u001b[0m            0.6973                     0.7007        0.5888  0.0045  1.0545\n",
      "     20            \u001b[36m0.7727\u001b[0m                     0.7748        \u001b[35m0.5098\u001b[0m            \u001b[31m0.7118\u001b[0m                     0.7115        \u001b[36m0.5701\u001b[0m  0.0041  1.0454\n",
      "     21            0.7658                     0.7685        \u001b[35m0.4972\u001b[0m            \u001b[31m0.7150\u001b[0m                     \u001b[94m0.7148\u001b[0m        0.5846  0.0036  1.0522\n",
      "     22            0.7694                     0.7761        0.5042            0.6924                     0.6953        \u001b[36m0.5630\u001b[0m  0.0032  1.0522\n",
      "     23            \u001b[36m0.7807\u001b[0m                     \u001b[32m0.7809\u001b[0m        \u001b[35m0.4814\u001b[0m            0.7005                     0.6982        0.5815  0.0028  1.0542\n",
      "     24            \u001b[36m0.7819\u001b[0m                     \u001b[32m0.7848\u001b[0m        \u001b[35m0.4706\u001b[0m            0.7069                     0.7056        \u001b[36m0.5592\u001b[0m  0.0024  1.0502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25            0.7787                     \u001b[32m0.7855\u001b[0m        0.4903            0.7134                     \u001b[94m0.7163\u001b[0m        0.5801  0.0020  1.0452\n",
      "     26            0.7686                     0.7787        0.4786            0.7037                     0.7101        0.5872  0.0016  1.0487\n",
      "     27            0.7783                     0.7839        \u001b[35m0.4636\u001b[0m            0.7150                     \u001b[94m0.7184\u001b[0m        0.5627  0.0013  1.0522\n",
      "     28            \u001b[36m0.7827\u001b[0m                     \u001b[32m0.7898\u001b[0m        0.4640            0.7069                     0.7107        0.5609  0.0010  1.0462\n",
      "     29            0.7783                     0.7861        \u001b[35m0.4556\u001b[0m            0.7118                     0.7157        \u001b[36m0.5584\u001b[0m  0.0007  1.0492\n",
      "     30            \u001b[36m0.7888\u001b[0m                     \u001b[32m0.7935\u001b[0m        \u001b[35m0.4514\u001b[0m            \u001b[31m0.7182\u001b[0m                     \u001b[94m0.7201\u001b[0m        \u001b[36m0.5550\u001b[0m  0.0005  1.0456\n",
      "     31            0.7811                     0.7880        \u001b[35m0.4471\u001b[0m            0.7118                     0.7160        0.5573  0.0003  1.0512\n",
      "     32            0.7848                     0.7900        \u001b[35m0.4456\u001b[0m            0.7037                     0.7060        0.5605  0.0002  1.0482\n",
      "     33            0.7872                     0.7927        0.4504            0.7101                     0.7128        0.5588  0.0001  1.0522\n",
      "     34            0.7876                     0.7933        0.4475            0.7085                     0.7110        0.5586  0.0000  1.0492\n",
      "     35            \u001b[36m0.7912\u001b[0m                     \u001b[32m0.7964\u001b[0m        0.4471            0.7085                     0.7110        0.5615  0.0000  1.0442\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5163\u001b[0m                     \u001b[32m0.5325\u001b[0m        \u001b[35m4.4089\u001b[0m            \u001b[31m0.5507\u001b[0m                     \u001b[94m0.5632\u001b[0m        \u001b[36m3.9256\u001b[0m  0.0100  1.0464\n",
      "      2            \u001b[36m0.6457\u001b[0m                     \u001b[32m0.6269\u001b[0m        \u001b[35m2.1577\u001b[0m            \u001b[31m0.6473\u001b[0m                     \u001b[94m0.6290\u001b[0m        \u001b[36m1.2014\u001b[0m  0.0100  1.0522\n",
      "      3            \u001b[36m0.6909\u001b[0m                     \u001b[32m0.6950\u001b[0m        \u001b[35m1.2768\u001b[0m            \u001b[31m0.6957\u001b[0m                     \u001b[94m0.6995\u001b[0m        \u001b[36m1.0245\u001b[0m  0.0099  1.0462\n",
      "      4            0.6804                     0.6897        \u001b[35m1.1679\u001b[0m            0.6570                     0.6683        1.6170  0.0098  1.0536\n",
      "      5            0.6183                     0.6451        1.1705            0.6151                     0.6433        1.5971  0.0097  1.0502\n",
      "      6            \u001b[36m0.6989\u001b[0m                     \u001b[32m0.7007\u001b[0m        \u001b[35m1.1119\u001b[0m            0.6699                     0.6732        \u001b[36m0.7149\u001b[0m  0.0095  1.0446\n",
      "      7            \u001b[36m0.7054\u001b[0m                     \u001b[32m0.7044\u001b[0m        \u001b[35m0.8389\u001b[0m            0.6828                     0.6820        0.9811  0.0093  1.0412\n",
      "      8            0.6566                     0.6774        0.8993            0.6457                     0.6693        0.9818  0.0090  1.0482\n",
      "      9            \u001b[36m0.7275\u001b[0m                     \u001b[32m0.7252\u001b[0m        0.9494            \u001b[31m0.7150\u001b[0m                     \u001b[94m0.7130\u001b[0m        \u001b[36m0.6960\u001b[0m  0.0087  1.0462\n",
      "     10            0.6921                     0.7064        0.9003            0.6844                     0.6990        0.7863  0.0084  1.0472\n",
      "     11            \u001b[36m0.7279\u001b[0m                     \u001b[32m0.7357\u001b[0m        \u001b[35m0.6999\u001b[0m            \u001b[31m0.7182\u001b[0m                     \u001b[94m0.7243\u001b[0m        \u001b[36m0.6131\u001b[0m  0.0080  1.0497\n",
      "     12            0.7175                     0.7202        \u001b[35m0.6491\u001b[0m            0.7101                     0.7151        0.6807  0.0076  1.0497\n",
      "     13            \u001b[36m0.7308\u001b[0m                     \u001b[32m0.7382\u001b[0m        0.7418            \u001b[31m0.7198\u001b[0m                     \u001b[94m0.7285\u001b[0m        \u001b[36m0.5657\u001b[0m  0.0072  1.0452\n",
      "     14            \u001b[36m0.7501\u001b[0m                     \u001b[32m0.7522\u001b[0m        \u001b[35m0.6149\u001b[0m            \u001b[31m0.7262\u001b[0m                     \u001b[94m0.7296\u001b[0m        0.5873  0.0068  1.0464\n",
      "     15            0.7368                     0.7373        \u001b[35m0.5531\u001b[0m            0.7150                     0.7178        0.6244  0.0064  1.0492\n",
      "     16            0.7493                     0.7494        0.5767            0.7214                     0.7234        \u001b[36m0.5257\u001b[0m  0.0059  1.0542\n",
      "     17            0.7461                     0.7510        0.5727            0.7150                     0.7222        0.5418  0.0055  1.0462\n",
      "     18            \u001b[36m0.7586\u001b[0m                     \u001b[32m0.7549\u001b[0m        \u001b[35m0.5237\u001b[0m            0.7214                     0.7192        \u001b[36m0.5212\u001b[0m  0.0050  1.0472\n",
      "     19            0.7513                     \u001b[32m0.7630\u001b[0m        \u001b[35m0.5026\u001b[0m            0.7246                     \u001b[94m0.7359\u001b[0m        0.5373  0.0045  1.0532\n",
      "     20            0.7586                     \u001b[32m0.7641\u001b[0m        0.5198            0.7246                     0.7296        0.5374  0.0041  1.0482\n",
      "     21            \u001b[36m0.7614\u001b[0m                     \u001b[32m0.7682\u001b[0m        0.5037            \u001b[31m0.7391\u001b[0m                     \u001b[94m0.7465\u001b[0m        0.5248  0.0036  1.0465\n",
      "     22            \u001b[36m0.7699\u001b[0m                     \u001b[32m0.7714\u001b[0m        0.5076            0.7246                     0.7272        0.5471  0.0032  1.0437\n",
      "     23            0.7650                     \u001b[32m0.7723\u001b[0m        \u001b[35m0.4881\u001b[0m            0.7230                     0.7305        0.5417  0.0028  1.0442\n",
      "     24            \u001b[36m0.7723\u001b[0m                     \u001b[32m0.7777\u001b[0m        0.4892            0.7311                     0.7373        0.5279  0.0024  1.0469\n",
      "     25            \u001b[36m0.7771\u001b[0m                     \u001b[32m0.7785\u001b[0m        \u001b[35m0.4773\u001b[0m            0.7359                     0.7399        0.5334  0.0020  1.0512\n",
      "     26            0.7735                     0.7767        \u001b[35m0.4620\u001b[0m            0.7262                     0.7305        0.5260  0.0016  1.0492\n",
      "     27            \u001b[36m0.7844\u001b[0m                     \u001b[32m0.7876\u001b[0m        0.4665            0.7279                     0.7331        0.5318  0.0013  1.0512\n",
      "     28            0.7723                     0.7816        0.4653            0.7246                     0.7341        0.5345  0.0010  1.0432\n",
      "     29            \u001b[36m0.7900\u001b[0m                     \u001b[32m0.7920\u001b[0m        \u001b[35m0.4488\u001b[0m            0.7230                     0.7263        0.5345  0.0007  1.0442\n",
      "     30            0.7900                     0.7905        0.4544            0.7279                     0.7293        0.5311  0.0005  1.0522\n",
      "     31            \u001b[36m0.7912\u001b[0m                     \u001b[32m0.7923\u001b[0m        \u001b[35m0.4474\u001b[0m            0.7279                     0.7308        0.5272  0.0003  1.0527\n",
      "     32            0.7892                     0.7907        \u001b[35m0.4465\u001b[0m            0.7246                     0.7281        0.5305  0.0002  1.0462\n",
      "     33            0.7908                     \u001b[32m0.7925\u001b[0m        \u001b[35m0.4432\u001b[0m            0.7246                     0.7278        0.5291  0.0001  1.0452\n",
      "     34            0.7900                     0.7915        \u001b[35m0.4421\u001b[0m            0.7279                     0.7314        0.5310  0.0000  1.0443\n",
      "     35            0.7908                     \u001b[32m0.7929\u001b[0m        0.4428            0.7262                     0.7302        0.5300  0.0000  1.0482\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5522\u001b[0m                     \u001b[32m0.5386\u001b[0m        \u001b[35m5.5949\u001b[0m            \u001b[31m0.5749\u001b[0m                     \u001b[94m0.5632\u001b[0m        \u001b[36m4.5144\u001b[0m  0.0100  1.0442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2            \u001b[36m0.6336\u001b[0m                     \u001b[32m0.6306\u001b[0m        \u001b[35m2.5546\u001b[0m            \u001b[31m0.6522\u001b[0m                     \u001b[94m0.6498\u001b[0m        \u001b[36m1.3478\u001b[0m  0.0100  1.0547\n",
      "      3            \u001b[36m0.6663\u001b[0m                     \u001b[32m0.6781\u001b[0m        \u001b[35m1.8552\u001b[0m            0.6200                     0.6340        1.9356  0.0099  1.0582\n",
      "      4            \u001b[36m0.6997\u001b[0m                     \u001b[32m0.6983\u001b[0m        \u001b[35m1.6830\u001b[0m            \u001b[31m0.6618\u001b[0m                     \u001b[94m0.6613\u001b[0m        1.8183  0.0098  1.0622\n",
      "      5            \u001b[36m0.7203\u001b[0m                     \u001b[32m0.7272\u001b[0m        \u001b[35m1.3194\u001b[0m            \u001b[31m0.6812\u001b[0m                     \u001b[94m0.6901\u001b[0m        \u001b[36m0.7600\u001b[0m  0.0097  1.0458\n",
      "      6            0.6824                     0.6871        \u001b[35m1.3165\u001b[0m            \u001b[31m0.7037\u001b[0m                     \u001b[94m0.7095\u001b[0m        0.8987  0.0095  1.0522\n",
      "      7            0.6848                     0.7011        \u001b[35m0.9439\u001b[0m            0.6506                     0.6698        0.7630  0.0093  1.0522\n",
      "      8            0.7134                     0.7219        \u001b[35m0.6692\u001b[0m            \u001b[31m0.7182\u001b[0m                     \u001b[94m0.7273\u001b[0m        \u001b[36m0.5830\u001b[0m  0.0090  1.0458\n",
      "      9            \u001b[36m0.7215\u001b[0m                     0.7155        \u001b[35m0.6376\u001b[0m            0.6779                     0.6737        0.6832  0.0087  1.0482\n",
      "     10            \u001b[36m0.7348\u001b[0m                     \u001b[32m0.7421\u001b[0m        \u001b[35m0.6293\u001b[0m            0.7021                     0.7113        \u001b[36m0.5627\u001b[0m  0.0084  1.0539\n",
      "     11            \u001b[36m0.7477\u001b[0m                     \u001b[32m0.7494\u001b[0m        \u001b[35m0.5661\u001b[0m            \u001b[31m0.7279\u001b[0m                     \u001b[94m0.7314\u001b[0m        0.5737  0.0080  1.0532\n",
      "     12            0.7312                     0.7304        0.6221            0.6940                     0.6944        0.6824  0.0076  1.0462\n",
      "     13            0.7098                     0.7160        0.6457            0.7037                     0.7107        0.6088  0.0072  1.0511\n",
      "     14            \u001b[36m0.7525\u001b[0m                     \u001b[32m0.7560\u001b[0m        0.5679            0.7214                     0.7264        \u001b[36m0.5426\u001b[0m  0.0068  1.0532\n",
      "     15            \u001b[36m0.7606\u001b[0m                     \u001b[32m0.7665\u001b[0m        \u001b[35m0.5365\u001b[0m            \u001b[31m0.7327\u001b[0m                     \u001b[94m0.7391\u001b[0m        \u001b[36m0.5348\u001b[0m  0.0064  1.0497\n",
      "     16            0.7545                     0.7605        \u001b[35m0.5179\u001b[0m            0.7021                     0.7084        0.5457  0.0059  1.0482\n",
      "     17            0.7574                     0.7531        \u001b[35m0.5176\u001b[0m            0.7230                     0.7204        0.5783  0.0055  1.0452\n",
      "     18            \u001b[36m0.7654\u001b[0m                     \u001b[32m0.7702\u001b[0m        0.5233            0.7198                     0.7264        0.5552  0.0050  1.0510\n",
      "     19            0.7614                     \u001b[32m0.7710\u001b[0m        \u001b[35m0.4944\u001b[0m            0.7150                     0.7261        \u001b[36m0.5329\u001b[0m  0.0045  1.0572\n",
      "     20            0.7630                     0.7678        0.4974            0.7005                     0.7072        0.5624  0.0041  1.0482\n",
      "     21            \u001b[36m0.7719\u001b[0m                     \u001b[32m0.7770\u001b[0m        \u001b[35m0.4847\u001b[0m            0.7214                     0.7284        \u001b[36m0.5260\u001b[0m  0.0036  1.0442\n",
      "     22            \u001b[36m0.7763\u001b[0m                     \u001b[32m0.7787\u001b[0m        \u001b[35m0.4832\u001b[0m            0.7311                     0.7355        \u001b[36m0.5231\u001b[0m  0.0032  1.0522\n",
      "     23            0.7690                     0.7752        0.5022            0.7262                     0.7326        0.5343  0.0028  1.0512\n",
      "     24            \u001b[36m0.7783\u001b[0m                     \u001b[32m0.7834\u001b[0m        \u001b[35m0.4760\u001b[0m            \u001b[31m0.7359\u001b[0m                     \u001b[94m0.7420\u001b[0m        \u001b[36m0.5120\u001b[0m  0.0024  1.0582\n",
      "     25            0.7775                     0.7817        \u001b[35m0.4730\u001b[0m            \u001b[31m0.7375\u001b[0m                     \u001b[94m0.7432\u001b[0m        0.5177  0.0020  1.0427\n",
      "     26            \u001b[36m0.7799\u001b[0m                     0.7813        0.4791            0.7375                     0.7399        0.5299  0.0016  1.0585\n",
      "     27            \u001b[36m0.7840\u001b[0m                     \u001b[32m0.7867\u001b[0m        \u001b[35m0.4694\u001b[0m            0.7311                     0.7349        0.5177  0.0013  1.0477\n",
      "     28            0.7832                     \u001b[32m0.7867\u001b[0m        \u001b[35m0.4591\u001b[0m            0.7246                     0.7296        \u001b[36m0.5101\u001b[0m  0.0010  1.0495\n",
      "     29            \u001b[36m0.7880\u001b[0m                     \u001b[32m0.7893\u001b[0m        0.4600            0.7295                     0.7325        0.5121  0.0007  1.0492\n",
      "     30            0.7864                     0.7875        \u001b[35m0.4524\u001b[0m            0.7343                     0.7373        0.5170  0.0005  1.0447\n",
      "     31            0.7856                     0.7880        \u001b[35m0.4510\u001b[0m            0.7295                     0.7334        0.5177  0.0003  1.0522\n",
      "     32            0.7844                     0.7867        \u001b[35m0.4483\u001b[0m            0.7262                     0.7293        0.5191  0.0002  1.0532\n",
      "     33            0.7864                     0.7886        \u001b[35m0.4423\u001b[0m            0.7311                     0.7343        0.5180  0.0001  1.0452\n",
      "     34            0.7864                     0.7885        \u001b[35m0.4419\u001b[0m            0.7295                     0.7328        0.5166  0.0000  1.0502\n",
      "     35            0.7864                     0.7886        \u001b[35m0.4412\u001b[0m            0.7311                     0.7343        0.5164  0.0000  1.0501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vapor\\anaconda3\\envs\\braindecode\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass classes=[0 1], y=[0 1 1 ... 1 1 1] as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5527\u001b[0m                     \u001b[32m0.6400\u001b[0m        \u001b[35m4.9797\u001b[0m            \u001b[31m0.5624\u001b[0m                     \u001b[94m0.6410\u001b[0m        \u001b[36m1.6108\u001b[0m  0.0100  3.4270\n",
      "      2            0.4942                     0.6315        \u001b[35m1.8993\u001b[0m            0.4996                     0.6378        \u001b[36m1.2204\u001b[0m  0.0100  2.3707\n",
      "      3            \u001b[36m0.7731\u001b[0m                     \u001b[32m0.6672\u001b[0m        \u001b[35m1.3197\u001b[0m            \u001b[31m0.7723\u001b[0m                     \u001b[94m0.6536\u001b[0m        \u001b[36m0.8574\u001b[0m  0.0099  2.3399\n",
      "      4            0.6649                     \u001b[32m0.6733\u001b[0m        \u001b[35m1.1433\u001b[0m            0.6538                     0.6415        1.0997  0.0098  2.3058\n",
      "      5            \u001b[36m0.7921\u001b[0m                     \u001b[32m0.6876\u001b[0m        \u001b[35m0.8536\u001b[0m            \u001b[31m0.7870\u001b[0m                     \u001b[94m0.6592\u001b[0m        \u001b[36m0.7635\u001b[0m  0.0097  2.2513\n",
      "      6            0.6750                     \u001b[32m0.7104\u001b[0m        \u001b[35m0.8224\u001b[0m            0.6615                     \u001b[94m0.6830\u001b[0m        \u001b[36m0.6235\u001b[0m  0.0095  2.2540\n",
      "      7            0.7725                     0.7054        \u001b[35m0.7075\u001b[0m            0.7653                     0.6560        0.9038  0.0093  2.2432\n",
      "      8            \u001b[36m0.8134\u001b[0m                     \u001b[32m0.7387\u001b[0m        \u001b[35m0.6912\u001b[0m            \u001b[31m0.7955\u001b[0m                     \u001b[94m0.7062\u001b[0m        \u001b[36m0.5590\u001b[0m  0.0090  2.2443\n",
      "      9            0.7041                     0.7298        \u001b[35m0.6848\u001b[0m            0.6964                     0.6943        0.6696  0.0087  2.2461\n",
      "     10            0.8010                     \u001b[32m0.7471\u001b[0m        \u001b[35m0.6066\u001b[0m            \u001b[31m0.7994\u001b[0m                     \u001b[94m0.7237\u001b[0m        \u001b[36m0.5490\u001b[0m  0.0084  2.2430\n",
      "     11            \u001b[36m0.8234\u001b[0m                     0.7369        \u001b[35m0.5600\u001b[0m            \u001b[31m0.8203\u001b[0m                     0.7180        0.5704  0.0080  2.2540\n",
      "     12            0.7992                     0.7452        \u001b[35m0.5479\u001b[0m            0.7831                     0.7054        0.5878  0.0076  2.2461\n",
      "     13            0.7922                     \u001b[32m0.7690\u001b[0m        \u001b[35m0.5328\u001b[0m            0.7614                     \u001b[94m0.7256\u001b[0m        0.5512  0.0072  2.2490\n",
      "     14            0.7705                     0.7612        0.5462            0.7676                     \u001b[94m0.7478\u001b[0m        0.5656  0.0068  2.2455\n",
      "     15            0.7841                     \u001b[32m0.7791\u001b[0m        0.5420            0.7676                     0.7361        \u001b[36m0.5267\u001b[0m  0.0064  2.2515\n",
      "     16            0.7767                     0.7746        \u001b[35m0.5078\u001b[0m            0.7630                     0.7332        0.5432  0.0059  2.2469\n",
      "     17            0.7705                     0.7704        0.5134            0.7676                     0.7478        0.5627  0.0055  2.2520\n",
      "     18            0.7579                     \u001b[32m0.7841\u001b[0m        \u001b[35m0.4962\u001b[0m            0.7289                     0.7342        0.5395  0.0050  2.2577\n",
      "     19            0.7864                     0.7813        \u001b[35m0.4962\u001b[0m            0.7607                     0.7352        0.5366  0.0045  2.2483\n",
      "     20            0.8174                     \u001b[32m0.7927\u001b[0m        \u001b[35m0.4862\u001b[0m            0.8002                     \u001b[94m0.7559\u001b[0m        \u001b[36m0.5162\u001b[0m  0.0041  2.2570\n",
      "     21            \u001b[36m0.8337\u001b[0m                     0.7796        \u001b[35m0.4853\u001b[0m            0.8110                     0.7358        0.5650  0.0036  2.2560\n",
      "     22            0.8254                     \u001b[32m0.7942\u001b[0m        \u001b[35m0.4798\u001b[0m            0.7986                     0.7416        0.5396  0.0032  2.2505\n",
      "     23            0.8116                     \u001b[32m0.7980\u001b[0m        \u001b[35m0.4696\u001b[0m            0.7924                     0.7462        0.5312  0.0028  2.2496\n",
      "     24            \u001b[36m0.8457\u001b[0m                     0.7794        0.4741            0.8195                     0.7242        0.5818  0.0024  2.2490\n",
      "     25            0.8161                     \u001b[32m0.8141\u001b[0m        \u001b[35m0.4637\u001b[0m            0.7932                     \u001b[94m0.7617\u001b[0m        0.5196  0.0020  2.2620\n",
      "     26            \u001b[36m0.8461\u001b[0m                     0.8052        \u001b[35m0.4613\u001b[0m            0.8180                     0.7400        0.5519  0.0016  2.2629\n",
      "     27            0.8217                     \u001b[32m0.8167\u001b[0m        \u001b[35m0.4521\u001b[0m            0.7909                     0.7519        0.5352  0.0013  2.2529\n",
      "     28            0.8014                     \u001b[32m0.8193\u001b[0m        \u001b[35m0.4364\u001b[0m            0.7730                     0.7511        0.5229  0.0010  2.2560\n",
      "     29            0.8297                     0.8182        0.4413            0.7963                     0.7519        0.5374  0.0007  2.2580\n",
      "     30            0.8289                     \u001b[32m0.8261\u001b[0m        0.4394            0.7978                     0.7578        0.5297  0.0005  2.2550\n",
      "     31            0.8376                     0.8205        \u001b[35m0.4351\u001b[0m            0.8071                     0.7568        0.5327  0.0003  2.2581\n",
      "     32            0.8339                     0.8250        \u001b[35m0.4326\u001b[0m            0.8048                     0.7554        0.5322  0.0002  2.2582\n",
      "     33            0.8250                     0.8250        \u001b[35m0.4212\u001b[0m            0.7971                     0.7590        0.5284  0.0001  2.2600\n",
      "     34            0.8260                     \u001b[32m0.8277\u001b[0m        0.4252            0.7932                     0.7567        0.5286  0.0000  2.2590\n",
      "     35            0.8339                     0.8262        0.4243            0.8017                     0.7552        0.5288  0.0000  2.2549\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7484\u001b[0m                     \u001b[32m0.6673\u001b[0m        \u001b[35m4.2190\u001b[0m            \u001b[31m0.7537\u001b[0m                     \u001b[94m0.6539\u001b[0m        \u001b[36m1.5870\u001b[0m  0.0100  2.2835\n",
      "      2            \u001b[36m0.7921\u001b[0m                     0.5607        \u001b[35m1.4689\u001b[0m            \u001b[31m0.7785\u001b[0m                     0.5486        1.8141  0.0100  2.2939\n",
      "      3            0.7419                     0.6419        1.6392            0.7390                     0.6215        2.0077  0.0099  2.2375\n",
      "      4            0.7477                     \u001b[32m0.6978\u001b[0m        \u001b[35m1.0989\u001b[0m            0.7521                     \u001b[94m0.6898\u001b[0m        \u001b[36m0.8841\u001b[0m  0.0098  2.2602\n",
      "      5            0.6242                     \u001b[32m0.7063\u001b[0m        \u001b[35m0.8652\u001b[0m            0.6243                     0.6871        \u001b[36m0.8204\u001b[0m  0.0097  2.2300\n",
      "      6            \u001b[36m0.8010\u001b[0m                     0.6989        0.8735            \u001b[31m0.7854\u001b[0m                     0.6616        \u001b[36m0.7349\u001b[0m  0.0095  2.2202\n",
      "      7            0.7671                     0.6887        \u001b[35m0.7557\u001b[0m            0.7576                     0.6446        0.9980  0.0093  2.2739\n",
      "      8            0.7130                     \u001b[32m0.7420\u001b[0m        \u001b[35m0.6897\u001b[0m            0.7018                     \u001b[94m0.7093\u001b[0m        \u001b[36m0.6919\u001b[0m  0.0090  2.1961\n",
      "      9            \u001b[36m0.8122\u001b[0m                     0.7166        0.7088            \u001b[31m0.7940\u001b[0m                     0.6618        0.7123  0.0087  2.2007\n",
      "     10            0.8016                     \u001b[32m0.7428\u001b[0m        \u001b[35m0.6216\u001b[0m            \u001b[31m0.7971\u001b[0m                     \u001b[94m0.7139\u001b[0m        \u001b[36m0.6100\u001b[0m  0.0084  2.2058\n",
      "     11            0.7444                     0.7398        \u001b[35m0.6079\u001b[0m            0.7258                     0.7022        0.6484  0.0080  2.2021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12            0.7934                     0.7131        \u001b[35m0.5754\u001b[0m            0.7862                     0.6822        0.7241  0.0076  2.1981\n",
      "     13            0.7380                     \u001b[32m0.7585\u001b[0m        \u001b[35m0.5710\u001b[0m            0.7149                     0.6989        0.6410  0.0072  2.2011\n",
      "     14            0.7857                     \u001b[32m0.7767\u001b[0m        \u001b[35m0.5494\u001b[0m            0.7676                     \u001b[94m0.7294\u001b[0m        0.6276  0.0068  2.2036\n",
      "     15            \u001b[36m0.8275\u001b[0m                     0.7168        0.5542            \u001b[31m0.8118\u001b[0m                     0.6810        0.6660  0.0064  2.2101\n",
      "     16            0.7281                     0.7763        \u001b[35m0.5425\u001b[0m            0.6956                     0.7122        0.6141  0.0059  2.2051\n",
      "     17            0.7847                     \u001b[32m0.7916\u001b[0m        \u001b[35m0.5151\u001b[0m            0.7568                     \u001b[94m0.7378\u001b[0m        \u001b[36m0.5963\u001b[0m  0.0055  2.2111\n",
      "     18            0.7946                     0.7670        0.5529            0.7645                     0.7141        0.6044  0.0050  2.2099\n",
      "     19            0.8070                     0.7876        \u001b[35m0.5079\u001b[0m            0.7699                     0.7224        0.6080  0.0045  2.2081\n",
      "     20            0.8099                     0.7768        \u001b[35m0.4946\u001b[0m            0.7816                     0.7128        0.6063  0.0041  2.2103\n",
      "     21            0.8093                     \u001b[32m0.8066\u001b[0m        \u001b[35m0.4945\u001b[0m            0.7746                     0.7286        \u001b[36m0.5958\u001b[0m  0.0036  2.2061\n",
      "     22            \u001b[36m0.8295\u001b[0m                     0.7938        \u001b[35m0.4767\u001b[0m            0.7893                     0.7175        0.6036  0.0032  2.2094\n",
      "     23            0.8095                     \u001b[32m0.8071\u001b[0m        \u001b[35m0.4752\u001b[0m            0.7653                     0.7146        \u001b[36m0.5924\u001b[0m  0.0028  2.2116\n",
      "     24            \u001b[36m0.8302\u001b[0m                     0.7947        \u001b[35m0.4738\u001b[0m            0.7916                     0.7189        0.6007  0.0024  2.2300\n",
      "     25            0.8256                     0.7956        \u001b[35m0.4633\u001b[0m            0.7924                     0.7144        0.6101  0.0020  2.2513\n",
      "     26            \u001b[36m0.8316\u001b[0m                     0.8034        \u001b[35m0.4598\u001b[0m            0.7901                     0.7297        \u001b[36m0.5880\u001b[0m  0.0016  2.2345\n",
      "     27            0.7872                     0.8023        \u001b[35m0.4550\u001b[0m            0.7537                     \u001b[94m0.7393\u001b[0m        0.6086  0.0013  2.2300\n",
      "     28            0.8099                     \u001b[32m0.8145\u001b[0m        \u001b[35m0.4499\u001b[0m            0.7699                     \u001b[94m0.7459\u001b[0m        0.5901  0.0010  2.2400\n",
      "     29            \u001b[36m0.8382\u001b[0m                     0.8116        \u001b[35m0.4464\u001b[0m            0.7940                     0.7270        0.6032  0.0007  2.2126\n",
      "     30            0.8180                     \u001b[32m0.8178\u001b[0m        \u001b[35m0.4370\u001b[0m            0.7676                     0.7327        0.5922  0.0005  2.2300\n",
      "     31            0.8236                     \u001b[32m0.8195\u001b[0m        0.4374            0.7754                     0.7291        0.5966  0.0003  2.2350\n",
      "     32            0.8331                     0.8174        0.4385            0.7885                     0.7354        0.6011  0.0002  2.2283\n",
      "     33            0.8213                     0.8169        \u001b[35m0.4335\u001b[0m            0.7738                     0.7348        0.5976  0.0001  2.2663\n",
      "     34            0.8236                     0.8162        0.4367            0.7769                     0.7334        0.5956  0.0000  2.2301\n",
      "     35            0.8217                     0.8188        \u001b[35m0.4287\u001b[0m            0.7730                     0.7327        0.6000  0.0000  2.2699\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.6163\u001b[0m                     \u001b[32m0.6197\u001b[0m        \u001b[35m4.3821\u001b[0m            \u001b[31m0.6057\u001b[0m                     \u001b[94m0.6172\u001b[0m        \u001b[36m1.5908\u001b[0m  0.0100  2.2239\n",
      "      2            0.5709                     0.6109        \u001b[35m1.6635\u001b[0m            0.5670                     0.6070        1.6716  0.0100  2.2171\n",
      "      3            \u001b[36m0.7120\u001b[0m                     0.5927        \u001b[35m1.6504\u001b[0m            \u001b[31m0.7010\u001b[0m                     0.5833        \u001b[36m1.2859\u001b[0m  0.0099  2.2217\n",
      "      4            \u001b[36m0.7657\u001b[0m                     \u001b[32m0.6732\u001b[0m        \u001b[35m0.8968\u001b[0m            \u001b[31m0.7529\u001b[0m                     \u001b[94m0.6735\u001b[0m        \u001b[36m0.8637\u001b[0m  0.0098  2.2201\n",
      "      5            \u001b[36m0.7766\u001b[0m                     0.6580        0.9041            \u001b[31m0.7637\u001b[0m                     0.6467        1.0954  0.0097  2.2201\n",
      "      6            0.7062                     \u001b[32m0.7186\u001b[0m        \u001b[35m0.7167\u001b[0m            0.6855                     \u001b[94m0.7061\u001b[0m        \u001b[36m0.6317\u001b[0m  0.0095  2.2193\n",
      "      7            0.6891                     0.7027        \u001b[35m0.6894\u001b[0m            0.6723                     0.6930        0.6523  0.0093  2.2071\n",
      "      8            \u001b[36m0.7810\u001b[0m                     \u001b[32m0.7244\u001b[0m        0.7081            0.7521                     0.6731        0.6869  0.0090  2.2093\n",
      "      9            0.6120                     0.6888        \u001b[35m0.6712\u001b[0m            0.5856                     0.6635        0.8844  0.0087  2.2081\n",
      "     10            0.7548                     0.7193        \u001b[35m0.6045\u001b[0m            0.7335                     \u001b[94m0.7103\u001b[0m        \u001b[36m0.5699\u001b[0m  0.0084  2.2071\n",
      "     11            0.7415                     \u001b[32m0.7342\u001b[0m        \u001b[35m0.5840\u001b[0m            0.7335                     \u001b[94m0.7471\u001b[0m        \u001b[36m0.5458\u001b[0m  0.0080  2.2124\n",
      "     12            \u001b[36m0.7845\u001b[0m                     \u001b[32m0.7680\u001b[0m        \u001b[35m0.5582\u001b[0m            0.7529                     0.7321        \u001b[36m0.5324\u001b[0m  0.0076  2.2099\n",
      "     13            0.7045                     0.7485        \u001b[35m0.5496\u001b[0m            0.6692                     0.7162        0.5839  0.0072  2.2091\n",
      "     14            0.7696                     0.7643        \u001b[35m0.5402\u001b[0m            0.7266                     0.7077        0.5515  0.0068  2.2091\n",
      "     15            0.7254                     0.7659        0.5476            0.6909                     0.7311        0.5580  0.0064  2.2101\n",
      "     16            0.7550                     0.7484        \u001b[35m0.5262\u001b[0m            0.7196                     0.6951        0.5870  0.0059  2.2191\n",
      "     17            0.7516                     0.7404        \u001b[35m0.5178\u001b[0m            0.7088                     0.6734        0.5985  0.0055  2.2119\n",
      "     18            0.7781                     0.7679        \u001b[35m0.5109\u001b[0m            0.7459                     0.7295        0.5343  0.0050  2.2091\n",
      "     19            \u001b[36m0.8050\u001b[0m                     \u001b[32m0.7738\u001b[0m        \u001b[35m0.5060\u001b[0m            \u001b[31m0.7792\u001b[0m                     0.7248        0.5367  0.0045  2.2101\n",
      "     20            \u001b[36m0.8331\u001b[0m                     \u001b[32m0.7776\u001b[0m        \u001b[35m0.4974\u001b[0m            \u001b[31m0.7955\u001b[0m                     0.7179        0.5409  0.0041  2.2113\n",
      "     21            0.8178                     \u001b[32m0.7980\u001b[0m        \u001b[35m0.4946\u001b[0m            0.7730                     0.7360        \u001b[36m0.5206\u001b[0m  0.0036  2.2121\n",
      "     22            0.7971                     0.7899        \u001b[35m0.4842\u001b[0m            0.7537                     0.7376        0.5228  0.0032  2.2174\n",
      "     23            0.7828                     \u001b[32m0.8034\u001b[0m        \u001b[35m0.4831\u001b[0m            0.7428                     0.7410        0.5244  0.0028  2.2260\n",
      "     24            0.8014                     \u001b[32m0.8097\u001b[0m        \u001b[35m0.4725\u001b[0m            0.7591                     \u001b[94m0.7543\u001b[0m        \u001b[36m0.5047\u001b[0m  0.0024  2.2221\n",
      "     25            0.7998                     0.8088        \u001b[35m0.4601\u001b[0m            0.7545                     0.7414        0.5224  0.0020  2.2168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     26            0.8068                     \u001b[32m0.8118\u001b[0m        0.4634            0.7676                     0.7478        0.5211  0.0016  2.3368\n",
      "     27            0.8196                     \u001b[32m0.8141\u001b[0m        \u001b[35m0.4570\u001b[0m            0.7723                     0.7456        0.5219  0.0013  2.4446\n",
      "     28            0.8107                     0.8070        \u001b[35m0.4551\u001b[0m            0.7614                     0.7423        0.5157  0.0010  2.3474\n",
      "     29            0.8165                     \u001b[32m0.8168\u001b[0m        \u001b[35m0.4491\u001b[0m            0.7769                     \u001b[94m0.7568\u001b[0m        0.5166  0.0007  2.3373\n",
      "     30            0.7868                     0.8159        \u001b[35m0.4407\u001b[0m            0.7452                     \u001b[94m0.7592\u001b[0m        0.5171  0.0005  2.3323\n",
      "     31            0.8095                     \u001b[32m0.8222\u001b[0m        0.4474            0.7607                     0.7552        0.5120  0.0003  2.3254\n",
      "     32            0.8043                     0.8215        \u001b[35m0.4379\u001b[0m            0.7552                     0.7519        0.5150  0.0002  2.3477\n",
      "     33            0.8068                     \u001b[32m0.8252\u001b[0m        \u001b[35m0.4347\u001b[0m            0.7560                     0.7541        0.5159  0.0001  2.3148\n",
      "     34            0.8103                     0.8202        \u001b[35m0.4328\u001b[0m            0.7661                     0.7569        0.5135  0.0000  2.3057\n",
      "     35            0.8062                     0.8210        \u001b[35m0.4322\u001b[0m            0.7583                     0.7538        0.5149  0.0000  2.3027\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.7521\u001b[0m                     \u001b[32m0.6222\u001b[0m        \u001b[35m3.5069\u001b[0m            \u001b[31m0.7490\u001b[0m                     \u001b[94m0.6327\u001b[0m        \u001b[36m1.1973\u001b[0m  0.0100  2.3088\n",
      "      2            0.4740                     0.5727        \u001b[35m1.7477\u001b[0m            0.4531                     0.5660        1.9336  0.0100  2.3108\n",
      "      3            0.6783                     \u001b[32m0.6559\u001b[0m        \u001b[35m1.3404\u001b[0m            0.6600                     \u001b[94m0.6403\u001b[0m        \u001b[36m1.0289\u001b[0m  0.0099  2.3145\n",
      "      4            0.5932                     \u001b[32m0.6919\u001b[0m        \u001b[35m0.9341\u001b[0m            0.5724                     \u001b[94m0.6622\u001b[0m        \u001b[36m0.8088\u001b[0m  0.0098  2.3128\n",
      "      5            0.6484                     \u001b[32m0.7060\u001b[0m        \u001b[35m0.8234\u001b[0m            0.6328                     \u001b[94m0.6856\u001b[0m        0.9645  0.0097  2.3318\n",
      "      6            0.7110                     0.7010        \u001b[35m0.7810\u001b[0m            0.6917                     0.6764        0.9181  0.0095  2.3108\n",
      "      7            \u001b[36m0.8120\u001b[0m                     0.7010        \u001b[35m0.7691\u001b[0m            \u001b[31m0.7963\u001b[0m                     0.6749        \u001b[36m0.7937\u001b[0m  0.0093  2.2929\n",
      "      8            0.7948                     \u001b[32m0.7458\u001b[0m        \u001b[35m0.7019\u001b[0m            0.7761                     \u001b[94m0.7245\u001b[0m        \u001b[36m0.6204\u001b[0m  0.0090  2.2081\n",
      "      9            0.7523                     \u001b[32m0.7492\u001b[0m        \u001b[35m0.6596\u001b[0m            0.7149                     0.6922        0.6424  0.0087  2.2067\n",
      "     10            0.7682                     0.6978        \u001b[35m0.6250\u001b[0m            0.7444                     0.6717        0.7675  0.0084  2.2141\n",
      "     11            0.7777                     \u001b[32m0.7630\u001b[0m        \u001b[35m0.6014\u001b[0m            0.7521                     \u001b[94m0.7266\u001b[0m        \u001b[36m0.5883\u001b[0m  0.0080  2.2101\n",
      "     12            0.7595                     \u001b[32m0.7800\u001b[0m        \u001b[35m0.5756\u001b[0m            0.7227                     \u001b[94m0.7271\u001b[0m        \u001b[36m0.5821\u001b[0m  0.0076  2.2102\n",
      "     13            0.7901                     0.7735        \u001b[35m0.5294\u001b[0m            0.7583                     0.7204        0.6019  0.0072  2.2181\n",
      "     14            0.7547                     0.7326        0.5734            0.7250                     0.6900        0.5973  0.0068  2.2011\n",
      "     15            \u001b[36m0.8186\u001b[0m                     \u001b[32m0.7813\u001b[0m        0.5472            0.7746                     \u001b[94m0.7386\u001b[0m        \u001b[36m0.5579\u001b[0m  0.0064  2.2091\n",
      "     16            0.7599                     0.7756        \u001b[35m0.5084\u001b[0m            0.7126                     0.7243        0.5725  0.0059  2.2081\n",
      "     17            0.7862                     0.7703        0.5201            0.7421                     0.7155        0.5856  0.0055  2.2090\n",
      "     18            0.7764                     \u001b[32m0.7940\u001b[0m        \u001b[35m0.4990\u001b[0m            0.7320                     0.7294        0.5582  0.0050  2.2014\n",
      "     19            0.7194                     0.7827        \u001b[35m0.4963\u001b[0m            0.6700                     0.7033        0.5890  0.0045  2.2111\n",
      "     20            0.7760                     0.7703        \u001b[35m0.4933\u001b[0m            0.7328                     0.7048        0.6173  0.0041  2.2111\n",
      "     21            0.7965                     \u001b[32m0.8068\u001b[0m        \u001b[35m0.4860\u001b[0m            0.7436                     0.7348        0.5793  0.0036  2.2156\n",
      "     22            0.8068                     \u001b[32m0.8097\u001b[0m        \u001b[35m0.4722\u001b[0m            0.7614                     \u001b[94m0.7423\u001b[0m        0.5624  0.0032  2.2111\n",
      "     23            \u001b[36m0.8395\u001b[0m                     0.7928        \u001b[35m0.4595\u001b[0m            \u001b[31m0.7994\u001b[0m                     0.7303        0.5795  0.0028  2.2085\n",
      "     24            0.8329                     0.7846        \u001b[35m0.4595\u001b[0m            0.7823                     0.7233        0.5976  0.0024  2.2211\n",
      "     25            0.8252                     \u001b[32m0.8188\u001b[0m        0.4633            0.7707                     0.7346        0.5673  0.0020  2.2041\n",
      "     26            0.8236                     \u001b[32m0.8237\u001b[0m        \u001b[35m0.4510\u001b[0m            0.7707                     \u001b[94m0.7430\u001b[0m        0.5692  0.0016  2.2119\n",
      "     27            0.8233                     \u001b[32m0.8239\u001b[0m        \u001b[35m0.4388\u001b[0m            0.7676                     0.7344        0.5732  0.0013  2.2181\n",
      "     28            0.8349                     \u001b[32m0.8327\u001b[0m        \u001b[35m0.4280\u001b[0m            0.7777                     0.7372        0.5816  0.0010  2.2122\n",
      "     29            0.8109                     0.8235        0.4304            0.7545                     0.7280        0.5860  0.0007  2.2161\n",
      "     30            \u001b[36m0.8465\u001b[0m                     0.8306        0.4290            0.7947                     0.7392        0.5843  0.0005  2.2151\n",
      "     31            0.8413                     0.8299        0.4365            0.7839                     0.7343        0.5835  0.0003  2.2106\n",
      "     32            0.8407                     \u001b[32m0.8333\u001b[0m        \u001b[35m0.4258\u001b[0m            0.7854                     0.7386        0.5836  0.0002  2.2057\n",
      "     33            0.8370                     \u001b[32m0.8348\u001b[0m        \u001b[35m0.4163\u001b[0m            0.7785                     0.7393        0.5838  0.0001  2.2171\n",
      "     34            0.8366                     0.8321        0.4206            0.7808                     0.7391        0.5847  0.0000  2.2121\n",
      "     35            0.8355                     0.8326        \u001b[35m0.4133\u001b[0m            0.7777                     0.7372        0.5852  0.0000  2.2109\n",
      "Re-initializing optimizer because the following parameters were re-set: lr, weight_decay.\n",
      "  epoch    train_accuracy    train_balanced_accuracy    train_loss    valid_accuracy    valid_balanced_accuracy    valid_loss      lr     dur\n",
      "-------  ----------------  -------------------------  ------------  ----------------  -------------------------  ------------  ------  ------\n",
      "      1            \u001b[36m0.5831\u001b[0m                     \u001b[32m0.6196\u001b[0m        \u001b[35m3.8405\u001b[0m            \u001b[31m0.5747\u001b[0m                     \u001b[94m0.6084\u001b[0m        \u001b[36m1.1949\u001b[0m  0.0100  2.2241\n",
      "      2            \u001b[36m0.7357\u001b[0m                     \u001b[32m0.6436\u001b[0m        \u001b[35m1.6562\u001b[0m            \u001b[31m0.7467\u001b[0m                     \u001b[94m0.6614\u001b[0m        1.8715  0.0100  2.2151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3            \u001b[36m0.7581\u001b[0m                     0.5949        \u001b[35m1.4044\u001b[0m            \u001b[31m0.7514\u001b[0m                     0.5789        \u001b[36m1.1294\u001b[0m  0.0099  2.2151\n",
      "      4            0.7471                     \u001b[32m0.6610\u001b[0m        \u001b[35m1.0595\u001b[0m            0.7459                     0.6526        \u001b[36m1.0676\u001b[0m  0.0098  2.2181\n",
      "      5            0.6585                     \u001b[32m0.6903\u001b[0m        \u001b[35m0.9996\u001b[0m            0.6468                     \u001b[94m0.6674\u001b[0m        \u001b[36m0.8071\u001b[0m  0.0097  2.2201\n",
      "      6            0.7523                     0.6763        \u001b[35m0.7279\u001b[0m            0.7467                     \u001b[94m0.6714\u001b[0m        0.9108  0.0095  2.2180\n",
      "      7            0.6779                     \u001b[32m0.7088\u001b[0m        \u001b[35m0.7250\u001b[0m            0.6731                     \u001b[94m0.6951\u001b[0m        \u001b[36m0.6843\u001b[0m  0.0093  2.2131\n",
      "      8            \u001b[36m0.8068\u001b[0m                     0.6920        0.9317            \u001b[31m0.8079\u001b[0m                     \u001b[94m0.7054\u001b[0m        \u001b[36m0.6488\u001b[0m  0.0090  2.2176\n",
      "      9            0.6686                     \u001b[32m0.7195\u001b[0m        \u001b[35m0.6279\u001b[0m            0.6638                     \u001b[94m0.7112\u001b[0m        \u001b[36m0.6475\u001b[0m  0.0087  2.2184\n",
      "     10            0.7570                     \u001b[32m0.7542\u001b[0m        \u001b[35m0.6155\u001b[0m            0.7583                     \u001b[94m0.7455\u001b[0m        \u001b[36m0.5568\u001b[0m  0.0084  2.2131\n",
      "     11            \u001b[36m0.8116\u001b[0m                     0.7259        \u001b[35m0.5579\u001b[0m            0.7963                     0.7067        0.6424  0.0080  2.2118\n",
      "     12            0.7890                     \u001b[32m0.7598\u001b[0m        0.5872            0.7668                     0.7356        0.5815  0.0076  2.2111\n",
      "     13            0.6752                     0.7135        0.5936            0.6669                     0.6947        0.6594  0.0072  2.2131\n",
      "     14            0.7448                     0.7450        0.5644            0.7289                     0.7091        0.6283  0.0068  2.2096\n",
      "     15            0.7804                     \u001b[32m0.7718\u001b[0m        \u001b[35m0.5551\u001b[0m            0.7599                     0.7380        0.5630  0.0064  2.2091\n",
      "     16            0.7944                     0.7648        \u001b[35m0.5354\u001b[0m            0.7684                     0.7265        0.5699  0.0059  2.2101\n",
      "     17            0.7690                     0.7703        0.5358            0.7614                     \u001b[94m0.7507\u001b[0m        \u001b[36m0.5463\u001b[0m  0.0055  2.2191\n",
      "     18            0.7510                     0.7681        \u001b[35m0.5166\u001b[0m            0.7304                     0.7418        0.5746  0.0050  2.2151\n",
      "     19            0.8112                     0.7709        \u001b[35m0.5112\u001b[0m            0.7792                     0.7264        0.5581  0.0045  2.2121\n",
      "     20            0.7558                     \u001b[32m0.7731\u001b[0m        \u001b[35m0.5062\u001b[0m            0.7343                     0.7291        0.5622  0.0041  2.2180\n",
      "     21            \u001b[36m0.8277\u001b[0m                     \u001b[32m0.7839\u001b[0m        \u001b[35m0.5000\u001b[0m            0.7816                     0.7262        0.5876  0.0036  2.2201\n",
      "     22            0.7882                     0.7711        \u001b[35m0.4936\u001b[0m            0.7545                     0.7230        0.5767  0.0032  2.2201\n",
      "     23            0.8174                     0.7697        \u001b[35m0.4923\u001b[0m            0.7862                     0.7206        0.5991  0.0028  2.2091\n",
      "     24            0.7793                     0.7824        0.5028            0.7452                     0.7207        0.5692  0.0024  2.2191\n",
      "     25            0.7903                     \u001b[32m0.7954\u001b[0m        0.4959            0.7452                     0.7274        0.5624  0.0020  2.2132\n",
      "     26            \u001b[36m0.8295\u001b[0m                     0.7892        \u001b[35m0.4745\u001b[0m            0.7940                     0.7237        0.5621  0.0016  2.2181\n",
      "     27            0.8188                     \u001b[32m0.8099\u001b[0m        \u001b[35m0.4686\u001b[0m            0.7769                     0.7350        0.5470  0.0013  2.2141\n",
      "     28            0.8145                     \u001b[32m0.8115\u001b[0m        0.4720            0.7754                     0.7374        0.5511  0.0010  2.2172\n",
      "     29            0.8064                     0.8040        \u001b[35m0.4632\u001b[0m            0.7637                     0.7287        0.5585  0.0007  2.2111\n",
      "     30            0.8221                     0.8069        \u001b[35m0.4577\u001b[0m            0.7808                     0.7341        0.5663  0.0005  2.2117\n",
      "     31            0.8289                     0.8039        0.4663            0.7885                     0.7371        0.5627  0.0003  2.2241\n",
      "     32            0.8219                     0.8093        \u001b[35m0.4514\u001b[0m            0.7808                     0.7324        0.5641  0.0002  2.2121\n",
      "     33            0.8165                     0.8110        \u001b[35m0.4465\u001b[0m            0.7761                     0.7312        0.5567  0.0001  2.2126\n",
      "     34            0.8190                     0.8113        0.4531            0.7785                     0.7326        0.5586  0.0000  2.2162\n",
      "     35            0.8202                     \u001b[32m0.8132\u001b[0m        \u001b[35m0.4459\u001b[0m            0.7785                     0.7326        0.5601  0.0000  2.2241\n"
     ]
    }
   ],
   "source": [
    "import Training\n",
    "\n",
    "parameters = {\n",
    "    # data\n",
    "    \"data_path\": \"F:/Masterthesis/Data\",\n",
    "    \"task\": \"N170\",\n",
    "    \"preprocessing\": \"heavy\",\n",
    "    \"n_subjects\": 40,\n",
    "    \"reject_incorrect_responses\": True,\n",
    "    # model\n",
    "    \"model\": \"eegnet\",\n",
    "    \"n_classes\": 2,\n",
    "    \"n_chans\": 30,\n",
    "    \"input_window_samples\": 1025,\n",
    "    \"seed\": 42,\n",
    "    # classifier\n",
    "    \"lr\": 0.001,\n",
    "    \"weight_decay\": 0,\n",
    "    \"batch_size\": 64,\n",
    "    \"n_epochs\": 35,\n",
    "    \"n_splits\": 5,\n",
    "    \"model_folder\": \"models_run3\"\n",
    "}\n",
    "\n",
    "\n",
    "for model in [\"eegnet\", \"shallow\", \"deep\"]:\n",
    "    parameters[\"model\"] = model\n",
    "    if model == \"eegnet\":\n",
    "        parameters[\"lr\"] = 0.001\n",
    "    elif model == \"shallow\":\n",
    "        parameters[\"lr\"] = 0.000625\n",
    "    elif model == \"deep\":\n",
    "        parameters[\"lr\"] = 0.01\n",
    "        parameters[\"weight_decay\"] = 0.0005\n",
    "    for preprocessing in [\"light\", \"medium\", \"heavy\"]:\n",
    "        parameters[\"preprocessing\"] = preprocessing\n",
    "        for task in [\"N170\", \"N400\", \"P3\"]:\n",
    "            parameters[\"task\"] = task\n",
    "            parameters[\"task\"] = task\n",
    "            df = load_df(parameters)\n",
    "            data, labels = create_data_labels(df)\n",
    "            Training.run_exp(data, labels, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc741160",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for model in [\"eegnet\", \"shallow\", \"deep\"]:\n",
    "    parameters[\"model\"] = model\n",
    "    for preprocessing in [\"light\", \"medium\", \"heavy\"]:\n",
    "        parameters[\"preprocessing\"] = preprocessing\n",
    "        for task in [\"N170\", \"N400\", \"P3\"]:\n",
    "            parameters[\"task\"] = task\n",
    "            df = Training.load_exp(parameters)\n",
    "            results.append([model,preprocessing,task,df.loc[df.index[-1],\"valid_balanced_accuracy\"].mean()])\n",
    "            #print(model+\", \"+preprocessing+\", \"+task+\": \"+str(df.loc[df.index[-1],\"valid_balanced_accuracy\"].mean()))\n",
    "df_results = pd.DataFrame(results, columns=[\"Model\", \"Preprocessing\", \"Task\", \"Validation Balanced Accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "368c7803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_16720_row0_col1,#T_16720_row1_col1,#T_16720_row2_col1{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_16720_\" ><thead>    <tr>        <th class=\"index_name level0\" >Model</th>        <th class=\"col_heading level0 col0\" >deep</th>        <th class=\"col_heading level0 col1\" >eegnet</th>        <th class=\"col_heading level0 col2\" >shallow</th>    </tr>    <tr>        <th class=\"index_name level0\" >Task</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_16720_level0_row0\" class=\"row_heading level0 row0\" >N170</th>\n",
       "                        <td id=\"T_16720_row0_col0\" class=\"data row0 col0\" >0.770606</td>\n",
       "                        <td id=\"T_16720_row0_col1\" class=\"data row0 col1\" >0.777929</td>\n",
       "                        <td id=\"T_16720_row0_col2\" class=\"data row0 col2\" >0.745493</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_16720_level0_row1\" class=\"row_heading level0 row1\" >N400</th>\n",
       "                        <td id=\"T_16720_row1_col0\" class=\"data row1 col0\" >0.740646</td>\n",
       "                        <td id=\"T_16720_row1_col1\" class=\"data row1 col1\" >0.744435</td>\n",
       "                        <td id=\"T_16720_row1_col2\" class=\"data row1 col2\" >0.726546</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_16720_level0_row2\" class=\"row_heading level0 row2\" >P3</th>\n",
       "                        <td id=\"T_16720_row2_col0\" class=\"data row2 col0\" >0.736983</td>\n",
       "                        <td id=\"T_16720_row2_col1\" class=\"data row2 col1\" >0.738017</td>\n",
       "                        <td id=\"T_16720_row2_col2\" class=\"data row2 col2\" >0.714750</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2ab0baeac40>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results[\"Preprocessing\"]==\"light\"].pivot(\n",
    "    index=\"Task\", \n",
    "    columns=\"Model\", \n",
    "    values=\"Validation Balanced Accuracy\").style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b738f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_31ecc_row0_col1,#T_31ecc_row1_col2,#T_31ecc_row2_col0{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_31ecc_\" ><thead>    <tr>        <th class=\"index_name level0\" >Preprocessing</th>        <th class=\"col_heading level0 col0\" >heavy</th>        <th class=\"col_heading level0 col1\" >light</th>        <th class=\"col_heading level0 col2\" >medium</th>    </tr>    <tr>        <th class=\"index_name level0\" >Task</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_31ecc_level0_row0\" class=\"row_heading level0 row0\" >N170</th>\n",
       "                        <td id=\"T_31ecc_row0_col0\" class=\"data row0 col0\" >0.769151</td>\n",
       "                        <td id=\"T_31ecc_row0_col1\" class=\"data row0 col1\" >0.777929</td>\n",
       "                        <td id=\"T_31ecc_row0_col2\" class=\"data row0 col2\" >0.772696</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_31ecc_level0_row1\" class=\"row_heading level0 row1\" >N400</th>\n",
       "                        <td id=\"T_31ecc_row1_col0\" class=\"data row1 col0\" >0.734077</td>\n",
       "                        <td id=\"T_31ecc_row1_col1\" class=\"data row1 col1\" >0.744435</td>\n",
       "                        <td id=\"T_31ecc_row1_col2\" class=\"data row1 col2\" >0.745359</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_31ecc_level0_row2\" class=\"row_heading level0 row2\" >P3</th>\n",
       "                        <td id=\"T_31ecc_row2_col0\" class=\"data row2 col0\" >0.753519</td>\n",
       "                        <td id=\"T_31ecc_row2_col1\" class=\"data row2 col1\" >0.738017</td>\n",
       "                        <td id=\"T_31ecc_row2_col2\" class=\"data row2 col2\" >0.743926</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2ab0ae7b4c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results[\"Model\"]==\"eegnet\"].pivot(\n",
    "    index=\"Task\", \n",
    "    columns=\"Preprocessing\", \n",
    "    values=\"Validation Balanced Accuracy\").style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d39196f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_8bf7b_row0_col2,#T_8bf7b_row1_col2,#T_8bf7b_row2_col2{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_8bf7b_\" ><thead>    <tr>        <th class=\"index_name level0\" >Preprocessing</th>        <th class=\"col_heading level0 col0\" >heavy</th>        <th class=\"col_heading level0 col1\" >light</th>        <th class=\"col_heading level0 col2\" >medium</th>    </tr>    <tr>        <th class=\"index_name level0\" >Task</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_8bf7b_level0_row0\" class=\"row_heading level0 row0\" >N170</th>\n",
       "                        <td id=\"T_8bf7b_row0_col0\" class=\"data row0 col0\" >0.765149</td>\n",
       "                        <td id=\"T_8bf7b_row0_col1\" class=\"data row0 col1\" >0.770606</td>\n",
       "                        <td id=\"T_8bf7b_row0_col2\" class=\"data row0 col2\" >0.774588</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8bf7b_level0_row1\" class=\"row_heading level0 row1\" >N400</th>\n",
       "                        <td id=\"T_8bf7b_row1_col0\" class=\"data row1 col0\" >0.722008</td>\n",
       "                        <td id=\"T_8bf7b_row1_col1\" class=\"data row1 col1\" >0.740646</td>\n",
       "                        <td id=\"T_8bf7b_row1_col2\" class=\"data row1 col2\" >0.746593</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8bf7b_level0_row2\" class=\"row_heading level0 row2\" >P3</th>\n",
       "                        <td id=\"T_8bf7b_row2_col0\" class=\"data row2 col0\" >0.742308</td>\n",
       "                        <td id=\"T_8bf7b_row2_col1\" class=\"data row2 col1\" >0.736983</td>\n",
       "                        <td id=\"T_8bf7b_row2_col2\" class=\"data row2 col2\" >0.744185</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2ab0bc3e730>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results[\"Model\"]==\"deep\"].pivot(\n",
    "    index=\"Task\", \n",
    "    columns=\"Preprocessing\", \n",
    "    values=\"Validation Balanced Accuracy\").style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de11d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_12165_row0_col1,#T_12165_row1_col1,#T_12165_row2_col2{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_12165_\" ><thead>    <tr>        <th class=\"index_name level0\" >Preprocessing</th>        <th class=\"col_heading level0 col0\" >heavy</th>        <th class=\"col_heading level0 col1\" >light</th>        <th class=\"col_heading level0 col2\" >medium</th>    </tr>    <tr>        <th class=\"index_name level0\" >Task</th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>        <th class=\"blank\" ></th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_12165_level0_row0\" class=\"row_heading level0 row0\" >N170</th>\n",
       "                        <td id=\"T_12165_row0_col0\" class=\"data row0 col0\" >0.736216</td>\n",
       "                        <td id=\"T_12165_row0_col1\" class=\"data row0 col1\" >0.745493</td>\n",
       "                        <td id=\"T_12165_row0_col2\" class=\"data row0 col2\" >0.741383</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_12165_level0_row1\" class=\"row_heading level0 row1\" >N400</th>\n",
       "                        <td id=\"T_12165_row1_col0\" class=\"data row1 col0\" >0.693768</td>\n",
       "                        <td id=\"T_12165_row1_col1\" class=\"data row1 col1\" >0.726546</td>\n",
       "                        <td id=\"T_12165_row1_col2\" class=\"data row1 col2\" >0.725070</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_12165_level0_row2\" class=\"row_heading level0 row2\" >P3</th>\n",
       "                        <td id=\"T_12165_row2_col0\" class=\"data row2 col0\" >0.712448</td>\n",
       "                        <td id=\"T_12165_row2_col1\" class=\"data row2 col1\" >0.714750</td>\n",
       "                        <td id=\"T_12165_row2_col2\" class=\"data row2 col2\" >0.718637</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x2ab0ae7bdc0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results[df_results[\"Model\"]==\"shallow\"].pivot(\n",
    "    index=\"Task\", \n",
    "    columns=\"Preprocessing\", \n",
    "    values=\"Validation Balanced Accuracy\").style.highlight_max(color = 'lightgreen', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8b143b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb44da2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6dd347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f8810e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Data file name in EEG.data (sub-001_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Expected to find a single channels file associated with sub-001_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-001\\**\\sub-001_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Participants file not found for sub-001_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    }
   ],
   "source": [
    "parameters[\"preprocessing\"] = \"light\"\n",
    "raw = load_raw(parameters, \"001\")\n",
    "epoch_light = epoch_raw(parameters, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0e0d2135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Data file name in EEG.data (sub-001_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Expected to find a single channels file associated with sub-001_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-001\\**\\sub-001_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Participants file not found for sub-001_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n"
     ]
    }
   ],
   "source": [
    "parameters[\"preprocessing\"] = \"medium\"\n",
    "raw = load_raw(parameters, \"001\")\n",
    "epoch_medium = epoch_raw(parameters, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c40fa638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Data file name in EEG.data (sub-001_task-N170_eeg.fdt) is incorrect, the file name must have changed on disk, using the correct file name (sub-001_ses-N170_task-N170_eeg.fdt).\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Expected to find a single channels file associated with sub-001_ses-N170_task-N170, but found 2: \"['F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_badChannels.tsv', 'F:\\\\Masterthesis\\\\Data\\\\N170\\\\sub-001\\\\ses-N170\\\\eeg\\\\sub-001_ses-N170_task-N170_channels.tsv']\".\n",
      "\n",
      "The search_str was \"F:\\Masterthesis\\Data\\N170\\sub-001\\**\\sub-001_ses-N170*channels.tsv\"\n",
      "  raw = read_raw_bids(bids_path)\n",
      "<ipython-input-59-03cda6a932f4>:7: RuntimeWarning: Participants file not found for sub-001_ses-N170_task-N170_eeg.set... Not reading in any particpants.tsv data.\n",
      "  raw = read_raw_bids(bids_path)\n",
      "\n",
      "Creating augmented epochs:   0%|                                                                | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Creating augmented epochs:  30%|████████████████▊                                       | 9/30 [00:00<00:00, 86.77it/s]\u001b[A\n",
      "Creating augmented epochs:  60%|█████████████████████████████████                      | 18/30 [00:00<00:00, 85.80it/s]\u001b[A\n",
      "Creating augmented epochs: 100%|███████████████████████████████████████████████████████| 30/30 [00:00<00:00, 85.46it/s]\u001b[A\n",
      "\n",
      "Computing thresholds ...:   0%|                                                                 | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "Computing thresholds ...:   3%|█▉                                                       | 1/30 [00:00<00:25,  1.14it/s]\u001b[A\n",
      "Computing thresholds ...:   7%|███▊                                                     | 2/30 [00:01<00:23,  1.17it/s]\u001b[A\n",
      "Computing thresholds ...:  10%|█████▋                                                   | 3/30 [00:02<00:23,  1.16it/s]\u001b[A\n",
      "Computing thresholds ...:  13%|███████▌                                                 | 4/30 [00:03<00:22,  1.17it/s]\u001b[A\n",
      "Computing thresholds ...:  17%|█████████▌                                               | 5/30 [00:04<00:20,  1.19it/s]\u001b[A\n",
      "Computing thresholds ...:  20%|███████████▍                                             | 6/30 [00:05<00:19,  1.23it/s]\u001b[A\n",
      "Computing thresholds ...:  23%|█████████████▎                                           | 7/30 [00:05<00:18,  1.24it/s]\u001b[A\n",
      "Computing thresholds ...:  27%|███████████████▏                                         | 8/30 [00:06<00:17,  1.26it/s]\u001b[A\n",
      "Computing thresholds ...:  30%|█████████████████                                        | 9/30 [00:07<00:16,  1.28it/s]\u001b[A\n",
      "Computing thresholds ...:  33%|██████████████████▋                                     | 10/30 [00:08<00:15,  1.32it/s]\u001b[A\n",
      "Computing thresholds ...:  37%|████████████████████▌                                   | 11/30 [00:08<00:14,  1.30it/s]\u001b[A\n",
      "Computing thresholds ...:  40%|██████████████████████▍                                 | 12/30 [00:09<00:14,  1.25it/s]\u001b[A\n",
      "Computing thresholds ...:  43%|████████████████████████▎                               | 13/30 [00:10<00:13,  1.24it/s]\u001b[A\n",
      "Computing thresholds ...:  47%|██████████████████████████▏                             | 14/30 [00:11<00:13,  1.23it/s]\u001b[A\n",
      "Computing thresholds ...:  50%|████████████████████████████                            | 15/30 [00:12<00:12,  1.22it/s]\u001b[A\n",
      "Computing thresholds ...:  53%|█████████████████████████████▊                          | 16/30 [00:13<00:11,  1.22it/s]\u001b[A\n",
      "Computing thresholds ...:  57%|███████████████████████████████▋                        | 17/30 [00:13<00:11,  1.18it/s]\u001b[A\n",
      "Computing thresholds ...:  60%|█████████████████████████████████▌                      | 18/30 [00:14<00:10,  1.16it/s]\u001b[A\n",
      "Computing thresholds ...:  63%|███████████████████████████████████▍                    | 19/30 [00:15<00:09,  1.16it/s]\u001b[A\n",
      "Computing thresholds ...:  67%|█████████████████████████████████████▎                  | 20/30 [00:16<00:08,  1.15it/s]\u001b[A\n",
      "Computing thresholds ...:  70%|███████████████████████████████████████▏                | 21/30 [00:17<00:07,  1.16it/s]\u001b[A\n",
      "Computing thresholds ...:  73%|█████████████████████████████████████████               | 22/30 [00:18<00:06,  1.19it/s]\u001b[A\n",
      "Computing thresholds ...:  77%|██████████████████████████████████████████▉             | 23/30 [00:19<00:05,  1.17it/s]\u001b[A\n",
      "Computing thresholds ...:  80%|████████████████████████████████████████████▊           | 24/30 [00:19<00:05,  1.16it/s]\u001b[A\n",
      "Computing thresholds ...:  83%|██████████████████████████████████████████████▋         | 25/30 [00:20<00:04,  1.21it/s]\u001b[A\n",
      "Computing thresholds ...:  87%|████████████████████████████████████████████████▌       | 26/30 [00:21<00:03,  1.22it/s]\u001b[A\n",
      "Computing thresholds ...:  90%|██████████████████████████████████████████████████▍     | 27/30 [00:22<00:02,  1.22it/s]\u001b[A\n",
      "Computing thresholds ...:  93%|████████████████████████████████████████████████████▎   | 28/30 [00:23<00:01,  1.27it/s]\u001b[A\n",
      "Computing thresholds ...:  97%|██████████████████████████████████████████████████████▏ | 29/30 [00:23<00:00,  1.23it/s]\u001b[A\n",
      "Computing thresholds ...: 100%|████████████████████████████████████████████████████████| 30/30 [00:24<00:00,  1.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 692.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "n_interp:   0%|                                                                                  | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|███████████▍                                                  | 21/114 [00:00<00:00, 202.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  37%|██████████████████████▊                                       | 42/114 [00:00<00:00, 193.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  54%|█████████████████████████████████▋                            | 62/114 [00:00<00:00, 193.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  72%|████████████████████████████████████████████▌                 | 82/114 [00:00<00:00, 184.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 184.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  10%|███████▋                                                                     | 1/10 [00:00<00:02,  3.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:02,  3.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:01,  3.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:01<00:01,  3.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  50%|██████████████████████████████████████▌                                      | 5/10 [00:01<00:01,  3.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:01<00:01,  3.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  70%|█████████████████████████████████████████████████████▉                       | 7/10 [00:01<00:00,  3.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:02<00:00,  3.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  90%|█████████████████████████████████████████████████████████████████████▎       | 9/10 [00:02<00:00,  4.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  3.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  33%|████████████████████████▋                                                 | 1/3 [00:03<00:06,  3.24s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  17%|██████████▎                                                   | 19/114 [00:00<00:00, 188.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  33%|████████████████████▋                                         | 38/114 [00:00<00:00, 188.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  51%|███████████████████████████████▌                              | 58/114 [00:00<00:00, 188.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  68%|█████████████████████████████████████████▉                    | 77/114 [00:00<00:00, 179.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  83%|███████████████████████████████████████████████████▋          | 95/114 [00:00<00:00, 171.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 175.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  10%|███████▋                                                                     | 1/10 [00:00<00:02,  3.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  20%|███████████████▍                                                             | 2/10 [00:00<00:01,  4.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  30%|███████████████████████                                                      | 3/10 [00:00<00:01,  4.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:01,  4.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  50%|██████████████████████████████████████▌                                      | 5/10 [00:01<00:01,  4.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  60%|██████████████████████████████████████████████▏                              | 6/10 [00:01<00:00,  4.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  70%|█████████████████████████████████████████████████████▉                       | 7/10 [00:01<00:00,  4.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  80%|█████████████████████████████████████████████████████████████▌               | 8/10 [00:01<00:00,  4.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  90%|█████████████████████████████████████████████████████████████████████▎       | 9/10 [00:02<00:00,  4.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:02<00:00,  4.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp:  67%|█████████████████████████████████████████████████▎                        | 2/3 [00:06<00:03,  3.20s/it]\u001b[A\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|██████████▉                                                   | 20/114 [00:00<00:00, 189.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  34%|█████████████████████▏                                        | 39/114 [00:00<00:00, 172.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  50%|███████████████████████████████                               | 57/114 [00:00<00:00, 166.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  65%|████████████████████████████████████████▏                     | 74/114 [00:00<00:00, 147.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  79%|████████████████████████████████████████████████▉             | 90/114 [00:00<00:00, 151.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 160.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Fold:   0%|                                                                                     | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold:  40%|██████████████████████████████▊                                              | 4/10 [00:00<00:00, 34.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Fold: 100%|████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 34.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "n_interp: 100%|██████████████████████████████████████████████████████████████████████████| 3/3 [00:07<00:00,  2.48s/it]\u001b[A\n",
      "\n",
      "\n",
      "Repairing epochs:   0%|                                                                        | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  18%|██████████▉                                                   | 20/114 [00:00<00:00, 198.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  35%|█████████████████████▊                                        | 40/114 [00:00<00:00, 192.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  53%|████████████████████████████████▋                             | 60/114 [00:00<00:00, 193.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs:  70%|███████████████████████████████████████████▌                  | 80/114 [00:00<00:00, 184.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Repairing epochs: 100%|█████████████████████████████████████████████████████████████| 114/114 [00:00<00:00, 185.86it/s]\u001b[A\u001b[A\n"
     ]
    }
   ],
   "source": [
    "parameters[\"preprocessing\"] = \"heavy\"\n",
    "raw = load_raw(parameters, \"001\")\n",
    "epoch_heavy = epoch_raw(parameters, raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca85a50e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
